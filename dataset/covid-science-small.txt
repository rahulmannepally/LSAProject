COVIDGR Dataset and COVID-SDNet
Methodology for Predicting COVID-19
Based on Chest X-Ray Images
S. Tabik , A. Gómez-Ríos, J. L. Martín-Rodríguez, I. Sevillano-García, M. Rey-Area, D. Charte,
E. Guirado, J. L. Suárez, J. Luengo, M. A. Valero-González, P. García-Villanova,
E. Olmedo-Sánchez, and F. Herrera
Abstract—Currently, Coronavirus disease (COVID-19),
one of the most infectious diseases in the 21st century, is diagnosed using RT-PCR testing, CT scans and/or
Chest X-Ray (CXR) images. CT (Computed Tomography)
scanners and RT-PCR testing are not available in most
medical centers and hence in many cases CXR images
become the most time/cost effective tool for assisting clinicians in making decisions. Deep learning neural networks
have a great potential for building COVID-19 triage systems
and detecting COVID-19 patients, especially patients with
low severity. Unfortunately, current databases do not allow
building such systems as they are highly heterogeneous
and biased towards severe cases. This article is threefold: (i) we demystify the high sensitivities achieved by
most recent COVID-19 classification models, (ii) under a
close collaboration with Hospital Universitario Clínico San
Cecilio, Granada, Spain, we built COVIDGR-1.0, a homogeneous and balanced database that includes all levels
Manuscript received September 25, 2020; revised October 27, 2020;
accepted November 3, 2020. Date of publication November 10, 2020;
date of current version December 4, 2020. This work was supported by
the project DeepSCOP-Ayudas Fundación BBVA a Equipos de Investigación Científica en Big Data 2018, COVID19_RX-Ayudas Fundación
BBVA a Equipos de Investigación Científica SARS-CoV-2 y COVID-19
2020, and the Spanish Ministry of Science and Technology under the
project TIN2017-89517-P. S. Tabik was supported by the Ramon y Cajal
Programme (RYC-2015-18136). A. Gómez-Ríos was supported by the
FPU Programme FPU16/04765. D. Charte was supported by the FPU
Programme FPU17/04069. J. Suárez was supported by the FPU Programme FPU18/05989. E.G was supported by the European Research
Council (ERC Grant agreement 647038 [BIODESERT]). This project
is approved by the Provincial Research Ethics Committee of Granada.
(Corresponding author: Siham Tabik.)
S. Tabik, A. Gómez-Ríos, I. Sevillano-García, D. Charte, J. L. Suárez,
J. Luengo, and F. Herrera are with Andalusian Research Institute in
Data Science, and Computational Intelligence, University of Granada,
18071 Granada, Spain (e-mail: siham@ugr.es; anabelgrios@decsai.
ugr.es; isega24ivan@gmail.com; fdavidcl@ugr.es; jlsuarezdiaz@ugr.es;
julianlm@decsai.ugr.es; herrera@decsai.ugr.es).
J. L. Martín-Rodríguez, M. A. Valero-González, P. García-Villanova,
and E. Olmedo-Sánchez are with Hospital Universitario Clínico
San Cecilio de Granada, 36310 Spain (e-mail: joseluismartin.rx@
hotmail.com; valerogonzalez@yahoo.es; pgvillanova@gmail.com;
euolm@yahoo.es).
M. Rey-Area is with atlanTTic Research Center for Telecommunication Technologies, University of Vigo, Galicia, Spain (e-mail:
mreyarea@gmail.com).
E. Guirado is with the Multidisciplinary Institute for Environment
Studies Ramón Margalef, University of Alicante, 03690, Spain (e-mail:
geesecillo@gmail.com).
Digital Object Identifier 10.1109/JBHI.2020.3037127
of severity, from normal with Positive RT-PCR, Mild, Moderate to Severe. COVIDGR-1.0 contains 426 positive and
426 negative PA (PosteroAnterior) CXR views and (iii) we
propose COVID Smart Data based Network (COVID-SDNet)
methodology for improving the generalization capacity of
COVID-classification models. Our approach reaches good
and stable results with an accuracy of 97.72% ± 0.95%,
86.90% ± 3.20%, 61.80% ± 5.49% in severe, moderate and
mild COVID-19 severity levels. Our approach could help in
the early detection of COVID-19. COVIDGR-1.0 along with
the severity level labels are available to the scientific community through this link https://dasci.es/es/transferencia/
open-data/covidgr/.
Index Terms—COVID-19, convolutional neural networks,
smart data.
I. INTRODUCTION
I
N THE last months, the world has been witnessing how
COVID-19 pandemic is increasingly infecting a large mass
of people very fast everywhere in the world. The trends are
not clear yet but some research confirm that this problem may
persist until 2024 [1]. Besides, prevalence studies conducted in
several countries reveal that a tiny proportion of the population
have developed antibodies after exposure to the virus, e.g., 5%
in Spain.1 This means that frequently a large number of patients
will need to be assessed in small time intervals by few number
of clinicians and with very few resources.
In general, COVID-19 diagnosis is carried out using at least
one of these three tests.  Computed Tomography (CT) scans-based assessment: it
consists in analyzing 3D radiographic images from different angles. The needed equipment for this assessment
is not available in most hospitals and it takes more than
15 minutes per patient in addition to the time required for
CT decontamination.2
 Reverse Transcription Polymerase Chain Reaction (RTPCR) test: it detects the viral RNA from sputum or
1[Online]. Available: https://english.elpais.com/society/2020-05-14/
antibody-study-shows-just-5-of-spaniards-have-contracted-the-coronavirus.
html 2[Online]. Available: //www.acr.org/Advocacy-and-Economics/ACRPosition-Statements/Recommendations-for-Chest-Radiography-and-CT-forSuspected-COVID19-Infection
© IEEE 2020. This article is free to access and download, along with rights for full text and data mining, re-use and analysis.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3596 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 1. The stratification of radiological severity of COVID-19. Examples of how RALE index is calculated.
nasopharyngeal swab [2]. It requires specific material and
equipment, which are not easily accessible and it takes at
least 12 hours, which is not desirable as positive COVID19 patients should be identified and tracked as soon as possible. Some studies found that RT-PCR results from several
tests at different points from the same patients were variable during the course of the illness producing a high falsenegative rate [3]. The authors suggested that RT-PCR test
should be combined with other clinical tests such as CT.
 Chest X-Ray (CXR): The required equipment for this
assessment are less cumbersome and can be lightweight
and transportable. In general, this type of resources is more
available than the required for RT-PCR and CT-scan tests.
In addition, CXR test takes about 15 seconds per patient
[2], which makes CXR one of the most time/cost effective
assessment tools.
Few recent studies provide estimates on expert radiologists
sensitivity in the diagnosis of COVID-19 based on CT scans,
RT-PCR and CXR. A study on a set of 51 patients with chest
CT and RT-PCR essay performed within 3 days, reported a
sensitivity in CT of 98% compared with RT-PCR sensitivity
of 71% [4]. A different study on 64 patients (26 men, mean age
56 ± 19 years) reported a sensitivity of 69% for CXR compared
with 91% for initial RT-PCR [2]. According to an analysis of 636
ambulatory patients [5], most patients presenting to urgent care
centers with confirmed coronavirus disease 2019 have normal or
mildly abnormal findings on CXR. Only 58.3% of these patients
are correctly diagnosed by the expert eye.
In a recent study [2], authors proposed simplifying the quantification of the level of severity by adapting a previously defined
Radiographic Assessment of Lung Edema (RALE) score [6] to
COVID-19. This new score is calculated by assigning a value
between 0-4 to each lung depending on the extent of visual
features such as, consolidation and ground glass opacities, in the
four parts of each lung as depicted in Fig. 1. Based on this score,
experts can identify the level of severity of the infection among
four severity stages, Normal 0, Mild 1-2, Moderate 3-5 and
Severe 6-8. In practice, a patient classified by expert radiologist
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3597
as Normal can have positive RT-PCR. We refer to these cases as
Normal-PCR+. Expert annotation adopted in this work is based
in this score.
Automated image analysis via Deep learning (DL) models
have a great potential to optimize the role of CXR images
for a fast diagnosis of COVID-19. A robust and accurate DL
model could serve as a triage method and as a support for
medical decision making. An increasing number of recent works
claim achieving impressive sensitivities > 95%, far higher than
expert radiologists. These high sensitivities are due to the bias
in the most used COVID-19 dataset, COVID-19 Image Data
Collection [7]. This dataset includes a very small number of
COVID-19 positive cases, coming from highly heterogeneous
sources (at least 15 countries) and most cases are severe patients,
an issue that drastically reduces its clinical value. To populate
Non-COVID and Healthy classes, AI researchers are using
CXR images from diverse pulmonary disease repositories. The
obtained models will have no clinical value as well since they
will be unable to detect patients with low and moderate severity,
which are the target of a clinical triage system. In view of this
situation, there is still a huge need for higher quality datasets built
under the same clinical protocol and under a close collaboration
with expert radiologists.
Multiple studies have proven that higher quality data ensures
higher quality models. The concept of Smart Data refers to
the process of converting raw data into higher quality data
with higher concentration of useful information [8]. Smart data
includes all pre-processing methods that improve value and
veracity of data. Examples of these methods include noise
elimination, data-augmentation [9] and data transformation [10]
among other techniques.
In this work, we designed a high clinical quality dataset,
named COVIDGR-1.0 that includes four levels of severity,
Normal-PCR+, Mild, Moderate and Severe. We identified these
four severity levels from a recent COVID-19 radiological study
[2]. We also propose COVID Smart Data based Network
(COVID-SDNet) methodology. It combines segmentation, dataaugmentation and data transformations together with an appropriate Convolutional Neural Network (CNN) for inference.
The contributions of this paper can be summarized as follows:
 We analyze reliability, potential and limitations of the most
used COVID-19 CXR datasets and models.
 From a data perspective, we provide the first public dataset,
called COVIDGR-1.0, that quantifies COVID-19 in terms
of severity levels, normal, mild, moderate and severe,
with the aim of building triage systems with high clinical
value.
 From a pre-processing perspective, we combined several
methods. To eliminate irrelevant information from the
input CXR images, we used a new pre-processing method
called segmentation-based cropping. To increase discrimination capacity of the classification model, we used a
class-inherent transformation method inspired by GANs.
 From a post-processing perspective, we proposed a new
inference process that fuses the predictions of the four
transformed classes obtained by the class-inherent transformation method to calculate the final prediction.
 From a global perspective, we designed a novel methodology, named COVID-SDNet, with a high generalization capacity for COVID-19 classification based on CXR
images. COVID-SDNet combines segmentation, datatransformation, data-augmentation, and a suitable CNN
model together with an inference approach to get the final
prediction.
Experiments demonstrate that our approach reaches good and
stable results especially in moderate and severe levels, with
97.72% ± 0.95% and 86.90% ± 3.20% respectively. Lower accuracies were obtained in mild and normal-PCR+ severity levels
with 61.80% ± 5.49% and 28.42% ± 2.58%, respectively.
This article is organized as follows: A review of the most used
datasets and COVID-19 classification approaches is provided in
Section II. Section III describes how COVIDGR-1.0 is built and
organized. Our approach is presented in Section IV. Experiments, comparisons and results are provided in Section V. The
inspection of the model’s decision using heatmaps is provided
in Section VI and the conclusions are pointed out in Section VII.
II. RELATED WORKS
The last months have known an increasing number of works
exploring the potential of deep learning models for automating
COVID-19 diagnosis based on CXR images. The results are
promising but still too much work needs to be done at the level
of data and models design. Given the potential bias in this type
of problems, several studies include explication methods to their
models. This section analyzes the advantages and limitations of
current datasets an models for building automatic COVID-19
diagnosis systems with and without decision explication.
A. Datasets
There does not exist yet a high quality collection of CXR
images for building COVID-19 diagnosis systems of high clinical value. Currently, the main source for COVID-19 class is
COVID-19 Image Data Collection [7]. It contains 76 positive and
26 negative PA views. These images were obtained from highly
heterogeneous equipment from all around the world. Another
example of COVID-19 dataset is Figure-1-COVID-19 Chest
X-ray Dataset Initiative [11]. To build Non-COVID classes, most
studies are using CXR from one or multiple public pulmonary
disease data-sets. Examples of these repositories are:  RSNA Pneumonia CXR challenge dataset on Kaggle [12].
 ChestX-ray8 dataset [13].
 MIMIC-CXR dataset [14].
 PadChest dataset [15].
For instance, COVIDx 1.0 [16] was built by combining three
public datasets: (i) COVID-19 Image Data Collection [7], (ii)
Figure-1-COVID-19 Chest X-ray Dataset Initiative [11] and (iii)
RSNA Pneumonia Detection Challenge dataset [12]. COVIDx
2.0 was built by re-organizing COVIDx 1.0 into three classes,
Normal (healthy), Pneumonia and COVID-19, using 201 CXR
images for COVID class, including PA(PosteroAnterior) and
AP(AnteroPosterior) views (seeTable I). Notice that for a correct
learning front view (PA) and back view (AP) cannot be mixed
in the same class.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3598 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE I
A BRIEF DESCRIPTION OF COVIDX DATASET [7] (ONLY PA VIEWS ARE
COUNTED)
Although the value of these datasets is unquestionable as they
are being useful for carrying out first studies and reformulations,
they do not guarantee useful triage systems for the next reasons.
It is not clear what annotation protocol has been followed
for constructing the positive class in COVID-19 Image Data
Collection. The included data is highly heterogeneous and hence
DL-models can rely on other aspects than COVID visual features
to differentiate between the involved classes. This dataset does
not provide a representative spectrum of COVID-19 severity
levels, most positive cases are of severe patients [17]. In addition,
an interesting critical analysis of these datasets has shown that
CNN models obtain similar results with and without eliminating
most of the lungs in the input X-Ray images [18], which confirms
again that there is a huge need of COVID-19 datasets with high
clinical value.
Our claim is that the design of a high quality dataset must
be done under a close collaboration between expert radiologists
and AI experts. The annotations must follow the same protocol
and representative numbers of all levels of severity, especially
Mild and Moderate levels, must be included.
B. DL Classification Models
Existing related works are not directly comparable as they
consider different combinations of public data-sets and different
experimental setup. A brief summary of these works is provided
in Table II.
The most related studies to ours as they proposed different
models to the typical ones are [16] and [19]. In [16], the authors
designed a deep network, called COVIDNet. They affirmed
that COVIDNet reaches an overall accuracy of 92.6%, with
97.0% sensitivity in Normal class, 90.0% in Non-COVID-19
and 87.1% in COVID-19. The authors of a smaller network,
called COVID-CAPS [19], also claim that their model achieved
an accuracy of 98.7%, sensitivity of 90%, and specificity of
95.8%. These results look too impressive when compared to
expert radiologist sensitivity, 69%. This can be explained by the
fact that the used dataset is biased to severe COVID cases [17].
In addition, the performed experiments in both cited works are
not statistically reliable as they were evaluated on one single
partition. The stability of these models, in terms of standard
deviation, has not been reported.
C. DL Classification Models With Explanation
Approaches
Several interesting explanations were proposed to help inspect the predictions of DL-models [21], [22] although all their
classification models were trained and validated on variations
of COVIDx. The authors in [21] first use an ensemble of two
CNN networks to predict the class of the input image, as Normal,
Pneumonia or COVID. Then highlight class-discriminating regions in the input CXR image using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation
(LRP). In [22], the authors proposed explaining the decision of
the classification model to radiologists using different saliency
map types together with uncertainty estimations (i.e., how certain is the model in the prediction).
III. COVIDGR-1.0: DATA ACQUISITION,
ANNOTATION AND ORGANIZATION
Instead of starting with an extremely large and noisy dataset,
one can build a small and smart dataset then augment it in a way
it increases the performance of the model. This approach has
proven effective in multiple studies. This is particularly true in
the medical field, where access to data is heavily protected due
to privacy concerns and costly expert annotation.
Under a close collaboration with four highly trained radiologists from Hospital Universitario Clínico San Cecilio, Granada,
Spain, we first established a protocol on how CXR images are
selected and annotated to be included in the dataset. A CXR
image is annotated as COVID-19 positive if both RT-PCR test
and expert radiologist confirm that decision within less than 24
hours. CXR with positive PCR that were annotated by expert
radiologists as Normal are labeled as Normal-PCR+. The involved radiologists annotated the level of severity of positive
cases based on RALE score as: Normal-PCR+, Mild, Moderate
and Severe.
COVIDGR-1.0 is organized into two classes, positive and
negative. It contains 852 images distributed into 426 positive and
426 negative cases, more details are provided in Table III. All
the images were obtained from the same equipment and under
the same X-ray regime. Only PosteriorAnterior (PA) view is
considered. COVIDGR-1.0 along with the severity level labels
are available to the scientific community through this link:
https://dasci.es/es/transferencia/open-data/covidgr/.
IV. COVID-SDNET METHODOLOGY
In this section, we describe COVID-SDNet methodology in
detail, covering pre-processing to produce smart data, including
segmentation and data transformation for increasing discrimination between positive and negative classes, combined with a
deep CNN for classification.
One of the pieces of COVID-SDNet is the CNN-based classifier. We have selected Resnet-50 initialized with ImageNet
weights for a transfer learning approach. To adapt this CNN to
our problem, we have removed the last layer of the net and added
a 512 neurons layer with ReLU activation and a two or four
neurons layer (according to the considered number of classes)
with softmax activation.
Let X be the set of n images and K the total number of classes.
Each image xi ∈ X has a true label yi with i = 1, 2,...,n.
The softmax function computes the probability that an image
belongs to class k with k = 1,...,K. Let w = (w1,...,wK)
be the output of the last fully connected layer before the softmax activation is applied. Then, this function is defined as:
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3599
TABLE II
SUMMARY OF RELATED WORKS THAT ANALYZE VARIATIONS OF COVIDX WITH CNN
TABLE III
A BRIEF SUMMARY OF COVIDGR-1.0 DATASET. ALL SAMPLES IN COVIDGR 1.0 ARE SEGMENTED CXR IMAGES CONSIDERING ONLY PA VIEW
softmax : RK → [0, 1]K,
softmax(w)j = exp(wj )
K
k=1 exp(wk) .
Let yi be the class prediction of the network for the image xi,
then yi = argmax(softmax(w)), where w is the output vector
of the last layer before softmax is applied for the input xi.
All the layers of the network were fine-tuned. We used a batch
size of 16 and SGD as optimizer.
The main stages of COVID-SDNet are three, two associated
to pre-processing for producing quality data (smart data stages)
and the learning and inference process. A flowchart of COVIDSDNet is depicted in Fig. 2.
1) Segmentation-Based Cropping: Unnecessary Information
Elimination: Different CXR equipment brands include different
extra information about the patient in the sides and contour of
CXR images. The position and size of the patient may also imply
the inclusion of more parts of the body, e.g., arms, neck, stomach.
As this information may alter the learning of the classification
model, first, we segment the lungs using the U-Net segmentation
model provided in [24], pre-trained on Tuberculosis Chest X-ray
Image datasets [25] and RSNA Pneumonia CXR challenge
dataset [12]. Then, we calculate the smallest rectangle that
delimits the left and right segmented-lungs. Finally, to avoid
eliminating useful information, we add 2.5% of pixels to the left,
right, up and down sides of the rectangle. The resulting rectangle
is cropped. An illustration with example of this pre-processing
is shown in Fig. 3.
2) Class-Inherent Transformations Network: To increase the
discrimination capacity of the classification model, we used,
FuCiTNet [10], a Class-inherent transformations (CiT) Network
inspired by GANs (Generative Adversarial Networks). This
transformation method is actually an array of two generators
GP and GN, where P refers to the positive class and N refers to
the negative class. GP learns the inherent-class transformations
of the positive class P and GN learns the inherent-class transformations of the negative class N. In other words, GP learns the
transformations that bring an input image from its own k domain,
with k ∈ {P, N}, to the P class domain. Similarly, GN learns
the transformations that bring the input image from its k space,
with k ∈ {P, N}, to the N class space. The classification loss is
introduced in the generators to drive the learning of each specific
k-class transformations. That is, each generator is optimized
based on the following loss function:
Lgenk = lMSE + 0.006 · lPerceptual + λ · lCE(y == k) (1)
Where lMSE is a pixel-wise Mean Square Error, lPerceptual is
a perception Mean Square Error and lCE is the classifier loss.
The weighted factor λ indicates how much the generator must
change its outcome to suit the classifier. More details about these
transformation networks can be found in [10].
The architecture of the generators consists of 5 identical residual blocks. Each block has two convolutional layers with 3 × 3
kernels and 64 feature maps followed by batch-normalization
layers and Parametric ReLU as activation function. The last
residual block is followed by a final convolutional layer which
reduces the output image channels to 3 to match the input’s
dimensions. The classifier is a ResNet-18 which consists of an
initial convolutional layer with 7 × 7 kernels and 64 feature
maps followed by a 3 × 3 max pool layer. Then, 4 blocks of
two convolutional layers with 3 × 3 kernels with 64, 128, 256
and 512 feature maps respectively followed by a 7 × 7 average
pooling and one fully connected layer which outputs a vector of
N elements. ReLU is used as activation function.
Once the generators learn the corresponding transformations,
the dataset is processed using GP and GN. Two pair of images (x+
i , x−
i ) will be obtained from each input image xi, i =
1,...,n, where x+
i and x−
i are respectively the positively and
negatively transformed images of xi. Note that, once the entire
dataset is processed, we have four classes (P+,P−, N+, N−)
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3600 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 2. Flowchart of the proposed COVID-SDNet methodology.
instead the original P and N classes. Let yi be the class of xi,
yi ∈ {P, N}. If yi = P, GP and GN will produce the positive
transformation x+
i with y+
i = P+ and the negative transformation x−
i with y−
i = P−, respectively. If yi = N, GP and GN
will produce the positive transformation x+
i with y+
i = N+ and
the negative transformation x−
i with y−
i = N−, respectively.
Fig. 4 illustrates with example the transformations applied by
GN andGP. Notice that these transformations are not meant to be
interpretable by the human eye but rather help the classification
model better distinguish between the different classes.
3) Learning and Inference Based on the Fusion of CNN
Twins: The CNN classification model described above in
this section (Resnet-50) is trained to predict the new four
classes: P+,P−, N+, N−. The output of the network (after softmax is applied) for each transformed image associated to the original one is a vector θ = (θP+, θP−, θN+, θN−),
where θj is the probability of the transformed image to
belong to class j ∈ {P+,P−, N+, N−}. Herein, we propose an inference process to fuse the output of the two
transformed images x+
i and x−
i to predict the label of the
original image xi. In this way, for each pair (x+
i , x−
i ),
the prediction of the original image yi will be either P
or N. Let y
 +
i = argmax θ = argmax (θP+, θP−, θN+, θN−)
and y
 −
i = argmax ψ = argmax (ψP+, ψP−, ψN+, ψN−) be the
ResNet-50 predictions for x+
i and x−
i respectively. Then:
1) If y
 +
i = N+ and y
 −
i = N−, then yi = N.
2) If y
 +
i = P+ and y
 −
i = P−, then yi = P.
3) If none of the above applies, then
yi =
⎧
⎨
⎩
N if max(θNj , ψNj ) > max(θPj , ψPj ),
j ∈ {+, −}
P otherwise .
Experimentally, we used a batch size of 16 and SGD as
optimizer.
V. EXPERIMENTS AND RESULTS
In this section we (1) provide all the information about
the used experimental setup, (2) evaluate two state-of-the-art
COVID classification models and FuCiTNet alone [10] on our
dataset then, analyze (3) the impact of data pre-processing and
(4) Normal-PCR+ severity level on our approach.
A. Experimental Setup
Due to the high variations between different executions, we
performed 5 different 5 fold cross validations in all the experiments. Each experiment uses 80% of COVIDGR-1.0 for
training and the remaining 20% for testing. To choose when
to stop the training process, we used a random 10% of each
training set for validation. In each experiment, a proper set of
data-augmentation techniques is carefully selected. All results,
in terms of sensitivity, specificity, precision, F1 and accuracy, are
presented using the average values and the standard deviation of
the 25 executions. The used metrics are calculated as follows:
recall(positive class) = sensitivity = TP
actual positives
recall(negative class) = specificity = TN
actual negatives
precision(positive class) = TP
predicted positives
precision(negative class) = TN
predicted negatives
accuracy = TP+TN
total predictions
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3601
Fig. 3. The segmentation-based cropping pre-processing applied to the input X-ray image.
Fig. 4. Class-inherent transformations applied to a negative sample. a) Original negative sample; b) Negative transformation; c) Positive
transformation.
F1 = 2 ·
precision · recall
precision + recall
TP and TN refers respectively to the number of true positives
and true negatives.
B. Analysis of COVIDNet and COVID-CAPS
We compare our approach with the two most related approaches to ours, COVIDNet [16] and COVID-CAPS [19].  COVIDNet: Currently, the authors of this network provide
three versions, namely A, B and C, available at [26]. A has
the largest number of trainable parameters, followed by B
and C. We performed two evaluations of each network
in such a way that the results will be comparable to
ours.
 First, we tested COVIDNet-A, COVIDNet-B and
COVIDNet-C, pre-trained on COVIDx, directly on our
dataset by considering only two classes: Normal (negative), and COVID-19 (positive). The whole dataset
(426 positive images and 426 negative images) is evaluated.We report inTable IV recall and precision results
for Normal and COVID-19 classes.
 Second, we retrained COVIDNet on our dataset. It is
important to note that as only a checkpoint of each
model is available, we could not remove the last layer
of these networks, which has three neurons. We used
5 different 5 fold cross validations. In order to be
able to retrain COVIDNet models, we had to add a
third Pneumonia class into our dataset. We randomly
selected 426 images from the Pneumonia class in
COVIDx dataset. We used the same hyper-parameters
as the ones indicated in their training script, that is, 10
epochs, a batch size of 8 and a learning rate of 0.0002.
We changed covid_weight to 1 and covid_percent to
0.33 since we had the same number of images in all
the classes. Similarly, we report in Table IV recall and
precision of our two classes, Normal and COVID-19,
and omit recall and precision of Pneumonia class. The
accuracy reported in the same table only takes into
account the images from our two classes. As with our
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3602 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE IV
COVIDNET AND COVID-CAPS RESULTS ON OUR DATASET
TABLE V
RESULTS OF COVID-19 PREDICTION USING RETRAINED COVIDNET-CXR A, RETRAINED COVID-CAPS, RESNET-50 WITH AND WITHOUT SEGMENTATION,
FUCITNET AND COVID-SDNET. ALL FOUR LEVELS OF SEVERITY IN THE POSITIVE CLASS ARE TAKEN INTO ACCOUNT
models, we report here the mean and standard deviation
of all metrics.
Although we analyzed all three A, B and C variations of
COVIDNet, for simplicity we only report the results of the
best one.
COVID-CAPS: This is a capsule network-based model
proposed in [19]. Its architecture is notably smaller than
COVIDNet, which implies a dramatically lower number
of trainable parameters. Since the authors also provide a
checkpoint with weights trained in the COVIDx dataset,
we were able to follow a similar procedure than with
COVIDNet:
 First, we tested the pretrained weights using COVIDx
on COVIDGR-1.0 dataset. COVID-CAPS is designed
to predict two classes, so we reused the same architecture with the new dataset and compute the evaluation
metrics shown in Table IV.  Second, COVID-CAPS architecture was retrained over
the COVIDGR-1.0 dataset. This process finetunes the
weights to improve class separation. The retraining
process is performed using the same setup and hyperparameters reported by the authors. Adam optimizer is
used across 100 epochs with a batch size of 16. Class
weights were omitted as with COVIDNet, since this
dataset contains balanced classes in training as well as
in test. Evaluation metrics are computed for five sets
of 5-fold cross-validation test subsets and summarized
in Table IV.
The results from Table IV show that COVIDNet and COVIDCAPS trained on COVIDx overestimate COVID-19 class in our
dataset, i.e., most images are classified as positive, resulting in
very high sensitivities but at the cost of low positive predictive
value. However, when COVIDNet and COVID-CAPS are retrained on COVIDGR-1.0 they achieve slightly better overall
accuracy and a higher balance between sensitivity and specificity, although they seem to acquire a bias favoring the negative
class. In general, none of these models perform adequately for
the detection of the disease from CXR images in our dataset.
C. Results and Analysis of COVID Prediction
The results of the baseline COVID classification model considering all the levels of severity, with and without segmentation,
FuCiTNet [10], and COVID-SDNet are shown in Table V.
In general, COVID-SDNet achieves better and more stable
results than the rest of approaches. In particular, COVID-SDNet
achieved the highest balance between specificity and sensitivity
with 76.94 ± 2.82 F1 in the negative class and 75.71 ± 3.35
F1 in the positive class. Most importantly, COVID-SDNet
achieved the best sensitivity 72.59 ± 6.77 and accuracy with
76.18 ± 2.70. FuCiTNet provides in general good but lower
and less stable results than COVID-SDNet. When comparing
the results of the baseline classification model with and without
segmentation, we can observe that the use of segmentation improves substantially the sensitivity, which is the most important
criteria for a triage system. This can be explained by the fact
that segmentation allows the model to focus on most important
parts of the CXR image.
C. Analysis Per Severity Level
To determine which levels are the hardest to distinguish by
the best approach, we have analyzed the accuracy per severity level (S), with accuracy(S) = Correct predictions(S)
Total number(S) , where
S ∈ {Normal-PCR+, Mild, Moderate, Severe}. The results are
shown in Table VI.
As it can be seen from these results, COVID-SDNet correctly
distinguish Moderate and Severe levels with an accuracy of
86.90% and 97.72%, respectively. This is due to the fact that
Moderate and Severe CRX images contain more important
visual features than Mild and Normal-PCR+ which ease the
classification task. Normal-PCR+ and Mild cases are much more
difficult to identify as they contain few or none visual features.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3603
TABLE VI
RESULTS OF COVID-SDNET PER SEVERITY LEVEL
TABLE VII
RESULTS OF THE BASELINE CLASSIFICATION MODEL WITH SEGMENTATION, COVID-SDNET, RETRAINED COVIDNET-CXR-A AND RETRAINED
COVID-CAPS. ONLY THREE LEVELS OF SEVERITY ARE CONSIDERED, MILD, MODERATE AND SEVERE
TABLE VIII
RESULTS OF COVID-SDNET BY SEVERITY LEVEL WITHOUT CONSIDERING
NORMAL-PCR+
These results are coherent with the clinical studies provided in
[5] and [2] which report that expert sensitivity is very low in
Normal-PCR+ and Mild infection levels. Recall that the expert
eye does not see any visual signs in Normal-PCR+ although
the PCR is positive. Those cases are actually considered as
asymptomatic patients.
D. Analysis of the Impact of Normal-PCR+
To analyze the impact of Normal-PCR+ class on COVID-19
classification, we trained and evaluated the baseline model,
FuciTNet, COVID-SDNet classification stage, COVIDNetCXR-A and COVID-CAPS, on COVIDGR-1.0 by eliminating
Normal-PCR+. The results are summarized in Table VII.
Overall, all the approaches systematically provide better results when eliminating Normal-PCR+ from the training and test
processes, including COVIDNet-CXR-A and COVID-CAPS.
In particular, COVID-SDNet still represents the best and most
stable approach.
E. Analysis Per Severity Level
A further analysis of the accuracy at the level of each severity
degree (see Table VIII) demonstrates that eliminating NormalPCR+ decreases the accuracy in Mild and Moderate severity
levels by 15.8% and 1.52% respectively.
These results show that although Normal-PCR+ is the hardest
level to predict, its presence improves the accuracy of lower
severity levels, especially Mild level.
VI. INSPECTION OF MODEL’S DECISION
Automatic DL diagnosis systems alone are not mature yet to
replace expert radiologists. To help clinician making decisions,
these tools must be interpretable so that clinicians can decide
whether to trust the model or not [27]. We inspect what led
our model make a decision by showing the regions of the input
image that triggered that decision along with its counterfactual
explanation by showing the parts that explain the opposite class.
We adapted Grad-CAM method [28] to explain the decision of
the negative and positive class.
Figs. 5, 6, and 7 show (a) the original CXR image, (b) visual
explanation by means of a heat-map that highlights the regions/pixels which led the model to output the actual prediction
and (c) its counterfactual explanation using a heat-map that
highlights the regions/pixels which had the highest impact on
predicting the opposite class. Higher intensity in the heat-map
indicates higher importance of the corresponding pixel in the
decision. The larger higher intensity areas in the heat-map
determine the final class. However, Fig. 8(b) represents first the
counterfactual explanation and Fig. 8(c) represents the explanation of the actual decision.
As expected, negative and positive interpretations are complementary, i.e, areas which triggered the correct decision are
opposite, in most cases, to the areas that triggered the decision towards negative. In CXR images with different severity levels, the heat-maps correctly point out opaque regions
due to different levels of infiltrates, consolidations and also to
osteoarthritis.
In particular, in Fig. 5(b), the red areas in the right lung points
out a region with infiltrates and also osteoarthritis in the spine
region. Fig. 6(b) correctly shows moderate infiltrates in the right
lower and lower-middle lung fields in addition to a dilation of
ascending aorta and aortic arch (red color in the center). Fig. 5(c)
shows normal upper-middle fields of both lungs (less important
on the left due to aortic dilation). Fig. 7(b) indicates an important
bilateral pulmonary involvement with consolidations.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3604 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 5. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 6. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 7. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 8. Heatmap that explains the parts of the input image that triggered the counterfactual explanation (b) and the negative actual prediction (c).
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3605
As it can be observed in Fig. 8(c), the explanation of the
negative class correctly highlights a symmetric bilateral pattern
that occupies a larger lung volume especially in regions with
high density. In fact, a very similar pattern is shown in the
counterfactual explanation of the positive class in Fig. 5(c), 6(c)
and 7(c).




NEW_PAPER




BIG DATA MINING AND ANALYTICS
ISSN 2096-0654 06/07 pp116–123
Volume 4, Number 2, June 2021
DOI: 10.26599/BDMA.2020.9020016

C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Prediction of COVID-19 Confirmed, Death, and Cured Cases in
India Using Random Forest Model
Vishan Kumar Gupta
, Avdhesh Gupta, Dinesh Kumar, and Anjali Sardana
Abstract: A novel coronavirus (SARS-CoV-2) is an unusual viral pneumonia in patients, first found in late December
2019, latter it declared a pandemic by World Health Organizations because of its fatal effects on public health. In this
present, cases of COVID-19 pandemic are exponentially increasing day by day in the whole world. Here, we are
detecting the COVID-19 cases, i.e., confirmed, death, and cured cases in India only. We are performing this analysis
based on the cases occurring in different states of India in chronological dates. Our dataset contains multiple classes
so we are performing multi-class classification. On this dataset, first, we performed data cleansing and feature
selection, then performed forecasting of all classes using random forest, linear model, support vector machine,
decision tree, and neural network, where random forest model outperformed the others, therefore, the random
forest is used for prediction and analysis of all the results. The K-fold cross-validation is performed to measure the
consistency of the model.
Key words: coronavirus; COVID-19; respiratory tract; multi-class classification; random forest
1 Introduction
The virus of coronaviruses (CoV) is a special kind
of virus that itself is a disease and it enhances the
existing disease in humans body which makes it a
very dangerous virus. This virus results in wheezing,
hard to breathe, bad digestive system, and liverwort,
effects badly human nervous system (center), and also
harms animals like cows, horses, and pigs that are kept,
raised, and used by people and different wild animals. In
  Vishan Kumar Gupta is with Department of Computer
Science and Engineering (CSE), Graphic Era Deemed
to be University, Dehradun 248002, India. E-mail:
vishangupta@gmail.com.
  Avdhesh Gupta and Anjali Sardana are with Department
of CSE, IMS Engineering College, Ghaziabad 201009,
India. E-mail: avdhesh.gupta@imsec.ac.in; anju.sardana@
gmail.com.
  Dinesh Kumar is with Department of CSE, KIET
Group of Institutions, Ghaziabad 201206, India. E-mail:
dineshvashist@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-17; revised: 2020-08-10;
accepted: 2020-08-21
2002–2003 the epidemic of Severe Acute Respiratory
Syndrome (SARS) and in 2012 the burst of the Middle
East Respiratory Syndrome (MERS) have illustrated the
probability of transferrable newly arrived COVID-19 in
human to human and animal to human and vice versa,
though there are very fewer cases of this kind, they
do exists. In late December 2019, the effect of secret
pneumonia in the whole world is a noticeable topic of
study[1]
.
In India, the first case of coronavirus disease 2019
(COVID-19) was announced on 30th January 2020. This
virus extends to the whole of India (in their different
districts) till April 2020 end. In India, the total cases
announced were 5734 in which 472 were recovered and
166 people were dead till 9th April 2020. In India, the
total cases announced were 236 184 in which 113 233
were recovered and 6649 people were dead till 6th June
2020. After this date, fresh cases are still coming into
light daily which is around 10 000. In India, the infection
rate of COVID-19 is lesser than that in some other
countries till date. The website worldometers[2] gives
us all these details in a precise manner. Figure 1 is
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 117
Fig. 1 Structure of coronavirus.
showing the structure of COVID-19, this structure looks
like a crown. The different parts of this virus are also
introduced in this diagram[3]
.
The objectives of this surveillance are the following:
(1) Monitor trends in COVID-19 disease at national
levels.
(2) Rapidly detect new cases in countries where
the virus has started to circulate and monitor cases in
countries where the virus is not circulating.
(3) Provide epidemiological information to conduct
risk assessments at the national and state level.
(4) Provide epidemiological information to guide
preparedness and response measures.
1.1 Transmission
In China, COVID-19 first case was reported in Huanan
Seafood Wholesale Market, Wuhan. The main reason
which was supposed for the spread of this virus is
the transmission from animal-to-human. Even so, the
upcoming COVID-19 cases were not related to the
subjection method. Hence the conclusion is that virus
transmission is from humans to humans, and people with
viruses indicative are the main recurrent reason for the
spread of COVID-19. Before the symptoms progress,
the transmission probability of COVID-19 appears to be
very rare, even though, this virus transmission can not
be prohibited. Besides these, the advice for every person
is that the people who are symptomless or asymptomatic
could pass on the virus and social distancing is the only
way to be secure from this virus[4]
.
Including rhinovirus and flu, additional wheezing
bacterium, it is believed that the droplets of sneeze
and cough of a person are the main reason for virus
imparting. In closed places, aerosol transmission is also
possible in case of long exposure to deep-mouthed
aerosol concentrations. In China, the result of data
analysis of SARS-CoV-2 spread is that the close contact
of two people is the demanded condition for the spread
of the virus. The virus extension is mainly restricted to a
person’s family members, other nearly contacted people
and healthcare experts[4]
.
1.2 Treatment and prevention
Currently, there is no isolated particular antiviral
treatment for COVID-19 virus and their treatments are
reassuring. The effects of recombination of IFN with
ribavirin are very less against the infection of COVID-19.
After the SARS and MERS pandemic, several valuable
efforts have been provided for the development of new
antivirals targeting the CoV proteases, polymerases, and
entry proteins, nevertheless, none of them has been
proven to be worthwhile in clinical trials, nevertheless, of
them has been proven to be worthwhile in clinical trials.
The patient who can already be recovered from COVID19 can donate their plasma and antibodies, because it has
been proved beneficial in the treatment of COVID-19[1]
.
As well, diverse vaccine schemes, like the use of
disabling viruses, live attenuated viruses, a vaccine based
on viral vector, subunit injection, recombinant proteins,
and DNA vaccines, have been evolved, but they are
tested only in the animals so far.
Till now there is not any effective injection or therapy
available for COVID-19, but only the finest measures
are to control the source of infection, early diagnosis,
reporting, isolation, supportive treatments, and on-time
producing outbreak details to keep away from inessential
anxiety. For every person, a fine exclusive hygiene,
wearing a shaped or suitable mask, ventilation, and
keeping away from massed areas will assist to block
COVID-19 virus or its inflammation[1]
.
The guidance and directions issued by the World
Health Organization (WHO) and other corporations are
as follows:
  Keep away from adjacent correspondence with
people suffering from serious CoV inflammation.
  Clean your hands regularly, mainly when you come
in close contact with CoV-infected people and the place
where they live.
  Keep away from unsafe connections with wild and
farm animals.
  Persons having symptoms of critical air shaft
inflammation should maintain a distance from other
peoples, enfold wheeze or sneezes with a throwaway
paper napkin or material, and clean their hands from
time to time.
  Specifically, in the department of a medical
emergency, proper arrangement of strict hygiene
measures are required for the prevention and control
of infections.
  Individuals that are immunocompromised should
118 Big Data Mining and Analytics, June 2021, 4(2): 116–123
avoid public gatherings.
This paper proposes machine learning schemes based
on a data-driven approach. This approach gives a
prediction about the number of infected people with
COVID-19 in the upcoming days using the available
data. This paper proposes a model, which can easily
forecast the count of fresh COVID-19 cases, so that the
management can make a preparation to handle these
cases.
Figure 2 shows the general diagram of the prediction
model, where the various features are taken, and their
multiple cases (classes) are predicted through random
forest prediction model.
This paper is organized as follows. Section 2
explains methodology and materials for the prediction
of COVID-19, where we present dataset and its features,
feature selection, and all the classes. The procedure
of the prediction model is clarified in Section 3. The
description of various machine learning models used
in this work and their performance metric is presented
in Section 4. Sections 5 present the result analysis,
comparison of reported and estimated cases. At long
last, the conclusion is exhibited in Section 6.
2 Methodology and Material
2.1 Dataset and its features
Coronaviruses are a large family of viruses that
may cause illness in animals or humans. In humans,
several coronaviruses are known to cause respiratory
infections ranging from the common cold to more severe
diseases, such as MERS and SARS. The most recently
discovered coronavirus causes coronavirus disease in
2019 (COVID-19)[5]
.
The number of new cases is increasing day by day
around the world. This dataset has information from the
Confirmed, death, and cured cases
Confirmed Indian National
Dataset features
Observation date, time,
and State/Union Territory
Prediction model
Confirmed Foreign National
State
Time
Observation date
Fig. 2 Prediction method.
states and union territories of India daily. The effect of
preventing measures, like social distancing, face mask,
and the lockdown, has also been considered.
The dataset consists of features of COVID-19
data which are taken from https://www.kaggle.com/
sudalairajkumar/covid19-in-india/ and also from the
Ministry of Health & Family Welfare. The dataset
consists only of 2342 samples of COVID-19 cases in
India from 30 January 2020 to 26 May 2020. Table 1
shows the attributes/features used in this study and
glimpse of dataset is presented in Table 2.
2.2 Feature selection
During the process of model building, feature selection
is used to select most relevant features out of all the
features. It reduces the complexity of the prediction
model. Here, we performed feature selection using
random forest importance algorithm in R programming
language[6]. The classification model features are
calculated using the above algorithm, whose input
parameters are all the features of dataset of COVID-19
cases in India.
So, we got three features, which were used for
the building of multi-class classification model using
a random forest importance algorithm. These are
“Obervation date”, “Time”, and “State/Union Territory”
out of five, only two features have been discarded,
that are “Confirmed Indian National” and “Confirmed
Foreign National”. These features are discarded, because
they impact only at the beginning of COVID-19
infection, when patients were coming from abroad, later
Table 1 Feature for the prediction of COVID-19 cases in
India.
Name Description
Observation date It is the date on which how many
COVID-19 positive cases have
occurred.
Time It is the time of that particular date
at which how mang COVID-19
positive cases have occurred.
State/Union Territory It is the name of the state/union
territory of India where COVID-19
cases were found.
Confirmed Indian National It is the total number of confirmed
COVID-19 cases found in India
itself at the starting of SARS-CoV-2
in India.
Confirmed Foreign National It is the total number of confirmed
COVID-19 cases found in India,
which came from any foreign
countries at the beginning of SARSCoV-2 cases in India.
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 119
Table 2 Dataset on SARS-CoV-2 in India.
Date Time State/Union
Territory
“Confirmed Indian
National” case
“Confirmed Foreign
National” case
Cured
case
Death
case
Confirmed case
30-01-2020 6:00 PM Kerala 1 0 0 0 1
04-03-2020 6:00 PM Rajasthan 1 14 0 0 15
07-03-2020 6:00 PM Telengana 1 0 0 0 1
07-03-2020 6:00 PM Tamil Nadu 1 0 0 0 1
08-03-2020 6:00 PM Ladakh 2 0 0 0 2
08-03-2020 6:00 PM Telengana 1 0 0 0 1
10-03-2020 6:00 PM Jammu and Kashmir 1 0 0 0 1
11-03-2020 7:00 PM Maharashtra 2 0 0 0 2
11-03-2020 7:00 PM Delhi 5 0 0 0 5
29-03-2020 7:30 PM Andhra Pradesh – – 1 0 19
10-04-2020 5:00 PM Maharashtra – – 125 97 1364
29-04-2020 5:00 PM Gujarat – – 434 181 3774
01-05-2020 5:00 PM Madhya Pradesh – – 482 137 2719
26-05-2020 8:00 PM West Bengal – – 1414 278 3816
CoV cases are arisen only based on internal infection
due to COVID-19’s communicable property. Therefore,
the values of these fields are not considered.
2.3 Target classes used in prediction dataset
Our dataset contains three target classes, which have
multiple discrete instances. These target classes are the
following:
(1) Confirmed cases: Number of confirmed cases at
any particular date. It may be increased or decreased
according to next date, time, and location-specific to the
Indian states only.
(2) Death cases: Number of death cases at any
particular date. It may be increased or decreased
according to next date, time, and location-specific to
the Indian states only.
(3) Cured cases: Number of cured cases at any
particular date. It may be increased or decreased
according to the next date, time, and location-specific to
the Indian states only.
3 Procedure of Prediction Model
We are developing a machine learning-based
methodology, which has the following four steps.
This methodology is also depicted in Fig. 3.
Step 1: Building multi-class classification model
using the training-testing concept. The dataset of
COVID-19 features of date-wise, time-wise, and statewise were taken from Kaggle and then trained and tested
at 70% and 30%, respectively.
Step 2: Feature selection. Before going to the model
formation, we selected only important features for the
reduction of the complexity of the model. For the same,
1. Data collection from Kaggle
2. Data cleansing
3. Feature selection
4. Model building
5. Result analysis
Fig. 3 Methodology of work.
we applied the random forest importance algorithm.
Section 2.2 describes it in detail. The formulas for the
prediction model in the confirmed, death, and cured
cases are the following:
Confirmed  f .Observation Date C TimeC
State/Union Territory/ (1)
Death  f .Observation Date C TimeC
State/Union Territory) (2)
Cured  f .Observation Date C TimeC
State/Union Territory/ (3)
Step 3: Training the dataset using the multi-class
classification. The dataset is then modeled using random
forest, Support Vector Machine (SVM), decision tree,
multinomial logistic regression, and neural network at
70% training dataset.
Step 4: Testing the dataset using the multi-class
120 Big Data Mining and Analytics, June 2021, 4(2): 116–123
classification: 30% data are tested using these all five
models, the results from all the five models are collected
and found that the random forest model outperformed the
other models for the prediction of confirmed, death, and
cured cases, individually. Therefore, we have considered
the random forest model for the prediction of this multiclass classification model.
4 Machine Learning Models Used in This
Study and Their Performance Metrics
These are the following models used for the prediction of
the cases of COVID-19 using multi-class classification:
(1) Decision tree (rpart): To build decision trees, we
used rpart() method of R programming language[7, 8]
.
(2) Random forest (randomForest): It is an
ensemble tree-based learning algorithm. The random
forest classifier is a set of decision trees from a randomly
selected subset of the training set. It aggregates the votes
from different decision trees to decide the final class of
the test object. We used randomForest() method of R
programming language for this algorithm[9, 10]
.
(3) Multinomial logistic regression (multinome):
In statistics, multinomial logistic regression is a
classification method that generalizes logistic regression
to multi-class problems, i.e., with more than two possible
discrete outcomes. We used multinome() method of
nnet package of R programming language for this
algorithm[11]
.
(4) Neural networks (nnet): Neural networks are
used just for classification as well as for regression.
We are using here feed-forward neural networks with a
single hidden layer, possibly with skip-layer connections.
We used nnet() method of R programming language for
this algorithm[7, 11]
.
(5) Support vector machine (svm): SVM can be
used for classification or regression. It represents the
input features as vectors, which are projected onto
higher-dimensional space. An optimal hyperplane is
then constructed for separating the different instances of
confirmed, death, or cured cases. We have used svm()
method of e1071 package of R programming language
for this algorithm[7, 12]
.
4.1 Performance tuning of the prediction models
Table 3 shows the popular prediction models, which are
used in our study, and the packages used by these models
are open source libraries in R programming language,
licensed under GNU GPL. All packages are used here
having some appropriate method for model formation,
Table 3 Machine learning models and their tuning
parameters.
Model Method Required
package
Tuning
parameter
Random forest randomForest randomForest mtry=2,
ntree=500
SVM svm e1071 kernal=radial,
degree=3
Decision tree rpart rpart usesurrogate=0
Neural
network nnet nnet size=10
Multinomial
logistic
regression
multinome nnet maxit=1000
which are tuned for better results[13]
.
4.2 Accuracy
The accuracy is computed as the percentage deviation
of the predicted target concerning the actual target
with some acceptable error. It is the main performance
evaluation parameter of any machine learning
model[7, 14]
.
Accuracy D
100
n
Xn
iD1
qi
;
qi D
(
1; if abs.pi  ai/ 6 2I
0; otherwise
(4)
where pi
is a predicted target, ai
is an actual target, and
qi
is an arbitrary variable, which contains the absolute
difference of predicted target value and actual target
value.
5 Result Analysis and Comparison of
Reported and Estimated Cases
The number of the total sample for training and testing is
2342 according to different date, time, and states, which
are taken from the website of Kaggle. This is the dataset
of multi-class classification to foresee confirmed, death,
and recovered/cured cases calculated through various
decision models, like decision tree, multinomial logistic
regression, neural network, SVM, and random forest.
The distribution of data in the training and testing
experiments has been set to 70% and 30%, respectively,
for all the methods used. Comparative performance of
all the methods in the prediction of confirmed, death, and
cured cases on accuracy has been highlighted. Accuracy
is computed as the percent deviation of the predicted
target concerning the actual target. The accuracy has
been calculated using Eq. (4), and Table 4 lists the
accuracy of all the models. The results show tha
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 121
Table 4 Multi-class classification accuracy calculated by
various machine learning models. (%)
Model name Confirmed cases Death cases Cured cases
Random forest 83.54 72.79 81.27
Decision tree 77.69 69.11 79.62
Multinomial logistic
regression 67.69 66.52 71.96
Neural network 70.28 63.18 69.16
SVM 71.35 70.12 68.27
the random forest method outperforms other machine
learning models. Random forest is an ensemble model
that uses bagging for sampling, therefore, we found
its overwhelming performance in comparison to other
models.
In the prediction of confirmed, death, and cured cases
on the testing dataset, random forest has the highest
accuracy of 83.54%, 72.79%, and 81.27% on confirmed,
death, and cured cases, respectively.
Figures 4, 5, and 6 show the histogram for the
comparison of accuracy of confirmed, death, and cured
cases, respectively, using the random forest model as
well as some other models. These results show that
the random forest model has outperformed the other
machine learning models.
Fig. 4 Performance comparison of random forest model
with other models in confirmed cases prediction.
Fig. 5 Performance comparison of random forest model
with other models in death cases prediction.
Fig. 6 Performance comparison of random forest model
with other models in cured cases prediction.
5.1 K-fold cross-validation
The K-fold cross-validation technique shows the robust
performance for the accuracy of any machine learning
model[7]. Here, we have used 7-fold cross-validation for
the prediction of confirmed, death, and cured cases. In
this case, at a time six data frames are used for training
and one data frame is used for testing. Table 5 describes
the accuracy of random forest model for the different
folds of dataset, and Fig. 7 shows the accuracy of the
random forest model in the form of a line graph for the
prediction of all the target classes, which depicts the
consistent performances of random forest model[15]
.
5.2 Comparison of total reported and estimated
confirmed, death, and cured cases
For this data-driven estimations, the data has been taken
from 30 January 2020 to 26 May 2020 from different
states of India. The comparison has also been made
for the daily reported positive confirmed cases with
estimated cases (by data-driven model) for some dates
and states. Tables 6, 7, and 8 are showing the comparison
made by us for the confirmed, death, and cured cases,
respectively.
6 Conclusion
We tend to explore five machine learning models with
three important features for estimating the confirmed,
Table 5 Accuracy provided by 7-fold cross-validation.
(%)
Fold Confirmed cases Death cases Cured cases
1 83.29 72.97 82.52
2 84.98 70.81 81.63
3 81.71 72.35 79.92
4 84.83 72.67 81.17
5 82.65 72.19 81.06
6 84.72 72.88 80.22
7 81.40 70.63 82.44
122 Big Data Mining and Analytics, June 2021, 4(2): 116–123
(a) Confirmed cases
(b) Death cases
(c) Cured cases
Fig. 7 Results of K-fold cross-validation.
Table 6 Comparison of total reported and estimated
confirmed cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 1596 1520 4:76
09-05-2020 Bihar 297 305 2.62
21-05-2020 Maharashtra 10 318 10 386 0.60
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 5897 5912 0.25
Table 7 Comparison of total reported and estimated death
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 97 88 9:27
09-05-2020 Bihar 5 5 0
21-05-2020 Maharashtra 1390 1376 1:01
22-05-2020 Gujarat 773 740 4:26
23-05-2020 Delhi 208 256 2.30
death, and cured cases of COVID-19 in the various states
of India. The qualitative measures are the confirmed,
death, and cured cases. Here, machine learning methods
do not embody any additional information from different
models or different templet structures. All the models
are evaluated on accuracy. Through the intensive
experiments, it is found that the random forest method
Table 8 Comparison of total reported and estimated cured
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 3427 3514 2:53
09-05-2020 Bihar 571 601 5.25
21-05-2020 Maharashtra 39 297 38 920 0.90
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 12 319 12 356 0.30
outperforms other machine learning methods, therefore,
we considered it as a final prediction model for the
prediction of our various cases. The K-fold crossvalidation is used to measure the consistency of random
forest model, which provided nearly linear performance
to the prediction of all these cases.
Acknowledgment
We are very much thankful to the Indian Ministry of
Health and Family Welfare (MoHFW) for making the data
available to the general public. Thanks to covid19india.org
for providing the individual states level details to the
general public. We are also thankful for Kaggle and the
worldometer website, which provide huge data in datewise to perform data analytics.




NEW_PAPER


Predictive Modeling of Covid-19 Data in the
US: Adaptive Phase-Space Approach
Vasilis Z. Marmarelis , Fellow, IEEE
Abstract—There are currently intensified efforts by the
scientific community world-wide to analyze the dynamics
of the Covid-19 pandemic in order to predict key epidemiological effects and assist the proper planning for its
clinical management, as well as guide sociopolitical
decision-making regarding proper mitigation measures.
Most efforts follow variants of the established SIR
methodological framework that divides a population into
“Susceptible”, “Infectious” and “Recovered/Removed”
fractions and defines their dynamic inter-relationships with
first-order differential equations. Goal: This paper proposes
a novel approach based on data-guided detection and
concatenation of infection waves – each of them described
by a Riccati equation with adaptively estimated parameters.
Methods: This approach was applied to Covid-19 daily
time-series data of US confirmed cases, resulting in
the decomposition of the epidemic time-course into five
“Riccati modules” representing major infection waves to
date (June 18th). Results: Four waves have passed the
time-point of peak infection rate, with the fifth expected
to peak on July 20th. The obtained parameter estimates
indicate gradual reduction of infectivity rate, although the
latest wave is expected to be the largest. Conclusions:
This analysis suggests that, if no new waves of infection
emerge, the Covid-19 epidemic will be controlled in the
US (<5000 new daily cases) by September 26th, and
the maximum of confirmed cases will reach 4,160,000.
Importantly, this approach can be used to detect (via
rigorous statistical methods) the emergence of possible
new waves of infections in the future. Analysis of data from
individual states or countries may quantify the distinct
effects of different mitigation measures.
Index Terms—Adaptive modeling of Covid-19 time-series
data, epidemiological predictive modeling, riccati-based
phase-space modeling, statistical detection of Covid-19 infection waves.
Impact Statement—Analysis of US Covid-19 data yielded
five RMs representing the dynamics of five infection waves.
The further application of this approach could allow interregional comparison of the obtained RM-decompositions.
Manuscript received May 29, 2020; revised June 22, 2020; accepted
July 1, 2020. Date of publication July 9, 2020; date of current version July
24, 2020. This work was supported by NIH under Grant R01-AG058162
awarded to the Biomedical Modeling & Simulations Center at the University of Southern California.
The author is with the Department of Biomedical Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail:
vzm@usc.edu).
Digital Object Identifier 10.1109/OJEMB.2020.3008313
I. INTRODUCTION
MANY efforts have been made recently to analyze the
time-course of the Covid-19 pandemic daily data in
various countries or regions and to predict key aspects of its eventual growth in order to assist the proper planning for healthcare
resources and related socioeconomic decision-making. Among
them, dominant role is played by the SIR class of compartmental
epidemiological models, introduced about a century ago by
Kermack and McKendrick [1], and its many variants over
the years [2]–[5] that generally utilize compartments of
“Susceptible”, “Infectious” and “Removed” fractions of the
population, which are interconnected with dynamic relationships described by nonlinear ordinary differential equations. Another commonly used approach employs linear Auto-Regressive
Integrated Moving-Average (ARIMA) models that have been
popular in econometrics [6]. From the policy-planning point of
view, practical importance is attained by predictive modeling
methods that can provide reliable estimates of key parameters
of the unfolding infectious process at each point in time on an
adaptive basis, as well as offer useful insights into the dynamic
structure of the infectious process. For example, such adaptive
methods can offer useful predictions of the maximum number of
total infections and an upper bound of the daily confirmed new
cases for the purpose of planning the proper clinical management
of the epidemic. Furthermore, the obtained model should be
interpretable in terms of the dynamic characteristics of the epidemic process (e.g. infectivity rate etc.) in order to assist policy
planning and operational implementation. From these observations arise two key aspects of a desirable modeling approach:
1) Suitable model form: The employed model form must
capture the essential dynamic characteristics of the epidemic process at each time-point in a manner that is
scientifically interpretable and operationally useful.
2) Robust estimation and adaptive modeling:Robust estimation of the model parameters at each time-point must be
feasible using tested statistical methods in a manner that
can detect possible changes in the underlying modeling
assumptions over time and offer the means for model
adaptation.
If these two key aspects can be secured, then it would be
possible to predict the maximum spread of anticipated infections
and the maximum rate of infections (as well as their respective
timing) in order to assist rational decision-making.
This paper presents one such approach that employs an
adaptive modeling/estimation strategy based on the use of
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 207
208 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
concatenated Riccati-type modules (each described by a
parabolic phase-space representation) and suitable adaptive statistical estimation methods. The potential utility of this approach
is initially demonstrated with the adaptive analysis of daily data
of reported Covid-19 confirmed cases in the US up to the present
time (June 18, 2020).
The extensive literature on the subject of epidemiological
modeling is not reviewed here in the interest of space, but
some basic comparisons of the proposed approach with the
most widely-used SIR class of models will be discussed. Some
representative recent modeling applications to Covid-19 data
that may be of interest to the readers include: a simulation study
of the SEIR model (a variant of the SIR model that includes a
compartment for “Exposed” individuals) for Covid-19 in Northern Italy [7], a model that seeks to estimate the transmission risk
of the epidemic [8], and a model for the spread of the epidemic
in China [9]. There are many Covid-related modeling studies
that have been posted as “preprints under review”, thus more
citations will soon be available.
II. MATERIALS AND METHODS
The key modeling element of the proposed approach is the
“Riccati module” (RM) that is defined by the Riccati Equation
(1) with constant coefficients A and B (defining a quadratic relation between the rate of change and the number of infectionsX(t)
at each time) [10]. The additive stochastic term R(t) represents
all unknown random influences (unknown external factors and
errors/noise) affecting the reported time-series data [11]–[15]:
dX(t)/dt = AX(t) − BX2(t) + R(t) (1)
This equation captures the essential self-limiting aspect of an
infectious process (due to the gradually acquired “herd immunity” and countervailing factors) in a relatively simple manner
by considering the “effective rate” (which relates the derivative
to the function) being reduced linearly with rising X(t) as: [A –
BX(t)], instead of being a constant as in the conventional rate
processes of the form: dX(t)/dt = AX(t).
Thus, the parameter A is the initial “infectivity rate constant”
that is dominant in the initial exponential-like growth of the
infection and quantifies the degree of contagiousness of an
infectious agent along with the level of contagious interactions
in a given “infection pool” (IP). On the other hand, the parameter
B depends on the size of susceptible population in the IP and
also quantifies the degree to which the aforementioned acquired
“herd immunity” and countervailing factors (both natural and
socially or administratively imposed by the infected community) constrain the initial rapid growth of the infection and
eventually achieve its control. This process is described by a
sigmoidal curve defined by Equation (2), which is the general
solution of the Riccati Equation (1) (in the absence of random
perturbations R(t)), where the maximum number Xmax of total
infections anticipated by the Riccati model (i.e. the plateau of
the sigmoidal curve) is given by the ratio of the two parameters
Xmax = (A/B):
X (t) = Xmax/ [1 + K exp (−At)] (2)
where K = [(Xmax/Xin) − 1], with Xin being the initial value
of X(t) at the start of the respective RM single-pool infection.
The two parameters, A and B, of each RM attain useful interpretations that offer insights into the dynamic characteristics of the
infectious process, which is generally decomposed into a cascade of RMs estimated via the proposed adaptive methodology
and representing the ongoing “recruitment” of distinct/major
IPs. This model-derived knowledge may assist the effective
management of an epidemic describable by a model composed
of such concatenated (latent) RMs.
It is clearly desirable to obtain reliable “running” estimates of
these parameters from time-series data (e.g. daily Covid-19 data)
at any given point in time. The Riccati-equation model has been
shown previously to represent self-limiting infectious processes
that are confined within single isolated “infection pools” (IPs)
[11]–[15]. The challenge in the study of the Covid-19 epidemic
is that, due to its highly contagious nature, there are multiple
communicating IPs that are recruited during the course of the
epidemic and contribute to the reported data at the respective national, international or multi-community level. This presents us
with the daunting task of separating the superimposed sigmoidal
time-courses of multiple RMs corresponding to the various IPs
(without the benefit of separate data from individual IPs). To
perform this task, we propose a methodology that utilizes an
adaptive estimation procedure to detect (via a “running” statistical Hypothesis test) and separate the concatenated parabolic
phase-space representations of the RMs that are present in the
data up to a given time-point.
The phase-space representation of a dynamic process X(t)
pertains to the relation between X(t) and its derivative over time
(in the absence of random perturbations). The Riccati Equation
(1) indicates that this relation is parabolic. For discrete-time data
(i.e. Covid-19 confirmed cases) up to time-step n, a cascade of
parabolic phase-plots can be fitted to the available phase-space
data, and estimates of all the parameters A and B at each timestep n can be obtained. These parameter estimates can be used to
predict the multi-sigmoidal time-course of the infectious process
according to a superposition of cascaded sigmoidal curves,
each described by Equation (2) with its distinct parameters.
This estimation task begins with the statistical detection and
estimation of the first RM that is described by the discretized
Riccati-model:
ΔX (n) /ΔT = AX (n) − BX2 (n) + R (n) (3)
where: ΔX(n) = [X(n) − X(n − 1)], and ΔT denotes the fixed
time-step (1 day in this case). Following adaptive estimation
of the first RM (see below), we perform statistical Hypothesis
testing (using a properly constructed F-statistic) at each timestep to detect the possible emergence of another RM and, if
such is detected, then estimate the distinct parameters of the two
RMs and separate the contributions to the total reported cases
(see below). This procedure is repeated at each time-step n until
all daily data have been analyzed to obtain adaptive estimates
of the distinct RM parameters A and B that correspond to all
detected RMs.
Regarding the robust estimation of the parameters A and
B, initial analysis indicated that the standard deviation of the
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 209
residual valuesR(n) depends roughly linearly onX(n). This nonstationary residual variance implies that least-squares fitting of
the model of Equation (3) would yield unreliable parameter
estimates. However, reliable estimates of A and B may be
obtained via least-squares regression of the “Normalized Rate of
Change”: ΔX(n)/X(n), (equivalent to the logarithmic derivative)
upon X(n) according to the equation:
ΔX (n) /X (n) = A − BX (n) + R (n) /X (n) (4)
when ΔT in Equation (4) is set to 1 (one day). Since the residual
term: R(n)/X(n), is expected to have (approximately) stationary
standard deviation, reliable parameter estimates can be obtained
at each time-step n. Furthermore, the “slope parameter” B in
Equation (4) can be evaluated for statistical significance at
each time-step n (by testing the Null Hypothesis that the slope
parameter is not significantly different from zero at a specified
confidence level) to assess whether Equation (4) remains an
appropriate representation of the data. When this Null Hypothesis gets rejected at some time-step n, then adaptive parameter
estimates can begin to be used for adaptive prediction of the
sigmoidal course of the infection accounted by the respective
RM.
This adaptive estimation procedure can be repeated at each
time-point n, until the linear relationship expressed by Equation
(4) ceases to represent the time-evolution of the data – an event
identified adaptively by examining the statistical significance
of the reduction in Residual Variance (using Hypothesis testing
with an F-statistic) of the regression of the “Normalized Rate
of Change” values: [ΔX(n)/X(n)] upon the linear relationship
of Equation (4) versus a second-degree polynomial expression
that would indicate the emergence of a new RM. Note that a
second-degree polynomial expression like the one in Equation
(5) (starting with a positive value at X = 0, since A must be
positive) may not have a zero-crossing in the phase-plot of the
“Normalized Rate of Change”, but this is not necessary because
it simply quantifies the divergence from the Null Hypothesis
(as an Alternative Hypothesis) and does not seek to represent
the dynamic characterisitcs of the infectious process. Thus,
we construct an adaptive statistical test using the Alternative
Hypothesis that the Normalized Rate of Change follows the
quadratic model of Equation (5):
ΔX (n) /X (n) = A − BX (n)
− CX2 (n) + R (n) /X (n) (5)
to be tested at each time-point against the Null Hypothesis of
the linear model of Equation (4). For this statistical Hypothesis
testing, we use the following F-statistic (with 1 and (N-3) degrees
of freedom) that represents the normalized reduction in Residual
Variance between the linear and the quadratic expressions (4)
and (5):
F1,N−3 = (N − 3) Q1/(Q2 (6)
where Q1and Q2denote the computed Residual Variances for
the linear and the quadratic expression, respectively, and N is
the number of data-points used in the regression.
TABLE I
ESTIMATED PARAMETERS OF THE RM MODEL COMPONENTS
The computed F1,N−3 is compared at each time-point to the
proper critical value Fcrit (for a significance level of 95%).
When F1,N−3 > Fcrit, the Null Hypothesis is rejected (at 95%
confidence level) and a new RM is deemed to be emerging
and included in the model by separating its contributions (and
parameters) from those of all other previous RMs. The contributions of all concatenated RM model components are included
in the total model prediction. The application of this approach is
demonstrated in the following section using daily reported data
of Covid-19 confirmed cases in the US from March 11 until June
18 (the completion date of this manuscript), while the epidemic
is still ongoing.
III. RESULTS
We analyzed the publicly reported data of daily new Covid-19
confirmed cases in the US (database curated by Johns Hopkins
University) and the cumulative number of confirmed cases since
March 11th 2020 (the day the cumulative cases first exceeded
1000 in the US) until June 18th 2020 (the completion date of this
manuscript), a period that covers a total of 100 days. Application
of the aforementioned methodology identified five latent Riccati
modules (RM) with distinct parameters A and B that are given
in Table I, along with the parameters K of Equation (2) and the
respective predictions of the maximum number of anticipated
cumulative cases due to each RM model component. Some other
key parameters of the five component RMs (e.g. the size and
timing of the peak infection rate for each RM) are also reported
in Table I. The timing of the peak infection rate (PIR) for each
RM is given by the expression:
T PIR = ln (K) /A (7)
and the corresponding PIR is determined by A and B as:
PIR = A2/ (4B) (8)
Equation (8) indicates the strong dependence of PIR on
A. Since the PIR value is critical for planning the clinical
management of the pandemic (lest the finite resources of the
healthcare system be temporarily overwhelmed). Equation (8)
underlines the importance of minimizing (i.e. controlling) A for
a given IP size Xmax = A/B. All these parameter estimates are
given in Table I for the five RMs, along with the time of their
earliest detection T det by the proposed algorithm. The units of
these parameter values are the following: A (days−1), B (days−1
210 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
Fig. 1. Cumulative confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and total concatenated-RM
model prediction (red), along with the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
cases−1), K (unitless), Xmax (cases), PIR (cases/day), T PIR
and T det (days since March 11th 2020).
The declining values of the estimated parametersAfor the five
RMs indicate that there is gradual reduction of the infectivity
rate, which may be partially due to the effect of the imposed
social-distancing and other mitigation measures (see Discussion). These parameter values are updated on a daily basis but
were shown to be rather stable away from the days of introduction of new RMs. The estimated parameters B for the five
RMs depend inversely on the size of the susceptible and exposed
population in the respective “infection pool” in combination
with the effect of mitigation measures (see Discussion). This
is consistent with the model-predicted maximum numbers of
confirmed cases for the five RMs. The total maximum number
of cumulative confirmed cases that is predicted by these five
RM components of the model is: 4,160,000 (substantially higher
than the current cumulative total of 2,191,100 cases). Of course,
this prediction is contingent upon the assumption that no new
infection waves will occur and be detected by the algorithm in
the future. In connection with this assumption, we note that the
F-statistic is rising recently and is approaching the critical value
that may trigger the detection of a new emergent infection wave.
Fig. 1 shows the cumulative number of confirmed cases in the
US since March 11th 2020 along with the total model prediction
and the predictions of the five RM components. The depicted
RM-decomposition of the time-course of the cumulative number
of confirmed cases offers useful insight into the time-course of
the epidemic unfolding over five major IPs (defined as the source
of statistically significant RMs) in the US between March 11th
and the present time (June 18th). Consistent with the estimates
shown in Table I, Fig. 1 indicates that the last RM model
component is expected to make the largest contribution to the
total number of confirmed cases, relative to the previous four
RMs (see Discussion).
The analysis of the daily new confirmed cases offers an
informative RM-decomposition that is shown in Fig. 2, along
with the actual time-series data and the total model prediction.
This result demonstrates the ability of the proposed approach to
Fig. 2. New daily confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and the total concatenatedRM model prediction (red), along with the predictions of the five RM
components (green-dashed, blue-dotted, purple-dot-dashed, browndotted, and black-dashed).
model multi-modal patterns of dynamic changes in the infectious
process due to merging of distinct infection pools – unlike
the unimodal patterns of the widely used SIR models. This
also allows the timely detection of emerging distinct waves of
infection (see Discussion).
The number of daily new confirmed cases due to each RM is
given by the expression:
ΔX (n) = A2K exp (−An) /{B[1 + K exp (−An)]2}
(9)
that exhibits a single peak at the PIR time-point T PIR (see
Equations (7) and (8)), which corresponds to the inflection point
of the respective sigmoidal curve and is half-way to the level
of the sigmoidal plateau (i.e. foretells the maximum value of
cumulative cases to be reached by each RM).
It is evident in Fig. 2 that the first four RMs have passed their
PIR time-points (see Table I). The last RM is expected to reach
its PIR time-point on Day 132 (i.e. on July 20th). This RM-based
model predicts that, unless a new IP is recruited in the near future,
the Covid-19 infection in the US will dip below 5,000 new daily
confirmed cases on Day 194 (i.e. on September 20th), as marked
with an arrow in Fig. 3 that shows the simulated prediction of
the five RM model components over the next 100 days (until
September 26th). It is evident in Fig. 3 that the infection wave
of the last RM is expected to be larger than the combined total
of the other four RMs (see Discussion).
The forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days
(provided that no new infection wave emerges) is shown in Fig. 4
and illustrates the dominant contribution of the last infection
wave that has not yet reached its inflection point (T PIR) that is
expected in 32 days (i.e. on July 20th).
A cyclical ripple is evident in the actual data of daily confirmed cases in Fig. 3 that is not accounted by the RM-based
model. It is probably due to time-varying influences related to the
weekly cycle of social life. The RM-based model is not expected
to account for such time-varying influences, although the use
of the fundamental Riccati Equation (1) can be extended in
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 211
Fig. 3. Forward prediction of the RM-based model for the new daily
confirmed cases in the US over the next 100 days (to September 26th)
made on June 18th (red line), along with the actual time-series data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
Fig. 4. Forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days (to September 26th) made on June 18th (red line), along with the actual data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
future work to time-varying coefficientsAin order to account for
these weekly variations. To examine the dominant frequencies
of these variations, Fig. 5 shows the frequency spectrum of the
residuals of the RM model prediction for the daily confirmed
cases that clearly depicts a 7-day spectral peak (located at
0.143 cycles/day).
Finally, since some take the view that simple curve-fitting
of the cumulative cases data to a sigmoidal expression may
be adequate, we examine whether a direct least-squares fitting
of the sigmoidal expression of Equation (2) to the time-series
data of cumulative confirmed cases may be able to yield a
reasonable approximation of the time-course of the data. The
result is shown in Fig. 6 and demonstrates the inferiority of
simple curve-fitting, both in terms of approximation accuracy
(by comparing with the RM-model approximation in Fig. 1)
and in terms of misleading parameter estimates: low infectivity
rate estimate of Asig = 0.065 and low prediction of maximum
number of confirmed cases: 2,120,000.
Fig. 5. The frequency spectrum of the residuals of the RM model
prediction for the new daily confirmed cases in the US that depicts a
7-day spectral peak at 143 millicycles/day.
Fig. 6. Direct least-squares fit (red line) of the cumulative cases of
confirmed Covid-19 patients in the US from March 11th to June 18th
(blue line with circles). The results are inferior to their counterparts from
the proposed RM-based modeling methodology that are shown in Fig. 1.
Fig. 7. Direct least-squares fit (red line) of the daily cases of confirmed
Covid-19 patients in the US from March 11th to June 18th (blue line with
circles). The results are inferior to their counterparts from the proposed
RM-based modeling methodology that are shown in Fig. 2.
For the data of daily confirmed cases, the direct least-squares
approximation is shown in Fig. 7 and demonstrates the inferiority of curve-fitting in terms of approximation accuracy (by
comparing with the RM-model approximation in Fig. 2) and the
fundamental inability of direct sigmoidal fitting to approximate
212 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
multi-modal phase-plots that can detect the emergence of new
major infection waves.
IV. DISCUSSION & CONCLUSION
A novel adaptive methodology for predictive modeling of the
time-course of daily and cumulative confirmed cases of Covid19 has been presented and its application to the reported data
for the US has been demonstrated. This methodology achieves
the decomposition of the time-course of the Covid-19 data in
terms of concatenated “Riccati Modules” (RM) and provides
potentially useful predictions as well as valuable insights into
the dynamic characteristics of the infectious process.
Specifically, the advocated approach detects the presence of
multiple overlapping “infection waves” that correspond to major
“infection pools” (IP) described by distinct and concatenated
RMs that are defined by the fundamental Riccati Equation (1) –
each with distinct parameters A and B that quantify the critical
dynamic aspects of the infectious time-course in the respective IP. The parameter A is the “infectivity rate constant” that
determines the initial exponential-like growth of the infection
and depends on the degree of contagiousness and the level of
contagious interactions in a given IP. In this sense, it is akin
to the “reproduction rate” of the conventional SIR models. The
parameter B depends on the size of the susceptible and exposed
population in each IP and also quantifies the degree to which
the gradually acquired “herd immunity” and mitigating factors/measures constrain the initial rapid growth of the infection
and eventually achieve its control according to the sigmoidal
time-course defined by Equation (2) reaching at its plateau the
maximum number of infections: Xmax = (A/B).
To achieve this RM-decomposition of the time-series data,
the proposed approach employs regression analysis in phasespace and statistical Hypothesis testing using an F-statistic (see
Methods) to detect the emergence of new infection waves at
a specified level of statistical significance. Running (adaptive)
estimates of the RM parameters are obtained at each time-point.
They were found to be rather stable away from the points where
new RMs are introduced into the model.
Analysis of Covid-19 daily data in the US from March 11th
to June 18th (when this manuscript was completed) yielded five
RMs that are concatenated as shown in Figs. 1 and 2. They
are deemed to represent the distinct dynamics of five infection
waves in major IPs that have the characteristics defined by
their respective parameters given in Table I. The small initial
RM-1 (possibly corresponding to the initial infection in the
Seattle area) is followed by the larger RM-2 and RM-3 (possibly corresponding to the rapid urban surge in New York City
and subsequently in other US urban centers and the Northeast,
respectively). The broader epidemic spread across smaller towns
and rural areas in the US, under local mitigation measures, may
correspond to RM-4 (slower growth and moderate size). The
emergence of the last and largest infection wave (described
by RM-5) was detected by the proposed algorithm on Day
60 (May 9th) and appears to coincide with the relaxation of
some mitigation measures across the US. The total number
of infections anticipated by the model is 4,160,000 (about
TABLE II
UNITS FOR MAGNETIC PROPERTIES
Vertical lines are optional in tables. Statements that serve as captions for the entire table do
not need footnote letters.
aGaussian units are the same as cg emu for magnetostatics; Mx = maxwell, G = gauss,
Oe = oersted; Wb = weber, V = volt, s = second, T = tesla, m = meter, A = ampere, J
= joule, kg = kilogram, H = henry.
double the current cumulative number), provided that there
will be no new RM added to the model because of Covid-19
spreading into a new IP or caused by significant change in the
current mitigation measures. Under the same key assumptions,
the current model predicts that the number of new confirmed
cases in the US will drop below 5,000 by September 20th (see
Fig. 3).
The results shown in Table I and Fig. 2 indicate an early
rapid reduction of the parameter A in successive RMs, which
plays a key role in determining the critical “stressor” of the
healthcare system, the Peak Infection Rate: PIR = A2/(4B),
provided that the parameter B is not drastically reduced. The last
RM anticipates its PIR to occur in 32 days (July 20th) without
exceeding the previous peaks of RM-1 and RM-2. It is worth
noting that the time between detection of a new infection wave
and its PIR increases with decreasing A.
Analysis of the daily confirmed cases shows the individual
contributions of the five RM components (see Fig. 2) and
demonstrates the versatility of the proposed approach to detect in
a statistically rigorous manner new emerging waves of infection
and be applicable to cases where the pattern of daily changes
is not unimodal. This constitutes an important advantage of
the proposed approach over the widely used SIR models and
other unimodal approaches. Another difference of the proposed
approach from the popular SIR model is that it does not take into
account the number of recovered cases and does not require full
immunity of the latter. To further explore this comparison, the
three equations of the classic SIR model can be combined in a
single nonlinear differential equation that takes the second-order
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 213
form:
d2Q/dt2 + k dQ/dt = s0b exp [−b Q (t)] (10)
where Q(t) is the integral from 0 to t of the infected fraction of
the population, k is the recovery rate, b is the infection rate and
s0is the initial size of the susceptible population. Equation (10)
indicates that the estimation of the unknown parameter b must
rely on iterative methods (which are far less robust and reliable
than regression utilized by the proposed approach) and that this
differential equation has only one stable equilibrium point when
Q(t)tends to infinity (a less flexible notion than the multiple finite
stable equilibrium points of the concatenated Riccati Equations
that are achieved by each RM when each reaches its individual
plateau for the respective Xmax = A/B). These comparisons
must be explored further in the future.
Regarding the cyclical variations that are evident in the timeseries data of daily confirmed cases, but not accounted by the
RM-based model (see Fig. 3), it is noted that the fundamental
Riccati Equation (1) can be extended in future work to timevarying coefficients that may account for the observed 7-day
cycle revealed in the spectrum of the residuals of the model
prediction (see Fig. 5). The 7-day cycle peaks at the end of each
week and may be due to increased social interactions during the
previous weekend (noting the average Covid incubation period
of 5 days).
It must be emphasized that the RM-based predictive modeling
is distinct from simple curve-fitting methods. This was demonstrated above by contrasting with the results of direct sigmoidal
least-squares fitting (see Figs. 6 and 7) and showing that the latter
may lead to serious mis-estimation of the key parameters of the
infectious process (e.g. much smaller infectivity rate estimate
and smaller predicted maximum number of confirmed cases) –
in addition to misconceptions regarding the dynamic structure
of the process (i.e. unimodal versus multi-modal phase-space
representation).
An interesting question arises with respect to the effect of
changing testing rates upon the obtained parameter estimates.
If the “true” incidence is Y(t), then the “apparent” incidence
due to a time-varying “testing rate function” f(t) is: X(t) =
f(t)Y(t). It can be shown that the “true” parameters A∗ and B∗
(corresponding to the unknown Y(t) values) are related to the
“apparent” parameter estimates A and B (obtained from the
available X(t) data) according to the expressions: A = A∗ +
f’(t)/f(t), and B = B∗/ f(t), where f’(t) = df(t)/dt. Since f(t)
ought to be positive and ≤1 for all times, then B is always an
overestimation of B∗, and A overestimates A∗ only when the
testing rate is increasing (f’(t) >0). For a constant testing rate,
A = A∗. For the estimated maximum number of cases, we have
the relation: Xmax = Y max [f(t) + f(t) / A∗].
This work (like others on Covid-19 predictive modeling) is
published under unique and unprecedented circumstances of an
ongoing pandemic, which render its validation open to the future
data that are publicly reported. The predictions made in this
paper will hold only if no new wave of infections occurs.
The proposed approach can be applied in the near future to
additional Covid-19 data from other countries or from various regions of the US in order to compare the obtained RMdecompositions (revealing the dynamic structure of infection
waves in these infectious processes) and the associated parameter estimates A and B of each RM. The distinct RMdecompositions for various countries/regions and the respective
parameter estimates may reveal valuable correlations with the
mitigation policies followed in each case to examine their effectiveness within each specific socio-cultural context in order
to guide future decision making by examining how much the
respective policies or socio-cultural conditions influence the estimated parameters A and B – and consequently Xmax = A/B
or PIR = A2/(4B).



NEW_PAPER


Diagnosis of COVID-19 from Chest X-Ray Images Using
Wavelets-Based Depthwise Convolution Network
Krishna Kant Singh and Akansha Singh
Abstract: Coronavirus disease 2019 also known as COVID-19 has become a pandemic. The disease is caused
by a beta coronavirus called Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). The severity of
the disease can be understood by the massive number of deaths and affected patients globally. If the diagnosis
is fast-paced, the disease can be controlled in a better manner. Laboratory tests are available for diagnosis, but
they are bounded by available testing kits and time. The use of radiological examinations that comprise Computed
Tomography (CT) can be used for the diagnosis of the disease. Specifically, chest X-Ray images can be analysed to
identify the presence of COVID-19 in a patient. In this paper, an automated method for the diagnosis of COVID-19
from the chest X-Ray images is proposed. The method presents an improved depthwise convolution neural network
for analysing the chest X-Ray images. Wavelet decomposition is applied to integrate multiresolution analysis in the
network. The frequency sub-bands obtained from the input images are fed in the network for identifying the disease.
The network is designed to predict the class of the input image as normal, viral pneumonia, and COVID-19. The
predicted output from the model is combined with Grad-CAM visualization for diagnosis. A comparative study with
the existing methods is also performed. The metrics like accuracy, sensitivity, and F1-measure are calculated for
performance evaluation. The performance of the proposed method is better than the existing methodologies and
thus can be used for the effective diagnosis of the disease.
Key words: coronavirus; COVID-19; deep learning; convolution neural network; X-Ray images
1 Introduction
A pandemic is an outbreak of a disease globally
affecting many populations. The world has witnessed
many pandemics in the 20th century. Flu viruses
are the major cause of pandemics. These viruses
show changing behaviour with the changing seasons
and thus their behaviour needs to be predicted for
  Krishna Kant Singh is with Department of ECE, KIET Group
of Institutions, Delhi-NCR, Ghaziabad 201206, India. E-mail:
krishnaiitr2011@gmail.com.
  Akansha Singh is with Department of CSE, ASET, Amity
University Uttar Pradesh, Noida 201310, India. E-mail:
akanshasing@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-05; revised: 2020-07-19;
accepted: 2020-07-28
prevention. Health professionals generally make the
correct predictions about most viruses. But some
viruses have exceptional behaviour and are difficult to
predict. Such viruses cause pandemics as humans do
not have the immunity to resist to such virus.
The latest coronavirus disease known as COVID-19
has appeared and spread extremely fast. Since its
discovery in December 2019 in Wuhan, China,
the disease has already spread over 199 countries
and territories. The Severe Acute Respiratory
Syndrome Coronavirus 2 (SARS-CoV-2) causes
COVID-19[1]. The virus is a Ribonucleic Acid (RNA)
virus from the Coronavirus family, most viruses from
this family cause common cold. The more severe
variety of coronaviruses is Severe Acute Respiratory
Syndrome Coronavirus (SARS-CoV) and Middle East
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 85
Respiratory Syndrome Coronavirus (MERS-CoV).
COVID-19 causes respiratory ailments ranging from
common cold to serious diseases like pneumonia. The
number of cases worldwide has reached 5 817 385
causing the deaths of 362 705 individuals as on May
30, 2020 as per the situation report published by
World Health Organization (WHO)[2]. The accurate
information about the emergence of COVID-19 is
still unknown. But the initial cases have established
links with the Huanan (Southern China) Seafood
Wholesale Market[3, 4]. The disease is contagious, and
the virus gets spread amongst humans via respiratory
droplets, physical contact, and also through fecal-oral
transmission[5]. Numerous cases of pneumonia of
unknown cause were reported in Wuhan, China in
December 2019. The cases showed similar clinical
characteristics with viral pneumonia[6]. The patients
suffering from COVID-19 infection are observed to
have serious pneumonia with abnormal observations
on chest Computed Tomography (CT) examination[7]
.
The unavailability of medicine for this disease requires
efficient diagnosis methods for controlling the disease.
Common cold to pneumonia is caused by a group
of viruses known as CoV. These diseases include
respiratory, enteric, renal, and neurological diseases.
These viruses are grouped into four genres namely
alpha-CoV, beta-CoV, gamma-CoV, and delta-CoV[8]
.
Figure 1 gives an overview of the disease.
The virus affects individuals from all age groups and
genders. A research study reveals that two groups of
people are specifically affected by this disease. The first
Fig. 1 Overview of COVID-19.
group of individuals are those who are above 60 years
old. The second group is of those individuals who
have some underlying medical condition like diabetes,
cardiovascular disease, and hypertension. The common
symptoms of COVID-19 include fever, dry cough, and
respiratory problems like shortness of breath, muscular
soreness, and fatigue. In some cases, diarrhoea and
vomiting are also reported. The severity of the disease
ranges from mild flu to pneumonia causing respiratory
ailments. The advance stage of the disease even
causes organ failures and Acute Respiratory Distress
Syndrome (ARDS) leading to the deaths of the patients.
The fast-paced human to human transmission of the
disease is a matter of great concern for the regulatory
authorities globally. The control of COVID-19 largely
depends on the diagnosis at the right time. The available
methods for diagnosis comprise of laboratory tests
like Reverse-Transcription Polymerase Chain Reaction
(RT-PCR), real-time RT-PCR (rRT-PCR), and Reverse
Transcription Loop-mediated isothermal Amplification
(RT-LAMP) test[9, 10]. The laboratory tests have some
limitations. Firstly, the test requires testing kits which
have limited availability in the supply chain. Secondly,
the test is time consuming due to the laboratory
processes involved. The X-Ray facilities are easily
accessible in all parts of the world and the results are
also produced at a fast pace. Therefore, the chest XRay images may be utilized for detecting the presence
of COVID-19. The development of an automated
method based on chest X-Ray images for support in
clinical decision making will be significant for the
disease control. According to WHO, the disease can
be controlled by stopping the chain of transmission.
Officials have reported that testing and isolation are the
two key actions that are useful in breaking the chain
of transmission. Therefore, the accurate diagnosis is
significant in controlling COVID-19.
The detection of COVID-19 can be done at an earlier
stage with chest images as compared to the PCR testing.
The chest X-Ray images can be analyzed by using
artificial intelligence techniques[11]
.
Numerous techniques for diagnosis of COVID-19
using machine learning techniques on radiological
images are available in the literature. A transfer learning
model for diagnosis of coronavirus from chest X-Ray
images is presented in Ref. [12]. Another method with
improved accuracy presented a segmentation-based
approach. The method classified the input images as
86 Big Data Mining and Analytics, June 2021, 4(2): 84–93
normal, viral pneumonia, and COVID-19[13]. A deep
learning-based model is applied on CT images for
detection of COVID-19. Some researchers have also
developed public datasets comprising of chest X-Ray
images of COVID-19 patients[14, 15]. A method named
COVID-Net is developed and applied on these public
datasets for diagnosis of COVID-19[14]. The use of deep
learning for diagnosis from the chest X-Ray images
provides good results. Deep learning models are being
widely used for medical image processing. In Ref. [16],
the detection of pneumonia is done using convolution
neural networks. In this paper, an automated method
for the diagnosis of COVID-19 from a deep network
is proposed. The proposed network utilizes the feature
generated by multiresolution analysis. The combination
of wavelet transforms along with the deep network
brings multiple advantages. The wavelet decomposition
is fed into the network. The network used is not the
traditional Convolutional Neural Network (CNN). A
depthwise separable network is utilized in this work.
2 Background
In this section, the wavelet technique and depthwise
convolution neural network are discussed.
2.1 Wavelet
Wavelet theory is a transform-based image processing
technique that makes use of Wavelet transforms.
Wavelets are derived from small waves of changing
frequency and limited duration[17]. These are useful
as they provide both temporal as well as frequency
information for images.
The 2D scaling functions, including '.x; y/,

H .x; y/,
V
.x; y/, and
D.x; y/, are required for
two-dimensional multiresolution analysis. All these
scaling functions are obtained by multiplying the onedimensional functions. The product of these produces
four two-dimensional separable scaling function and
separable “directionally sensitive” wavelets:
'.x; y/ D '.x/'.y/ (1)

H .x; y/ D .x/'.y/ (2)

V
.x; y/ D '.x/ .y/ (3)

D.x; y/ D .x/ .y/ (4)
These functions record the variance in horizontal,
vertical, and diagonal directions. The separabilty in
Eqs. (1)–(4) is the major cause of the directional
sensitivity. The computational complexity of the 2D
transform remains the same. The scaled and translated
basis functions are defined as
'j;m;n.x; y/ D 2
j=2'.2j
x  m; 2j y  n/ (5)

i
j;m;n.x; y/ D2
j=2
i
.2j
x  m; 2j y  n/;
i D fH; V; Dg (6)
The discrete wavelet transform of an image f .x; y/
of size M  N is
W' .jo; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/ 'jo;m;n.x; y/
(7)
W i
 .j; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/
i
j;m;n.x; y/;
i D fH; V; Dg (8)
where jo is an arbitrary starting scale and the
W' .jo; m; n/ coefficients define an approximation of
f .x; y/ at scale jo. W i

.j; m; n/ coefficients add
horizontal, vertical, and diagonal details for scales
greater than jo. Generally, jo D 0 is selected and N D
M D 2
j
so that j D 0; 1; 2; : : : ; j  1, and m D n D
0; 1; 2; : : : ; 2j  1.
Given W' and W i

of Eqs. (7) and (8), f .x; y/
is obtained by performing inverse discrete wavelet
transform:
f .x; y/D
1
p
MN
X
m
X
n
W'.jo; m; n/'jo;m;n.x; y/C
1
p
MN
X
iDH;V;D
X1
jDjo
X
m
X
n
W i
 .j; m; n/ i
j;m;n.x; y/
(9)
2.2 Depthwise separable convolution neural
network
The standard convolution layer of a neural network
has large number of parameters. This leads to
over fitting of the network. Depthwise convolution
and depthwise separable convolution layers overcome
this problem. These convolution layers reduce the
computational cost as well as the number of parameters.
The depthwise convolution layers can reduce the
computational cost and the parameter space. The
reduction in parameters in no way reduces the efficiency
of the network. The standard convolution is divided into
depthwise and pointwise convolution[18]. The depthwise
convolution is responsible for applying convolution on
every input. The output of depthwise convolution is
merged using pointwise convolution. The l-th layer of
the network having a 3D input tensor x
l
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 87
x
l 2 I
HlW lDl
where H; W; and D represent the
height, weight, and depth of the input vector. The
convolution layer output .yi
lC1j
lC1;d / represents the
point at location .i; j / in d-th channel and l C 1 layer.
This can be computed using
yi
lC1j
lC1;d D
X
D
dD0
fd
X
H
iD0
X
W
jD0
fi:j  x
l
i
lC1j
lC1;d
(10)
where fd is a pointwise filter of size 1  1.
The depthwise separable convolution performs the
operation in two steps. In the first step, a depthwise
convolution is applied on the input. Thereafter, the
pointwise convolution is applied on the output of
the depthwise convolution. The spatial correlations
are obtained from depthwise convolution and the
channel wise correlations are obtained from pointwise
convolution. The combination of these two forms the
feature map.
3 Proposed Method
The proposed method is based on depthwise separable
convolution network and spectral pooling using wavelet
transforms. The network is formulated by combining
multiresolution analysis with deep learning. The
traditional CNN layers suffer from over fitting and high
computational cost due to large number of parameters
generated at each layer. Powerful properties of the
Discrete Wavelet Transform (DWT), spectral domain,
spectral pooling, and spectral parameterization of
convolutional layers are utilized as a means to improve
CNNs by improving training convergence, allowing
flexible pooling dimensions, and retaining or improving
competitive classification accuracies.
The filters in the network learn from the spectral
domain instead of the spatial domain. The low
frequency spectrum of the input contains most of
the details and the high frequency spectrum contains
noise information. This non-uniformity of spectrum
power enables the removal of high frequencies do
minimal damage of input information. Spectral pooling
truncates the spectral representation of an image–kernel
product. Simply put, spectral pooling is simple lowpass filter. This technique is desirable because it can
be combined with the convolution theorem to achieve
fast training results. The convolution theorem states
that convolution can be used considerably by being
performed in the spectral domain as element-wise
multiplication. The details of the proposed network are
discussed in the following section. Given an image x,
it can be divided into four subbands xLL; xLH; xHL;
and xHH using the Discrete Wavelet transform with
convolution filters fLL; fLH; fHL; and fHH. These filters
have fixed parameters and a stride of 2. The stride of
two provides the down sampling of the result obtained
from convolution. These four sub-bands are fed into
the depthwise separable network for further processing.
The flow chart of the proposed method is shown in
Fig. 2.
The proposed method comprises of the following
steps:
(1) Input image: The COVID-19 dataset comprises
of the chest X-Ray images. These images are used for
the detection. The images are of different sizes, thus
they are resized to 3  224  224 .
(2) Image normalization: The input images are
normalized prior to any further processing. Normalized
images are enhanced images with no errors due to
lightening conditions.
(3) Image decomposition with wavelet: This step is
one of the most significant steps that convert the spatial
domain input to frequency domain. The input images
are decomposed into four sub-bands. Haar Wavelet
transform is used to decompose the image into sub
bands. The dataset is augmented and split into training
and testing set.
(4) Convolution layers: This step comprises of three
standard convolution blocks. The input is convolved in
these three blocks.
(5) Spectral pooling and batch normalization:
Next layer is the pooling layer which combines the
features from the output of the different layers. In
this paper, average pooling is performed in which the
convolution is followed by down sampling.
(6) Output layer: The next layer is the fully
connected layer. The softmax optimizer is applied in the
last layer to predict the output.
(7) Grad-CAM output visualization: The
prediction output obtained from the network needs
to be visualized for building trust on the network for
making diagnosis decision. The Grad-CAM utilizes the
gradient information from the last layer of the network
to visually represent the class activation map.
(8) Diagnosis decision: Finally, any given input
chest X-Ray image is classified into one of three classes,
i.e., normal, COVID-19, or viral pneumonia.
The details of the network architecture are discussed
in the following sections.
88 Big Data Mining and Analytics, June 2021, 4(2): 84–93
Fig. 2 Proposed methodology.
3.1 Network architecture
The input layer of the network is fed with chest X-Ray
images. The network comprises of eighteen convolution
layers. The network comprises of a mix of regular and
depthwise convolution layers. The batch size is fixed
to eight. There are six regular and twelve depthwise
layers. Multiresolution analysis is integrated into the
network after the first convolution block. Between the
convolution layers, max pooling layers are added. The
batch normalization layers are used to solve the local
minima problem by mapping the activations to the mean
of zero and unit variance. It also makes the convergence
for the network fast[19]. The over fitting problem is
solved by using a dropout of 0.2[20]. The specifications
of the network layers are given in Table 1.
3.1.1 Convolution layer
Given an input vector with n components X D fx1;
x2; x3; : : : ; xng 2 R
n
, the output vector Y D fy1;
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 89
Table 1 Model summary.
Layer type Output shape Number of parameters Kernel size Dropout Number of filters
Input .224; 224; 3/ 0  0
Wavelet Lambda .112; 112; 12/ 0 3  3 0 4
Separable Conv 2dx2 (ReLU) .14; 14; 256/ 3436 3  3 0 32
Batch normalization .14; 14; 256/ 1024  0
Maxpooling 2d .7; 7; 256/ 0  0
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 68 096 3  3 0 64
Batch normalization .7; 7; 256/ 68 096  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 1024 3  3 0 128
Batch normalization .7; 7; 256/ 512  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 102 272 3  3 0 256
Batch normalization .7; 7; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 256/ 133 888 3  3 0 256
Batch normalization .3; 3; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 512/ 267 264 3  3 0 512
Batch normalization .3; 3; 512/ 2048  0
Maxpooling 2d .1; 1; 512/ 0  0.2
FC1 (ReLU) (512) 262 656 0.7 512
FC2 (ReLU) (128) 65 664 0.5 128
FC3 (ReLU) (64) 8256 0.3 64
FC4 (ReLU) (32) 2080 0.2 32
FC5 (ReLU) (3) 99 0 3
y2; y3; : : : ; yng 2 R
n
.
yi D
X
j2Ni
wj xj (11)
where Ni
is a set of indices of neighbours xi and
the weight wj . The computation of yi
is equivalent to
convolution operation of the input by the weight vector.
Thus it can be written using the convolution operator
as
y D x  w (12)
where w D .w0; w1; : : : :; wn1/ 2 R
n
.
3.1.2 Pooling layer
After the convolution layer is the pooling layer. In
this paper, average pooling is used in connection with
multiresolution analysis. The output of the pooling layer
is the vector with fewer number of components as
compared to the input vector. The output of the pooling
layer is defined as
yj D
1
p
p
X1
kD0
xpjCk; y 2 R
m (13)
where p is the support of pooling and m D
n
p
.
The value of p defines the value by which the number
of parameters is reduced. For example, if the value of
p is 3, then the number of parameters is reduced to
one third by taking triplets in average. Pooling can be
written in the form of down sampling as follows:
y D .x  p/ # l (14)
Average pooling performs convolution by p followed
by down sampling by l.
3.2 Activation function
The activation function used is the ReLU function.
Activation function is significant in the convergence
of the network. ReLU is the rectified linear activation
function, and is the most used activation function[21]
.
This function overcomes the vanishing gradient
problem and makes the model more efficient and faster.
Mathematically, it can be expressed as
f .x/ D max .0; x/ (15)
Thus, the function brings all negative values to
zero whereas positive values remain as it. The ReLU
function is used in the hidden layers. In the last
layer, softmax activation function is used. The softmax
function is
Softmax .xi/ D
e
90 Big Data Mining and Analytics, June 2021, 4(2): 84–93
where xi
is the observed output and divided by the sum
of all possible output.
3.3 Training method
The training of the network is one of the most
significant tasks. The weight vector of the network is
updated to minimize the value of the cost function.
The probabilities over the classes for classification
are computed. The loss function used in this paper
is categorical cross entropy[22]. The other important
task in training is to balance the dataset. The data are
balanced with the help of data augmentation. With data
augmentation, new samples are generated. A rotation
angle of 15 degrees to C15 degrees is used for
augmenting the dataset. The optimization method used
here is Adam optimization with weight decay. This
leads to faster convergence and higher performance
of the network. The other parameters are number of
epochs which are chosen to be 100 and the batch
size is set to 8. The model is evaluated using metrics
like F1-score, precision, validation accuracy, sensitivity,
specificity, etc., which is detailed in Section 5.
4 Dataset
The dataset used for the experiments comprises of chest
X-Ray images of COVID-19, viral pneumonia patients,
and healthy individuals. The annotated Post Anterior
(PA) view of chest X-Ray images is used[23, 24]. A total
of 1439 images from the three classes are available in
the dataset. The number of images of COVID-19 is 132;
viral pneumonia is 629; and the number of images of
normal case is 678. The images are of both males and
females from all over the world. For model building
process, we split the dataset into training and test set
that 80% for training the model and 20% for validation
purpose. Table 2 presents the distribution of the images
present in the dataset. The sample images depicting
normal, viral pneumonia, and COVID-19 patients are
shown in Fig. 3[19]
.
Table 2 Distribution of images in train and test sets.
Image type Train Test
Normal 542 136
Viral pneumonia 503 126
COVID-19 106 26
Total 1151 288
5 Experiment and Result
The implementation of the proposed network is done
using Keras library in Python. The experimental setup
and results are presented in this section. The model
was tuned to obtain the best results. The decomposition
of the image was done using Haar wavelet transform.
A total of twelve separable and six convolution layers
are used. Adam optimizer with weighted decay is
used for optimization of the network. The quantitative
analysis of the results obtained is done using sensitivity,
precision, and F1-score[25]. These metrics are computed
using Eqs. (17) – (20). Sensitivity represents the
correctness of classification. It can be computed as
Sensitivity D
TP
TP C FN
 100% (17)
The misclassifications are reported by precision. If
there are no misclassifications, the precision will be
100%. F1-score is the harmonic mean of precision and
sensitivity. The F1-score of value one represents perfect
precision and sensitivity.
Precision D
TP
TP C FP
 100% (18)
F1-score D 2
precision  sensitivity
precision C sensitivity
 100% (19)
Accuracy D
TP C TN
TP C TN C FP C FN
 100% (20)
where TP; FP, and FN represent the true positive,
false positive, and false negative, respectively. The
confusion matrix for the three classes normal, COVID19, and viral pneumonia is shown in Table 3. The values
Fig. 3 Sample images of normal, viral pneumonia, and COVID-19 infected patients[9]

Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 91
Table 3 Confusion matrix.
Disease type Predicted result
Normal COVID-19 Viral pneumonia
Normal 130 1 5
COVID-19 1 24 1
Viral pneumonia 3 1 122
obtained for the proposed method are summarized in
Table 4.
Figure 4 shows the Grad-CAM for the three classes.
The Grad-CAM visualization is used along with the
classifier predictions for diagnosis of the disease
accurately.
The performance of the proposed method is
Table 4 Value for the proposed method. (%)
Disease type Accuracy Precision Sensitivity F1-score
Normal 96.53 97 96 96
COVID-19 98.61 92 92 92
Viral pneumonia 96.53 95 97 96
Fig. 4 Grad-CAM visualization of (a) normal, (b) COVID19, and (c) viral pneumonia.
compared with other existing methods. The results are
compared with four latest techniques that have used
deep learning models for the diagnosis of COVID-19
using chest X-RAY images. The results are summarized
in Table 5. The analyses of the results reveal that the
proposed method outperforms the existing methods.
DarkCovidNet uses You Only Look Once (YOLO)
network with 17 layers for detection of COVID-19
from chest X-Ray images[26]. The performance of
DarkCovidNet is average with an overall accuracy of
approximately 87%. The second and third methods are
based on EfficientNet[27]. Two variations of the method
are presented namely flat and hierarchical. These two
methods have an overall accuracy of approximately
93%. The DeTraC-ResNet18 performs better than these
methods and has an overall accuracy of 95.12%. The
proposed method has further improved the overall
accuracy. The overall accuracy of the proposed method
is 95.83%. The bar graph of the comparative study is
shown in Fig. 5.
6 Conclusion
The paper presented an automated method for
detection of COVID-19 from chest X-Ray images. An
improved depthwise convolution network is designed
that incorporates spectral analysis. The convolution and
pooling layers are reformulated as a generalized case of
filtering and down sampling. With this reformulation,
multiresolution analysis is integrated with depthwise
Table 5 Comparative analysis. (%)
Method Accuracy Precision Sensitivity F1-score
DarkCovidNet 87.02 89.96 85.35 87.37
Flat-EfficientNet B3 93.34 93.93 93.96 93.94
HierarchicalEfficientNet B3 93.51 93.93 93.55 93.73
DeTraC-ResNet18 95.12 93.36 97.91 95.58
Proposed 95.83 95.67 96.07 95.63
Fig. 5 Comparative study.
92 Big Data Mining and Analytics, June 2021, 4(2): 84–93
network. The input images are decomposed using
Haar wavelet for multiresolution analysis. The wavelet
is applied in the form of fixed weight filters. The
developed model is applied on chest X-Ray images for
detection of COVID-19 disease. The model classifies
the images into three classes: normal, viral pneumonia,
and COVID-19. A comparative study is also performed
to evaluate the performance of the proposed method.
The developed methodology can be used for diagnosis
of COVID-19 from chest X-Ray images. The use of XRay images will help in controlling the disease.



NEW_PAPER



Effect of E-Learning on Public Health and Environment During
COVID-19 Lockdown
Avani Agarwal, Sahil Sharma, Vijay Kumar, and Manjit Kaur
Abstract: E-learning is the most promising venture in the entire world. During the COVID-19 lockdown, e-learning is
successfully providing potential information to the students and researchers. In developing nations like India, with
limited resources, e-learning tools and platforms provide a chance to make education available to middle and low
income households. This paper gives insights about three different online services, namely Google Classroom,
Zoom, and Microsoft Teams being used by three different educational institutions. We aim to analyze the efficiency
and acceptability of e-learning tools among Indian students during the COVID-19 lockdown. The paper also aims to
evaluate the impact of e-learning on the environment and public health during COVID-19 lockdown. It is found that
e-learning has potential to reduce carbon emissions, which has beneficial impact on the environment. However, the
mental health is impacted as e-learning may lead to self-isolation and reduction in academic achievements that may
lead to anxiety and mental depression. Due to usage of electronic devices for learning, the eyes and neck muscles
may be put in strain, having deleterious effects on physical health.
Key words: e-learning; environment; health; COVID-19
1 Introduction
E-learning and online education provide an opportunity
for students to increase their knowledge base in a
flexible environment while using limited resources
and capital. For a developing country like India,
online tools can help students achieve productive and
diverse education by incorporating various themes in
different areas of interest. The online platforms are
slowly gaining popularity due to the improvements in
design, visuals, ease of navigation, and quality content.
  Avani Agarwal and Sahil Sharma are with the Department
of Computer Science, Thapar Institute of Engineering and
Technology, Patiala 147001, India.
  Vijay Kumar is with Department of Computer Science and
Engineering, National Institute of Technology, Hamirpur,
Himachal Pradesh 177005, India.
  Manjit Kaur is with Department of Computer Science
Engineering, School of Engineering and Applied Sciences,
Bennett University, Greater Noida 201310, India. E-mail:
manjit.kaur@bennett.edu.in.
To whom correspondence should be addressed.
Manuscript received: 2020-06-15; accepted: 2020-08-05
Many studies have shown that e-learning can help
improve the knowledge base and make understanding
of concepts easier by providing bite-sized, collaborative,
and interactive content. Studies have proven that a
personalized and assisted learning-based curriculum is
better than the traditional curriculum. The best quality
of education can be provided through e-learning tools by
personalizing the guidance and mentorship according to
the needs of students[1, 2]. The e-learning platforms give
students flexibility and empower students by allowing
them to learn at their own pace and schedule. A student
can choose the time and day to learn or consume the
content provided on these various platforms. We have
material available at our disposal, which can be either
free of cost or paid, open for a lifetime or a limited
amount of time.
Moreover, the content consumed on an online platform
is consistent and standardized in comparison to the
different teaching styles of professors. A diverse range
of options are provided to users by e-learning[3, 4]. Open
online course providers are edX, Udacity, and Coursera,
and Udemy provides both free and paid online courses
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 105
that cover various topics from diverse fields. These
online platforms not only fulfill the current need of
educators but also create new demands which then
help improve the current services being provided to
students[5]. There are websites like GeeksforGeeks
and Tutorials point which enjoy popularity among
engineering students. YouTube also provides the content
to students pursuing different majors and fields, for
example, Khan Academy is one of such YouTube
Channels that helped build basic concepts of high school
students by keeping the material easy to understanding,
participation, and interaction. The YouTube channel
posts videos after thoroughly researching the topics to
help students understand even the small and hidden
concepts of mathematics[6]
.
In India, universities and colleges integrate the Internet
and web pages into classroom teaching. Teaching
staff makes lecture slides, assignments, and important
notifications available to the students via a course site.
The study material may be downloadable as a PDF file
or a PowerPoint file. Students may participate via onlinediscussion forums and examinations may be conducted
by using an e-learning tool. However, despite the
advancing technologies in higher education, institutes
have failed to incorporate the e-learning practices in
main-stream activities and tap the benefits of online
learning[7, 8]. The teachers may be interested in adopting
online tools, however the student’s attitude and aptitude
learning towards online platforms, standardization, and
interactive content of an online platform play critical
roles in determining the behavior roles of students
towards the e-learning environment[9–12]
.
Usually the mode of instruction through e-learning
platforms is designed by professionals who lack the
knowledge of psychological aspects of the domain
on students. Quality of interactive content needs to
be controlled and updates regularly to capture the
interests of the students. A learning context model helps
realize adaptive technological implementations and
personalizing learning environments. Such environments
improve the quality and increase the quantity of learnings
of the students[13]. In the recent years, robots have helped
increase learning in Science, Technology, Engineering,
and Mathematics (STEM) concepts. A constructionbased approach which collaborates educational robots
can be used to teach complex principles and algorithms
like that of computer science programming languages.
LEGO multi-robots may be used for construction-based
approach towards collaborating learning[14]
.
The main objective of this paper is to evaluate the
impact of e-learning on the environment. This paper
also evaluates the effects of e-learning on health of
the students and researchers. Finally, the case study
of e-learning tools adopted in India during COVID-19
lockdown is also considered.
The remaining paper is organized as follows: Section
2 discusses the impact of e-learning on environment.
Section 3 discusses the implication of e-learning on
social life. Section 4 presents the case study of e-learning
during COVID-19 lockdown. Section 5 concludes the
paper.
2 Impact of E-Learning on Environment
E-learning can effectively reduce the energy usage and
emission of carbon dioxide. According to a study in the
Netherlands, e-learning not only has potential to reduce
carbon emissions but also helps decrease the carbon
footprint and carbon impact of students and travel staff.
Moreover, e-learning not only reduces cost and time
but also is helpful to restore the environment. It is also
helpful to eliminate the necessity of traveling from one
place to another. There are some impacts on environment
due to e-learning[15]
.
2.1 Impact on forest
According to National Wildlife Foundation, 60% of
schools and universities’ waste is paper. Sixteen trees
are needed to generate the one-ton paper. The recycling
of ten tons paper is equivalent to the use of 100 barrels
crude oil[16]. E-learning not only reduces the cutting of
trees for paper generation but also reduces the resource
required for recycling the paper. The registration,
administration, curriculum, and study materials are
digitalized and will also reduce 50% of students’ cost.
2.2 Impact on air
University of West Georgia studied that if hundred
students did not travel to schools/universities, carbon
dioxide emissions may be reduced by 10 tons. The
study of the Netherlands reported that e-learning reduced
the percentage of carbon dioxide emissions and carbon
footprint of students and staff[15]. As per literature, 350
million printer’s cartridges became dead every year
and 1000 years are required to decay these cartridges.
These materials can be easily eliminated through the
e-learning[16]
.
3 Implication of E-Learning on Social Life
The e-learning contents are responsible for solving the
environmental issues. However, it can significantly affect
106 Big Data Mining and Analytics, June 2021, 4(2): 104–115
the social and mental health of students[16]
.
3.1 Impact on mental health
The excessive exposure of electronic device greatly
affected the mental health of users. According to
American Psychiatric Association, the extreme use of
e-learning may lead to social isolation. The e-learning
not only reduces the academic achievement but also is
responsible for mental depression. The e-learning is also
responsible for sleep deprivation due to the deadline of
assignment submissions. According to Harvard analysis,
it is observed that sleep deprivation has direct relation
with the academic outcomes.
3.2 Impact on physical health
The study of materials and completion of assignment on
digital media require a lot of time on electronic devices.
The excessive use of electronic device has a great effect
on physical health of users. These are responsible for
mortality rate due to over-sitting on electronic gadgets.
The eyestrain and muscle injuries may be possible due
to overuse of computers.
4 E-Learning Tools Adopted During
COVID-19 Lockdown in India
On March 25th, 2020, India’s Prime Minister
Mr. Narendra Modi imposed a nationwide lockdown as
a countermeasure to control the coronavirus pandemic.
The lockdown was later extended on April 11th, 2020
in various states of India due to the increase in the
number of coronavirus patients across different regions
of the country. Universities, schools, and educational
institutions were closed, and students went back to their
homes. Hence, the educational institutions had to rely
on e-learning and online education tools to provide
students the necessary study material, schedule lectures,
and to conduct examinations. The lockdown acted as a
catalyst to help teachers adopt online tools. As of April
2020, according to the Ministry of Human Resource
Development, India, platforms like Diksha, e-pathshala,
NROER, NIOS, e-yantra, and FOSSEE are endeavors
of the government to help educate the masses online.
SWAYAM, an initiative by the Indian government, gets
50 000 views daily. Some other online methods adopted
in different universities across India are (1) video and
audio meetings, tools like Zoom, Loom, Gotomeeting,
Skype, Bluejeans, Webex, and Google meet are being
used; (2) discussion and collaboration boards make use
of slack and flock; (3) storage and sharing files are
supported by Dropbox and Nextcloud; and (4) document,
presentation, spreadsheet, and videos are made using
G-suite, Prezi, GitBook, Confluence, Office365, and
Adobe Acrobat. With teachers adopting and using elearning techniques and tools to educate students, we
aim to analyze the efficacy and acceptability of teaching
aids provided and adopted among students of educational
institutions, during the COVID-19 lockdown in India,
by conducting a survey in three different educational
institutions — Google Classroom, Zoom, and Microsoft
Teams. The objective was to analyze the students are
willing to adopt e-learning practices as a part of their
classroom learning by conducting surveys in various
educational institutions.
While conducting the surveys at the three educational
institutions, it was presumed that the students had an
internet connection, access to a mobile or a laptop,
previous knowledge to operate a mobile phone or
personal digital device, understood the default language
of the platform, and the sampling done can be mapped
to larger scales with minimum errors.
Case study 1: Thapar Institute of Engineering and
Technology (TIET), Patiala, India
Thapar Institute of Engineering and Technology is a
private engineering college located in Patiala, Punjab,
India. The educational institution offers various courses
in different fields of engineering. The traditional methods
used for classroom teaching are whiteboard, blackboard,
and a smart board that enable teachers to display
presentations and write notes. In the laboratories,
computers and necessary hardware and software
are provided to students for experimentation and
performing assignments. 75% attendance is mandatory
to pass a course. Each course has an official website
where course coordinators post important information,
syllabus, marking scheme, lecture slides, and laboratory
assignments. Details regarding quizzes and tests are
notified to students via group representatives or via
an update on the course site. Mid-semester tests and
end-semester tests are conducted every semester, which
are scheduled according to a date sheet that is made
available on the web portal— Webkiosk, which is
allocated to every student. Apart from these official
websites, students have access to myHerupa, an initiative
taken by Thapar students, where updates regarding
coursework for each subject are made available for
the first-year, second-year, and third-year engineering
students. During the COVID-19 lockdown, the college
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 107
was temporarily shut down. All classroom activities
and lectures were suspended on campus. Students
and teaching faculty members went back to their
homes; many situated far from college. The teachers
of the university used e-learning tools and methods to
provide education online for students. Lectures were
pre-recorded and shared via WhatsApp and Google
Drive links. Videos of laboratory assignments were prerecorded and uploaded on course sites. Many teachers
scheduled live online lectures using Zoom application
to make material accessible to students. Zoom Video
Communication provides a remote conferencing service.
It allows video conferencing of 100 participants up to
forty minutes free of cost. Paid subscriptions are also
available to allow more participants and to increase the
time limit. The service also allows one-to-one video
conferencing and group conferencing, and allows users
to message all members of a meeting at once or message
a selective group of people, providing stimuli to activate
students’ auditory and visual senses, thus enhancing and
replicating their in-person interactions[9, 10]. Slides were
uploaded on the course site, and students were notified.
For the courses, Image processing (UCS615) and
Innovation and Entrepreneurship (UTA012), the thirdyear students pursuing the BEng degree in computer
science submitted their assignments via Google forums.
A Google form was then circulated among the students
of the Thapar Institute of Engineering and Technology,
where students answered questions regarding the elearning platforms used by educators to impart education
online (see Figs. 1–3).
Case study 2: National Institute of Technology,
Hamirpur (NIT-H), India
National Institute of Technology is a public college
located at Hamirpur, Himachal Pradesh, India. The
Ministry of Human Resource Development, India
funds it. It is an engineering college for undergraduate
students in various engineering courses. The on-campus
practices include classroom teaching using tools such
as whiteboards and blackboards. Teachers sometimes
use slides to deliver their lectures. Apart from these
tools, there is a web portal for students, which
notifies them about their semester grades. All relevant
information is circulated using messaging applications
like WhatsApp. The use of smartphones helps make
material accessible to students[11]. To make study
material available and to conduct tests for the first-year
students pursuing the MEng degree in Computer
Vision and Image Processing during the COVID-19
lockdown, Google Classroom has been adopted by
Fig. 1 Most important feature of e-learning for Thapar Institutes.
Fig. 2 Mode of preference for learning during COVID-19 lockdown.
108 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Fig. 3 Response to the question of whether e-learning
methods should be adopted in daily classroom teaching.
the institute. To use this platform, a user has to sign
into the Google Classroom. While using the G Suite
for education account, the user clicks on whether they
are a teacher or a student. The G Suite account is set
up by an accredited college. Using Google Classroom
services, slides are uploaded, and assignments are
given to the students. This study material is available
to the students via Google Classroom, and they turn
in their assignments by submitting them to a private
electronic mail account. Video links are also provided
using Google Classroom. The marks and grades of
students are made available on the platform. Timed and
pre-scheduled quizzes are also being conducted via this
platform. Computer Vision and Image Understanding
assignments were submitted via the Google Classroom
platform. A survey was conducted by circulating a
Google forum among the first-year students pursuing the
MEng degree in computer vision to gain the feedback
and viewpoint of students on e-learning tools and
teaching aids being provided during the COVID-19
lockdown (see Figs. 4–6).
Case study 3: Manav Rachna International School,
Mohali, India
Manav Rachna International School is a private school
for primary and secondary education. The school has
traditional tools like whiteboards and blackboards to
teach students from Class One to Class Ten. The
school also has smart boards, smart class, and projector,
which allow teachers to display slides, play videos,
and make interactive content for the students. The
pupils of a class make notes in their notebooks. These
notebooks may be evaluative or checked by an assigned
teacher. During the COVID-19 lockdown, the online
Fig. 4 Best feature of Google Classroom according to the National Institute of Technology, Hamirput students.
Fig. 5 Online education tool preferred by NIT-H students.
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 109
Fig. 6 Response towards the e-learning methods in NIT-H.
education tool used is Office365, a solution provided
by Microsoft. The products provided by Office365
to educators and teachers include Outlook, Teams,
Excel, Word, PowerPoint, OneNote, Publisher, and
Access, according to the official Office365 website.
The school is using the e-learning tool Teams provided
by Office365. The lockdown initiated the process of
providing official IDs to teachers and students using
manavrachna.net. The teachers can make various teams
for different classes. The chat option allows teachers
to chat with parents and students either one to one,
or by making a group of all students or selected
students. The assignment section provided by Teams
allows teachers to post assignments. Its design notifies
teachers if a student has viewed the assignment, has
turned in the assignment, and if the student has not
opened the assignment by displaying view, turned in
and not turned in, respectively. The students can submit
their assignments by clicking on the add work button
to upload their solved assignments. The class notebook
section allows students to solve mathematics questions
easily due to user-friendly design. It allows the teachers
to view all the notebooks at once. However, students can
only view their notebook. The quizzes and tasks assigned
may be timed, and time bounds are facilitated by the
class notebook section. The files tab allows the teachers
to post relevant study material or reading material for
students to view. Along with these tabs and options,
the post tab is used to view all the notifications, tasks,
and assignments uploaded by the teachers of different
subjects for a team. The students from Class One to
Class Nine were surveyed to gain insight about the
acceptability of e-learning tools being used to combat
COVID-19 lockdown among young children, aged 5 – 15
years old.
4.1 Results from case study 1: Thapar Institute of
Engineering and Technology
The students pursuing the BEng degree in different
majors at the Thapar Institute of Technology were
surveyed. Out of 167 students surveyed, 126 were males
and 41 females. 43.1% of students surveyed were thirdyear students going to the fourth year while 31.1%,
21%, and 4.8% of students surveyed were the firstyear, second-year, and fourth-year students, respectively.
Although the number of female students surveyed is
significantly less than that of male students, the modal
choice of preferences for every question asked on the
survey was the same for the two genders. Hence, it can
be said that gender does not influence e-learning.
The survey was conducted in April 2020 and questions
included the most important feature for students for an
e-learning platform, there preferred choice of online
education tools, how often were users using Zoom
application to view live college lectures on a weekly
basis, if users were satisfied with the e-learning methods
adopted by their institution, and if the user thinks that
educational institutions should adopt tools provided
by e-learning platforms on a daily basis. 118 students
out of 167 students regarded the quality of services
provided by e-learning platforms as an important feature,
while 101 students and 81 students were in support of
ease of accessibility and user interface, respectively.
Other students regarded the price point of e-learning
tools to be the most important feature of an e-learning
platform. 70.7% of students surveyed preferred prerecorded video lectures provided via YouTube links
as the most convenient e-learning tool. Pre-recorder
lectures provided via Google Drive links and Slides
uploaded on course sites enjoyed a majority of 71
students and 77 students, respectively. It is observed
that 33.5% of students are satisfied with e-learning tools.
However, 32.9% of students are not satisfied with these
tools. 52.7% of students agreed on using the Zoom
application to view live lectures at least three times
a week. The majority of the students (60.5%) were
not satisfied with the e-learning methods adopted by
the institute. However, 49.7% of students thought that
educators should try to utilize tools provided by online
education platforms daily (see Table 1).
110 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 1 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Thapar Institute
of Engineering and Technology.
Item No. Item in detail
Number of
students
(max nD 167)
Number
of males
(nD126)
Number of
females
(nD41)
Model
Distribution of
students
1 First-year students 52 32 20
–
2 Second-year students 35 25 10
3 Third-year students 72 61 11
4 Fourth-year students 8 8 0
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
User interface is the most important feature of
e-learning platforms 81 61 20
Quality of service is
the most important
feature of elearning platforms
2
Quality of service is the most important feature
of e-learning platforms 118 93 25
3
Ease of access is the most important feature of
e-learning platforms 101 77 24
Preferred choice
of e-learning tool
during COVID-19
lockdown. (Multiple
choice correct)
1
Pre-recorded lectures shared via YouTube links
are a preferred choice of online education tools
during COVID-19 lockdown.
118 95 23
Pre-recorded
lectures shared
via YouTube links
are a preferred
choice of online
education tools
during COVID-19
lockdown.
2
Pre-recorded lectures shared via Google Drive
links are a preferred choice of online education
tools during COVID-19 lockdown.
70 55 15
3
Google Slides uploaded on the official course
site are a preferred choice of online education
tools during COVID-19 lockdown.
77 60 17
4
Live lectures using Zoom application are the
preferred choice of online education tools
during COVID-19 lockdown.
37 29 8
How frequently
was the Zoom
application used
weekly to access
lectures? (Single
choice correct)
1
Zoom application used at least thrice a week to
access live lectures. 88 65 23
Zoom application
used at least thrice
a week to access
live lectures.
2
Zoom application used twice a week to access
live lectures. 30 22 8
3
Zoom application used once a week to access
live lectures. 49 39 10
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Not satisfied with the e-learning methods
adopted by the institute during COVID-19
lockdown.
101 79 22
Not satisfied with
the e-learning
methods adopted
by the institute
during COVID-19
lockdown.
2
Satisfied or may be satisfied with the elearning methods adopted by the institute
during COVID-19 lockdown.
66 47 19
Should e-learning
tools be adopted
in daily classroom
teaching? (Single
choice correct)
1
E-learning tools should be or may be adopted
in daily classroom teaching. 128 98 30 E-learning tools
should be or may
be adopted in daily
classroom teaching. 2
E-learning tools should not be adopted in daily
classroom teaching. 39 28 11
4.2 Results from case study 2: National Institute of
Technology, Hamirpur
Sixteen first-year students pursuing computer vision at
NIT-H, were surveyed in April 2020. Out of 16 students,
5 were females, and 11 were males. Table 2 shows the
survey of Google Classroom services were being used
during the COVID-19 lockdown. The questions included
in the survey were if Google Classroom was helpful
in teaching outside the classroom, what was the best
feature of Google Classroom according to the students, if
students were satisfied with Google Classroom teaching,
if the submission of assignment for Computer Vision
and Image Processing using the Google Classroom
was convenient, was it easy to conduct quizzes on the
online platform, if it is easy to access Google Classroom
material, if the laptop or mobile devices were preferred
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 111
Table 2 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of National
Institution of Technology, Hamirpur.
Item No. Item in detail
Number of students
(n D 16/
Number of males
.n D 11/
Number of females
.n D 5/
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
Ease of accessibility is the most
critical feature of e-learning platforms. 13 8 5
2
User Interface is the essential feature
of e-learning platforms. 7 5 2
3
Quality of services is the most crucial
feature of e-learning platforms. 9 7 2
Preferred choice of
e-learning tool during
COVID-19 lockdown,
other than Google
Classroom. (Multiple
choice correct)
1
Pre-recorded lectures shared via
YouTube links are a preferred choice
of online education tools during
COVID-19 lockdown.
13 8 5
2
Pre-recorded lectures shared via
Google Drive links are a preferred
choice of online education tools
during COVID-19 lockdown.
2 2 0
3
Live lectures via Zoom or Google
meet are a preferred choice of online
education tools during COVID-19
lockdown.
1 1 0
What are the benefits
of e-learning?
(Multiple choice
correct)
1
With online learning, there is the ease
of access. 11 7 4
2
With online learning, there is
consistency. 7 5 2
3
With online learning, the schedule is
flexible. 13 8 5
4
With online learning, there is the use
of limited resources. 8 5 3
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Satisfied or may be satisfied with the
e-learning methods adopted by the
institute during COVID-19 lockdown.
16 11 5
2
Not satisfied with the e-learning
methods adopted by the institute
during COVID-19 lockdown.
0 0 0
Should the features
of online learning be
adopted into daily
classroom teaching?
(Single choice correct)
1
Some features of online learning
should be or may be adopted in daily
classroom teaching.
15 10 5
2
Some features of online learning
should not be adopted in daily
classroom teaching.
1 1 0
to access Google Classroom, what was the best feature
of the platform provided according to students, what was
another online educational tool that students preferred,
what were the advantages of online education according
to students, if the students were satisfied with the online
learning tool adopted by the university, and if students
wanted to incorporate few features of online education
with daily classroom teaching. For a few questions,
responses were recorded on a scale of 1–5, one being
unsatisfactory, and five being satisfactory. 81.3% of the
students surveyed thought that the ease of accessibility
was the best feature of Google Classroom and prerecorded lectures shared via YouTube links enjoyed a
majority of 13 students out of 16 as the preferred online
education tool (see Table 3). The majority of students
voted for the flexibility of schedule as the advantage of
online education.
4.3 Results from case study 3: Manav Rachna
International School
Table 4 shows the survey conducted in Manav Rachna
112 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 3 Students’ response to survey conducted regarding Google Classroom practices adopted by teaching faculty of National
Institute of Technology, Hamirpur on a scale of 1 – 5, with five being maximum. The values are averaged.
No. Item Number of students
(max n D 16)
Number of males
.n D 11/
Number of females
.n D 5/
1
Google Classroom helped in teaching outside of
the classroom. 4.125 4.182 4
2
Students are satisfied with Google Classroom
as an e-learning tool during the COVID-19
lockdown.
4.187 4.273 4
3
Submission of digital image processing
assignments using Google Classroom was
convenient.
4.500 4.636 4.2
4
It was convenient to answer quizzes on Google
Classroom. 4.187 4.272 4
5
It is easy to access learning material in Google
Classroom. 4.812 4.818 4.8
6
It was easier to use Google Classroom on the
laptop than on Mobile. 3.937 3.909 4
Table 4 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Manav Rachna
International School, Mohali.
Item No. Item in detail
Number of
students
(nD91)
Number of
males
(nD49)
Number of
females
(nD42)
Students division among
various levels from nursery
to Class 9.
1 Nursery and Kindergarten 42 21 21
2 Grades 2–5 31 15 16
3 Grades 6–9 18 5 13
Are students satisfied with
the Microsoft Teams tool
being used during COVID19 lockdown? (Single
answer correct)
1
Students are satisfied or may be satisfied by the
Microsoft Team tool being used during COVID-19
lockdown.
90 48 42
2
Students are not satisfied with the Microsoft Teams
tool being used during COVID-19 Lockdown. 1 1 0
Features of Microsoft
Teams preferred by
students. (Multiple answers
correct)
1
Students like the Chat/Call Tab feature supported
by Teams. 70 37 33
2
Students like the Assignment Tab feature
supported by Teams. 56 29 27
3
Students like the Post Section Tab feature
supported by Teams. 23 11 12
4
Students like the Files Section feature supported
by Teams. 21 10 11
5
Students like the Class notebook Tab feature
supported by Teams. 35 20 15
Are students able to achieve
their learning outcomes
through e-learning? (Single
choice correct)
1
You will be or may be able to achieve the required
learning outputs from these sessions? 82 41 41
2
You will not be able to achieve the required
learning outputs from these sessions. 9 8 1
What are the benefits of elearning? (Multiple choice
correct)
1 With online learning, there is the ease of access. 45 25 20
2 With online learning, the schedule is flexible. 39 18 21
3
With online learning, there can be interactive
content.
36 16 20
Should the features of online
learning be adopted into
daily classroom teaching?
(Single choice correct)
1
Some features of online learning should be or may
be adopted in daily classroom teaching. 77 41 36
2
Some features of online learning should not be
adopted in daily classroom teaching. 14 8 6
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 113
International School, Mohali, India. Out of 91 students
surveyed, 49 students (53.85%) were males, and 42
students (46.15%) were females. 98.90% of students
were satisfied with the Microsoft Teams tool being used
during the COVID-19 lockdown. Students preferred
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application. 61.54%, 25.27%, 23.07%, and 38.46% of
students liked the assignment tab, post section tab, files
tab, and class notebook tab feature, respectively. 90.10%
of students felt that they could achieve their learning
outcomes via Microsoft Teams application being used
during COVID-19 lockdown. 49.45%, 42.85%, and
39.5% of students felt that ease of access, the flexibility
of schedule, and interactive bite-sized content are the
benefits of e-learning platforms. 84.61% of students were
in favor of the adoption of online learning tools into daily
classroom teaching (see Table 5).
4.4 Results from the three case studies
For all three institutions, the majority agreed with
adopting some e-learning practices with daily classroom
education. For TIET students, mode of preference
for e-leaning was pre-recorded lectures via YouTube
links. The students of NIT-H also gave preference to
pre-recorded lectures via YouTube links apart from
Google Classroom as a preferred choice of e-learning
tool. Majority of students of Manav Rachna International
School and NIT-H found ease of access as the best
advantage of e-learning platforms. From the surveys,
it can be seen that the students of all three educations
would like some features of e-learning tools to be
adopted in daily classroom education.
5 Conclusion
In this paper, initially, the impact of the COVID-19
lockdown is discussed on the environment. Thereafter,
the impact of COVID-19 lockdown is discussed on
the health of the students and researchers. Finally, elearning environment for three educational institutions
during COVID-19 lockdown is discussed. Zoom,
Google Classroom, and Microsoft Teams were not
being previously used by TIET, NIT-H, and Manav
Rachna International School, respectively. The student’s
preferences and choices were successfully identified and
noted in the three institutions by conducting surveys.
From the surveys, it can be seen that the students
of all three educations would like some features of
e-learning tools to be adopted in daily day to day
classroom teaching. For NIT-H and Manav Rachna
International School, it was successfully identified that
students enjoyed the ease of access of material via
e-learning tools. Such tools can be thought to be
incorporated in daily classroom teaching. For TIET,
students already have online portals where information
is updated regularly. Apart from TIET, students at NIT-H
and Manav Rachna International School were satisfied
with the e-learning platforms being used during the
COVID-19 lockdown. From the survey conducted at
Thapar Institution of Engineering and Technology, we
came to know that even if 60.4% of students were not
satisfied with the e-learning practices being used by
their institution during COVID-19 lockdown, 49.7%
of students were still willing to incorporate e-learning
practices in their daily classroom education. From
the three surveys conducted, it can be seen that the
majority of students are eager to adopt the e-learning
platform features in their regular classroom teaching.
Out of 274 students, 220, that is, 80.2% of students
felt that e-learning platforms’ features should be or may
be integrated with the daily classroom teaching. The
maximum number of students, that is, 73.59% of both
the universities preferred pre-recorded lectures being
provided via YouTube links as the preferred means of
e-learning practice during COVID-19. YouTube links
allow students to access the videos any time they like,
making the material easily accessible and providing the
flexibility of the schedule. Out of the students who
answered what they prefer feature of online education,
52.3% supported ease of access, and 48.5% supported
the flexibility of the schedule. Students preferred
Table 5 Students from three institutions respond to the adoption of e-learning practices in daily classroom education.
Item No. Item in detail Number of students
.n D 274/
Number of
males .n D 186/
Number of
females .n D 88/ Mode
Should the features
of online learning
be adopted into
daily classroom
teaching? (Single
choice correct).
1
Some features of online learning
should be or may be adopted in
daily classroom teaching.
220 149 71
Some features of
online learning
should be or may
be adopted in
daily classroom
teaching.
2
Some features of online learning
should not be adopted in daily
classroom teaching.
54 37 17
114 Big Data Mining and Analytics, June 2021, 4(2): 104–115
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application at Manav Rachna International School. At
the National Institute of Technology, Hamirpur, 100%
of students were satisfied with the Google Classroom
practices adopted by their institution. At Manav Rachna
International School, Mohali, 98.90% of students were
satisfied with the Microsoft Teams’ platform adopted
during the COVID-19 platform.
To access these platforms, a mobile device and an
internet connection are required. It is necessary for
the student to be proficient in the English language,
which is the standard or default language for many
e-learning platforms. There are 560 million internet
connections in India, making it the second-largest online
market in the world after China[12]. During the COVID19 lockdown in India, institutions have adopted many
e-learning practices. With the world moving towards
digitization, COVID-19 may act as a catalyst to make
education online. With students and teachers using
these services to educate themselves and masses, new
problems and solutions may be discovered, which may
help popularize online education in India. In the future
studies, from the three case studies, the choices and
preferences of the students should be implemented in
e-learning platforms and in-depth analysis of student
behavior and their choices regarding user interface and
flexibility should be underscored.



NEW_PAPER



A Proactive and Practical COVID-19
Testing Strategy
—KUAN SONG
Gago Ltd., Beijing 100870, China
—SHIQI JIAO
Gago Ltd., Beijing 100870, China
—QIANG ZHU
Gago Ltd., Beijing 100870, China
—HUITAO WU
Zhejiang Lab, Hangzhou 311122, China
(Corresponding author: Kuan Song.)
IEEE DOI 10.1109/EMR.2020.3017648
Abstract—To reopen the economy safely during the COVID-19 pandemic,
governments need the capability to proactively identify new and often
asymptomatic infections, as well as contact tracing. Policymakers and public
health professionals need a sampling-testing method that can achieve broad
population coverage without overwhelming medical workers. We observe that
COVID-19 high-risk groups are located in the hubs and cliques of our geo social network, formed by the close encounters of people during daily life.
These individuals are the de facto “canary in a coal mine”. We propose that
nations offer free and anonymous testing service to them. With open-source
computer algorithms and datasets, only a small fraction of the population
selected for COVID-19 testing can cover the majority of high-exposure-risk
individuals. A 0.3% sampled testing for a megacity covers 3/4 of its entire
population. A 3% sampled testing for a rural town covers 3/4 of its entire
population. With government oversight and public consent, this approach can
serve each province/state or city/township for decentralized daily testing
planning. However, to protect privacy, we recommend constructing the geo social network of anonymized cellphones, not named individuals. This
infrastructure should be dismantled once the pandemic is largely over. This
can be achieved by policymakers, health workers, and engineers together in
solidarity.
Key words: COVID-19, decisions under risk and uncertainty, geo-social
networks, network theory, sampling strategy
PROBLEM FORMULATION
THE COVID-19 pandemic puts
global governments in a dilemma.
Before social distancing and stay-at home orders, rapid chain infection
happened. Strict stay-at-home orders
save lives but risk economic
recession. Public opinions are
growing increasingly polarized and
led to armed protesting [1]. If the
economy collapses in any nation, the
ensuing mass unemployment and
social unrest can expose the most
fragile families to the pandemic.
Reopening the economy safely is,
thus, a necessary public health policy.
However, recklessly loosening
stay-at-home policies and reopening
the economy in hard-hit nations can
be risky. Asymptomatic COVID-19
patients can infect others in offices or
onboard public transportation.
Droplets and aerosols from people
talking can carry the virus [2]. If the
chain of community infection goes
undetected, it can grow like wildfire.
Hospitals will again be overwhelmed
and the pandemic can become
endemic. Thus, a prerequisite to
reopening the economy is the ability
to rapidly identify new cases among
the asymptomatic population [3]. That
enables contact tracing of community
infection, and subsequent containing
local outbreaks. There are other
prerequisites such as a declining
number of patients, universal
availability of PPEs, which are as
important but will not be discussed in
this study.
To that end, Mr. B. Gates prescribed a
drastically increase of nucleic testing
capability for COVID-19 [4].
IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020 63
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/Meanwhile, a Harvard panel report
proposed daily proactive testing of 5–
20 million people in the United States
alone or 2–6% of the total population
[5]. The study did not specify how
they come to that estimation nor how
good that estimation is. The
challenge to that testing capability lies
not only in the production and
distribution of test kits but more
crucially in the logistics of the actual
tests. There might not be enough
medical workers and lab technicians
in the US to conduct 20 million tests a
day. Peto et al. [3] advocate universal
weekly random testing of 13% of the
U.K. population to reach 90%
coverage. That translates to  2%
daily testing of the entire population.
This is a huge logistic challenge for
the U.K. as well. Similar random
sampling schemes are being
developed for India [6]. However,
none of these testing schemes
materialized since their conception.
This probably is because
governments deem them impractical.
This logistical challenge can be
readily solved, if only a selected
0.1–0.3% sample of the total
population is needed to tested
daily or weekly. As of now, megacities
in the United States, Europe, and
China already have that testing
capacity.
We propose the daily testing of only a
small subset of the asymptomatic
population, specifically targeting the
hubs and cliques in a geo-social
network of anonymous cellphones. If
any result comes back positive, then
the people around them need further
testing as contact tracing. The geo social network of anonymous
cellphones in a given area during a
given time period consists of vertices
and links. The vertices are the
cellphones, carried by their owners
active in the economy. The links
among them indicate significant close
encounter, such as working in the
same office, living in the same house,
and sharing the same ride.
The following graph illustrates a
simple geo-social network of three
young working professionals. Mary,
Giuseppe, and Lee work in a small
consulting firm. Mary shares her
house with a partner and jogs with a
group of X (5 to 20) people to the
office daily. Giuseppe shares a house
with his parents and 2 siblings and
drives alone to the office daily. Lee
lives alone in his condo and takes a
40-min metro ride to the office daily
with Y (10 to 50) people in a train car.
In the geo-social network graph, we
use F to denote family members, and
C to denote commuters they meet
daily. For simplicity we assume that
other family members stay strictly at
home, the commuters interact with no
one else, and all the people in this
graph are asymptomatic.
Given such a geo-social network,
who should we administer COVID-19
tests to if we only have three test kits
available every day? What about two
test kits? Or even just a meager one
test kit per day? We might want to
reserve testing to the people who are
most exposed to the virus, and who
have the highest potential to infect
others. Very often the same people
meet both criteria. Naturally, we
would choose to first test Mary,
Giuseppe, and Lee because they
connect to more people than others.
Lee has the highest exposure risk
because of the packed subway ride
with dozens of commuters, and thus,
he should get the test if only one test
kit is available. In our opinion, each
municipality and/or CDC office should
have the tools to automatically
analyze such geo-social networks
and provide testing service to the
individuals with the highest exposure
risks.
There exists no full-scale study on
COVID-19 exposure on individuals.
Patients of old age or with pre existing medical conditions have the
highest death rate once infected, but
not necessarily the highest exposure
chances before getting ill. We
observed that two types of people
might be the most exposed to
COVID-19 due to their distinctive geo social network niches. We could
focus our limited testing capabilities
on them.
Around the world, senior government
officials have been disproportionately
hit by COVID-19. The list includes
prime ministers of Britain and Russia,
the first Ladies of Spain and Canada,
the first family of Brazil, and countless
ministers around the world. Likely this
situation resulted from their busy daily
schedule to meet with a large number
of people, often internationally. In
other words, the “hubs” in our geo social network are most exposed to
infection risks. In a sense, they are
the canary in a coal mine. Timely
testing for them could buy time for
their local communities.
People spending long hours in
close quarters have seen horrendous
local outbreaks of COVID-19.
Well-known cases include the
Diamond Princess, USS Theodore
Roosevelt, USS Kidd, and many
hospital wards, retirement homes,
factories [7], and prisons [8] around
the world. In a geo-social network,
these communities are known as
clique’s because each member is
within close vicinity of all other
members and, therefore, geo-socially
interconnected. Such cliques are
often exposed to airborne droplets
carrying the virus, which leads to
unusually high percentages of local
infection.
Thus, our goal is to identify, in each
geo-social network of a workforce
embracing economic reopening, the
hub’s and clique’s people for daily
COVID-19 testing even though they
are asymptomatic. If any hub’s or
clique’s individual turns up positive
for COVID-19, the geo-social network
of his/her immediate daily interaction
circle needs to be tested, and the
patients quarantined. We argue that
this is an efficient sampling strategy
64 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020for COVID-19 testing in a reopened
economy.
Each city has its own logistical
constraints on testing. Some cities
can afford to test daily 1% of its
workforce, others may afford to test
0.1%, which testing percentage is
sufficient? How to measure
sufficiency? How can each city
perform its own rapid assessment on
a daily basis?
METHODOLOGY AND
EXPERIMENT
To address the abovementioned
questions, we conducted a pilot study
using existing social network tools on
two real-world social network
datasets. The simplest approach is to
single out individuals with the most
links in the geo-social network for
testing. But the problem with that
approach is that those individuals are
often in the same local community
and, thus, have highly overlapped
geo-social networks [9]. For example,
doctors and nurses working in the
same ER room, or the congress
members of the same nation. If we
concentrate our testing resources on
them, we will miss out on the big
picture in the population and have a
social inequality issue.
Thus, we aim to find the individuals
with the most links in the geo-social
network, while the individuals directly
linked to them cover the maximum
percentage of the population. This
can be achieved by dividing the geo social network of mega-cities like
Wuhan or NYC into small
communities or cliques. We can then
identify the hub’s in each community.
Unfortunately, in mathematics and
computer science, this problem is
NP-hard. To find the exact optimal
solution takes exponentially
computation time as the size of the
population grows. There exist
heuristic solutions that can produce
imperfect yet useable solutions with a
limited time budget. These solutions
were developed over the past two
decades not just to analyze social
networks and internet traffic [9].
These algorithms are also the
workhorses behind Internet search
engines such as Google [10] and
Microsoft Bing [11].
The heuristic algorithms examined
here are developed in academia and
open-source. We also share crude
yet simple Python snippets [12], [13]
to make use of these models with
real-world datasets. We hope that the
public health sector can integrate
these methods without hiccups. In our
pilot study, both algorithms can
analyze geo-social networks with
millions of vertices (people) in several
minutes on a Linux workstation. This
indicates the feasibility of
decentralized day-to-day operations
in each municipality without additional
charges.
The Louvain algorithm was created
by Blondel et al. [14] from the
University of Louvain, Belgium. It is a
bottom-up clustering algorithm to find
communities large or small, often very
different in size. The METIS algorithm
[15],[16] was created by G. Karypis
and V. Kumar from the University of
Minnesota, USA. It enables parallel processing to partition social
networks into communities of similar
Figure 2. Selecting the hubs from a sample geo-social network. sizes.
Figure 1. Sample geo-social network of a small consulting company.
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 65The first dataset we tested on is a
Googleþ social network dataset [17],
including 107 614 people, and 13 673
453 links among them. On average
each person is connected to 127
others. This number is comparable to
the number of people a working
professional meets daily in a busy
metropolis using public
transportation. It is a densely
connected network.
The second dataset we tested on is
an Internet server topology dataset
[18] originally assembled to study the
transmission of computer viruses. It
has 1 696 415 vertices (machines)
and 11 095 298 links among them. On
average each machine is connected
to 6.5 others. This number is
comparable to the number of people
a working professional meets daily in
a small town without using public
transportation. It is a sparsely
connected network.
To be clear, we do not assume that
COVID-19 transmits along with cyber social networks. We consider the two
datasets previously because they
have network structures similar to
geo-social networks of the workforce,
which has close-range physical
interactions daily in a reopened
economy.
Our study is designed in the following
four steps. First, we partition the
network datasets into U clusters
using the METIS algorithm and the
Louvain algorithm. Then in each
cluster, we single out K individuals
who have the most connections
within the cluster. In total, we have
U 
K individuals chosen for COVID-19
testing. As a simpler baseline choice,
we single out the top U 
K individuals
with the most connection links in the
complete geo-social network. We
adopted the value of parameter U as
the total number of individuals S
divided by 100 or 1000. In this way,
the total amount of individuals chosen
[U 
K] will be a percentage of the total
population. The evaluation metric is
the coverage of the tested individuals,
defined as the number of individuals
immediately linked to the tested
individuals divided by the total
number of individuals. The four steps
are illustrated in Figure 2 using the
sample described in Figure 1.
FINDINGS
The following two tables list the
coverage rates from three different
algorithms on two real-world
datasets. They can tell us to an extent
how well the geo-social network
sampling and testing cover the
population in a reopened economy.
The “Coverage” percentages are
calculated as the percentage of
people who had close contacts with
the COVID-19 test subjects, out of the
general population.
On both datasets and all sampling
percentages, the METIS algorithm
steadily outperforms other algorithms
in terms of coverage rate. This does
not indicate that the Louvain
algorithm is inferior. It was designed
to identify natural-looking
subcommunities large and small. Its
most suitable use would be to
visualize and trace local community
transmission.
On the densely connected Googleþ
dataset, we are indeed running a
simulation of busy urban life such as
that in NYC, or Wuhan. Results listed
in Table 1 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
Table 2. Coverage Percentage out of Geo-Social Network Sampling
Test on Skitter Dataset.
Table 1. Coverage Percentage out of Geo-Social Network Sampling
Test on Googleþ Dataset.
66 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020an immediate-connection coverage of
74.1% of the population. By sampling
2% of the population, we can
effectively represent an immediate connection coverage of 92.3% of the
population. Beyond 2% sampling,
extra sampling and testing work offer
marginal benefit.
On the sparsely connected Skitter
dataset, we are indeed running a
simulation of quiet small-town life
such as that in Ithaca upstate NY, or
Suifenhe China. Results listed in
Table 2 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
an immediate-connection coverage of
51.4% of the population. By sampling
3% of the population, we can
effectively represent an immediate connection coverage of 77.7% of the
population. Beyond 3% sampling,
extra sampling and testing work offer
marginal benefit.
DISCUSSIONS
In summary, our study shows that a
highly efficient sampling, testing, and
tracing scheme can be achieved by
constructing the geo-social network of
a city or township, safeguarding the
economy reopening. The busier the
city is, the smaller percentage we
need to test for COVID-19. We
estimate that 0.3% to 3% can monitor
COVID-19 transmission covering the
majority of the population. This is not
to say that our sampling can keep
COVID-19 from happening, but rather
a realistic managed low-occurrence
live-with-COVID approach. Also
arguably this is also not as important
as the universal wearing of masks as
PPE.
This pilot study assumes that a geo social network dataset for each city/
township can be constructed every
day. Indeed it can, only if with public
consensus and government
oversight. Our cellphones currently
produce multiple location-tracking
data streams, including
telecommunication tracking,
operating system tracking, and map
API-based tracking. In each nation,
the cellphone service providers
acquire coarse-resolution tracking
data streams via the triangulation of
3G/4G base stations. Operating
system tracking data stream exists in
each Android phone and IPhone as
an essential service by integrating
GPS and WiFi signals. In addition,
most of the cellphone apps on the
market call various precision map/
location service APIs from Google
Map, Amap, Bing Maps, Baidu maps,
HERE maps, or Tencent maps for
location upon App use. That tracking
computes the 3G/4G signal along
with GPS and WiFi. The current data
records link location to each unique
cellphone, but not to individual
persons. These data records are
highly confidential and literally
guarded by laws like the European
GDPR against wanton usage.
Societies already embraced some of
their usages in real time, such as
Google traffic alert [33]. Hence, a
geo-social network of anonymous
cellphones can be quickly computed
out of existing data streams, with the
right permission clearance. This
study does not advocate collecting
cellphone location data with personal
IDs.
Geo-social network could be
constructed through another
process, arguably less intrusive.
Google and Apple are developing a
Bluetooth contact-alert service [19].
It can tell the user whether his/her
phone was within Bluetooth
distance of a COVID-19 patient’s
phone recently. However, this
feature is only valid if everyone
turns Bluetooth on and, thus, may
not eventually work out. By now,
this effort has largely died OFF.
With location data sitting idle with the
telecommunication service providers
and tech giants, the general public,
and national governments may want
to discuss and decide whether or not
to make use of it during the pandemic
[20], [21]. People have valid reasons
to worry about privacy,[22] but these
are not normal times [23]. Safe and
moral usages of this data flow require
mandatory erasure of any and all
personal details from the dataset and
render it anonymous except to
oneself. For example, only the citizen
him/herself can know that he/she is a
hub of the geo-social network. If he/
she wants to show up for work without
endangering coworkers, he/she
needs to have a free COVID-19 test.
When a patient’s test comes back
positive, then the people who had a
recent interaction with him/her have
the right to be notified via their
phones. Automatic contact tracing
can be done with technology instead
of spreading thin our medical
workforce in the field. When the
pandemic is about to be fully
eliminated, this “war-time”
infrastructure should be dismantled
so as not to be abused in peacetime.
We find it is logistically feasible for
local facilities to operate a daily
routine. First, every night, the local
locational data flows from either
telecommunication providers or tech
giants are used to construct the geo social network of the previous day.
Residents who are the identified
0.3%–3% hubs in that network wake
up the next morning with a text
message notification for a quick test
before showing up for work. Testing
capacities vary from region to region.
Some developed nations might afford
to test them every day. Developing
nations might afford to test once a
week. Either way helps.
To further alleviate the pressure on
logistics, nations can consider a
recent practice [30] in Wuhan,
China during May 13–22, 2020.
Nasal swabs from multiple persons
from the same neighborhood are
mixed into one testing. This is
known as pooled testing. It reduces
logistics pressure of testing to 1/5
or even 1/10, compared to
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 67conducting 1 test for each
individual. In the United States, the
importance of pooled testing is just
gaining recognition [31], but not yet
implemented en masse.
Pooled testing and geo-social
network sampling can boost each
other in many ways. First, each batch
in pooled testing can consist of
individuals from the same “clique” of
the geo-social network because they
share similar risks of infection.
Second, when testing resources are
very scarce, pooled testing of
selected “hubs” in the geo-social
network can be highly efficient. Third,
tracing of infection chains can be
achieved with geo-social networks
after pooled testing.
Another possibility to improve this
approach is to integrate the infection
rate of population groups into the geo social network. A vanilla geo-social
network can measure the chance of
exposure to infection. When
multiplied by the infection rate of age
groups, it can measure the chance of
infection.
Around the world, pilot experiments
on locational tracking to fight the
pandemic are sprouting, for example
in Israel [24], South Korea [21], and
China [25]. In China, Alibaba and
Tencent scrambled to work with
government oversight creating
location-based health-checkup Apps
starting in late January 2020. The
initial version went online on February
11 after 2 weeks of intensive
development [26]. It can only trace
location down to city blocks and tell
the user whether they have been to
COVID-19 hot zones in the past 14
days. The majority of the Chinese
public chose to adopt this
infrastructure. Along with other
measures such as universal mask wearing and quarantines, it
contributed significantly to the
Chinese effort of containing and
almost total elimination of COVID-19.
This effort released openly its
technical whitepapers [25] on May 1,
2020. However, at the time being
there is yet no reported effort to use
that infrastructure for proactive
nucleic or antibody testing for the
general public.
On April 27, Science Magazine
recently called for the utilization of
mobile phone data for modeling and
contact tracing [27]. Gradually,
policymakers, scientists, and
engineers globally are coming to
realize that data from mobile phones
can help them combat COVID-19. It is
important that peoples are aware of
this option, can debate about it, and
make a decision for their own nation.
We do not yet know how long this
pandemic lasts and how bad it can
go. Therefore, all options should stay
on the table. For epicenters of the
pandemic, government might want to
integrate all possible measures
together to turn the tide against the
pandemic.
This pilot study is a baby step to
introduce to the field of public health
the importance of social network
analyses. We have already seen the
use of traditional S-I-R modeling for
infectious diseases since the onset of
the pandemic. The S-I-R models
assume equal infection risk for all
individuals and, thus, is insufficient
alone. Social network analyses
provide insights into exposure risks of
each individual and, thus, can be
integrated into S-I-R models for
S-E-I-R modeling. We assume that
everyone has equal immunity in our
model because of limited data. If
possible to collect more detailed
information about individuals, we
hope to improve our model
considering the covariates affecting
personal immunity. To battle the
pandemic and potentially endemic
COVID-19 as a planetary challenge,
interdisciplinary teamwork among
epidemiologists, computer scientists
and data scientists, and lawmakers is
needed. We hope to see our model
revised and applied in policies and
day-to-day operations [28]. Modeling
can only tell us so much. Politics does
the rest [29]. The bottom line against
dystopian use of location data is to
construct a geo-social network of
anonymous cellphones, not of people
without privacy. Make this a service
instead of surveillance. And this
service should only be temporary
during the pandemic. Our planet after
the pandemic does not need
Geoslavery [22].
CONTRIBUTORS
Conceptualization: KS/HW;
Programming and Analysis: ZQ/SJ/
KS; Writing: KS/HW.
ACKNOWLEDGMENT
The authors would like to thank L. Yu,
C. Deng, C. Pei, W. Jiang, L. Xu, and
K. Dong for many rounds of fruitful
discussions. The open access fee for
this article was provided by Gago
Inc,. Beijing, China.



NEW_PAPER

Received May 13, 2020, accepted June 17, 2020, date of publication June 19, 2020, date of current version July 1, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3003810
Iteratively Pruned Deep Learning Ensembles
for COVID-19 Detection in Chest X-Rays
SIVARAMAKRISHNAN RAJARAMAN 1
, (Member, IEEE), JENIFER SIEGELMAN2
,
PHILIP O. ALDERSON3
, LUCAS S. FOLIO4,5, LES R. FOLIO6
,
AND SAMEER K. ANTANI 1
, (Senior Member, IEEE)
1Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD 20894, USA
2Takeda Pharmaceuticals, Cambridge, MA 02139, USA
3School of Medicine, Saint Louis University, St. Louis, MO 63104, USA
4Functional and Applied Biomechanics Section, Clinical Center, National Institutes of Health, Bethesda, MD 20892, USA
5Walt Whitman High School, Bethesda, MD 20817, USA
6Radiological and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, MD 20894, USA
Corresponding author: Sivaramakrishnan Rajaraman (sivaramakrishnan.rajaraman@nih.gov)
This work was supported by the Intramural Research Program of the National Library of Medicine (NLM), and the U.S. National Institutes
of Health (NIH).
ABSTRACT We demonstrate use of iteratively pruned deep learning model ensembles for detecting
pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus
(2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are
trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific
feature representations. The learned knowledge is transferred and fine-tuned to improve performance
and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or
COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and
improve memory efficiency. The predictions of the best-performing pruned models are combined through
different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that
the weighted average of the best-performing pruned models significantly improves performance resulting in
an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The
combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning
resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening
using chest radiographs.
INDEX TERMS COVID-19, convolutional neural network, deep learning, ensemble, iterative pruning.
I. INTRODUCTION
Novel Coronavirus disease 2019 (COVID-19) is caused
by the new Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2) that originated in Wuhan in
the Hubei province in China and has spread worldwide.
The World Health Organization (WHO) declared the out break a pandemic on March 11, 2020 [1]. The disease is
rapidly affecting worldwide population with statistics quickly
falling out of date. As of April 12, 2020, there are over
1.8 million confirmed cases reported globally with over
100,000 reported deaths. Lung disease that causes difficulty
in breathing has been reported as an early indicator along
with hyperthermia in the COVID-19 infected population [1].
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque .
The lung abnormalities caused by non-2019-nCOV viruses
are observed as peripheral or hilar and visually similar to,
yet often distinct from, viral pneumonia and other bacterial
pathogens [2].
Reverse transcription-polymerase chain reaction
(RT-PCR) tests are performed to detect the presence of
the virus and are considered the gold standard to diagnose
COVID-19 infection. However, they are reported to have
variable sensitivity and in some geographic regions may not
be widely available [3]. While not currently recommended
as primary diagnostic tools, chest X-rays (CXRs) and com puted tomography (CT) scans have been used to screen for
COVID-19 infection and evaluate disease progression in
hospital admitted cases [3], [4]. While chest CT offers greater
sensitivity to pulmonary disease, there are several challenges
to its use. These include the non-portability, the requirement
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 115041S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 1. Graphical abstract of the proposed study.
to sanitize the room and equipment between patients followed
by a delay of at least an hour [4], the risk of exposing
the hospital staff and other patients, and persons under
investigation (PUIs) to the virus. Although not as sensitive,
portable CXRs are considered as an acceptable alternative
[4] since the PUIs can be imaged in more isolated rooms,
limiting personnel exposure and because sanitation is much
less complex to obtain than with CT.
Automated computer-aided diagnostic (CADx) tools
driven by automated artificial intelligence (AI) methods
designed to detect and differentiate COVID-19 related tho racic abnormalities should be highly valuable given the heavy
burden of infected patients. This is especially important in
locations with insufficient CT availability or radiological
expertise and CXRs produce fast, high throughput triage such
as in a mass casualty [5]. Automated approaches, once vali dated, have been shown to reduce inter- and intra-observer
variability in radiological assessments [6]. Additionally,
CADx tools have gained immense significance in clinical
medicine by supplementing medical decision making and
improving screening and diagnostic accuracy [7]. These tools
combine elements of radiological image processing with
computer vision for identifying typical disease manifesta tions and localizing suspicious regions of interest (ROI).
At present, recent advances in machine learning, particularly
data-driven deep learning (DL) methods using convolutional
neural networks (CNNs), have shown promising performance
in identifying, classifying, and quantifying disease patterns
in medical images. This is particularly true for CT scans
and CXRs [7]. These models learn the hierarchical feature
representations from medical images to analyze for typical
disease manifestations and localize suspicious densities for
ROI evaluation [7].
In this study, we highlight the benefits offered through the
use of an ensemble of iteratively pruned DL models toward
distinguishing CXRs showing COVID-19 pneumonia-related
opacities, from bacterial pneumonia, and normals using pub licly available CXR collections. Fig. 1 shows the graphi cal abstract of the proposed study. Fig. 2 shows instances
of CXRs being normal, showing bacterial pneumonia, and
COVID-19-related pneumonia.
A custom CNN and a selection of pretrained CNN mod els are trained on a large-scale selection of CXRs to learn
CXR modality-specific feature representations. The learned
knowledge then is transferred and fine-tuned to classify the
normal and abnormal CXRs. We leverage the benefits of
modality-specific knowledge transfer, iterative pruning, and
FIGURE 2. CXRs showing (A) clear lungs, (B) bacterial pneumonia
manifesting as consolidations in the right upper lobe and retro-cardiac
left lower lobe, and (C) COVID-19 pneumonia infection manifesting as
peripheral opacities in the left lung.
ensemble strategies to reduce model complexity, improve
robustness, generalization, and inference capability of the DL
model.
The remainder of the manuscript is organized as follows:
Section II discusses prior works. Section III discusses
the datasets and methods used toward modality-specific
knowledge transfer, iterative pruning, and ensemble learn ing. Section IV elaborates on the results obtained, and
Section V concludes the study with a discussion on the merits
and limitations of the proposed approach and future work
directions.
II. PRIOR WORK
A. COVID-19 DETECTION
A study of the literature reveals several AI efforts for
COVID-19 screening. The authors of [3] distinguished
COVID-19 viral pneumonia manifestations from that of other
viral pneumonia on chest CT scans with high specificity.
It was observed that COVID-19 pneumonia was found to be
peripherally distributed with ground glass opacities (GGO)
and vascular thickening. The authors of [8] established
a publicly available collection of 275 CT scans showing
COVID-19 pneumonia manifestations and trained a deep
CNN to achieve 0.85 F-score in classifying CTs as nor mal or showing COVID-19 pneumonia-related opacities.
The authors of [9] used a customized CNN and pretrained
AlexNet model to classify CXRs as normal or showing
COVID-19 pneumonia with 94.1% and 98% accuracy respec tively. The authors of [10] used a ResNet-50 [11] CNN to
classify normal, pneumonia, and COVID-19 viral pneumo nia manifestations in CXRs and achieved an accuracy of
98.18 % and F-score of 98.19. CXRs are also commonly
analyzed to diagnose and differentiate other types of pneumo nia including bacterial and non-COVID-19 viral pneumonia
[2]. The authors of [12] proposed a custom CNN model
that was designed by combining manual design prototyp ing with a machine-driven designing approach to classify
CXRs as normal or showing non-COVID-19 or COVID-19
pneumonia-related opacities with 92.4% accuracy.
B. MODALITY-SPECIFIC KNOWLEDGE TRANSFER
With limited amounts of COVID-19 pneumonia CXR data,
traditional transfer learning strategies offer promise [13]
where the learned feature representations are fine-tuned to
115042 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
improve performance. However, unique challenges posed
in the appearance of medical images [6] including high
inter-class similarity and low intra-class variance lead to
model bias and overfitting resulting in reduced perfor mance and generalization. These issues can be alleviated
through modality-specific knowledge transfer by retraining
CNN models on a large CXR image collection to learn
modality-specific feature representations. Modality-specific
model knowledge transfer [14] and ensembles [15] have
demonstrated superior disease ROI localization compared to
individual constituent models.
C. MODEL PRUNING
To alleviate burdens from computing resources, DL models
can be pruned to reduce the inference cost and facilitate
deployment in low-resource conditions with no loss or even
improvement in performance. Reed [16] performed a neu ral model pruning to decrease computational complexity.
Hassibi et al. [17] deleted network parameters by leveraging
the second derivative term in the Taylor series and improved
model generalization. The authors of [18] found that the
earlier layers in the neural networks have low activations
that can effectively be excluded from the network without
affecting the model performance. They proposed an iterative
optimization method to gradually eliminate the neurons with
the least activations toward reducing the memory and power
requirements and promoting faster model inference. When
applied to medical imaging, the authors of [19] proposed a
genetic algorithm-based pathway evolution strategy to prune
DL models. This resulted in a 34% reduction in the network
parameters and improved the mass classification performance
in breast mammograms. A systematic weight pruning strat egy [20] was used to prune a YOLO-model [21] based pneu monia detector for classifying CXRs as normal or showing
pneumonia-like manifestations using the Radiological Soci ety of North America (RSNA) [22] CXR collection. However,
there is room for further research in this area.
D. ENSEMBLE CLASSIFICATION
CNNs are non-linear models that learn complex relationships
from the data through error backpropagation and stochastic
optimization, making them highly sensitive to random weight
initializations and the statistical noise present in the training
data. These issues can be alleviated by ensemble learning
by training multiple models and combining their predictions
where an individual model’s weaknesses are offset by the
predictions of other models. Combined predictions are shown
to be superior to individual models [23]. There are several
ensemble strategies reported in the literature including max
voting, simple and weighted averaging, stacking, boosting,
blending, and others that are shown to minimize the variance
error and improve generalization and performance of CNN
models. Applied to CXRs, the authors of [7], [14], and [24]
leveraged the use of an ensemble of CNN models toward
improving TB detection in CXRs. An averaging ensemble
of pretrained CNNs was used by the authors of [25] toward
improving cardiomegaly detection using CXRs.
TABLE 1. Dataset characteristics. Numerator and denominator denotes
the number of train and test data respectively (N = Normal,
UP = Pneumonia of unknown type, BP = Bacterial (proven)
pneumonia, CP = COVID-19 pneumonia).
III. MATERIALS AND METHODS
A. DATA COLLECTION AND PREPROCESSING
Table 1 shows the distribution of CXRs across different
categories. We used the following four publicly available
CXR collections in this retrospective analysis:
1) PEDIATRIC CXR DATASET [2]
The authors collected from Guangzhou Women and
Children’s Medical Center in Guangzhou, China, the anterior posterior (AP) CXRs of children from 1 to 5 years of
age, showing normal lungs, bacterial pneumonia, and
non-COVID-19 viral pneumonia. Expert radiologists curated
the CXR collection to remove low-quality chest radiographs.
2) RSNA CXR DATASET [22]
This multi-expert curated dataset includes images from the
National Institutes of Health (NIH) CXR-14 dataset [26].
The dataset was released for the Kaggle pneumonia detec tion challenge, organized jointly by RSNA and NIH. The
collection includes normal CXRs and abnormal images with
non-pneumonia and pneumonia-like opacities. The images
are made available at 1024×1024 pixel resolution in DICOM
format.
3) TWITTER COVID-19 CXR DATASET
A cardiothoracic radiologist from Spain made available a
collection of 134 CXRs with 2K×2K pixel resolution in
JFIF format via Twitter of SARS-CoV-2 positive subjects.
(https://twitter.com/ChestImaging)
4) MONTREAL COVID-19 CXR DATASET [27]
A publicly available periodically updated GitHub repository
that includes COVID-19 CXR cases and other pulmonary
viral disease manifestations in AP, posterior-anterior (PA),
and AP-Supine views. As of April 7, 2020, the repository had
179 CXRs showing COVID-19 pneumonia-related opacities.
We performed patient-level splits of these CXR collections
to allocate 90% for training and 10% for testing at dif ferent stages of learning discussed in this study. We ran domly allocated 10% of the training data to validate the DL
models. The ground truth (GT) for the test set, comprising
of 27 CXRs showing COVID-19 pneumonia-related opacities
is set by the verification of publicly identified cases from
expert radiologists who annotated the test set.
B. LUNG ROI SEGMENTATION
While mild COVID-19 cases mimic common upper
respiratory viral infections, advanced disease results in
VOLUME 8, 2020 115043S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 3. The segmentation approach showing U-Net based mask
generation and Lung ROI cropping.
FIGURE 4. Architecture of the customized CNN model. (I/P = Input,
CONV = Convolution, GAP = Global average pooling, DO = Dropout,
D = Dense with Softmax activation, N = Normal predictions,
A = Abnormal Predictions).
respiratory dysfunction and is the principal cause for
triggering mortality. In developing DL solutions for detecting
the disease, it is important to guard them against irrelevant
features that could severely affect reliable decision-making.
For this study, we performed U-Net based semantic segmen tation [28] to segment the lung pixels from the background.
We used a U-Net with Gaussian dropout layers [29] added to
the U-Net encoder. A dropout ratio of 0.2 was empirically
determined and used in this study. Fig. 3 illustrates the
segmentation steps performed in this study.
We used a collection of CXRs with lung masks from
[30] to train the U-Net model to generate lung masks of
256 × 256 pixel resolution for the aforementioned datasets.
We used model checkpoints to monitor its performance and
stored only the best model weights to generate the final lung
masks. These masks then are superimposed on the CXR
images to crop them as a bounding box containing the lung
pixels. The cropped lungs are resized to 256×256 pixel reso lution. The lung crops are further preprocessed by performing
pixel rescaling, median filtering for noise removal and edge
preservation, normalization for mean, and standardization for
identical feature distribution. The preprocessed lung crops are
used for model training and evaluation at different stages of
learning discussed in this study.
C. MODELS AND COMPUTATIONAL RESOURCES
We evaluated the performance of a customized CNN and
a selection of ImageNet pretrained CNN models, viz.,
a) VGG-16 [31], b) VGG-19 [31], c) Inception-V3 [32], d)
Xception [33], e) InceptionResNet-V2 [32]; f) MobileNet-V2
[34], g) DenseNet-201 [35], and h) NasNet-mobile [36].
Our customized CNN is a linear stack of strided separable
convolution layers, global average pooling (GAP), and a
dense layer with Softmax activation. Fig. 4 shows the archi tecture of the custom CNN used in this study. We used
Dropout to reduce issues due to model overfitting by pro viding restricted regularization and improving generalization
by reducing the model sensitivity to the specifics of the
training input [29]. We used strided convolutions that were
shown to improve performance on several visual recognition
benchmarks, compared to max-pooling layers [37]. Separable
convolutions were used to reduce model parameters [33] and
FIGURE 5. Architecture of the pretrained CNNs. (I/P = Input,
PCNN = truncated model, ZP = Zero-padding, CONV = Convolution,
GAP = Global Average Pooling, DO = Dropout, D= Dense with Softmax
activation, O/P = Output).
improve performance compared to conventional convolution
operations. The number of separable convolutional filters are
initialized to 32 and increased by a factor of two in the
successive convolutional layers. We used 5 × 5 filters and
a stride length of 2 in all convolutional layers. We added a
GAP layer to average the spatial feature dimensions that are
fed into the final dense layer with Softmax activation.
We used the Talos optimization package [38] to optimize
the parameters and hyperparameters of the customized CNN
that include a) dropout ratio, b) optimizer and c) non-linear
activation function. The model is trained and evaluated
with the optimal parameters to classify the CXRs to their
respective categories.
We instantiated the pretrained CNN with their ImageNet
weights and truncated them at the fully-connected layers.
The following layers are added to the truncated model:
(a) zero-padding, (b) a strided separable convolutional layer
with 5 × 5 filters and 1024 feature maps, (c) GAP layer,
(d) Dropout layer with an empirically determined dropout
ratio of 0.5, and (e) final dense layer with Softmax activation.
Fig. 5 shows the customized architecture of the pretrained
models used in this study.
We optimized the following hyperparameters of the
pretrained CNNs using a randomized grid search method
[39]: (a) momentum, (b) L2-regularization, and (c) initial
learning rate of the Stochastic Gradient Descent (SGD) opti mizer. The search ranges were initialized to [0.85 0.99],
[1e−10 1e−3], and [1e−9 1e−2] and for the momentum,
L2-regularization, and the initial learning rate respectively.
The pretrained CNNs were retrained with smaller weight
updates to improve generalization and categorize the CXRs
to their respective classes. Class weights were used during
model training to penalize the overrepresented classes to
prevent overfitting and improve performance [40]. We used
model checkpoints to store the best model weights for further
analysis.
D. MODALITY-SPECIFIC TRANSFER LEARNING
AND FINE-TUNING
We performed modality-specific transfer learning where
the customized CNN and ImageNet pretrained models are
retrained on the RSNA CXR collection to learn CXR
modality-specific features and classify the CXRs into
normal and abnormal categories. The RSNA CXR collec tion includes normal CXRs and abnormal images contain ing pneumonia-related opacities. In this way, the weight
layers are made specific to the CXR modality through
learning the features of normal and abnormal lungs. The
learned knowledge is transferred and fine-tuned to a related
task of classifying CXRs that are pooled from pediatric,
115044 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
Twitter COVID-19, and Montreal COVID-19 CXR collec tions, respectively, as normal, or showing bacterial pneumo nia, or COVID-19 pneumonia-related opacities, to improve
classification performance.
The top-3 performing modality-specific CNNs are
instantiated and truncated at their deepest convolutional
layer and added with the following layers: (a) zero-padding,
(b) a strided separable convolutional layer with 5 × 5 fil ters and 1024 feature maps, (c) GAP layer, (d) Dropout
layer and (e) final dense layer with Softmax activation. The
modified models are fine-tuned to classify CXRs as being
normal or showing bacterial pneumonia or COVID-19 viral
pneumonia. Class weights were used during model training to
award higher weights to the under-represented class to reduce
issues due to class imbalance and improve generalization
and performance. Fine-tuning is performed through SGD
optimization and model checkpoints were used to store the
best weights for further analysis.
E. ITERATIVE MODEL PRUNING
We iteratively pruned the fine-tuned models to find the
optimal number of neurons in the convolutional layers to
reduce model complexity with no loss in performance.
We gradually eliminated the neurons with fewer activations
at each time step through iterative pruning and model retrain ing. We used the average percentage of zeros (APoZ) [18],
the percentage of zero neuron activations observed with the
validation dataset, as the measure to rank the neurons in each
convolutional layer. We iteratively pruned a percentage of
neurons with the highest APoZ from each layer at each time
step and retrained the pruned model. The process is repeated
until the maximum percentage of pruning is achieved. The
best-pruned model is then selected from the collection of
iteratively pruned models based on their performance with
the test set. The retrained pruned model is expected to achieve
similar or better performance than the unpruned models with
reduced model complexity and computational requirements.
The algorithm for iterative pruning performed in this study is
described below:
F. LEARNING ITERATIVELY PRUNED ENSEMBLES
The best performing pruned models are selected to construct
the ensemble to improve prediction performance and gener alization as compared to any individual constituent model.
We used several ensemble strategies including max voting,
averaging, weighted averaging, and stacking to combine the
predictions of the pruned models toward classifying CXRs as
normal or showing bacterial or COVID-19 viral pneumonia related opacities. For the stacking ensemble, we used a neural
network-based meta-learner that learns to optimally com bine the predictions of the individual pruned models. The
meta-learner consisting of a single hidden layer with nine
neurons is trained to interpret the multi-class input from
the top-3 pruned models and a final dense layer outputs
the predictions to categorize the CXRs to their respective
classes.
Algorithm 1 Iterative Pruning
Input: B = {(xi, yi)|xi ∈ X, yi ∈ Y }, pruning percentage
(P), maximum pruning percentage (M)
1. Train and evaluate the base models on B and store the
best model weights
2. while percent pruned (PP) <= M do
a. Calculate the number of filters in each convolu tional layer
b. Identify and delete P percentage of filters in each
convolutional layer with the highest average per centage of zeros
c. Retrain and evaluate the pruned model on B and
store the best-pruned weights
d. PP + = P
e. Incrementally prune the network, retraining it each
time and save the pruned model
end while
Return: M + 1 number of pruned models
G. VISUALIZATION STUDIES
Visualizing the learned behavior of the DL models is a
debated topic, particularly in medical visual recognition
tasks. There are several visualization strategies reported in
the literature that include (a) visualizing the overall net work structure and (b) gradient-based visualization that
performs gradient manipulation during network training.
Gradient-weighted class activation mapping (Grad-CAM)
is a gradient-based visualization method that computes the
scores for a given image category concerning the fea ture maps of the deepest convolutional layer in a trained
model [41]. The gradients that are flowing backward are
pooled globally to measure the importance of the weights
in the decision-making process. In this study, we verified
the learned behavior of the pruned models by comparing
salient ROI with consensus GT annotations from experienced
radiologists.
H. STATISTICAL ANALYSES
We analyzed the model’s performance for statistical
significance at different stages of learning. We used con fidence intervals (CI) as the measure to analyze the skill
of the CNN models. A shorter CI infers a smaller margin
of error or a relatively precise estimate while a larger CI
allows more margin for error and therefore results in reduced
precision [42]. We computed the 95% CI values for the
AUC at different learning stages to explain the models’
predictive performance. The CI values are computed to be
the Clopper–Pearson exact interval that corresponds to the
separate 2-sided interval with individual coverage probabil ities of (0.95)1/2
. We used StatsModels version 0.11.0 to
compute CI measures. The codes associated with this study
are made available at https://github.com/sivaramakrishnan rajaraman/Iteratively-pruned-model-ensembles-for-COVID 19-detection-in-CXRs.
VOLUME 8, 2020 115045S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 2. Optimal values for the parameters and hyperparameters for the
custom and pretrained models obtained through optimization tools
(M = Momentum, ILR = Initial learning rate, L2 = L2-weight decay,
and D = Dropout ratio).
TABLE 3. Performance metrics achieved during modality-specific transfer
learning using the RSNA CXR dataset (Acc. = Accuracy; Sens. = Sensitivity,
Prec. = Precision, F = F-score, MCC = Matthews correlation coefficient,
and Param. = trainable parameters). The values in square brackets show
the 95% CI that are computed to be the Clopper–Pearson exact interval
corresponding to the separate 2-sided interval with individual coverage
probabilities of (0.95)1/2.
IV. RESULTS AND DISCUSSION
The optimal values for the parameters and hyperparameters
obtained for the customized and pretrained CNNs with
the Talos optimization tool and randomized grid search,
respectively, are shown in Table 2.
Table 3 shows the performance achieved through
modality-specific knowledge transfer, by the customized and
pretrained CNNs using the RSNA CXR dataset.
It can be observed that the VGG-16, VGG-19, and
Inception-V3 models were more accurate than the other mod els under study. The aforementioned models demonstrated
promising AUC values with a shorter CI and hence a smaller
margin of error, thereby offering precise estimates compared
to the other models. This is because the architecture depths
of the VGG and Inception-V3 models are optimal to learn
the hierarchical representations of features from the CXR
data and classify them into normal and pneumonia classes.
Considering the F-score and MCC that give a balanced
measure of precision and recall, the aforementioned models
delivered performance that was superior to the other models.
TABLE 4. Performance metrics achieved by the top-3 modality-specific
knowledge transfer models on the target tasks.
The top-3 performing modality-specific knowledge
transfer models (VGG-16, VGG-19, and Inception-V3) are
instantiated with their modality-specific weights and trun cated at their fully connected layers and appended with the
task-specific heads. Table 4 shows the performance achieved
by the task-specific models toward the following classifi cation tasks: (a) binary classification to classify CXRs as
normal or COVID-19 pneumonia and (b) multi-class clas sification to classify CXRs as normal or as showing bacterial
pneumonia or COVID-19 pneumonia.
It can be observed that for the binary classification task, all
the models are 100% accurate, however, VGG-16 has the least
number of trainable parameters. For multi-class classifica tion, it can be observed that the Inception-V3 model was more
accurate with a shorter CI for the AUC metric, signifying that
it has the least margin for error and hence provides a more pre cise estimate. Considering F-score and MCC, the Inception V3 model delivered superior performance compared to
VGG-16 and VGG-19 models.
For the multi-class classification task, the predictions
of the task-specific models (VGG-16, VGG-19, and
Inception-V3) are combined through several ensemble
methods including max voting, simple averaging, weighted
averaging, and model stacking. We didn’t perform ensemble
learning for the binary classification task since the indi vidual models are 100% accurate in classifying CXRs as
normal or showing COVID-19 pneumonia-related opacities.
Table 5 shows the performance achieved for the multi-class
classification with different ensemble strategies. It can be
observed that a simple average of the models’ predictions
is more accurate with a shorter CI for the AUC metric,
signifying a smaller margin of error and therefore, higher
precision, compared to other ensemble methods. Considering
the F-score and MCC, the averaging ensemble outper formed other ensemble strategies in classifying CXRs as
normal, or as showing bacterial pneumonia or COVID-19
viral pneumonia.
For the multi-class classification task, we iteratively
pruned the task-specific models (VGG-16, VGG-19, and
115046 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 5. Performance metrics achieved by the unpruned models through
different ensemble strategies for the multiclass classification task.
TABLE 6. Performance metrics achieved by the best iteratively pruned
models and compared with the baseline unpruned models from Table 4
(U-unpruned and P-pruned).
Inception-V3) by removing 2% of the neurons with the
highest APoZ in each convolutional layer at a given time
step and retrained the pruned model to evaluate its perfor mance on the validation set. We used model checkpoints to
store the best-pruned model that gave a superior performance
with the validation set. The process is repeated until the
maximum pruning percentage of 50% is reached. We then
evaluated the performance of all the pruned models on the test
set. The pruned model that achieved superior performance
with the test set is used for further analysis.
Table 6 shows a comparison of the performance achieved
by the pruned models to that of the baseline, unpruned
task-specific models shown in Table 4. It can be observed
that the pruned models are more accurate than their unpruned
counterparts. Considering the F-score and MCC metrics,
the pruned models are found to deliver superior perfor mance than the unpruned models. It is interesting to note
that the performance improvement is achieved with a sig nificant reduction in the number of parameters. As can
be seen, the number of parameters in the pruned VGG 16 model reduced by 46.03% compared to its unpruned
counterpart. Similarly, the number of trainable parameters
reduced by 16.13% and 36.1% for the pruned VGG-19 and
Inception-V3 models, respectively, with the added benefit of
FIGURE 6. Grad-CAM Visualizations showing salient ROI detection by
different pruned models. (A) CXR showing COVID-19 viral
pneumonia-related opacities with GT annotations, (B) VGG-16 pruned
model, (C) VGG-19 pruned model, and (D) Inception-V3 pruned model.
Bright red corresponds to the pixels carrying higher importance and
hence weights for categorizing the test sample to the COVID-19 viral
pneumonia category.
performance improvement in terms of accuracy, F-score, and
MCC metrics, compared to their unpruned counterparts.
Fig. 6 shows the results of performing Grad-CAM
visualizations to localize the salient ROIs used by the dif ferent pruned models to classify a sample test CXR into the
COVID-19 viral pneumonia category. The visualizations are
compared with consensus GT annotations provided by the
expert radiologists. The predictions of the pruned models are
decoded for the test sample. Two-dimensional heat maps are
generated in bright red, which corresponds to the pixels car rying higher importance and hence weights for categorizing
the test sample to COVID-19 pneumonia infected category.
Distinct color transitions are observed for varying ranges
of pixel importance toward making the predictions. Salient
ROIs are localized by superimposing the heat maps on the
input sample CXR. It is observed that the pruned models
precisely localize the salient ROI. This underscores the fact
that the pruned models have learned the implicit rules that
generalize well and conform to the experts’ knowledge about
the problem.
Table 7 shows a comparison of the performance metrics
achieved with the different ensemble strategies for the
unpruned and pruned models toward classifying the CXRs as
normal or showing bacterial pneumonia, or COVID-19 viral
pneumonia.
While performing weighted averaging ensemble for both
unpruned and pruned models, the predictions are awarded the
importance based on their F-score and MCC measures that
offer a balanced measure of precision and sensitivity. From
Table 6, it can be observed that the pruned and unpruned
VOLUME 8, 2020 115047S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 7. Comparing the performance metrics achieved with the pruned
and unpruned model ensembles from Table 4.
FIGURE 7. Confusion matrix obtained with the weighted-average pruned
ensemble.
Inception-V3 model delivered superior performance, fol lowed by VGG-19 and VGG-16 models. In this regard, we
assigned weights of 0.5, 0.3, and 0.2 to the predictions of
Inception-V3, VGG-19, and VGG-16 models, respectively.
It can be observed that the weighted averaging ensemble
of the predictions of the pruned models delivered superior
performance in all aspects. Fig. 7 and Fig. 8 shows the confu sion matrix and AUC curves, respectively, obtained with the
weighted-averaging pruned ensemble.
The 95% CI for the AUC metric has the shortest error
margin with a more precise estimate than that obtained with
the other ensemble methods. Considering the F-score and
MCC, the weighted averaging ensemble outperformed the
other ensemble strategies in classifying CXRs as normal,
bacterial pneumonia, or COVID-19 viral pneumonia.
FIGURE 8. ROC curves showing micro/macro-averaged and class-specific
AUC obtained with the weighted-average pruned ensemble.
V. CONCLUSION
The COVID-19 pandemic has had an enormously negative
impact on population health and national economies world wide. Early diagnosis has often been suboptimal and serolog ical tests have not been widely available. The opportunity to
utilize CXRs as part of the diagnostic approach could add an
important and nearly universally available tool to the battle
against COVID-19 or other respiratory viruses that might
emerge in the future. In the current study, we demonstrate
that this can be done by applying ensemble DL to findings
seen in CXRs.
Modality-specific transfer learning performed with a
large-scale CXR collection with a diversified data distribu tion helped in learning CXR modality-specific features. The
learned feature representations served as a good weight ini tialization and improved model adaptation and generalization
compared to ImageNet pretrained weights, when transferred
and fine-tuned for a related CXR classification task.
Iterative pruning of the task-specific models and selection
of the best performing pruned model not only improved
prediction performance on the test data but also significantly
reduced the number of trainable parameters. This is because
there are redundant network parameters (neurons) in a deep
model that do not contribute to improving the prediction
performance. If these neurons with lesser activations can be
identified and removed, it results in a faster and smaller model
with similar or improved performance than the unpruned
models. This would facilitate deploying these models on
browsers and mobile devices.
We further improved the performance by constructing
ensembles of the pruned models. By empirically evaluating
the performance of the pruned models and awarding weights
based on their predictions, we observed that the weighted
averaging ensemble of the pruned models outperformed the
other ensemble methods.
We performed visualization studies to validate the
pruned model localization performance and found that the
pruned models precisely localized the salient ROI used in
categorizing the input CXRs to their expected categories.
115048 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
We observe that combined use of CXR modality-specific
knowledge transfer, iterative model pruning, and ensem ble learning reduced prediction variance, model complexity,
promoted faster inference, performance, and generalization.
However, the success of this approach is controlled by two
broad factors: (i) dataset size and inherent variability, and
(ii) computational resources needed for successful deploy ment and use. With dataset size, we specifically refer to the
minimum number of topically relevant images, in this case,
CXRs with viral pneumonia that are distinct from bacte rial and normal images, that are needed to build confidence
into the ensemble. With computational resources, we recog nize the training time and memory constraints required for
practicable deployment. However, low-cost GPU solutions,
high-performance computing (HPC), and cloud technology
would address the feasibility in this regard. Future studies
could explore visualizing and interpreting the learned behav ior of the pruned model ensembles and their application
to other screening situations like COVID-19 detection and
localization in 3D CT scans, etc. At present, we expect that
the proposed approach can be quickly adapted for detection
of COVID-19 pneumonia using digitized chest radiographs.



NEW_PAPER



Received August 21, 2020, accepted August 26, 2020, date of publication September 18, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025010
DL-CRC: Deep Learning-Based Chest Radiograph
Classification for COVID-19 Detection: A Novel
Approach
SADMAN SAKIB 1
, TAHRAT TAZRIN 1
, MOSTAFA M. FOUDA 2,3, (Senior Member, IEEE),
ZUBAIR MD. FADLULLAH 1,4, (Senior Member, IEEE),
AND MOHSEN GUIZANI 5
, (Fellow, IEEE)
1Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada
2Department of Electrical and Computer Engineering, College of Science and Engineering, Idaho State University, Pocatello, ID 83209, USA
3Department of Electrical Engineering, Faculty of Engineering at Shoubra, Benha University, Cairo 11629, Egypt
4Thunder Bay Regional Health Research Institute (TBRHRI), Thunder Bay, ON P7B 7A5, Canada
5Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar
Corresponding author: Sadman Sakib (ssak2921@lakeheadu.ca)
This work was supported in part by the MITACS Accelerate under Grant IT18879, and in part by the Natural Sciences and Engineering
Research Council of Canada (NSERC) under Discovery Grant RGPIN-2020-06260.
ABSTRACT With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians
continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities.
Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely
available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be
used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the
COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph
classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other
abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available
sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal
cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI)
algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and
generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train
a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our
customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection
accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few
actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify
our customized CNN model by extensively comparing it with widely adopted CNN architectures in the
literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based,
and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it
can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence
of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.
INDEX TERMS COVID-19, convolutional neural network (CNN), deep learning, generative adversarial
network (GAN), pneumonia.
I. INTRODUCTION
The severe acute respiratory syndrome coronavirus 2 (SARS CoV-2), first observed in Wuhan, China, turned into a global
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
pandemic of COVID-19 (coronavirus disease 2019) [1].
COVID-19 has a destructive impact on the well-being of peo ple, particularly senior citizens and patients with underlying
health conditions and compromised immunity levels. By mid July 2020, the COVID-19 pandemic already contributed to
over 570,000 mortalities and more than 13 million cases
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 171575S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
of COVID-19 infection [2]. A critical step to combat the
pandemic is to effectively detect COVID-19 infected patients
as early as possible so that they may receive appropriate
attention and treatment. Early detection of COVID-19 is
also important to identify which patients should isolate to
prevent the community spread of the disease. However,
considering the recent spreading trend of the COVID-19,
an effective detection remains a challenging task, particularly
in communities with limited medical resources. While the
reverse transcription polymerase chain reaction (RT-PCR)
test-kits emerged as the main technique for COVID-19 diag nosis, chest X-ray (chest X-ray), computed tomography (CT)
scans, and biomarkers (i.e. high C-reactive protein (CRP),
low procalcitonin (PCT), low lymphocyte counts, elevated
Interleukin-6 (IL6), and Interleukin-10 (IL10)) are also being
increasingly considered by many nations to aid diagnosis
and/or provide evidence of more severe disease progres sion [3]–[5].
As depicted in Fig. 1, the existing system for detecting
COVID-19 using the aforementioned virus and antibody test ing modalities is time-consuming and requires additional
resources and approval, which can be a luxury in many devel oping communities. Hence, at many medical centers, the test
kits are often unavailable. Due to the shortage of kits and
false-negative rate of virus and antibody tests, the authorities
in Hubei Province, China momentarily employed radiologi cal scans as a clinical investigation for COVID-19 [6].
FIGURE 1. Challenges of existing system and our research focus for
COVID-19 screening in rural areas.
Motivated by this, several researchers and sources
recommend the use of chest radiograph for suspected
COVID-19 detection [7]–[9]. Therefore, radiologists can
observe COVID-19 infected lung characteristics (e.g., ground
glass opacities and consolidation) by harnessing non-invasive
techniques such as CT scan or chest X-ray. However, it is
difficult to differentiate the COVID-19-inflicted features
from those of community acquired bacterial pneumonia [10].
Therefore, for many patients, manual inspection of the radio graph data and accurate decision making can be overwhelm ing for the radiologists, and an automated classification tech nique needs to be developed. In addition, radiologists may get
infected and need to isolate that may impact rural commu nities with a limited number of hospitals, radiologists, and
caregivers. Moreover, as the second wave of COVID-19 is
anticipated in the fall of 2020, preparedness to combat such
scenarios will involve increasing use of portable chest X-ray
devices due to widespread availability and reduced infection
control issues that currently limit CT utilization [10]. There fore, as depicted in Fig. 1, in this paper, to automate the
COVID-19 detection using X-ray images, we aim to develop
an artificial intelligence (AI)-based smart chest radiograph
classification framework to distinguish the COVID-19 cases
with high accuracy from other abnormal (e.g., pneumonia)
and normal cases. In this vein, the main contributions of the
paper can be summarized as follows:
• A deep learning-based predictive analytics approach is
employed to propose a smart and automated classifica tion framework for predicting COVID-19, pneumonia,
and normal cases. Our proposed deep learning-based
chest radiograph classification (DL-CRC) framework
consists of a data augmentation of radiograph images
(DARI) algorithm and a customized convolutional neu ral network model.
• A uniquely compiled dataset from multiple publicly
available sources is prepared with radiographs of healthy
(normal), COVID-19, and pneumonia cases reported to
date. The limited number of COVID-19 instances in
the dataset is identified as the prime reason for train ing bottleneck of deep learning algorithms. As a solu tion, our proposed DARI algorithm essentially combines
a customized generative adversarial network (GAN)
model with several generic augmentation techniques
to generate synthetic radiograph data to overcome the
COVID-19 class imbalance problem due to limited
dataset availability.
• We train a customized CNN model based on combined
real and synthetic radiograph images that contributes to
significantly improved accuracy of 93.94% in contrast
with 54.55% when only actual COVID-19 instances in
public datasets are used for training. While chest X-ray
is regarded as a less sensitive modality in detecting
COVID-19 infection in lungs compared to CT scans
in the literature [10], we demonstrate the good per formance of our custom CNN model in identifying
COVID-19 cases in the real dataset with high accu racy implying that our approach nullifies the need
for using expensive CT scan machines because the
COVID-19 detection accuracy using our custom CNN
model is much higher compared to the reported base line [10].
• We rigorously analyze the computational complexity
of the DARI, training, and running/inference steps of
our proposed DL-CRC framework. The analyses, fur ther corroborated by experimental results, reveal that
our proposed methodology leads to significantly lower
training time, and particularly much improved infer ence time, which is crucial for deploying the trained
model into portable X-ray devices for fast and reliable
COVID-19 feature detection in lung radiographs.
171576 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
• The performance of our customized CNN model is
extensively compared with the state-of-the-art CNN
architectures in the literature (i.e., depth-based CNNs,
multi-path-based CNNs, and so forth) [11]. Our proposal
is demonstrated to substantially outperform the contem porary models in terms of classification efficiency.
The remainder of the paper is organized as follows.
Section II surveys the relevant research work regarding
COVID-19 and the relevant use of AI. The problem of tradi tional COVID-19 detection and challenges associated with it
to apply in developing communities is discussed in section III.
Our proposed input representation and deep learning model
are presented in section IV. The performance of our proposal
is evaluated in section V and extensively compared with those
of well-known CNN architectures. Some of the limitations of
the study is briefly explored in section VI. Finally, section VII
concludes the paper.
II. RELATED WORK
This section explores the relevant research work in the lit erature from two perspectives, i.e., imaging modalities for
COVID-19 detection, and AI-based analysis of radiograph
samples.
A. IMAGING MODALITIES FOR COVID-19 DETECTION
Most nations had to take measures to react to the sudden
and rapid outbreak of COVID-19 within a relatively short
period of time. According to [12], radiology departments
have started to focus more on preparedness rather than diag nostic capability, after sufficient knowledge was gathered
regarding COVID-19. The study in [5] stated the resemblance
of COVID-19 with other diseases caused by other coron avirus variants such as the severe acute respiratory syndrome
(SARS) and the middle east respiratory syndrome (MERS).
The importance of a tracking the lung condition of a recov ering coronavirus patient using CT scans was also mentioned
in the study. Chest imaging techniques were highlighted to be
a crucial technique for detecting COVID-19 by capturing the
bilateral nodular and peripheral ground glass opacities in the
lung radiograph images [13].
B. AI-BASED RADIOGRAPH ANALYSIS
The application of AI, for early detection, diagnosis, moni toring, and developing vaccines for COVID-19, were elabo rately discussed in [14]. Several research work exist in the
literature that exploited various deep learning techniques on
X-ray data to demonstrate reasonable performance [15]–[18].
In [19], a model, referred to as DarkCovidNet, for early
detection of COVID-19 was proposed which utilized 17 con volutional layers to perform binary and multi-class classi fication involving normal, COVID, and pneumonia cases.
While the model reported an overall accuracy of 98.08%
for the binary classification and 87.02% for multi-class clas sification, our reconstruction of the DarkCovidNet using
multiple datasets indicated overtraining and much lower
accuracy when non-biased test data are presented to the
model. Several other papers applied deep learning models on
CT scan images to detect and monitor COVID-19 features
in the radiograph data [20], [21]. Ardakani et al. in [22]
employed implemented the state-of-the-art CNN architec tures such as AlexNet, ResNet-18, ResNet-50, ResNet-101,
SqueezeNet, VGG-16, VGG-19, MobileNet-V2, GoogleNet,
and XceptionCT to differentiate between COVID-19 and
non-COVID-19 cases. Their experiments showed that deep
learning could be considered as a feasible technique for iden tifying COVID-19 from radiograph images. To avoid poor
generalization and overfitting due to lack of COVID-19 sam ples in available datasets, a GAN model was used in [23]
to generate synthetic data, which achieved a dice coefficient
of 0.837. The applicability of GAN for COVID-19 radiograph
data synthesis can be confirmed from the broader spectrum of
GAN applications on various medical data according to the
survey in [24]. The survey identified various unique proper ties of GAN such as domain adaptation, data augmentation,
and image-to-image translation that encouraged researchers
to adopt it for image reconstruction, segmentation, detection,
classification, and cross-modality synthesis for various med ical applications.
III. PROBLEM STATEMENT
With the rapidly surging pandemic, the demand for efficient
COVID-19 detection has dramatically increased. The lack of
availability of COVID-19 viral and antibody test-kits, and the
time required to obtain the test results (in the order of days
to weeks) in many countries are posing a great challenge in
developing/rural areas with less equipped hospitals or clinics.
For instance, in many developing countries, hospitals do
not have sufficient COVID-19 test-kits, and therefore, they
require the assistance of more advanced medical centers to
collect, transport, and test the samples. This creates a bot tleneck in mass testing for COVID-19. Therefore, to meet
the daily demand for an enormous amount of new test cases,
an automated and reliable complementary COVID-19 detec tion modality is necessary, particularly to confront the sec ond wave of the pandemic. Radiograph image utilization for
initial COVID-19 screening may play a pivotal role in areas
with inadequate access to a viral/antibody testing. In several
studies, CT scans were used for analyzing and detecting fea tures of COVID-19 [25] due to higher resolution of features
of ground glass opacities and lung consolidation compared
to chest X-ray images. However, due to infection control
matters associated with patient transport to CT suites, rela tively high cost (for procurement, operation and maintenance
of CT equipment), and the limited number of CT machines
in developing/rural areas, CT scan is not a practical solu tion for detecting COVID-19 [10]. On the other hand, chest
X-ray can be employed to identify COVID-19 or other pneu monia cases as a more practical and cost-effective solution
because X-ray imaging equipment are pervasive at hospital
ERs, public healthcare facilities, and even rural clinics. Even
for trained radiologists, detecting chest X-ray images pose
VOLUME 8, 2020 171577S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
challenges to distinguish between features of COVID-19 and
community acquired bacterial pneumonia [10]. Moreover,
the influx of patients into hospital ERs during pandemic,
manual inspection of radiograph data and accurate decision
making can lead to a formidable tradeoff between detection
time and accuracy that can overwhelm the radiologist depart ment. Therefore, an automated classification technique needs
to be designed. As the second wave of COVID-19 is expected
in many countries, preparedness to combat the pandemic
will involve increasing use of portable chest X-ray devices
due to widespread availability and reduced infection control
issues that currently limit CT utilization [10]. In the following
section, we address the aforementioned problem and present
a deep learning-based approach to effectively solve the prob lem.
FIGURE 2. Our customized generative adversarial network (GAN) model
for data augmentation.
IV. PROPOSED DEEP LEARNING-BASED CHEST
RADIOGRAPH CLASSIFICATION (DL-CRC) FRAMEWORK
Deep learning in smart health analytics is a prominent inter disciplinary field that merges computer science, biomedi cal engineering, health sciences, and bioinformatics. Various
medical imaging devices have a dedicated image and signal
analysis and processing module, on which deep learning based models can be implemented to provide accurate, real time inferences. Motivated by this, we conceptualize a deep
learning-based chest radiograph classification (DL-CRC)
framework, which can used for automating COVID-19 detec tion from radiograph images.
Our proposed DL-CRC framework consists of two compo nents: (i) the data augmentation of radiology images (DARI)
algorithm, and (ii) a deep learning model. Our proposed
DARI algorithm generates synthetic X-ray images by adap tively switching between a customized GAN architecture
and generic data augmentation techniques such as zoom and
rotation. The synthetic X-ray images are combined with the
actual radiograph data to build a robust dataset for efficiently
training the deep learning model, i.e., the second component
of our DL-CRC framework. A custom CNN architecture is
designed to construct the deep learning model to carry out
automated feature extraction and classification of the radio graph images.
Next, the details of the proposed DARI algorithm and
custom CNN model of our envisioned DL-CRC framework
are presented, followed by a rigorous complexity analysis of
the proposed methodology in training and inference phases.
A. PROPOSED DARI ALGORITHM
Here, we propose an adaptive data augmentation of radio graph images algorithm, referred to as DARI. Our proposed
DARI algorithm performs an on-demand generation of syn thetic X-ray images, triggered by class imbalance in the orig inal dataset. The generated synthetic images are combined
with actual radiograph images to construct a robust training
dataset. This is essential, in the COVID-19 context, where
enough representative samples of COVID-19 chest X-ray
images are not sufficient in the currently available datasets.
DARI leverages a custom GAN model, as depicted in Fig. 2,
along with generic data augmentation techniques such as
zoom and rotation. The GAN model is invoked if the number
of samples in a class is less than a certain pre-defined thresh old (δ). In the GAN model, a generator (G) and a discrimi nator (D) are trained simultaneously until the discriminator
is unable to separate the generated data samples from the
original ones. The generator receives random noise as input
and produces chest X-ray images, which are, in turn, received
by the discriminator. Thus, the GAN can be regarded as a
two-player minimax game between a discriminative model
(D) and a generative model (G) [26]. By exerting a noisy
sample nx with the data distribution of p(nx ) as the input,
the generative network G outputs new data X
0
, distribution
of which, denoted by p(X
0
), is supposed to be identical to that
of the distribution of original data, p(X). The discriminative
network, D, is employed to distinguish the true data sample X
with the distribution of p(X) and the generated sample X
0 with
a distribution of p(X
0
). Then, this adversarial training process
can be formulated as follows,
minG maxDV(D, G) = EX∼p(X)
log(D(X))
+ Enx∼p(nx )
log(1 − D(nx )). (1)
We customize the GAN model for chest X-ray image
augmentation as follows. The generator is constructed with
a stack of ng hidden layers. Each layer comprises a dense
layer, followed by Leaky Rectified Linear Unit (LeakyReLU)
as the activation function. In each successive layer (i
th) of the
generator, the number of neuron units (i.e., nodes) is twice
the number of nodes in the preceding layer. On the other
hand, in the discriminator model, it receives collections of
original (X) and generated (X
0
) X-ray radiograph data with
COVID-19 infected lung images. Here, the inputs to the dis criminator are X = [x1, x2, . . . xn] and X
0 = [x
0
1
, x
0
2
, . . . x
0
n
],
where each xi represents an original image while each x
0
i
denotes an augmented chest X-ray image. Similar to the
171578 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
generator, the discriminator’s structure also consists of nd
hidden layers, and each i
th layer contains a sequence of a
dense layer with LeakyReLU as the activation function [27].
A dropout layer is then included. Let pi denote the dropout
rate. The number of nodes in each i
th layer is denoted by Di
.
Note that Di =
1
2
· Di−1. The discriminator aims to optimize
the loss function by distinguishing generated images from the
original ones. Our custom GAN model is trained for ξmax
number of iterations, where ξmax ∈ Z
+. The detailed steps of
our proposed DARI algorithm are presented in Algorithm 1.
Here, we either invoke the GAN or a more generic type of
data augmentation, based upon a given condition as illustrated
in Algorithm 1. This procedure takes two inputs: (i) type
of augmentation, and (ii) data for augmentation. For one
condition, the proposed GAN model gets executed from steps
2 to 22. When the other condition is fulfilled, the generic data
augmentation is performed as described in steps 23 to 25,
which includes enlarging the image by Z quantity and rotating
by θ amount.
B. PROPOSED CUSTOM CNN MODEL FOR
COVID-19 DETECTION IN X-ray IMAGES
Next, we need to train a deep learning model which can take
advantage of the robust dataset obtained from our proposed
DARI algorithm in section IV-A. Since the problem can
be regarded as a classification task of normal, COVID-19,
and other abnormal cases (e.g., pneumonia), we investigate
the contemporary deep learning architectures suited for clas sification. In contrast with other variants of deep learning
architectures (i.e., long-short term memory (LSTM), deep
belief networks, and so forth) and extreme learning machines,
CNNs are regarded as the most powerful deep learning
architecture for image classification. Therefore, we explore
the robust CNN models recently employed to gain rea sonable classification accuracy with chest X-ray data [19].
By applying the contemporary CNN models on the latest
dataset compiled from four public repositories, we realize that
their reported performances are constrained by overfitting
and influenced by biased test data. To address this issue,
we propose a two-dimensional (2-D), custom CNN model
for classifying X-ray images to predict COVID-19 cases as
depicted in Fig. 3. The 2-D CNN structure is utilized to learn
the discriminating patterns automatically from the radiograph
images.
The proposed CNN model consists of three components.
The first component is a stack of nc convolution layers while
the second segment consists of nd fully connected layers.
The final component is responsible for generating the output
probability. At first, the convolution layers (i.e., the first com ponent of the model) receive radiograph images (X) as input,
identify discriminative features from the input examples, and
pass them to the next component for the classification task.
Each i
th layer among the nc convolution layers consists of a
filter size of z
i
. Initially, the filter size is set to xir
in the 1st
layer, and it is decreased by λ in each successive layer. In the
Algorithm 1 Data Augmentation of Radiograph Images
(DARI)
Input: type (type of data augmentation,
possible values ‘generic’,
‘GAN’), D (collection of data
for augmentation)
Output: γ (augmented sample data)
1 γ ← ∅
2 if (type=‘GAN’) then
3 Initialize ξmax (maximum number of
epochs), B (mini-batch size), and
naug (number of data to augment)
4 mg ← construct generator model as
depicted in Fig. 2
5 md ← construct discriminator model
as depicted in Fig. 2
6 foreach e ∈ ξmax do
7 for (i=1 to B) do
8 nx ← generate naug samples of
random noise to initialize
the generator
9 gi ← generate image by
passing nx to the generator mg
10 ri ← select random set of
samples from D
11 X
∗ ← construct collection
from generated (gi) and
original samples (ri)
12 md ← update the discriminator
model by batch training using
X
∗
13 end
14 nx ← generate naug samples of
random noise
15 mg ← update the generator model
parameters
16 if e=ξmax then
17 γ ← generate collection of
augmented images by using nx
18 foreach img ∈ γ do
19 save img to corresponding
directory
20 end
21 end
22 end
23 else
24 γ ← augment data by applying
zooming rate of Z and rotation of θ
on each item from data collection D
25 end
26 return γ
forward pass, the convolution operation is performed between
the input image and the filter coefficients using Eq. 2. Here,
VOLUME 8, 2020 171579S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 3. Proposed DL-CRC framework consisting of our envisioned
DARI algorithm and custom CNN model. (1) The test data is obtained by
splitting the original images that are not used for training. (2) DARI
algorithm adaptively uses GAN and generic data augmentation
techniques to generate synthetic chest X-ray images which are combined
with the remaining original radiograph images to construct a robust
training dataset. (3) The training input is passed to our customized CNN
model, which performs automated feature extraction and classification.
x
l
ij and w
l
ij denote the output and the filter weights of the l
th
layer, respectively.
x
l
ij =
X
i∈xir
,j∈xic
(x
l−1
ij × w
l
ij). (2)
Hyper-parameter tuning is conducted to select the optimal
activation function, , as shown in in Eq. 2. The activation
function considers a constant, denoted by α > 0.
Next, we apply a dropout of rate pi as the regularization
technique that will assist the network in evading overfit ting and achieve better model generalization by randomly
disregarding randomly selected neurons in the hidden lay ers [28]. To reduce the feature size and computational power
need, we introduce the max-pooling layer with a pool size
of ki = (k
i
r
, k
i
c
) in the hidden layers where ki
is set to a
fraction µ of the initial dimension of the input xi
. The max pooling layers assist the model in capturing abstract spatial
information more robustly and enhancing the model’s gen eralization ability of the model [29]. The output features of
the convolution layers are converted into a one-dimensional
(1-D) vector by flattening the layer, and then forwarded to the
stack of nd fully-connected or dense layers for the automated
classification stage. The number of nodes in the first dense
layer is equal to xir
, and it is decreased by a factor of λ in each
successive i
th layer with respect to the number of nodes in the
previous layer. The output of the n
th dense layer is propagated
through a dropout layer of rate pi
.
Finally, the output layer computes the probability of the
input xi belonging to each class. The learning is set to a
constant ηc throughout the training of the model. The clas sification task receives radiograph samples as input X =
[x1, x2, . . . xn], and outputs a sequence of labels Y =
[y1, y2, . . . yn]. Here, each xi corresponds to the pixel values
of the input images. On the other hand, each yi denotes a
distinct class. Each xi has the dimension of (xir
, xic
, ϑi). In this
case, xir
, xic
, and ϑi denote the image height, width, and the
number of channels for the i
th sample. The augmented and
real samples are passed to the training data during the training
phase, and some part of the real samples are considered as the
test dataset during the testing phase.
C. TRAINING AND RUNNING PHASES OF PROPOSED
DL-CRC
From hereon, we discuss the steps of the training and running
phases of our proposed DL-CRC algorithm.
The steps of the training phase of our proposed DL-CRC
framework is presented in Algorithm 2. The training stage of
DL-CRC commences from Algorithm 2, which takes C, k, B,
λ, and δ as inputs to our custom CNN model. The description
of each input parameter is provided in the input section of the
algorithm. Steps 1 to 3 of Algorithm 2 initialize the required
parameters. In steps 4 to 10, all data are loaded from location,
and the test data are split by the ratio of λ to be utilized in the
running phase for evaluating the model. Initially, all data are
171580 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
Algorithm 2 Training Phase (DL-CRC)
Input: C (collection for training,
testing, and validation data
location), k (number of fold
in cross-validation), ξ
(number of epoch), B
(mini-batch size), λ (test
ratio), δ (threshold value for
class imbalance ratio), N
(total number of samples
across all classes)
Output: Mt (Trained model)
1 Mt ← ∅
2 X ← []
3 Y ← []
4 X
∗ ← read all data from C[train]
5 if (len(X
∗
)> 0) then
6 I
∗ ← generate random values in
range[0, λ × len(X
∗
)]
7 foreach index i ∈ I
∗ do
8 move C[train] + X
∗
[i] to C[test] + X
∗
[i]
9 end
10 end
11 foreach class ci ∈ C[train] do
12 x
∗
i ← read all data from ci
13 if (len(x
∗
i
)/N < δ) then
14 x
∗
i
+= DARI(‘gan’, x
∗
i
)
15 end
16 foreach class data ∈ x
∗
i
do
17 X+=data
18 Y+=ci
19 end
20 end
21 for (fold no. j=1 to k) do
22 Xtrain, ytrain, Xval, yval ← set data and
labels of j
th fold from X, Y
23 Xtrain += DARI(‘generic’, Xtrain)
24 Xval += DARI(‘generic’, Xval)
25 Mt ← update the CNN model depicted
in Fig. 3 by training it using Xtrain
for ξ and B
26 evaluate Mt by using Xval, yval
27 end
28 save the model parameters of Mt
29 return Mt
stored in the training directory. Hence, they are loaded from
the location of training data. Steps 11 to 20 are responsible for
checking whether any data augmentation is required or not,
and accordingly preparing all the training and validation data
from the dataset. Specifically, steps 13 to 15 check whether
the training data in any class is less than a predefined thresh old δ or not, based on the condition if it can exploit the
Algorithm 3 Running Phase (DL-CRC)
Input: testPath (location of test
images)
Output: ypred (prediction of testing
samples)
1 Xtest ← read all data from testPath
2 Mt ← load the saved pre-trained model
3 yprob ← predict the probabilities of
each data from Xtest
4 ypred ← argmax(yprob)
5 return ypred
proposed data augmentation of radiograph images (DARI)
algorithm described in Algorithm 1. Our customized CNN
model is trained in steps 21-27, utilizing the model structure
illustrated in Fig. 3. At the penultimate step, the trained
model (Mt) is stored for further testing and validation. Finally,
in step 29, the algorithm returns the trained model.
Next, in the running phase, the CNN model of our proposed
DL-CRC framework follows Algorithm 3. It receives the
location of sample data for inference and returns the predicted
class labels (ypred) for the corresponding data. After reading
the data from step 1, the pre-trained model (Mt) is loaded in
the following step. In step 4, the model Mt
is employed to
predict the probabilities for a sample test data to be in each of
the possible classes. Finally, in the last step, the class with the
maximum probability is identified for each sample data, and
then returned as a collection of predictions for all the data.
D. COMPUTATION OVERHEAD ANALYSIS
In the remainder of the section, we rigorously analyze the
computational overhead of our proposed model in terms of
time-complexity. The analyses are divided into training and
running phases.
1) TRAINING PHASE
The training phase includes both our proposed DARI (Algo rithm 1) for data augmentation and training our customized
CNN model (Algorithm 2). Particularly for the analysis
of Algorithm 2, we consider that the appropriate hyper parameters of our CNN model are already selected after
hyperparameter tuning. We partition the analysis of the train ing phase into three main segments, i.e., DP (required data
preparation), DA (data augmentation), and CNN (the execu tion of the CNN model). Therefore, the total computational
complexity can be expressed as follows.
C(T ) = O(DP) + O(DA) + O(CNN). (3)
In the first three steps (1-3) of Algorithm 2, where initial ization is conducted, the time complexity can be denoted as
constant time, O(1). In the 4th step, all the data from the train
path are read. So, if there are fn number of data available to
train, the time complexity will be O(fn). Steps 5-9 split the test
data by the λ ratio. Therefore, the complexity associated with
VOLUME 8, 2020 171581S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
these steps is O(λ). Hence, the computational complexity of
the data preparation phase can be denoted as:
O(DP) = O(3) + O(fn) + O(λ) ≈ O(fn) + O(λ). (4)
The data augmentation part of the complexity analy sis mainly consists of our proposed DARI (Algorithm 1),
invoked in steps 13-15 of Algorithm 2. This requires loading
data from each class in step 12 that results in the computa tional complexity of O(cl × f
i
n
). Here, cl denotes the number
of classes while f
i
n
refers to the number of data read from
i
th class. Then, through steps 13-15, the DARI algorithm is
invoked and its complexity is denoted as ODARI. Suppose
that ng and nd denote the numbers of layers in the genera tor and discriminator, respectively. Then, the computations
required by the generator and the discriminator models can
be denoted as Gc (Eq. 5) and Dc (Eq. 6), respectively:
Gc = 2(Xng
i=1
x
i
g × w
i
g + b
i
g
), (5)
Dc = 2(Xnd
i=1
x
i
d × w
i
d + b
i
d
). (6)
Combining the previous two expressions of Gc and Dc,
the overall overhead of DARI (Algorithm 1) is evaluated as
follows.
O(DARI) = O(cl×ξmax×B×(Gc+Dc))+O(cl × naug),
(7)
where naug, ξmax, and B denote the number of data to augment,
maximum number of epochs, and mini-batch size, respec tively.
In steps 16-19 of the training algorithm, assuming the
length of each x
∗
i
as lx∗
i
, the computational overhead is O(lx∗
i
).
Therefore, the overall complexity of the data augmentation
stage can be expressed as:
O(DA) = O(cl × f
i
n
) + O(DARI) + O(lx∗
i
). (8)
From steps 21 to 27, the training algorithm invokes the
adopted 2-D CNN structure. The computational overhead for
this part can be derived from Eq. 9:
O(CNN) = O(CNNcl) + O(CNNdl), (9)
where O(CNNcl) and O(CNNdl) denote the computational
overheads in the convolutional layers and dense layers,
respectively. If we consider for a layer i, the number of filters
in the i
th layer z
i
, input image x
i with the dimension of
(x
i
r
, x
i
c
) and kernel k
i with the dimension of (k
i
r
, k
i
c
), then the
computational complexity of the convolutional layers can be
expressed as:
O(CNNcl) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
))). (10)
After the convolutional layers, for n layers, assuming w
i
and b
i
are the weight vector and the bias of i
th layer, the com plexity of the fully connected layers is given by:
O(CNNdl) = O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (11)
Hence, combining the aforementioned equations, to final ize the computational complexity of the proposed CNN,
we can re-write Eq. 9 as follows:
O(CNN) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
)))
+ O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (12)
Finally, to determine the total time complexity of the train ing phase of the DL-CRC algorithm, we can substitute the
corresponding values from Eqs. 4, 8, and 12 into Eq. 3.
2) RUNNING PHASE
The running phase is conducted to infer classes of each test
data using the pre-trained model and then evaluate the model.
As shown in Algorithm 3, if we consider the number of test
data to be ntest, the computational overhead in the testing
phase can be given by:
C(R) = O(ntest). (13)
Eq. 13 demonstrates that the model is able to pro duce results in linear time. This implies that our proposed
DL-CRC framework comprising DARI algorithm and the
customized CNN model can be deployed on clinical-grade
X-ray machines with image processing capability, computing
resources having access to digitized radiograph images from
analog X-ray machines, and even portable X-ray machines
in movable booths and trucks with adequate shielding and
power supply. Thus, our model is viable for automating the
radiograph image classification with fast turn-around time for
COVID-19 detection.
V. PERFORMANCE EVALUATION
To evaluate the performance of our proposed DL-CRC frame work, in this section, we describe the collected datasets used
to train our customized CNN model, followed by extensive
experimental results and discussion.
A. DATASET PREPARATION
The dataset employed for the supervised radiograph image
classification using our proposed DL-CRC framework con sists of three classes: COVID-19, pneumonia, and normal
chest X-ray images. We collected the dataset using four dif ferent existing datasets of Posteroanterior (PA) chest X-rays,
and combined those into a single dataset to utilize it for the
classification purpose. We developed the dataset from GitHub
for COVID-19 X-rays [30], X-ray data collected in this study
for cases of pneumonia, and normal images [31], CheXpert
171582 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 1. Brief description of the used dataset for X-ray image
classification.
dataset collected by Stanford ML group [32], and the rest of
the normal and pneumonia chest X-ray images were collected
from the dataset in [33]. Table 1 lists the initial class distri bution of the collected chest X-ray dataset. The number of
samples collected for COVID-19 is significantly lower than
the other two classes because this is a novel disease, and at this
moment, data regarding COVID-19 is challenging to obtain.
In other words, the number of COVID-19 class samples in
the merged dataset is lower than the threshold value for class
imbalance ratio, δ. Therefore, to overcome the effect of the
low amount of COVID-19 data, we employed our proposed
DARI algorithm to increase the number of samples. We then
applied our proposal along with contemporary CNN models
to verify which one yields the best COVID-19 detection
performance.
B. PERFORMANCE INDICATORS
To evaluate the classification results, we primarily adopted
the combination of three measurement indicators, accuracy,
weighted precision, and weighted F1 score. The accuracy of
a test is its ability to correctly differentiate the three cases.
Assume that C denotes the number of classes in the consid ered classification task, |yi
| refers to the number of samples
in the i
th class, and |Y | indicates the total number of samples
in all the classes. Then, the accuracy can be represented as
follows.
Accuracy =
PC
i=1
(TPi)
|Y |
. (14)
Next, we define the weighted precision. Our aim is to
measure how precise the model is in terms of the number of
samples actually present in the i
th class out of those predicted
to be in that class. This number is multiplied by the weight of
the i
th class to obtain the weight precision as follows.
Weighted precision =
X
C
i=1
(
|yi
|
|Y |
×
TPi
TPi + FPi
). (15)
Next, the weighted F1 score is defined as the weighted
average of precision and recall. Although we did not use
recall directly as a performance measure, because of using
the F1 score, it is implicitly used. The weighted F1 score can
be obtained as follows,
Weighted F1 score =
X
C
i=1
(
|yi
|
|Y |
× 2
Pi × Ri
Pi + Ri
). (16)
Here, Pi and Ri are the precision and recall of i
th class,
respectively. Pi can be expressed as TPi/(TPi + FPi) and
Pi can be denoted as TPi/(TPi + FNi). TPi
, FPi
, and FNi
denotes True Positive, False Positive, and False Negative
for i
th class respectively. TPi
indicates the number of cases
correctly identified to be in the i
th class; FPi represents the
number of cases incorrectly identified to be in the i
th class,
and FNi denotes the number of cases incorrectly identified
as a class other than the i
th class. In addition, for evaluating
our results more comprehensively we also employed class
specific classification accuracy (i.e., normal, COVID-19, and
pneumonia detection accuracy) for all three classes.
C. RESULTS AND DISCUSSION
We have followed a systematic approach by applying differ ent techniques to find the optimal model for the classification
task. All the experiments were conducted on a workstation
with Intel Core i7, 3.00GHz CPU, 16 GB RAM, powered
by Nvidia RTX 2060 Graphics Processing Unit (GPU). The
simulations were implemented employing Python’s Keras
and TensorFlow library. The visualization of the experimental
results was achieved by utilizing Python’s Matplotlib library.
During the simulations, we have resized the image samples by
setting both xir
and xic
to 100 to keep the images consistent in
terms of size. The number of channels of the samples (ϑi) was
set to 1 as the input images were grayscale in nature. The val ues of xir
and xic were selected based on manual tuning. Using
our proposed DARI algorithm, on-demand data augmentation
is performed by adaptively employing GAN, rotation (θ) of 5
degrees, and zooming (Z) rate of 0.50. The value of δ was
set to 0.1. We systematically constructed three experimental
scenarios to conduct a comprehensive performance compari son of our proposed DL-CRC framework consisting of DARI
algorithm and our customized CNN models with the state of-the-art CNN models which have been recently reported to
provide reasonable accuracies for COVID-19 detection. The
three scenarios, constructed in an incremental fashion, are
described below.
1) In our first scenario, we designed our customized deep
CNN model architecture depicted in Fig. 3. The param eters of the model were selected based on the results of
the grid search technique.
2) In the second scenario, we implemented the proposed
DARI algorithm to analyze the effect of the generic and
GAN-based data augmentation to train the CNN-based
model in a robust fashion to significantly improve the
COVID-19 detection accuracy.
3) In the third and final scenario, we trained several state of-the-art CNN models using different deep learning
paradigms on our compiled dataset. The same test data
(unknown chest X-ray original images with normal,
COVID-19, and pneumonia cases) were presented to
the customized CNN model of our proposed DL-CRC
framework as well as the contemporary CNN models.
The results were used to compare the performances of
our proposal and these contemporary models in terms
of COVID-19 and pneumonia detection efficiency.
VOLUME 8, 2020 171583S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 4. Performance in terms of accuracy for different combinations of
activation functions and optimizers.
FIGURE 5. Performance in terms of precision for different combinations
of activation functions and optimizers.
FIGURE 6. Performance in terms of F1 score for different combinations of
activation functions and optimizers.
In the first scenario, we implemented the customized CNN
model of our proposed DL-CRC framework and carried out
a grid search to achieve the optimal model parameters (i.e.,
FIGURE 7. Performance comparison for diverse ratios of the
COVID-19 X-ray images generated by the GAN with respect to the existing
number of samples in the dataset.
the best activation functions and optimizer). It is worth not ing that other customized CNN models revealed a perfor mance bottleneck in terms of validation accuracy and we
found the model in Fig. 3 to be the most lightweight yet
efficient for automating the chest X-ray classification task.
Figs. 4, 5, and 6 demonstrate the results obtained from the
hyper-parameter tuning in terms of accuracy, precision, and
F1 score, respectively. These performances were extensively
evaluated across six optimizers (Stochastic Gradient Descent
(SGD), Adaptive Moment Estimation (Adam), Root Mean
Square Propagation (RMSProp), Adaptive Delta (AdaDelta),
Nesterov and Adam (Nadam), and Adaptive Gradient Algo rithm (Adagrad)) and five activation functions (tanh, sig moid, Scaled Exponential Linear Unit (SELU), Rectified
Linear Unit (ReLU), and Exponential Linear Unit (ELU)). As
depicted by the results in these figures, SELU demonstrated
better performances on average when compared with the
other activation functions. However, the best performance
was exhibited when ELU is adopted as the activation function
with the value of constant α = 1.0 and the optimizer set to
Adagrad with the learning rate of 0.001. For this first exper imental setting for selecting the optimal hyper-parameters
of the deep learning-based model, the mini-batch size (B)
was set to 8, and the number of epochs (ξ ) was set to 20.
With this configuration, the validation accuracy, precision,
and F1 score were found to be 97.25%, 97.24%, and 97.21%,
respectively. Therefore, for further analysis, we applied this
configuration in the customized CNN model of our DL-CRC
framework. Furthermore, in the max-pooling layer of our
proposed CNN architecture, we conducted manual parameter
tuning, and the pool size ki was assigned as µ, where µ = 2%
of the initial size of the input xi
.
In the second experimental scenario, as the number of
COVID-19 samples in the collected dataset was lower than
the pre-defined threshold δ, we applied our proposed DARI
algorithm to increase the number of COVID-19 samples so
that the model can be trained with a robust training data
171584 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 8. Confusion matrix of testing phase employing 5-fold stratified cross-validation.
and eventually predict positive COVID-19 cases with high
accuracy. In Fig. 7, we altered the proportions for our cus tomized GAN model in the DARI algorithm with respect to
the original sample size of the COVID-19 class. The ratios
of GAN-generated samples of the proposed approach were
varied from 50% to 200% with respect to the number of
COVID-19 examples in the original dataset. The number of
iterations for producing the augmented samples using the
GAN-based method was set to 200. Among the proportions
mentioned earlier, the COVID-19 detection performance of
our customized CNN model was found to be the highest
(with an accuracy of 93.94%) when the number of newly
generated samples was 100% of the size of the original
COVID-19 samples. Therefore, we picked this configura tion to be used in our conducted experiments in the next
scenario.
After producing the augmented samples for the COVID-19
class, we analyzed the effect of combining the adaptive
generic data augmentation and GAN-based DARI algorithm
with the CNN architecture to fully implement and fine-tune
the DL-CRC framework, and compared the performance with
the base CNN model only (i.e., without adopting DARI
algorithm). The experiment was conducted utilizing a five fold stratified cross-validation. Using the stratification tech nique, the samples are rearranged so that each fold has a
stable representation of the whole dataset by maintaining
the percentage of samples for each class [34]. In our third
experimental setup, the number of epochs (ξ ) was set to
100, and the mini-batch size (B) was set to 8. The num ber of convolutional layers, nc, was set to five. The num ber of fully-connected/dense layers, nd , was also fixed to
five. Note that these hyperparameter values were manually
tuned. To analyze the results more critically in terms of
COVID-19 detection efficiency, in this experimental setting,
we also investigated the normalized and non-normalized val ues of the confusion matrices of our customized CNN model
TABLE 2. Performance comparison of the proposed DL-CRC and CNN
with generic and GAN-based data augmentation.
without (i.e., CNN-only model) and with the proposed DARI
algorithm (i.e., the complete DL-CRC framework). Fig. 8
represents the normalized confusion matrix where the pro posed CNN model is implemented without applying the data
augmentation, and Fig. 8 depicts the same for the combined
CNN and DARI algorithm. Despite similar performances of
both approaches, the normalized confusion matrix demon strates that our proposed DL-CRC framework is much more
robust for classifying positive COVID-19 and pneumonia
cases. The proposed DL-CRC exhibited 93.94% and 88.52%
accuracies while detecting positive COVID-19 and pneu monia cases, respectively. The encouraging classification
performance indicates that our proposed deep learning based DL-CRC framework is able to classify the radio graph images with high efficiency, specifically for COVID-19
detection.
Furthermore, we analyzed the impact of generic and GAN based data augmentation separately combined with our cus tomized CNN model and compared the COVID-19 detection
accuracy with the proposed DL-CRC framework. Table 2
exhibits the simulation results, which proves that both the
generic and GAN-based data augmentation had significant
influence in enhancing the COVID-19 detection efficiency.
The simulation results in the table show that our CNN only base model achieved 54.5%, CNN with generic data
augmentation obtained 63.4%, and CNN with the proposed
VOLUME 8, 2020 171585S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 3. Performance comparison of our proposed DL-CRC architecture
with the existing CNN architectures for all three classes.
GAN-based data augmentation delivered 84.5% COVID-19
detection accuracy. On the other hand, the proposed DL-CRC
framework demonstrated the highest COVID-19 detection
accuracy (93.94%). This good performance is attributed to
the combination of our customized CNN model with the pro posed DARI algorithm where both generic and GAN-based
data augmentation are adaptively performed, Therefore, it is
evident from these results that our proposed DL-CRC frame work made the customized CNN model much more robust
with DARI algorithm.
In the third experimental scenario, we compared the perfor mance of our customized CNN model with the performances
of the state-of-the-art CNN models such as Inception-Resnet
V2, Resnet, and DenseNet. The reason behind choosing these
contemporary models is their good performances reported
in the recent literature for COVID-19 detection. It is worth
noting that Inception-ResNet v2 and DenseNet belong to the
depth-based and multi-path-based CNN paradigms, respec tively. On the other hand, ResNet combines both depth based and multi-path-based CNN architectures. Table 3
demonstrates the comparative analysis, which indicates
the efficiency of our proposed DL-CRC framework in
terms of COVID-19 and pneumonia detection using chest
X-ray images. Our proposed model, outperformed ResNet,
Inception-ResNet v2, and DenseNet. Although Densenet
achieves 98.01% prediction performance for normal test
cases, its accuracy is only 72.42% for pneumonia detection
while it exhibits the poorest performance of 60.61% for
identifying COVID-19 cases. This implies that multi-path based structure, although reported in recent work, is not suit able for COVID-19 detection. On the other hand, Inception
ResNet v2, using the depth-based CNN modeling paradigm,
achieves improved COVID-19 detection accuracy (69.70%).
The combination of these two modeling paradigms is incor porated in ResNet, which is able to predict test cases having
COVID-19 samples slightly elevated accuracy of 72.72%.
On the other hand, our proposed DL-CRC framework, com bining our envisioned DARI algorithm and customized CNN
model, is able to detect the COVID-19 cases with a sig nificantly high accuracy of 93.94%. Note that the pneumo nia (the other abnormal case) present in the test dataset is
also detected with much higher accuracy (88.52%) compared
to the contemporary models. Even though the performance
slightly drops for normal case identification, the accuracy
is still close to 96% in case of our proposal. Furthermore,
in the final column of Table 3, the AUC (area under the ROC
(receiver operating characteristic) curve) values are also listed
for the proposed DL-CRC and contemporary models. The
AUC score of our proposed DL-CRC is 0.9525 which demon strates the reasonable accuracy of identification across all
samples in the test data. Thus, the encouraging performance
of the proposed DL-CRC algorithm over prominent CNN
models clearly demonstrates that the proposed technique can
be useful for detecting COVID-19 and pneumonia cases with
a significantly high (i.e., reliable) accuracy.
Furthermore, we compare the performance of our proposal
with a recent custom model, referred to as DarkCovidNet
[19]. For multi-class classification, the accuracy of Dark CovidNet was reported to be 87.02%, which is considerably
lower than that of our proposed model’s performance
(93.94%), which we believe ensures the effectiveness of our
proposed model. In addition, we have conducted two-fold
experiments to validate and compare our proposed tech nique (DL-CRC) with DarkCovidNet. Table 4 demonstrates
the results obtained when our proposed model is tested on
both datasets, and the DarkCovidNet model is tested on
both datasets. Both models were trained by employing the
respective dataset used by the work in [19] and our cur rent work. These experimental results presented in Table 4
were produced after training the models for 25 epochs for
each case, and then the trained models were tested on both
datasets. Our proposed technique outperformed DarkCovid Net for detection accuracies for both normal and COVID-19
cases. In addition to the classification efficiency, our pro posed DL-CRC framework is more lightweight than that of
used in DarkCovidNet. Our customized CNN model of DL CRC consists of 5 convolutional layers while the DarkCovid Net model comprises 17 convolutional layers, making our
model’s training phase more lightweight and computationally
less expensive than the DarkCovidNet model.
Moreover, while some researches reported overall accu racy, they did not mention the COVID-19 detection accuracy.
On the other hand, most researches applying deep learning
techniques did not report the AUC score, which is a robust
representative performance metric for practically evaluating
the COVID-19 detection ability of the model. In summary,
by applying various contemporary CNN models (Inception
with Resenet V2, Resnet, Densenet) and a recent customized
model (DarkCovidNet) for COVID-19 detection on the latest
dataset compiled from four public repositories, we realized
that their reported performances are constrained by overfit ting and influenced by biased test data. Thus, the accuracy
bottleneck of those existing models justifies why we required
to build a customized CNN model in this research and com bine it with the DARI algorithm to perform robust training
and avoid overfitting to ensure high COVID-19 detection
accuracy and a significantly high AUC score.
VI. LIMITATIONS OF THE STUDY
In this section, we briefly discuss some limitations and pos sible future work that can be conducted to extend the study.
171586 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 4. Comparison of the performance our proposed model with that of DarkCovidNet [19] on both datasets.
• Our study and experiments have been conducted at a
very critical stage and time-sensitive manner to com bat the COVID-19 pandemic with a proof-of-concept
COVID-19 using radiograph images. Despite compiling
datasets from multiple sources with X-ray images con taining COVID-19 samples, the used data was consid erably small in size. Therefore, synthetic images were
generated using our customized GAN-assisted data aug mentation technique that were used to train a robust
CNN model to perform binary (normal and COVID-19)
and three-way classification (normal, pneumonia, and
COVID-19) with significantly high accuracy. Due to
the lack of real datasets consisting of other diseases
(e.g., SARS, MERS, and so forth) which exhibit acute
respiratory distress syndrome (ARDS) and pneumonia like conditions in the lungs, more class labels were not
considered in our work.
• From a physician’s perspective, it is important to diag nose the severity of COVID-19. However, due to the lack
of labeled data, in this work, our model could not be
used to classify the various stages of COVID-19 such
as asymptomatic, mild, high and severe.
• The proposed technique performed efficiently when we
utilized it to analyze X-ray samples. However, the study
can be extended to evaluate the system’s performance
in COVID-19 detection while using other radiograph
techniques such as CT scan, lung ultrasound, and lung
PET (positron emission tomography) scan.
• The dataset used in this study is limited by only
one modality type, i.e., X-ray images containing
COVID-19 features. Further customization in our CNN
model will be required if we want to combine multiple
imaging modalities (e.g., lung CT scan, ultrasound, PET
along with X-ray images), other modalities (e.g., body
temperature, ECG, MCG, diabetes level, renal function,
and so forth), and patient parameters (e.g., age, gen der, ethnicity, travel history, and contact history) to per form an in-depth COVID-19 classification. Therefore,
a multi-modal input characterization and corresponding
AI model customization will be needed in the future for
interpreting and explaining the classification results.
VII. CONCLUSION
In this paper, we addressed the emerging challenges of
detecting COVID-19. Due to the shortage of efficient diag nosis equipment and personnel in many areas, particularly
in developing and/or rural zones, numerous people remain
non-diagnosed. This results in a substantial gap between the
number of confirmed and actual cases. Radiographs such as
chest X-ray images and CT scans have been demonstrated
to have the potential for detecting COVID-19 infection in
the lungs that can complement the time-consuming viral
and antibody testing. While CT scans have higher resolu tion or fine-grained details compared to X-ray images, X-ray
machines are pervasive in hospital emergency rooms, public
health facilities, and even rural health centers or clinics.
In addition, because X-ray is a much cheaper alternative
and an appealing solution for portability in mobile trucks
and COVID-19 screening booths with adequate shielding
and power supply, how to identify COVID-19 infection of
the lung by recognizing patterns such as glass opacities and
lung consolidations raised a formidable research problem,
that we addressed in this paper. Also, we discussed why
it is necessary to automate the X-ray image classification
to be well prepared for the next wave of COVID-19 pan demic, when radiologists and caregivers are expected to be
overwhelmed by patient influx as well as the need to self isolate in case they themselves become infected. This means
there is a pressing need to automate the classification of
radiographs, particularly X-ray images, to minimize the turn around time for COVID-19 detection. Therefore, to leverage
the availability and cost-efficiency of chest X-ray imaging,
in this paper, we proposed a framework called DL-CRC
(Deep learning-based chest radiograph classification) to auto mate COVID-19 detection that can complement existing viral
and antibody testing methods.
Our proposed DL-CRC framework consists of two parts:
the DARI algorithm (which adaptively employs a customized
generative adversarial network and generic data augmen tation techniques such as zoom and rotation) and a two dimensional convolutional neural network (CNN) model. We
employed a unique dataset for multiple publicly available
sources, containing radiograph images of COVID-19 and
pneumonia infected lungs, along with normal lung imaging.
The classification accuracy significantly increased to 94.61%
by adopting our proposed DL-CRC framework. Our pro posal was compared with existing deep learning models from
diverse categories such as depth-based CNN (e.g., Inception ResNet v2), multi-path-based CNN (DenseNet), and hybrid
CNN (ResNet) architectures. Extensive experimental results
demonstrated that our proposed combination of DARI and
custom CNN-based DL-CRC framework significantly out performed the existing architectures. Thus, incorporating our
proposed model with significantly high accuracy into the
VOLUME 8, 2020 171587S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
clinical-grade as well as portable X-ray equipment can allow
an automated and accurate detection of COVID-19 in the
scrutinized patients.




NEW_PAPER


C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Collaborative City Digital Twin for the COVID-19 Pandemic:
A Federated Learning Solution
Junjie Pang, Yan Huang, Zhenzhen Xie, Jianbo Li 
, and Zhipeng Cai
Abstract: The novel coronavirus, COVID-19, has caused a crisis that affects all segments of the population. As the
knowledge and understanding of COVID-19 evolve, an appropriate response plan for this pandemic is considered
one of the most effective methods for controlling the spread of the virus. Recent studies indicate that a city Digital
Twin (DT) is beneficial for tackling this health crisis, because it can construct a virtual replica to simulate factors,
such as climate conditions, response policies, and people’s trajectories, to help plan efficient and inclusive decisions.
However, a city DTsystem relies on long-term and high-quality data collection to make appropriate decisions, limiting
its advantages when facing urgent crises, such as the COVID-19 pandemic. Federated Learning (FL), in which
all clients can learn a shared model while retaining all training data locally, emerges as a promising solution for
accumulating the insights from multiple data sources efficiently. Furthermore, the enhanced privacy protection
settings removing the privacy barriers lie in this collaboration. In this work, we propose a framework that fused city
DT with FL to achieve a novel collaborative paradigm that allows multiple city DTs to share the local strategy and
status quickly. In particular, an FL central server manages the local updates of multiple collaborators (city DTs),
providing a global model that is trained in multiple iterations at different city DT systems until the model gains the
correlations between various response plans and infection trends. This approach means a collaborative city DT
paradigm fused with FL techniques can obtain knowledge and patterns from multiple DTs and eventually establish a
“global view” of city crisis management. Meanwhile, it also helps improve each city’s DT by consolidating other DT’s
data without violating privacy rules. In this paper, we use the COVID-19 pandemic as the use case of the proposed
framework. The experimental results on a real dataset with various response plans validate our proposed solution
and demonstrate its superior performance.
Key words: COVID-19; Digital Twin (DT); Federated Learning (FL); deep learning
  Junjie Pang is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, and is also with
the Business School, Qingdao University, Qingdao 266000, China. E-mail: pangjj18@163.com.
  Yan Huang is with the College of Computing and Software Engineering, Kennesaw State University, Atlanta, GA 30060, USA.
E-mail:yhuang24@kennesaw.edu.
  Zhenzhen Xie is with the College of Computer Science and Technology, Jilin University, Changchun 130012, China. E-mail:
xiezz14@mails.jlu.edu.cn.
  Jianbo Li is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, E-mail:
lijianbo@188.com.
  Zhipeng Cai is with the Department of Computer Science, Georgia State University, Atlanta, GA 30303, USA. E-mail: zcai@gsu.edu.
 To whom correspondence should be addressed.
Manuscript received: 2021-02-26; accepted: 2021-03-18760 Tsinghua Science and Technology, October 2021, 26(5): 759–771
1 Introduction
Coronavirus (COVID-19), an infectious disease
caused by the recently discovered coronavirus, was
identified on December 31th 2019[1] (https://www.who.
int/emergencies/diseases/novel-coronavirus-2019). The
virus has spread worldwide in less than three months,
infected more than 116 million people, and caused
over 2 575 196 deaths (https://www.worldometers.info/
coronavirus/). This widespread coronavirus outbreak
received tremendous attention from the research and
medical perspective. However, a specific antiviral
treatment of COVID-19 remains unavailable. Therefore,
an early and radical government response can be
considered the most effective method when facing a
novel infectious disease. However, determining the
response plan properly can be challenging because of a
lack of experience and efficient data sources.
A mathematical model is a possible solution for
the intervention and surveillance of the infectious
disease[2]. For example, the Susceptible-Infected Susceptible (SIS) epidemic model is widely used in
describing the spreading process for a virus in a static
network with an assumption of a constant population.
This model can also combine with a time-varying
dynamic network to describe more complex propagation.
We also observe that the significant proliferation of
machine learning techniques has resulted in the rapid
development of intelligent forecasting models[3]. Recent
works demonstrate their comparable performance in
capturing non-trivial atypical trends and typical patterns
for epidemic control, such as the Wiener-series-based
machine learning model for measuring the H1N1 virus
spread after an intervention[4], and the representation
learning model that generates interpretable epidemic
forecasting results for seasonal influenza forecasting[5]
.
However, these models still have several challenges
and limitations in predicting infection trends of a novel
infectious disease, such as COVID-19:
Uncertain influence: In contrast to other pandemic
predictions, the prediction model of unknown infectious
diseases, such as COVID-19, must learn the influence
of various response plan settings, such as mask-wearing,
shelter in place, and statewide school closures.
Cold start problem: When a new virus starts to
spread, the local health department always needs a long
time to properly collect sufficient data to generate a
response to the pandemic. Note that the same response
plan could have varied effects in different locations: a
radical response plan may only bring economic risks
to a low-risk areas, while the same actions could result
in losing control of the spreading virus and economic
damage for severely affected areas.
Privacy protection: The data resources related to a
health crisis, such as COVID-19 pandemic, unavoidably
contain sensitive information. This situation means that
we cannot collaboratively share these data unless we can
provide a strong privacy guarantee[6]. However, medical
institutions and local governments may expect a high performance model for epidemic control, which means
massive data collection is required for deep learning based models. Because of privacy and confidentiality
concerns, these applications can possibly be prevented,
such that data silos emerge[7]. These silos are isolated
islands of data, which can make health data management
disorganized and inefficient. Moreover, they make it
prohibitively costly for the local agencies to extract
knowledge, share insights, and realize collaborations
with other regions[8]
.
As shown in Fig. 1, we proposes a Digital Twin
(DT) enabled collaborative training framework based
on a federated learning paradigm to resolve the
above problems. We use a city DT to build a virtual
replica of the city/state that provides a digital view of
Federated Learning (FL) central server
City DT
Real world
Fig. 1 Overview of the collaborative framework for a multiple city DT.Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 761
city/state facilities, human activities, and other types
of information to enable information convergence in
multiple aspects of infection trend, thus enabling the
prediction of the uncertain influence caused by different
events. City DT allows each region to accumulate
historical data efficiently, while demonstrating a
remarkable potential for offering continuous interaction
with the physical world to refine prediction[9, 10]
.
Specifically, Time Convolutional Networks (TCN) is
adopted to implement a city DT, ensuring superior
performance for modeling the temporal information
dynamics and the future infection trend prediction under
a local response plan.
To further resolve the cold start problem and privacy
concerns, FL[11] is introduced as the collaborative
training paradigm. It only involves the parameters
shared among multiple parties in training collaborative
machine learning models. Thus, FL can significantly
lower the privacy risks in collaborative knowledge
exchange[12]. These features, combined with the high quality contribution from local city DT, are essential
for establishing a prediction model and accumulating
knowledge and insights for an unknown virus, such as
COVID-19, in a short period.
Our contributions can be summarized as follows:
  To resolve the uncertain influence challenge for
COVID-19 pandemic management, we are among the
first to propose a novel collaborative learning framework
with city DT embedding.
  The proposed TCN-based city DT helps determine
the effects of various local response plans for each
city/area, which is the first attempt to utilize a non trivial deep learning model for epidemic forecasting
considering fine-granularity time pattern features.
  Considering the cold start problem and privacy
concerns, we use the FL as the solution, which offers
collaborative learning via only parameter-sharing not to
disturb each city DT’s privacy rules.
  Extensive simulations with a real dataset reveal that
our proposed framework significantly outperforms the
non-trivial baseline and the non-FL city DT solution
with a strong privacy guarantee.
The remainder of the paper is organized as
follows. Section 2 introduces related works. The basic
definitions and problem statements are presented in
Section 3. Section 4 explains the detailed structure
and methodology of the proposed framework. The
experiments and results are analyzed in Section 5.
Finally, conclusions and future work are presented in
Section 6.
2 Related Work
In this section, we start with a brief review of traditional
methods for epidemic prediction, and then discuss the
related techniques and the need for the collaborative
training framework.
Deep learning-based epidemic control: Historical
insights from temporal infection data have been
crucial for epidemic control and prevention, and could
benefit other problems in smart city systems[13, 14] or
enhanced social network analysis[15]. Deep learning based techniques have demonstrated a remarkable
performance to model such temporal correlations and
recognize multiple patterns[16, 17], including the deep
neural network-based short-term and high-resolution
epidemic forecasting for influenza-like illness[18], the
semi-supervised deep learning framework that integrates
computational epidemiology and social media mining
techniques for epidemic simulation, called SimNest[19]
and EpiRP[20], which use representational learning
methods to capture the dynamic characteristics of
epidemic spreading on social networks for epidemics oriented clustering and classification.
Moreover, recent breakthroughs in infectious disease
modeling, forecasting, and real-time disease surveillance
have further convinced us that these activities mitigate
the effects of disease outbreaks. In addition, with
the rapid growth of cloud computing and wireless
data communication architectures[21, 22], deep learning models demonstrate constantly improving efficiency.
Given various application scenarios and objectives,
deep learning-based models can be different. A typical
solution for localized flu “nowcasting” and flu activity
inferring is ARGONet[23], which is a network-based
approach leveraging spatio-temporal correlations across
different states to improve the prediction accuracy.
ARGONet uses a spatial network to capture the
spatio-temporal correlations across different states and
produces more precise retrospective estimates based on
the information from influenza-related Google search
frequencies, electronic health records, and historical
influenza trends. Instead of leveraging multiple data
source, such as ARGONet, the studies in Ref. [24]
proposed a multi-task learning-based model that is only
uses user-generated content (Web search data). They
investigate linear and nonlinear model capabilities and
find that disease rate estimates can be significantly762 Tsinghua Science and Technology, October 2021, 26(5): 759–771
improved in the case study of an influenza-like illness.
However, these successful attempts are based on large scale data sources or massive historical information
of the disease with similar spreading patterns, which
means that high-dimensionality, irregularity forms,
noise, privacy concerns, or sparsity problems may
affect these learning-based models’ performance[25, 26]
,
especially when we face unexpected infectious disease
outbreaks, such as the COVID-19 pandemic.
For filling the data gap, the city DT is proposed as
a promising solution. It is a virtual representation of a
device or a specific application scenario that can interact
with the target environment to collect data continuously
for real-time decision-making. Several successful
research attempts include a disaster city DT[27, 28]
,
energy management[29], and city-scale Light Detection
and Ranging (LiDAR) point clouds[30]. Furthermore,
Singapore[31] and Germany[32] have launched the city scale DT to monitor and improve utilities, which enhance
the transparency, sustainability, and availability of a DT.
In this way, the city DT offers us a high-quality and
real-time data resource to describe the spread of an
epidemic, whereas data silos naturally emerge because
of privacy barriers[33, 34]. To maintain the advantages of
DT and tolerate the data sparsity challenge, FL, which
allows multiple stack-holders to share data and train a
global model, has become a preferred scheme[11]. In
typical FL scheme settings, each data owner (FL client)
engages in a collaborative training process without
transferring the raw data to the others. Through FL,
the central server manages each client’s local training
updates and aggregates their contributions to enhance the
global model’s performance. Several concrete scenarios,
including Google’s Gboard[35], health AI[36], and smart
banking[37], show the advantages of FL in handling
collaborative training issues and data difficulties among
diverse data owners. Therefore, we are motivated
to utilize FL techniques to resolve the data sparsity
challenges and design a collaborative city DT for
COVID-19 pandemic control.
3 Preliminary and System Model
In this section, we first explain the preliminaries of
the proposed framework. The structural design, which
combines DT and FL for COVID-19 pandemic control,
will be explained with a mathematical definition of
the problem objective. The detailed methodology and
proposed solution will be illustrated in Section 4.
3.1 Preliminaries
TCN: Given these advantages and a delicate-designed
convolutional architecture, TCN can handle variable
length inputs, such as those of Recurrent Neural Network
(RNN)-based methods[38], and convincingly outperform
baseline recurrent architectures across various sequence
modeling tasks. By leveraging a much simpler, 1-D
fully-convolutional network, TCN can build a very
long sufficient history size for a variable length of a
input sequence, avoiding large memory requirements
and intricate network architecture, such as those of
gated RNNs. Its model pipeline has two distinguishing
features: causal convolution and dilated convolution.
The causal convolutions consider that the output at time
t is convoluted only with elements that occurred before t,
which suggests that current spatial-temporal information
depends only on the past and not on any future inputs.
Then, to further achieve longer history data without
introducing an extremely deep network or very large
filters, a TCN uses a dilated convolution to enlarge
the sequence data’s maximum length (receptive field).
Notably, the receptive field can be changed by stacking
more dilated convolution layers or increasing the filter
sizes, which fully explain the robustness and flexibility.
FL: FL is a privacy-enhanced distributed learning
framework with an emphasis on using mobile and edge
devices for collecting data and scaling the computation
resources[11]. Unlike previous research handling with
training data in a centralized manner, FL’s essential
property uses a “parameter-only” collaborative training
to avoid disturbing each FL clients’ privacy rules. Thus,
various participating clients can solve the learning task
through a hub-and-spoke topology for model aggregation
while maintaining the raw data on their devices. In
particular, for a new FL training task, (1) the FL
central server trains a global model for initialization,
then distributes this model to the existing collaborators
(clients); (2) after receiving the global model, each
collaborator uses the local dataset to update the local
parameters and generates the local updates; (3) based
on specified synchronization settings, all these updates
are sent to the FL central server for aggregation, and the
global model is improved; (4) these distributed update
iterations are repeated until the global model converges
or achieves the expected performance.
DT: A DT is a digital representation of a physical
asset, environment, or system, that was initially
developed to automatically aggregate, analyze, andJunjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 763
visualize complex information through continuous
interactions with the physical world.
3.2 City DT for COVID-19 pandemic control
From the above facts, we observe explicit advantages
of using FL to establish the collaborative training
framework of multiple city DTs. First, by separating
local model training and global model updates, FL
offers a strong capability to deal with the isolated data
island problem between multiple DTs. Secondly, with
enhanced privacy settings, each city DT can obtain the
collaboration achievements without violating its privacy
rules. These properties are essential for COVID-19
pandemic control, because different regions need a
collaboration paradigm with lower privacy risks to
quickly realize an effective response plan. Furthermore,
for each city DT using a TCN as the time-series data
modeling method, the shared global model can provide
more temporal correlation perspectives, which is a
complementary approach to make the city DT quickly
converge to a robust performance.
In our proposed work, a city DT has three primary
components: the physical environment of the city,
a virtual replica describing the city’s architecture,
functions, and behaviors, and active communications
between the two to obtain real-time spatiotemporal
data from various infrastructure and human systems[39]
.
According to the three components, we compose a city
DT for COVID-19 pandemic control using the following
metrics:
COVID-19 case number: The COVID-19 case
number is the number of identified confirmed cases. It
is the direct evidence to describe the characteristics of
human-to-human transmission. Daily updates of case
numbers represent infection trend changes and show
whether a response plan is operated efficiently. In our
framework, each DT model is from a specific area, so
that the case number is bounded with the area and time
information.
COVID-19 testing number: This metric measures
how many individuals get tested of COVID-19 in the
affected regions. The actual total number of people
infected with COVID-19 cannot be obtained. In this
situation, the number of confirmed cases depends on the
testing number, because it can be used to further interpret
and revise the COVID-19 case number. Meanwhile,
the positive rate, computed as the testing number in
a particular time window, is an essential metric for
describing if the target area controls the spread properly.
Therefore, we must use both numbers to estimate the
current infection status and mitigate the risks of under reporting cases and deaths.
COVID-19 confirmed death number: The
confirmed death number describes the ability of
COVID-19 to cause death, which is another direct piece
of evidence of how a region is affected. Furthermore, it
is an important metric for identifying at-risk populations
and guiding the response plan to adjust the medical
resource allocations. The confirmed death number and
case number can have very different trends because the
same response plan may affect these metrics differently.
For example, several infected regions can bring the
number of deaths down for the same response plan, but
other areas may only lower the case number. Thus, the
death rate helps us understand the severity of this virus
and evaluate each response plan’s fine-grained function.
Response plan: For COVID-19 pandemic control,
various organizations and governments develop several
local-level response plans or even a country-level
response plan to prepare for and respond to COVID-19.
In our DT model, we use Ri D .li
; tst; tend / to represent
a response plan, where li
is the location, with tst and
tend denoting the starting time and end time of Ri
. We
include the following response plans in the proposed
model: 14-day quarantine, domestic travel limitations,
gathering limits and stay-at-home orders, nonessential
business closures, reopening plans, mask policy, etc.
The effectiveness of different response plans can vary
because they may be affected by several external factors,
such as a sudden emergency, adverse weather conditions,
or vaccinations.
Temporal effects: In our work, two types of temporal
effects are considered as the primary factors in each city
DT model: temporal effects of historical infection status
(e.g., historical case numbers and historical deaths) and
external factors (e.g., selected response plans, events,
and gatherings). Note that our proposed city DT
model’s primary goal is to determine whether the specific
response plan can flatten the infection curve and evaluate
the period of validity of the plan. We thus need a robust
epidemic forecasting model that can consider multiple
temporal factors and hidden periodicity.
Historical infection status: For a fast-evolving
pandemic, such as the COVID-19 pandemic, the
historical case numbers are direct evidence of the
correlation between past conditions and the current
infection status. In Fig. 2, we take the historical daily
case information of three states (NV: Nevada, UT: Utah,764 Tsinghua Science and Technology, October 2021, 26(5): 759–771
Fig. 2 Correlation between the current infection trend and
the historical infection numbers.
and WI: Wisconsin) as examples of these temporal
effects. From the early March data of all three states, we
observe the same immediate effect of historical infection
numbers, because they lead to a continuously increasing
number of infections until April 2nd, which indicates
that the temporal correlations can play an essential role
in explaining and predicting future infection trends.
External factors: To determine whether external
factors can have an immediate or delayed effect on future
infection trends, we observe the correlation between
each specific factor and the infection status in the next
few days. In our work, the response plans are considered
the primary external factor, because the choice of a
specified response plan can also significantly affect
the number of infections. This effect can be various,
depending on the strictness of that policy, people’s
acceptance of it, and many other factors, such as
various climate conditions or the population density.
For example, in Fig. 2, we observe that after taking
a specified response plan, such as domestic travel
limitations or gathering limits, the infection trend of
all three states can be significantly decreased. However,
for different reasons, the validity period of the response
plan can vary, so all three states exhibit an increasing
infection trend over time. Thus, the temporal effect of
a specific response plan can be complicated because
external factors, such as the 14-day time window, the
indeterminate period that a response plan starts to
take effect, and a paroxysmal public crisis, may also
lead to infection trend changes, which suggests that
it is a challenge to estimate the temporal effects of a
specific response plan from such a complicated physical
environment.
3.3 Problem statement
To place the COVID-19 pandemic under control,
different local agencies in each city/region may choose
their own strategy to meet the local requirements. This
divergence occurs mainly because different regions
should consider the local intrinsic properties. For
instance, Area A, which is a thinly populated district
with very low infection rates, would prefer to choose
a less radical response plan; while the another Area
B, where has severe infection conditions, is very
likely to choose a less radical response plan, like
restricting activities and closing most of the facilities.
This situation means that each region can only obtain
knowledge by trial-and-error operation schemes for
seeking an effective response plan, and the increasing
time cost could lead to a delayed response plan with
poor performance. Moreover, to train a city DT model
to predict future infection trends after a response plan,
enough features must be used to construct the temporal
correlations, which suggests that a collaborative city
DT-training framework must be considered instead.
In coping with these challenges and limitations,
the FL protocol is used in our collaborative city DT
framework. In this paper, we study the problem of
forecasting future infection trends for specific response
plans. Formally, this problem is stated as follows:
Given multiple city DTs, D D D1; D2; : : : ; Di
, each
expects collaborations and is bounded with a local data
sensing method to generate individualize data source
si;1; si;2; : : : ; si;mi
, our federated training problem is to
optimize the following function:
min
w
(
F .w/ ,
X
N
iD1
piFi.w/
)
;Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 765
where N is the number of city DTs, w represents the
parameter of FL global model, pi D mi=m, where m
is the number of data points in all city DT’s data source
and mi
is the number of data points of i-th city DT. For
city DT Di
, f . / is the loss function of a data point, so
that the local objective Fi. / of Di can be defined as
Fi.w/ ,
1
mi
Xmi
jD1
f




NEW_PAPER



Received November 25, 2020, accepted December 8, 2020, date of publication December 14, 2020,
date of current version December 31, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3044858
Artificial Intelligence Applied to Chest X-Ray
Images for the Automatic Detection of COVID-19.
A Thoughtful Evaluation Approach
JULIÁN D. ARIAS-LONDOÑO 1
, (Senior Member, IEEE), JORGE A. GÓMEZ-GARCÍA 2
,
LAUREANO MORO-VELÁZQUEZ3
, (Member, IEEE), AND
JUAN I. GODINO-LLORENTE 2
, (Senior Member, IEEE)
1Department of Systems Engineering, Universidad de Antioquia, Medellín 050010, Colombia
2Bioengineering and Optoelectronics Laboratory (ByO), Universidad Politécnica de Madrid, 28031 Madrid, Spain
3Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD 21218, USA
Corresponding author: Juan I. Godino-Llorente (ignacio.godino@upm.es)
This work was supported in part by the Ministry of Economy and Competitiveness of Spain under Grant DPI2017-83405-R1, and in part
by the Universidad de Antioquia, Medellín, Colombia.
ABSTRACT Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or
antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the
significant number of false negatives of these tests and provide complementary evidence about the presence
and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest
X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence
for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network.
These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to
differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed
to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from
different sources, including more than 8, 500 COVID-19 examples. Three different experiments following
three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to
evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical
analysis of different variability issues that might compromise the system and its effects is performed. With
the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for
the worst but most explainable experiment, which requires a previous automatic segmentation of the lung
region.
INDEX TERMS COVID-19, deep learning, pneumonia, radiological imaging, chest X-ray.
I. INTRODUCTION
COVID-19 pandemic has rapidly become one of the biggest
health world challenges in recent years. The disease spreads
at a fast pace: the reproduction number of COVID-19 ranged
from 2.24 to 3.58 during the first months of the pandemic
[1], meaning that, on average, an infected person transmitted
the disease to 2 or more people. As a result, the number
of COVID-19 infections dramatically increased from just
a hundred cases in January –most of them concentrated in
The associate editor coordinating the review of this manuscript and
approving it for publication was Wenming Cao .
China– to more than 43 million in November spread all
around the world [2].
COVID-19 is caused by the coronavirus SARS-COV2, a
virus that belongs to the same family of other respiratory
disorders such as the Severe Acute Respiratory Syndrome
(SARS) and Middle East Respiratory Syndrome (MERS).
The symptomatology of COVID-19 is diverse and arises
after incubation of around 5.2 days. The symptoms might
include fever, dry cough, and fatigue; although, headache,
hemoptysis, diarrhea, dyspnoea, and lymphopenia are also
reported [3], [4]. In severe cases, an Acute Respiratory Dis tress Syndrome (ARDS) might be developed by underlying
pneumonia associated with COVID-19. For the most severe
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 226811J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
cases, the estimated period from the onset of the disease to
death ranges from 6 to 41 days (with a median of 14 days),
being dependent on the patient’s age and the patient’s immune
system status [3].
Once the SARS-COV2 reaches the host’s lung, it gets
into the cells through a protein called ACE2, which serves
as the ‘‘opening’’ of the cell lock. After the virus’s genetic
material has multiplied, the infected cell produces proteins
that complement the viral structure to produce new viruses.
Then, the virus destroys the infected cell, leaves it, and
infects new cells. The destroyed cells produce radiological
lesions [5]–[7] such as consolidations and nodules in the
lungs, that are observable in the form of ground-glass opacity
regions in the X-Ray (XR) images (Fig. 1c). These lesions
are more noticeable in patients assessed 5 or more days after
the onset of the disease, and especially in those older than
50 [8]. Findings also suggest that patients recovered from
COVID-19 have developed pulmonary fibrosis [9], in which
the connective tissue of the lung gets inflamed, leading to a
pathological proliferation of the connective tissue between
the alveoli and the surrounding blood vessels. Given these
signs, radiological imaging techniques –using plain chest
XR and thorax Computer Tomography (CT)– have become
crucial diagnosis and evaluation tools to identify and assess
the severity of the infection.
Since the declaration of the COVID-19 pandemic, the
World Health Organization identified four major key areas
to reduce the impact of the disease in the world: to prepare
and be ready; detect, protect, and treat; reduce transmission;
and/or innovate and learn [10]. Concerning the area of detec tion, significant efforts have been undertaken to improve the
diagnostic procedures of COVID-19. To date, the gold stan dard in the clinic is still a molecular diagnostic test based on a
polymerase chain reaction (PCR), which is precise but time consuming, requires specialized personnel and laboratories,
and is in general limited by the capacities and resources
of the health systems. An alternative to PCR is the rapid
tests such as those based on real-time reverse transcriptase polymerase chain reaction (RT-PCR), as they can be more
rapidly deployed, decrease the load of the specialized labora tories and personnel, and provide faster diagnosis compared
to traditional PCR.
Other tests, such as those based on antigens, are now
available but are mainly used for massive testings (i.e. for
non-clinical applications) due to a higher chance of missing
an active infection. In contrast with RT-PCR, which detects
the virus’s genetic material, antigen tests identify specific
proteins on the virus’s surface, requiring a higher viral load,
which significantly shortens the sensitivity period.
In clinical practice, the RT-PCR test is usually comple mented with a chest XR, in such a manner that the com bined analysis reduces the significant number of false neg atives and, at the same time, brings additional information
about the extent and severity of the disease. In addition to
that, thorax CT is also used as a second-row method for
evaluation. Although the evaluation with CT provides more
accurate results in the early stages and have been shown to
have greater sensitivity and specificity [11], XR imaging has
become the standard in the screening protocols since it is fast,
minimally-invasive, low-cost, and requires simpler logistics
for its implementation.
In the search for rapid, more objective, accurate and sensi tive procedures, which could complement the diagnosis and
assessment of the disorder, a trend of research has emerged
to employ clinical features extracted from thorax CT or chest
XR with automatic detection purposes. A potential benefit of
studying the radiological images is that these can character ize pneumonic states even in asymptomatic population [12].
However, more research is needed in this field as the lack
of findings in infected patients is also reported [13]. The
consolidation of such technology will permit a speedy and
accurate diagnosis of COVID-19, decreasing the pressure
on microbiological laboratories in charge of the PCR tests
and providing more objective means of assessing the dis ease’s severity. To this end, techniques based on deep learn ing have been employed to leverage XR information with
promising results. Although it would be desirable to employ
CT for detection purposes, some significant drawbacks are
often present, including higher costs, a more time-consuming
procedure, thorough hygienic protocols to avoid infection
spread, and the requirement of specialized equipment that
might not be readily available in hospitals or health centers.
By contrast, XR imaging procedures are available as first
screening tests in many hospitals or health centers, at lower
expenses.
Several approaches for COVID-19 detection based on
chest XR images and different deep learning architectures
have been published in the last few months, reporting classifi cation accuracies around 90% or higher. However, the central
analysis in most of those works is focused on the variations
of network architectures, whereas there is less attention to
the variability factors that a real solution should tackle before
it can be deployed in the medical setting. In this sense, no
analysis has been provided to demonstrate the reliability of
the networks’ predictions, which in the context of medical
solutions acquires particular relevance. Moreover, most of
the works in state of the art have validated their results with
data sets containing dozens or a few hundreds of COVID-19
samples, limiting the proposed solutions’ impact.
With these antecedents in mind, this paper uses a deep
learning algorithm based on CNN, data augmentation, and
regularization techniques to handle data imbalance for the
discrimination between COVID-19, controls, and other types
of pneumonia. The methods are tested with the most extensive
corpus to date, to the authors’ knowledge. Three different
sets of experiments were carried out in the search for the
most suitable and coherent approach. To this end, the paper
also uses explainability techniques to gain insight about the
manners on how the neural network learns, and interpretabil ity in terms of the overlapping among the regions of interest
selected by the network and those that are more likely affected
by COVID-19. A critical analysis of factors that affect the
226812 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 1. Experiments considered in the paper. First row: raw chest XR images belonging to the control, pneumonia, and
COVID-19 classes. Second row: Grad-CAM activation mapping for the XR images. Despite the high accuracy, the model
focuses its attention on areas different from the lungs in some cases. Third row: Grad-CAM activation mapping after
zooming in, cropping to a squared region of interest and resizing. Zooming to the region of interest forces the model to
focus its attention to the lungs, but errors are still present. Fourth row: Grad-CAM activation mapping after a zooming and
segmentation procedure. Zooming in and segmenting force the model to focus attention in the lungs. The black background
represents the mask introduced by the segmentation procedure.
VOLUME 8, 2020 226813J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
performance of automatic systems based on deep learning is
also carried out.
This paper is organized as follows: section II presents some
background and antecedents on the use of deep learning for
COVID-19 detection. section III presents the methodology,
section IV presents the results obtained, whereas V presents
the discussions and main conclusions of this paper.
II. BACKGROUND
A large body of research has emerged on the use of Artificial
Intelligence (AI) to detect different respiratory diseases using
plain XR images. For instance, in [14] authors developed
a 121-layer Convolutional Neural Network (CNN) architec ture, called Chexnet, which was trained with a dataset of
100, 000 XR images for the detection of different types of
pneumonia. The study reports an area under the Receiving
Operating Characteristic (ROC) curve of 0.76 in a multiclass
scenario composed of 14 classes.
Directly related to the COVID-19 detection, three CNN
architectures (ResNet50, InceptionV3 and InceptionRes NetV2) were considered in [15], using a database of just
50 controls and 50 COVID-19 patients. The best accuracy
(98%) was obtained with ResNet50. In [16], seven different
deep CNN models were tested using a corpus of 50 controls
and 25 COVID-19 patients. The best results were attained
with the VGG19 and DenseNet models, obtaining F1-scores
of 0.89 and 0.91 for controls and patients. The COVID-Net
architecture was proposed in [17]. The net was trained with
an open repository, called COVIDx, composed of 13, 975 XR
images, although only 358 -from 266 patients– belonged to
the COVID-19 class. The attained accuracy was of 93.3%. In
[18] a deep anomaly detection algorithm was employed for
the detection of COVID-19, in a corpus of 100 COVID-19
images (taken from 70 patients), and 1, 431 control images
(taken from 1008 patients). 96% of sensitivity and 70% of
specificity was obtained. In [19], a combination of a CNN for
feature extraction and a Long Short Term Memory Network
(LSTM) for classification were used for automatic detection
purposes. The model was trained with a corpus gathered from
different sources, consisting of 4, 575 XR images: 1, 525 of
COVID-19 (although 912 come from a repository applying
data augmentation), 1, 525 of pneumonia, and 1, 525 of con trols. In a 5-folds cross-validation scheme, a 99% accuracy
was reported. In [20], the VGG16 network was used for
classification, employing a database of 132 COVID-19, 132
controls and 132 pneumonia images. Following a hold-out
validation, about 100% accuracy was obtained identifying
COVID-19, being lower on the other classes.
Authors in [21] adapted a model for the classification of
COVID-19 by using transfer-learning based on the Xception
network. Experiments were carried out in a database of 127
COVID-19, 500 controls, and 500 patients with pneumo nia gathered from different sources, attaining about 97%
accuracy. A similar approach, followed in [22], used the
same corpus for the binary classification of COVID-19 and
controls; and for the multiclass classification of COVID-19,
controls, and pneumonia. With a modification of the Darknet
model for transfer-learning and 5-folds cross-validation, 98%
accuracy in binary classification and 87% in multiclass clas sification was obtained. Another Xception transfer-learning based approach was presented in [23], but considering two
multi-class classification tasks: i) controls vs. COVID-19
vs. viral pneumonia and bacterial pneumonia; ii) controls
vs. COVID-19 vs. pneumonia. To deal with the imbalance
of the corpus, an undersampling technique was used to
randomly discard registers from the larger classes, obtain ing 290 COVID-19, 310 controls, 330 bacterial pneumonia,
and 327 viral pneumonia chest XR images. The reported
accuracy was 89% in the 4-class problem and 94% in the
3-class scenario. Moreover, in a 3-class cross-database exper iment, the accuracy was 90%. In [24], four CNN networks
(ResNet18, ResNet50, SqueezeNet, and DenseNet-121) were
used for transfer learning. Experiments were performed on
a database of 184 COVID-19 and 5, 000 no-finding and
pneumonia images. Reported results indicate a sensitivity of
about 98% and a specificity of 93%. In [25], five state-of-the art CNN systems –VGG19, MobileNetV2, Inception, Xcep tion, InceptionResNetV2– were tested on a transfer-learning
setting to identify COVID-19 from control and pneumonia
images. Experiments were carried out in two partitions: one
of 224 COVID-19, 700 bacterial pneumonia, and 504 control
images; and another that considered the previous normal and
COVID-19 data but included 714 cases of bacterial and viral
pneumonia. The MobileNetV2 net attained the best results
with 96% and 94% accuracy in the 2 and 3-classes clas sification. In [26], the MobileNetV2 net was trained from
scratch and compared to one net based on transfer-learning
and to another based on hybrid feature extraction with fine tuning. Experiments performed in a dataset of 3905 XR
images of 6 diseases indicated that training from scratch
outperforms the other approaches, attaining 87% accuracy
in the multiclass classification and 99% in the detection
of COVID-19. A system, also grounded on the Inception Net and transfer-learning, was presented in [27]. Experi ments were performed on 6 partitions of XR images with
COVID-19, pneumonia, tuberculosis, and controls. Reported
results indicate 99% accuracy, in a 10-folds cross-validation
scheme, in the classification of COVID-19 from other classes.
In [28], fuzzy color techniques were used as a pre processing stage to remove noise and enhance XR images
in a 3-class classification setting (COVID-19, pneumonia,
and controls). The pre-processed images and the original
ones were stacked. Then, two CNN models were used to
extract features: MobileNetV2 and SqueezeNet. A feature
selection technique based on social mimic optimization and a
Support Vector Machine (SVM) was used. Experiments were
performed on a corpus of 295 COVID-19, 65 controls and 98
pneumonia XR images, attaining about 99% accuracy.
Given the limited amount of COVID-19 images, some
approaches have focused on generating artificial data to train
better models. In [29], an auxiliary Generative Adversarial
Network (GAN) was used to produce artificial COVID-19
226814 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
XR images from a database of 403 COVID-19 and 1, 124
controls. Results indicated that data augmentation increased
accuracy from 85% to 95% on the VGG16 net. Similarly,
in [30], GAN was used to augment a database of 307
images belonging to four classes: controls, COVID-19, bac terial and viral pneumonia. Different CNN models were
tested in a transfer-learning-based setting, including Alexnet,
Googlenet, and Restnet18. The best results were obtained
with Googlenet, achieving 99% in a multiclass classifica tion approach. In [31], a CNN based on capsule networks
(CapsNet), was used for binary (COVID-19 vs. controls)
and multi-class classification (COVID-19 vs. pneumonia
vs. controls). Experiments were performed on a dataset of
231 COVID-19, 1, 050 pneumonia and 1, 050 controls XR
images. Data augmentation was used to increase the num ber of COVID-19 images to 1, 050. On a 10-folds cross validation scheme, 97% accuracy for binary classification,
and 84% multi-class classification were achieved. The Cov XNet architecture, based on depth-wise dilated convolution
networks, was proposed in [32]. In the first stage, pneumo nia (viral and bacterial) and control images were employed
for pretraining. Then, a a refined model of COVID-19 is
obtained using transfer learning. In experiments using two databases, 97% accuracy was achieved for COVID-19 vs.
controls, and of 90% for COVID-19 vs. controls vs. bacte rial and viral cases of pneumonia. In [33], an easy-to-train
neural network with a limited number of training parame ters was presented. To this end, patch phenomena found on
XR images were studied (bilateral involvement, peripheral
distribution, and ground-glass opacification) to develop a
lung segmentation and a patch-based neural network that
distinguished COVID-19 from controls. The basis of the
system was the ResNet18 network. Saliency maps were also
used to produce interpretable results. In experiments per formed on a database of controls (191), bacterial pneumonia
(54), tuberculosis (57) and viral pneumonia (20), about 89%
accuracy was obtained. Likewise, interpretable results were
reported in terms of large correlations between the saliency
maps’ activation zones and the radiological findings found
in the XR images. The authors also indicate that when the
lung segmentation approach was not considered, the system’s
accuracy decreased to about 80%. In [34], 2D curvelets trans formations were used to extract features from XR images. A
feature selection algorithm based on meta-heuristic was used
to find the most relevant characteristics, while a CNN model
based on EfficientNet-B0 was used for classification. Exper iments were carried out in a database of 1, 341 controls, 219
COVID-19, and 1, 345 viral pneumonia images, and 99%
classification accuracy was achieved with the proposed
approach. Multiclass and hierarchical classification of differ ent types of diseases producing pneumonia (with 7 labels and
14 label paths), including COVID-19, were explored in [35].
Since the database of 1, 144 XR images was heavily imbal anced, different resampling techniques were considered. By
following a transfer-learning approach based on a CNN archi tecture to extract features, and a hold-out validation with
5 different classification techniques, a macro-avg F1-Score of
0.65 and an F1-Score of 0.89 were obtained for the multiclass
and hierarchical classification scenarios, respectively. In [36],
a three-phases approach is presented: i) to detect the presence
of pneumonia; ii) to classify between COVID-19 and pneu monia; and, iii) to highlight regions of interest of XR images.
The proposed system utilized a database of 250 images of
COVID-19 patients, 2, 753 with other pulmonary diseases,
and 3, 520 controls. By using a transfer-learning system
based on VGG16, about 0.97 accuracy was reported. A
CNN-hierarchical approach using decision trees (based on
ResNet18) was presented in [37], on which a first tree clas sified XR images into the normal or pathological classes;
the second identified tuberculosis; and the third COVID-19.
Experiments were carried out on 3 partitions obtained after
having gathered images from different sources and data aug mentation. The accuracy for each decision tree –starting from
the first– was about 98%, 80%, and 95%, respectively.
A. ISSUES AFFECTING RESULTS IN THE LITERATURE
Table 1 presents a summary of state of the art in the auto matic detection of COVID-19 based on XR images and deep
learning. Despite the excellent results reported, the review
reveals that some of the proposed systems suffer from certain
shortcomings that affect the conclusions extracted in their
respective studies, limiting the translational possibilities to
the clinical environment. Likewise, variability factors have
not been deeply studied in these papers and their study can
be regarded as necessary.
For instance, one of the issues that affect most of the
reviewed systems to detect COVID-19 from plain chest XR
images is the use of very limited datasets, which compromises
their generalization capabilities.
Indeed, to date and from the authors’ knowledge, the
paper employing the largest database of COVID-19 considers
1, 525 XR images gathered from different sources. However,
912 images belong to a data augmented repository, which
does not include additional information about the initial num ber of files or the number of augmented images. In general
terms, most of the works employ less than 300 COVID-19
XR images, having systems that use as few as 50 images.
However, this is understandable given that some of these
works were published during the onset of the pandemics when
the number of available registers was limited.
On the other hand, a good balance in the patients’ age is
considered essential to avoid the model to learn age-specific
features. However, several previous works have used XR
images from children to populate the pneumonia class.1 This
might be biasing the results given the age differences of
COVID-19 patients.
Despite many works in the literature report a good perfor mance in detecting COVID-19, most of the approaches follow
1First efforts used the RSNA Pneumonia Detection Challenge dataset,
which is focused on the detection of pneumonia cases in children.
https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview
VOLUME 8, 2020 226815J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 1. Summary of the literature in the field.
a brute force approach exploiting deep learning’s potentiality
to correlate with the outputs (i.e., the class labels) but provide
low interpretability and explainability of the process. It is
unclear if the good results are due to the system’s actual
capability to extract information related to the pathology or
because it leart other aspects during training that are biasing
and compromising the results. As a matter of example, just
one of the studies reported in the literature follows a strat egy that forces the network to focus on the most significant
areas of interest for COVID-19 detection [33]. It does so by
proposing a methodology based on semantic segmentation of
the lungs. In the remaining cases, it is unclear if the models
are analyzing the lungs or if they are categorizing given
any other information available, which might be interesting
for classification purposes but might lack diagnostic inter est. This is relevant, as in all the analyzed works in liter ature, pneumonia and controls classes come from a certain
repository, whereas others such as COVID-19 comes from
a combination of sources and repositories. Having classes
generated in different conditions might undoubtedly affect
the results, and as such, a critical study about this aspect is
needed. In the same line, other variability issues such as the
sensor technology employed, the type of projection used, the
sex of the patients, and even age, require a thorough study.
Finally, the literature review revealed that most of the
published papers showed excellent correlation with the dis ease but low interpretability and explainability (see Table 1).
Indeed, it is often more desirable in clinical practice to
obtain interpretable results that correlate with pathological
conditions or a particular demographic or physiological vari able than a black box system that yields a binary or a multi class decision. From the revision of literature, only [33] and
[32] partially addressed this aspect. Thus, further research on
this topic is needed.
With these ideas in mind, this paper addresses these aspects
by training and testing with a wide corpus of RX images,
proposing and comparing two strategies to preprocess the
images, analyze the effect of some variability factors, and
provide some insights to more explainable and interpretable
results. The primary goal is to present a critical overview
of these aspects since they might be affecting the modeling
capabilities of the deep learning systems for the detection of
COVID-19.
III. METHODOLOGY
The design methodology is presented in the following
section. The procedure followed to train the neural network
is described first, along with the process that was followed to
create the dataset. The network and the source code to train
it are available at https://github.com/jdariasl/COVIDNET, so
results can be readily reproduced by other researchers.
A. THE NETWORK
The core of the system is a deep CNN based on the
COVID-Net2 proposed in [17]. Some modifications were
2Following the PyTorch implementation available at
https://github.com/IliasPap/COVIDNet
226816 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
made to include regularization components in the last two
dense layers and a weighted categorical cross-entropy loss
function to compensate the class imbalance. The network
structure was also refactored to allow gradient-based local ization estimations [38], which are used after training in the
search for an explainable model.
The network was trained with the corpus described in III-B
using the Adam optimizer with a learning rate policy: the
learning rate decreases when learning stagnates for some time
(i.e., ’patience’). The following hyperparameters were used
for training: learning rate = 2
-5, number of epochs = 24,
batch size = 32, factor = 0.5, patience = 3. Furthermore,
data augmentation for pneumonia and COVID-19 classes was
leveraged with the following augmentation types: horizontal
flip, Gaussian noise with a variance of 0.015, rotation, elastic
deformation, and scaling. The variant of the COVID-Net
was built and evaluated using the PyTorch library [39]. The
CNN features from each image are concatenated by a flatten
operation, and the resulting feature map is fed to three fully
connected layers to generate a probability score for each
class. The first two fully connected layers include dropout
regularization of 0.3 and ReLU activation functions. Dropout
was necessary because the original network tended to overfit
since the very beginning of the training phase.
The network’s input layer rescales the images keeping the
aspect ratio, with the shortest dimension scaled to 224 pixels.
Then, the input image is cropped to a square of 224 × 224
pixels located in the center of the image. Images are nor malized using a z-score function with parameters mean =
[0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225], for
each of the three RGB channels respectively. Even though we
are working with grayscale images, the network architecture
was designed to be pre-trained on a general-purpose database
including colored images; this characteristic was kept in case
it would be necessary to use some transfer learning strategy
in the future.
The network’s output layer provides a score for each of
the three classes (i.e. control, pneumonia, or COVID-19),
which is converted into three probability estimates –in the
range [0, 1]– using a softmax activation function. The class
membership’s final decision is made according to the highest
of the three probability estimates obtained.
B. THE CORPUS
The corpora used in the paper have been compiled from a set
of Posterior-Anterior (PA) and Anterior-Posterior (AP) XR
images from different public sources. The compilation con tains images from participants without any observable pathol ogy (controls or no findings), pneumonia, and COVID-19
cases. After the compilation, two subsets of images were
generated, i.e., training and testing. Table 2 contains the
number of images per subset and class. Overall, the corpus
contains more than 70, 000 XR images, including more than
8, 500 images belonging to COVID-19 patients.
The repositories of XR images employed to create the cor pus used in this paper are presented next. Most of these con TABLE 2. Number of images per class for training and testing subsets.
tain solely registers of controls and pneumonia patients. Only
the most recent repositories include samples of COVID-19
XR images. In all cases, the annotations were made by a
specialist as indicated by the authors of the repositories.
The COVID-19 class is modelled compiling images com ing from three open data collection initiatives: HM Hospi tales COVID [40], BIMCV-COVID19 [41] and Actualmed
COVID-19 [42] chest XR datasets. The final result of the
compilation process is a subset of 8, 573 images from more
than 3, 600 patients at different stages of the disease.3
Table 3 summarizes the most significant characteristics of
the datasets used to create the corpus, which is presented next:
1) HM HOSPITALES COVID-19 DATASET
This dataset was compiled by HM Hospitals [40]. It con tains all the available clinical information about anonymous
patients with the SARS-CoV-2 virus treated in different cen ters belonging to this company since the beginning of the
pandemic in Madrid, Spain.
The corpus contains the anonymized records of 2, 310
patients and includes several radiological studies for each
patient corresponding to different stages of the disease. A
total of 5, 560 RX images are available in the dataset, with
an average of 2.4 image studies per subject, often taken in
intervals of two or more days. The histogram of the patients’
age is highly coherent with the demographics of COVID-19
in Spain (see Table 3 for more details).
Only patients with at least one positive PCR test or positive
immunological tests for SARS-CoV-2 were included in the
study. The Data Science Commission and the Research Ethics
Committee of HM Hospitales approved the current research
study and the data for this purpose.
2) BIMCV COVID19 DATASET
BIMCV COVID19 dataset [41] is a large dataset with chest
radiological studies (XR and CT) of COVID-19 patients
along with their pathologies, results of PCR and immuno logical tests, and radiological reports. It was recorded by the
Valencian Region Medical Image Bank (BIMCV) in Spain.
The dataset contains the anonymized studies of patients with
at least one positive PCR test or positive immunological tests
for SARS-CoV-2 between February 26th and April 18th,
2020. The corpus is composed of 3, 013 XR images, with an
average of 1.9 image studies per subject, taken in intervals
of approximately two or more days. The histogram of the
patients’ age is highly coherent with the demographics of
3Figures at the time the datasets were downloaded. The datasets are still
open, and more data might be available in the next future.
VOLUME 8, 2020 226817J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 3. Demographic data of the datasets used. Only those labels confirmed are reported.
COVID-19 in Spain (Table 3). Only patients with at least
one positive PCR test or positive immunological tests for
SARS-Cov-2 were included in the study.
3) ACTUALMED SET (ACT)
The actualmed COVID-19 Chest XR dataset initiative [42]
contains a series of XR images compiled by Actualmed and
Universitat Jaume I (Spain). The dataset contains COVID-19
and control XR images, but no information is given about the
place or date of recording and/or demographics. However, a
metadata file is included. It contains an anonymized descrip tor to distinguish among patients and information about the
XR modality, type of view, and the class to which the image
belongs.
4) CHINA SET - THE SHENZHEN SET
The set was created by the National Library of Medicine,
Maryland, USA, in collaboration with the Shenzhen No.3
People’s Hospital at Guangdong Medical College in Shen zhen, China [43].
The dataset contains normal and abnormal chest XR with
manifestations of tuberculosis and includes associated radi ologist readings.
5) THE MONTGOMERY SET
The National Library of Medicine created this dataset in
collaboration with the Department of Health and Human
Services, Montgomery County, Maryland, USA. It contains
data from XR images collected under Montgomery County’s
tuberculosis screening program [43], [44].
6) ChestX-ray8 DATASET (CRX8)
The ChestX-ray8 dataset [45] contains 12, 120 images from
14 common thorax disease categories from 30, 805 unique
patients, compiled by the National Institute of Health (NIH).
For this study, the images labeled with ’no radiological find ings’ were used to be part of the control class, whereas the
images annotated as ’pneumonia’ were used for the pneumo nia class.
7) CheXpert DATASET
CheXpert [46] is a dataset of XR images created for an
automated evaluation of medical imaging competitions and
contains chest XR examinations carried out in Stanford Hos pital during 15 years. For this study, we selected 4, 623 pneu monia images using those annotated as ’pneumonia’ with
and without additional comorbidity. COVID-19 never caused
these comorbidities. The motivation to include pneumonia
with comorbidities was to increase the number of pneumonia
examples in the final compilation for this study, increasing
this cluster’s variability.
8) MIMIC-CXR DATABASE
MIMIC-CXR [47] is an open dataset complied from 2011 to
2016, and comprising de-identified chest RX from patients
admitted to the Beth Israel Deaconess Medical Center. In
our study, we employed the images for the pneumonia class.
The labels were obtained from the agreement of the two
methods indicated in [47]. The dataset reports no information
about gender or age; thus, we assume that the demograph ics are similar to those of CheXpert dataset and those of
pneumonia [48].
C. IMAGE PRE-PROCESSING
XR images were converted to uncompressed grayscale ’.png’
files, encoded with 16 bits, and preprocessed using the
DICOM WindowCenter and WindowWidth details (when
needed). All images were converted to a Monochrome 2
photometric interpretation. Initially, the images were not re scaled to avoid loss of resolution in later processing stages.
Only AP and PA views were selected. No differentiation
was made between erect, either standing or sitting, or decu bitus. This information was inferred by a careful analysis of
the DICOM tags and required manual checking due to certain
labeling errors.
D. EXPERIMENTS
The corpus collected from the aforementioned databases was
processed to compile three different datasets of equal size
to the initial one. Each of these datasets was used to run a
different set of experiments.
1) EXPERIMENT 1. RAW DATA
The first experiment was run using the raw data extracted
from the different datasets. Each image is kept with the orig inal aspect ratio. Only a histogram equalization was applied.
226818 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
2) EXPERIMENT 2. CROPPED IMAGE
The second experiment consists of preprocessing the images
by zooming in, cropping to a squared region of interest, and
resizing to a squared image (aspect ratio 1 : 1). The process
is summarized in the following steps:
1) Lungs are segmented from the original image using
a U-Net semantic segmentation algorithm.4 The algo rithm used reports Intersection-Over-Union (IoU) and
Dice similarity coefficient scores of 0.971 and 0.985
respectively.
2) A black mask is extracted to identify the external
boundaries of the lungs.
3) The mask is used to create two sequences, adding
the grey levels of the rows and columns respectively.
These two sequences provide four boundary points,
which define two segments of different lengths in the
horizontal and vertical dimensions.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated with the lungs,
taking advantage of the higher added values outside the
lungs (Fig. 2). The process to obtain the squared region
requires identifying the middle point of each of the
identified segments and cropping in both dimensions
using the length of the longest of these two segments.
5) The original image is cropped with a squared template
placed in the centre of the matrix using the information
obtained in the previous step. No mask is placed over
the image.
6) Histogram equalization of the image obtained.
This process is carried out to decrease the variability of the
data, to make the training process of the network simpler, and
to ensure that the region of significant interest is in the centre
of the image with no areas cut.
3) EXPERIMENT 3. LUNG SEGMENTATION
The third experiment consists of preprocessing the images by
masking, zooming in, cropping to a squared region of interest,
and resizing to a squared image (aspect ratio 1 : 1). The
process is summarized in the following steps:
1) Lungs are segmented from the original image using
the same semantic segmentation algorithm used in
experiment 2.
2) An external black mask is extracted to identify the
external boundaries of the lungs.
3) The mask is used to create two sequences, adding the
grey levels of the rows and columns respectively.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated to the lungs,
taking advantage of the higher added values outside
them (Fig. 2).
4Following the Keras implementation available at https://github.com
/imlab-uiip/lung-segmentation-2d
FIGURE 2. Identification of the squared region of interest. Plots in the top
and left represent the normalized accumulated gray level in the vertical
and horizontal dimension respectively.
5) The original image is cropped with a squared template
placed in the center of the image.
6) The mask is dilated with a 5 × 5 pixels kernel, and it is
superimposed to the image.
7) Histogram equalization is applied only to the seg mented area (i.e. the area corresponding to the lungs).
This preprocessing makes the training of the network much
simpler and forces the network to focus the attention on
the lungs region, removing external characteristics –like the
sternum– that might influence the obtained results.
E. IDENTIFICATION OF THE AREAS OF SIGNIFICANT
INTEREST FOR THE CLASSIFICATION
The areas of significant interest used by the CNN for
discrimination purposes are identified using a qualitative
analysis based on a Gradient-weighted Class Activation
Mapping (Grad-CAM) [38]. This is an explainability method
that serves to provide insights about the manners on how
deep neural networks learn, pointing to the most significant
areas of interest for decision-making purposes. The method
uses the gradients of any target class to flow until the final
convolutional layer, and to produce a coarse localization map
which highlights the most important regions in the image
identifying the class. The result of this method is a heat map
like those presented in Fig. 1, in which the colour encodes the
importance of each pixel in differentiating among classes.
IV. RESULTS
The model has been quantitatively evaluated computing
the test Positive Predictive Value (PPV), Recall, F1-score
(F1), Accuracy (Acc), Balanced Accuracy (BAcc), Geometric
Mean Recall (GMR) and Area Under the ROC Curve (AUC)
for each of the three classes in the corpus previously described
in section III-B. The performance of the models is assessed
using an independent testing set, which has not been used
VOLUME 8, 2020 226819J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 4. Performance measures for the three experiments considered in the paper.
FIGURE 3. ROC curves and confusion matrices for each one of the experiments, considering each one of the classes separately. Top: ROC curves. Bottom:
Normalized confusion matrices. Left: Original images (experiment 1). Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
during development. A 5-folds cross-validation procedure
has been used to evaluate the obtained results (Training/Test
balance: 90/10 %). The performance of the CNN network on
the three experiments considered in this paper is summarized
in Table 4. Likewise, the ROC curves per class for each of the
experiments, and the corresponding confusion matrices are
presented in Fig. 3. The global ROC curve displayed in Fig. 4
for each experiment summarizes the global performance of
the experiments.
Considering experiment 1, and although slightly higher for
controls, the detection performance remains almost similar
for all classes (the PPV ranges from 91-93%) (Table 4). The
remaining measures per class follow the same trend, with
similar figures but better numbers for the controls. ROC
curves and confusion matrices of Fig. 3a and Fig. 3d point out
that the largest source of confusion for COVID-19 is the pneu monia class. The ROC curves for each one of the classes reach
in all cases AUC values larger than 0.99, which, in principle
is considered excellent. In terms of global performance, the
system achieves an Acc of 91% and a BAcc of 94% (Table 4).
This is also supported by the average ROC curve of Fig. 4,
which reveals the excellent performance of the network and
226820 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 4. Average ROC curves for each experiment, including AUC values.
the almost perfect behaviour of the ROC curve. Deviations
are small for the three classes.
When experiment 2 is considered, a decrease in the perfor mance per class is observed in comparison to experiment 1.
In this case, the PPV ranges from 81-93% (Table 4), with a
similar trend for the remaining figures of merit. ROC curves
and confusion matrices in Fig. 3a and Fig. 3d report AUC
values in the range 0.96-0.99, and an overlapping of the
COVID-19 class mostly with pneumonia. The global perfor mance of the system -presented in the ROC curve of Fig. 4
and Table 4- yields an AUC of 0.98, an Acc of 87% and a
BAcc of 81%.
Finally, for experiment 3, PPV ranges from 78% − 96%
(Table 4). In this case, the results are slightly worse than those
of experiment 2, with the COVID-19 class presenting the
worse performance among all the tests. According to Fig. 3c,
AUCs range from 0.94 to 0.98. Confusion matrix in Fig. 3f
reports a large level of confusion in the COVID-19 class
being labelled as pneumonia 18% of the times. In terms of
global performance, the system reaches an Acc of 91% and a
BAcc of 87% (Table 4). These results are consistent with the
average AUC of 0.97 shown in Fig. 4.
A. EXPLAINABILITY AND INTERPRETABILITY OF THE
MODELS
The regions of interest identified by the network were ana lyzed qualitatively using Grad-CAM activation maps [38].
Results shown by the activation maps, permit the identifica tion of the most significant areas in the image, highlighting
the zones of interest that the network is using to discriminate.
In this regard, Fig. 1, presents examples of the Grad-CAM
of a control, a pneumonia, and a COVID-19 patient, for each
of the three experiments considered in the paper. It is impor tant to note that the activation maps are providing overall
information about the behaviour of the network, pointing to
the most significant areas of interest, but the whole image is
supposed to be contributing to the classification process to a
certain extent.
The second row in Fig. 1 shows several prototypical results
applying the Grad-CAM techniques to experiment 1. The
examples show the areas of significant interest for a control,
pneumonia and COVID-19 patient.
The results suggest that the detection of pneumonia or
COVID-19 is often carried out based on information that is
outside the expected area of interest, i.e. the lung area. In the
examples provided, the network focuses on the corners of the
XR image or in areas around the diaphragm. In part, this is
likely due to the metadata which is frequently stamped on
the corners of the XR images. The Grad-CAM plots corre sponding to the experiment 2 (third row of Fig. 1), indicates
that the model still points towards areas which are different
from the lungs, but to a lesser extent. Finally, the Grad-CAM
of experiment 3 (fourth row of Fig. 1) presents the areas of
interest where the segmentation procedure is carried out. In
this case, the network is forced to look at the lungs, and
therefore this scenario is supposed to be more realistic and
more prone to generalizing as artifacts that might bias the
results are somehow discarded.
On the other hand, for visualization purposes, and in order
to interpret the separability capabilities of the system, a t-SNE
embedding is used to project the high dimensional data of the
layer adjacent to the output of the network, to a 2-dimensional
space. Results are presented in Fig. 5 for each of the three
experiments considered in the paper.
Fig. 5 indicates that a good separability exists for all
the classes in both training and testing data, and for all
experiments. The boundaries of the normal cluster are very
well defined in the three experiments, whereas pneumonia
and COVID-19 are more spread, overlapping with adjacent
classes.
In general terms, the t-SNE plots demonstrate the ability
of the network to learn a mapping from the input data to the
desired labels. However, despite the shape differences found
for the three experiments, no additional conclusions can be
extracted.
B. POTENTIAL VARIABILITY FACTORS AFFECTING THE
SYSTEM
There are several variability factors which might be biasing
the results, namely: the projection (PA vs. AP); the tech nology of the detector (Computed Radiography (CR) vs.
Digital Radiography (DX)); the gender of the patients; the
age; potential specificities of the dataset; or having trained
with several images per patient.
The use of several images per patient represents a certain
risk of data leak in the COVID-19 class due to its underlying
imbalance. However, our initial hypothesis is that using sev eral images per COVID-19 patient but obtained at different
instants in time (with days of difference), would increase the
variability of the dataset, and thus that source of bias would
be disregarded. Indeed, the evolution of the associated lesions
often found in COVID-19 is considered fast, in such a manner
that very different images are obtained in a time interval
as short as one or two days of the evolution. Also, since
VOLUME 8, 2020 226821J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 5. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
TABLE 5. Performance measures considering the XR projection (PA/AP).
every single exploration is framed differently, or sometimes
even taken with different machines and/or projections, the
potential bias is expected to be minimized.
Concerning the type of projection, and to evaluate its
effectiveness, the system has been studied taking into
account this potential variability factor, which is consid ered to be one of the most significant. In particular,
Table 5, presents the outcomes after accounting for the
influence of the XR projection (PA/AP) in the perfor mance of the system. In general terms, the system demon strates consistency with respect to the projection used,
and differences are mainly attributable to smaller train ing and testing sets. However, significant differences are
shown for projection PA in class COVID-19/experiment 3,
decreasing the F1 up to 65.61%. The reason for the
unexpected drop in performance is unknown, but likely
226822 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 6. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3). Labels correspond to data sets and classes.
attributable to an underrepresented class in the corpus (see
Table 3).
Besides, Table 6 shows –for the three experiments under
evaluation and for the COVID-19 class– the error distribu tion with respect to the sex of the patient, technology of
the detector, dataset and projection. For the four variability
factors enumerated, results show that the error distribution
committed by the system follows –with minor deviations– the
existing proportion of the samples in the corpus. These results
suggest that there is no clear bias with respect to these poten tial variability factors, at least for the COVID-19 class which
is considered the worst-case due to its underrepresentation.
Similar results would be expected for control and pneumonia
classes, but these results are not provided due to the lack of
certain labels in some of the datasets used (see Table 3).
Concerning age, the datasets used are reasonably well
balanced (Table 3), but with a certain bias in the normal class:
COVID-19 and pneumonia classes have very similar average
ages, but controls have a lower mean age. Our assumption
has been that age differences are not significantly affecting
the results, but the mentioned difference might explain why
the normal cluster in Fig. 5 is less spread than the other two.
In any case, no specific age biases have been found in the
errors committed by the system.
An additional study was also carried out to evaluate the
influence of potential specificities of the different datasets
used to compile the corpus (i.e. the variability of the results
with respect to the datasets merged to build the corpus). This
variability factor is evaluated in Fig. 6 using different t-SNE
plots (one for each experiment in a similar way than in Fig. 5)
but differentiating the corresponding cluster for each dataset
and class.
Results for the different datasets and classes are clearly
merged or are adjacent in the same cluster. However, sev eral datasets report a lower variability for certain classes
(i.e. variability in terms of scattering). This is especially
clear in Chexpert and NIH pneumonia sets, which are suc cessfully merged with the corresponding class but appear
VOLUME 8, 2020 226823J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 6. Percentage of testing samples and error distribution with
respect to several potential variability factors for the COVID-19 class.
(% in hits represents the percentage of samples of every factor under
analysis in the correctly predicted set).
clearly clustered, suggesting that these datasets have certain
unknown specific characteristics different to those of the
complementary datasets. The model has been able to manage
this aspect but is a factor to be analyzed in further studies.
V. DISCUSSION AND CONCLUSION
This study evaluates a deep learning model for the detection
of COVID-19 from RX images. The paper provides addi tional evidence to the state of the art, supporting the poten tial of deep learning techniques to accurately categorize XR
images corresponding to control, pneumonia, and COVID-19
patients (Fig. 1). These three classes were chosen under the
assumption that they can support clinicians in making better
decisions, establishing potential differential strategies to han dle patients depending on their cause of infection [17]. How ever, the main goal of the paper was not to demonstrate the
suitability of deep learning for categorizing XR images but to
make a thoughtful evaluation of the results and the different
preprocessing approaches, searching for better explainability
and interpretability of the results while providing evidence of
potential effects that might bias results.
The model relies on the COVID-Net network, which has
served as a basis for the developing a more refined archi tecture. This network has been chosen due to its tailored
characteristics and given the previous good results reported
by other researchers. The COVID-Net was trained with a
corpus compiled using data gathered from different sources:
the control and pneumonia classes –with 49, 983 and 24, 114
samples respectively– were collected from the ACT, Chi naset, Montgomery, CRX8, CheXpert, and MIMIC datasets;
and the COVID-19 class was collected from the information
available at the BIMCV, ACT, and HM Hospitales datasets.
Although the COVID-19 class only contains 8, 573 chest
RX images, the developers of the data sources are continu ously adding new cases to the respective repositories, so the
number of samples is expected to grow in the future. Despite
the unbalance of the COVID-19 class, up to date, and to the
authors’ knowledge, this is the most extensive compilation of
COVID-19, images based on open repositories. Despite that,
the number of COVID-19 RX images is still considered small
compared to the other two classes. Therefore, it was necessary
to compensate for the class imbalance by modifying the
network architecture, including regularization components in
the last two dense layers. To this end, a weighted categorical
cross-entropy loss function was used to compensate for this
effect. Likewise, data augmentation techniques were used for
pneumonia and COVID-19 classes to generate more samples
for these two underrepresented classes automatically.
We stand that automatic diagnosis is much more than a
classification exercise, meaning that many factors have to be
considered to bring these techniques to clinical practice. In
this respect, there is a classic assumption in the literature
that the associated heat maps –calculated with Grad-CAM
techniques- provide a clinical interpretation of the results,
which is unclear in practice. In light of the results shown in
the heat maps depicted in Fig. 1, we show that experiment 1
must be carefully interpreted. Despite the high-performance
metrics obtained in experiment 1, the significant areas identi fied by the network are pointing towards certain areas with
no clear interest for the diagnosis, such as corners of the
images, the sternum, clavicles, etc. From a clinical point of
view, this is biasing the results. It means that other approaches
are necessary to force the network to focus on the lung
area. In this respect, we have developed and compared the
results with two preprocessing approaches based on cropping
the images and segmenting the lung area (experiment 2 and
experiment 3). Again, given the heat maps corresponding
to experiment 2, we also see similar explainability prob lems to those enumerated for experiment 1. The image area
reduction proposed in experiment 2 significantly decreases
the system’s performance by removing the metadata that
usually appears in the top left or right corner. This technique
removes areas that can help categorize the images but have
no interest from the diagnosis point of view. However, while
comparing experiments 2 and 3, performance results improve
in the third approach, which focuses on the same region
of interest but with a mask that forces the network to see
only the lungs. Thus, results obtained in experiments 2 and
3 suggest that eliminating the needless features extracted
from the background or non-related regions improves the
results. Besides, the third approach (experiment 3) provides
more explainable and interpretative results, with the network
focusing its attention only on the area of interest for the
disease. The gain in explainability of the last method is still
at the cost of a lower accuracy with respect to experiment
1, but the improvement in explainability and interpretability
is considered critical in translating these techniques to the
clinical setting. Despite the decrease in performance, the
proposed method in experiment 3 has provided promising
results, with an 91.53% Acc, 87.6 BAcc, 87.37% GMR,
and 0.97 AUC.
Performance results obtained are in line with those pre sented in [17], which reports sensitivities of 95, 94, and 91
for control, pneumonia, and COVID-19 classes respectively
–also modeling with the COVID-Net in similar conditions as
our experiment 1–, but training with a much smaller corpus
of 358 RX images from 266 COVID-19 patients, 8, 066
226824 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
controls, and 5, 538 RX images belonging to patients with
different types of pneumonia.
The paper also critically evaluates the effect of several
variability factors that might compromise the network’s per formance. For instance, the projection (PA/AP) effect was
evaluated by retraining the network and checking the out comes. This effect is important, given that PA projections are
often practiced in erect positions to observe pulmonary ways
better and are expected to be examined in healthy or slightly
affected patients. In contrast, AP projections are often pre ferred for patients confined in bed, and as such are expected
to be practised in the most severe cases. Since AP projections
are common in COVID-19 patients, in these cases, more
blood will flow to the lungs’ apices than when standing;
thus, not considering this variability factor may result in
a misdiagnosis of pulmonary congestion [49]. Indeed, the
obtained results have highlighted the importance of taking
into account this factor when designing the training corpus,
as PPV decreases for PA projections in our experiments with
COVID-19 images. This issue is probably due to an under representation of this class (Table 5), which would require a
further specific analysis when designing future corpora.
On the other hand, results have shown that the error distri bution for the COVID-19 class follows a similar proportion to
the percentage of images available in the corpus while cate gorizing by gender, the detector’s technology, the projection,
and the dataset. These results suggest no significant bias with
respect to these potential variability factors, at least for the
COVID-19 class, which is the less represented one.
An analysis of how the clusters of classes were distributed
is also presented in Fig. 5, demonstrating how each class
is differentiated. These plots help identify existing overlap
among classes (especially that present between pneumonia
and COVID-19, and to a lesser extent between controls and
pneumonia). Similarly, since the corpus used to train the
network was built around several datasets, a new set of t-SNE
plots was produced, but differentiating according to each
of the subsets used for training (Fig. 6). This test served
to evaluate the influence of each dataset’s potential specific
characteristics in the training procedure and, hence, possible
sources of confusion that arise due to particularities of the
corpora that are tested. The plots suggest that the different
datasets are correctly merged in general terms, but with some
exceptions. These exceptions suggest that there might be
certain unknown characteristics in the datasets used, which
cluster the images belonging to the same dataset together.
The COVID-Net has also demonstrated being a good start ing point for the characterization of the disease employing XR
images. Indeed, the paper’s outcomes suggest the possibility
to automatically identify the lung lesions associated with
a COVID-19 infection (see Fig.1) by analyzing the Grad CAM mappings of experiment 3, providing an explainable
justification about the way the network works. However,
the interpretation of the heat maps obtained for the control
class must be carried out carefully. Whereas the areas of
significant interest for pneumonia and COVID-19 classes are
supposed to point to potential lesions (i.e. with higher density
or with different textures in contrast to controls), the areas of
significant interest for the classification in the control group
are supposed to correspond to something complementary,
potentially highlighting less dense areas. Thus, in the control
class, these areas do not point towards any kind of lesion in
the lungs.
Likewise, the system developed in experiment 3 attains
comparable results to those achieved by a human evaluator
differentiating pneumonia from COVID-19. In this respect,
the ability of seven radiologists to correctly differentiate
pneumonia and COVID-19 from XR images was tested in
[50]. The results indicated that the radiologists achieved sen sitivities ranging from 97% to 70% (mean 80%), and speci ficities ranging from 7% to 100% (mean 70%). These results
suggest that AI systems have a potential use in a supervised
clinical environment.
COVID-19 is still a new disease, and much remains
to be studied. The use of deep learning techniques
would potentially help understand the mechanisms on
how the SARS-CoV2 attacks the lungs and alveoli and
how it evolves during the different stages of the dis ease. Despite there is some empirical evidence on the
evolution of COVID-19 –based on observations made by
radiologists [6]–, the employment of automatic techniques
based on machine learning would help analyze data mas sively, guide research onto certain paths, or extract conclu sions faster. Nevertheless more interpretable and explainable
methods are required to go one step forward.
Inline with the previous comment, and based on the empir ical evidence respecting the evolution of the disease, it has
been stated that during the early stages of the disease, ground glass shadows, pulmonary consolidation and nodules, and
local consolidation in the centre with peripheral ground glass density are often observed. However, once the disease
evolves, the consolidations reduce their density resembling
a ground-glass opacity that can derive in a ‘‘white lung’’ if
the disease worsens or in a minimization of the opacities
if the course of the disease improves [6]. In this manner,
if any of these characteristic behaviours are automatically
identified, it would be possible to stratify the disorder’s stage
according to its severity. Computing the extent of the ground glass opacities or densities would also be useful to assess the
severity of the infection or to evaluate the evolution of the
disease. In this regard, the infection extent assessment has
been previously tested in other CT studies of COVID-19 [51]
using manual procedures based on observation of the images.
Solutions like the one discussed in this paper are intended
to support a much faster diagnosis and alleviate radiolo gists and specialists’ workload, but not to substitute their
assessment. A rigorous validation would open the door to
integrating these algorithms in desktop applications or cloud
servers for its use in the clinic environment. Thus, its use,
maintenance, and update would be cost-effective and straight forward and would reduce healthcare costs and improve
diagnosis response time and accuracy. [52]. In any case,
VOLUME 8, 2020 226825J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
the deployment of these algorithms is not exempt from
controversies: hosting the AI models in a cloud service
would entail uploading the images that might be subject
to national and international regulations and constraints to
ensure privacy [53].

