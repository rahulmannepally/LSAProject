COVIDGR Dataset and COVID-SDNet
Methodology for Predicting COVID-19
Based on Chest X-Ray Images
S. Tabik , A. Gómez-Ríos, J. L. Martín-Rodríguez, I. Sevillano-García, M. Rey-Area, D. Charte,
E. Guirado, J. L. Suárez, J. Luengo, M. A. Valero-González, P. García-Villanova,
E. Olmedo-Sánchez, and F. Herrera
Abstract—Currently, Coronavirus disease (COVID-19),
one of the most infectious diseases in the 21st century, is diagnosed using RT-PCR testing, CT scans and/or
Chest X-Ray (CXR) images. CT (Computed Tomography)
scanners and RT-PCR testing are not available in most
medical centers and hence in many cases CXR images
become the most time/cost effective tool for assisting clinicians in making decisions. Deep learning neural networks
have a great potential for building COVID-19 triage systems
and detecting COVID-19 patients, especially patients with
low severity. Unfortunately, current databases do not allow
building such systems as they are highly heterogeneous
and biased towards severe cases. This article is threefold: (i) we demystify the high sensitivities achieved by
most recent COVID-19 classification models, (ii) under a
close collaboration with Hospital Universitario Clínico San
Cecilio, Granada, Spain, we built COVIDGR-1.0, a homogeneous and balanced database that includes all levels
Manuscript received September 25, 2020; revised October 27, 2020;
accepted November 3, 2020. Date of publication November 10, 2020;
date of current version December 4, 2020. This work was supported by
the project DeepSCOP-Ayudas Fundación BBVA a Equipos de Investigación Científica en Big Data 2018, COVID19_RX-Ayudas Fundación
BBVA a Equipos de Investigación Científica SARS-CoV-2 y COVID-19
2020, and the Spanish Ministry of Science and Technology under the
project TIN2017-89517-P. S. Tabik was supported by the Ramon y Cajal
Programme (RYC-2015-18136). A. Gómez-Ríos was supported by the
FPU Programme FPU16/04765. D. Charte was supported by the FPU
Programme FPU17/04069. J. Suárez was supported by the FPU Programme FPU18/05989. E.G was supported by the European Research
Council (ERC Grant agreement 647038 [BIODESERT]). This project
is approved by the Provincial Research Ethics Committee of Granada.
(Corresponding author: Siham Tabik.)
S. Tabik, A. Gómez-Ríos, I. Sevillano-García, D. Charte, J. L. Suárez,
J. Luengo, and F. Herrera are with Andalusian Research Institute in
Data Science, and Computational Intelligence, University of Granada,
18071 Granada, Spain (e-mail: siham@ugr.es; anabelgrios@decsai.
ugr.es; isega24ivan@gmail.com; fdavidcl@ugr.es; jlsuarezdiaz@ugr.es;
julianlm@decsai.ugr.es; herrera@decsai.ugr.es).
J. L. Martín-Rodríguez, M. A. Valero-González, P. García-Villanova,
and E. Olmedo-Sánchez are with Hospital Universitario Clínico
San Cecilio de Granada, 36310 Spain (e-mail: joseluismartin.rx@
hotmail.com; valerogonzalez@yahoo.es; pgvillanova@gmail.com;
euolm@yahoo.es).
M. Rey-Area is with atlanTTic Research Center for Telecommunication Technologies, University of Vigo, Galicia, Spain (e-mail:
mreyarea@gmail.com).
E. Guirado is with the Multidisciplinary Institute for Environment
Studies Ramón Margalef, University of Alicante, 03690, Spain (e-mail:
geesecillo@gmail.com).
Digital Object Identifier 10.1109/JBHI.2020.3037127
of severity, from normal with Positive RT-PCR, Mild, Moderate to Severe. COVIDGR-1.0 contains 426 positive and
426 negative PA (PosteroAnterior) CXR views and (iii) we
propose COVID Smart Data based Network (COVID-SDNet)
methodology for improving the generalization capacity of
COVID-classification models. Our approach reaches good
and stable results with an accuracy of 97.72% ± 0.95%,
86.90% ± 3.20%, 61.80% ± 5.49% in severe, moderate and
mild COVID-19 severity levels. Our approach could help in
the early detection of COVID-19. COVIDGR-1.0 along with
the severity level labels are available to the scientific community through this link https://dasci.es/es/transferencia/
open-data/covidgr/.
Index Terms—COVID-19, convolutional neural networks,
smart data.
I. INTRODUCTION
I
N THE last months, the world has been witnessing how
COVID-19 pandemic is increasingly infecting a large mass
of people very fast everywhere in the world. The trends are
not clear yet but some research confirm that this problem may
persist until 2024 [1]. Besides, prevalence studies conducted in
several countries reveal that a tiny proportion of the population
have developed antibodies after exposure to the virus, e.g., 5%
in Spain.1 This means that frequently a large number of patients
will need to be assessed in small time intervals by few number
of clinicians and with very few resources.
In general, COVID-19 diagnosis is carried out using at least
one of these three tests.  Computed Tomography (CT) scans-based assessment: it
consists in analyzing 3D radiographic images from different angles. The needed equipment for this assessment
is not available in most hospitals and it takes more than
15 minutes per patient in addition to the time required for
CT decontamination.2
 Reverse Transcription Polymerase Chain Reaction (RTPCR) test: it detects the viral RNA from sputum or
1[Online]. Available: https://english.elpais.com/society/2020-05-14/
antibody-study-shows-just-5-of-spaniards-have-contracted-the-coronavirus.
html 2[Online]. Available: //www.acr.org/Advocacy-and-Economics/ACRPosition-Statements/Recommendations-for-Chest-Radiography-and-CT-forSuspected-COVID19-Infection
© IEEE 2020. This article is free to access and download, along with rights for full text and data mining, re-use and analysis.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3596 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 1. The stratification of radiological severity of COVID-19. Examples of how RALE index is calculated.
nasopharyngeal swab [2]. It requires specific material and
equipment, which are not easily accessible and it takes at
least 12 hours, which is not desirable as positive COVID19 patients should be identified and tracked as soon as possible. Some studies found that RT-PCR results from several
tests at different points from the same patients were variable during the course of the illness producing a high falsenegative rate [3]. The authors suggested that RT-PCR test
should be combined with other clinical tests such as CT.
 Chest X-Ray (CXR): The required equipment for this
assessment are less cumbersome and can be lightweight
and transportable. In general, this type of resources is more
available than the required for RT-PCR and CT-scan tests.
In addition, CXR test takes about 15 seconds per patient
[2], which makes CXR one of the most time/cost effective
assessment tools.
Few recent studies provide estimates on expert radiologists
sensitivity in the diagnosis of COVID-19 based on CT scans,
RT-PCR and CXR. A study on a set of 51 patients with chest
CT and RT-PCR essay performed within 3 days, reported a
sensitivity in CT of 98% compared with RT-PCR sensitivity
of 71% [4]. A different study on 64 patients (26 men, mean age
56 ± 19 years) reported a sensitivity of 69% for CXR compared
with 91% for initial RT-PCR [2]. According to an analysis of 636
ambulatory patients [5], most patients presenting to urgent care
centers with confirmed coronavirus disease 2019 have normal or
mildly abnormal findings on CXR. Only 58.3% of these patients
are correctly diagnosed by the expert eye.
In a recent study [2], authors proposed simplifying the quantification of the level of severity by adapting a previously defined
Radiographic Assessment of Lung Edema (RALE) score [6] to
COVID-19. This new score is calculated by assigning a value
between 0-4 to each lung depending on the extent of visual
features such as, consolidation and ground glass opacities, in the
four parts of each lung as depicted in Fig. 1. Based on this score,
experts can identify the level of severity of the infection among
four severity stages, Normal 0, Mild 1-2, Moderate 3-5 and
Severe 6-8. In practice, a patient classified by expert radiologist
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3597
as Normal can have positive RT-PCR. We refer to these cases as
Normal-PCR+. Expert annotation adopted in this work is based
in this score.
Automated image analysis via Deep learning (DL) models
have a great potential to optimize the role of CXR images
for a fast diagnosis of COVID-19. A robust and accurate DL
model could serve as a triage method and as a support for
medical decision making. An increasing number of recent works
claim achieving impressive sensitivities > 95%, far higher than
expert radiologists. These high sensitivities are due to the bias
in the most used COVID-19 dataset, COVID-19 Image Data
Collection [7]. This dataset includes a very small number of
COVID-19 positive cases, coming from highly heterogeneous
sources (at least 15 countries) and most cases are severe patients,
an issue that drastically reduces its clinical value. To populate
Non-COVID and Healthy classes, AI researchers are using
CXR images from diverse pulmonary disease repositories. The
obtained models will have no clinical value as well since they
will be unable to detect patients with low and moderate severity,
which are the target of a clinical triage system. In view of this
situation, there is still a huge need for higher quality datasets built
under the same clinical protocol and under a close collaboration
with expert radiologists.
Multiple studies have proven that higher quality data ensures
higher quality models. The concept of Smart Data refers to
the process of converting raw data into higher quality data
with higher concentration of useful information [8]. Smart data
includes all pre-processing methods that improve value and
veracity of data. Examples of these methods include noise
elimination, data-augmentation [9] and data transformation [10]
among other techniques.
In this work, we designed a high clinical quality dataset,
named COVIDGR-1.0 that includes four levels of severity,
Normal-PCR+, Mild, Moderate and Severe. We identified these
four severity levels from a recent COVID-19 radiological study
[2]. We also propose COVID Smart Data based Network
(COVID-SDNet) methodology. It combines segmentation, dataaugmentation and data transformations together with an appropriate Convolutional Neural Network (CNN) for inference.
The contributions of this paper can be summarized as follows:
 We analyze reliability, potential and limitations of the most
used COVID-19 CXR datasets and models.
 From a data perspective, we provide the first public dataset,
called COVIDGR-1.0, that quantifies COVID-19 in terms
of severity levels, normal, mild, moderate and severe,
with the aim of building triage systems with high clinical
value.
 From a pre-processing perspective, we combined several
methods. To eliminate irrelevant information from the
input CXR images, we used a new pre-processing method
called segmentation-based cropping. To increase discrimination capacity of the classification model, we used a
class-inherent transformation method inspired by GANs.
 From a post-processing perspective, we proposed a new
inference process that fuses the predictions of the four
transformed classes obtained by the class-inherent transformation method to calculate the final prediction.
 From a global perspective, we designed a novel methodology, named COVID-SDNet, with a high generalization capacity for COVID-19 classification based on CXR
images. COVID-SDNet combines segmentation, datatransformation, data-augmentation, and a suitable CNN
model together with an inference approach to get the final
prediction.
Experiments demonstrate that our approach reaches good and
stable results especially in moderate and severe levels, with
97.72% ± 0.95% and 86.90% ± 3.20% respectively. Lower accuracies were obtained in mild and normal-PCR+ severity levels
with 61.80% ± 5.49% and 28.42% ± 2.58%, respectively.
This article is organized as follows: A review of the most used
datasets and COVID-19 classification approaches is provided in
Section II. Section III describes how COVIDGR-1.0 is built and
organized. Our approach is presented in Section IV. Experiments, comparisons and results are provided in Section V. The
inspection of the model’s decision using heatmaps is provided
in Section VI and the conclusions are pointed out in Section VII.
II. RELATED WORKS
The last months have known an increasing number of works
exploring the potential of deep learning models for automating
COVID-19 diagnosis based on CXR images. The results are
promising but still too much work needs to be done at the level
of data and models design. Given the potential bias in this type
of problems, several studies include explication methods to their
models. This section analyzes the advantages and limitations of
current datasets an models for building automatic COVID-19
diagnosis systems with and without decision explication.
A. Datasets
There does not exist yet a high quality collection of CXR
images for building COVID-19 diagnosis systems of high clinical value. Currently, the main source for COVID-19 class is
COVID-19 Image Data Collection [7]. It contains 76 positive and
26 negative PA views. These images were obtained from highly
heterogeneous equipment from all around the world. Another
example of COVID-19 dataset is Figure-1-COVID-19 Chest
X-ray Dataset Initiative [11]. To build Non-COVID classes, most
studies are using CXR from one or multiple public pulmonary
disease data-sets. Examples of these repositories are:  RSNA Pneumonia CXR challenge dataset on Kaggle [12].
 ChestX-ray8 dataset [13].
 MIMIC-CXR dataset [14].
 PadChest dataset [15].
For instance, COVIDx 1.0 [16] was built by combining three
public datasets: (i) COVID-19 Image Data Collection [7], (ii)
Figure-1-COVID-19 Chest X-ray Dataset Initiative [11] and (iii)
RSNA Pneumonia Detection Challenge dataset [12]. COVIDx
2.0 was built by re-organizing COVIDx 1.0 into three classes,
Normal (healthy), Pneumonia and COVID-19, using 201 CXR
images for COVID class, including PA(PosteroAnterior) and
AP(AnteroPosterior) views (seeTable I). Notice that for a correct
learning front view (PA) and back view (AP) cannot be mixed
in the same class.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3598 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE I
A BRIEF DESCRIPTION OF COVIDX DATASET [7] (ONLY PA VIEWS ARE
COUNTED)
Although the value of these datasets is unquestionable as they
are being useful for carrying out first studies and reformulations,
they do not guarantee useful triage systems for the next reasons.
It is not clear what annotation protocol has been followed
for constructing the positive class in COVID-19 Image Data
Collection. The included data is highly heterogeneous and hence
DL-models can rely on other aspects than COVID visual features
to differentiate between the involved classes. This dataset does
not provide a representative spectrum of COVID-19 severity
levels, most positive cases are of severe patients [17]. In addition,
an interesting critical analysis of these datasets has shown that
CNN models obtain similar results with and without eliminating
most of the lungs in the input X-Ray images [18], which confirms
again that there is a huge need of COVID-19 datasets with high
clinical value.
Our claim is that the design of a high quality dataset must
be done under a close collaboration between expert radiologists
and AI experts. The annotations must follow the same protocol
and representative numbers of all levels of severity, especially
Mild and Moderate levels, must be included.
B. DL Classification Models
Existing related works are not directly comparable as they
consider different combinations of public data-sets and different
experimental setup. A brief summary of these works is provided
in Table II.
The most related studies to ours as they proposed different
models to the typical ones are [16] and [19]. In [16], the authors
designed a deep network, called COVIDNet. They affirmed
that COVIDNet reaches an overall accuracy of 92.6%, with
97.0% sensitivity in Normal class, 90.0% in Non-COVID-19
and 87.1% in COVID-19. The authors of a smaller network,
called COVID-CAPS [19], also claim that their model achieved
an accuracy of 98.7%, sensitivity of 90%, and specificity of
95.8%. These results look too impressive when compared to
expert radiologist sensitivity, 69%. This can be explained by the
fact that the used dataset is biased to severe COVID cases [17].
In addition, the performed experiments in both cited works are
not statistically reliable as they were evaluated on one single
partition. The stability of these models, in terms of standard
deviation, has not been reported.
C. DL Classification Models With Explanation
Approaches
Several interesting explanations were proposed to help inspect the predictions of DL-models [21], [22] although all their
classification models were trained and validated on variations
of COVIDx. The authors in [21] first use an ensemble of two
CNN networks to predict the class of the input image, as Normal,
Pneumonia or COVID. Then highlight class-discriminating regions in the input CXR image using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation
(LRP). In [22], the authors proposed explaining the decision of
the classification model to radiologists using different saliency
map types together with uncertainty estimations (i.e., how certain is the model in the prediction).
III. COVIDGR-1.0: DATA ACQUISITION,
ANNOTATION AND ORGANIZATION
Instead of starting with an extremely large and noisy dataset,
one can build a small and smart dataset then augment it in a way
it increases the performance of the model. This approach has
proven effective in multiple studies. This is particularly true in
the medical field, where access to data is heavily protected due
to privacy concerns and costly expert annotation.
Under a close collaboration with four highly trained radiologists from Hospital Universitario Clínico San Cecilio, Granada,
Spain, we first established a protocol on how CXR images are
selected and annotated to be included in the dataset. A CXR
image is annotated as COVID-19 positive if both RT-PCR test
and expert radiologist confirm that decision within less than 24
hours. CXR with positive PCR that were annotated by expert
radiologists as Normal are labeled as Normal-PCR+. The involved radiologists annotated the level of severity of positive
cases based on RALE score as: Normal-PCR+, Mild, Moderate
and Severe.
COVIDGR-1.0 is organized into two classes, positive and
negative. It contains 852 images distributed into 426 positive and
426 negative cases, more details are provided in Table III. All
the images were obtained from the same equipment and under
the same X-ray regime. Only PosteriorAnterior (PA) view is
considered. COVIDGR-1.0 along with the severity level labels
are available to the scientific community through this link:
https://dasci.es/es/transferencia/open-data/covidgr/.
IV. COVID-SDNET METHODOLOGY
In this section, we describe COVID-SDNet methodology in
detail, covering pre-processing to produce smart data, including
segmentation and data transformation for increasing discrimination between positive and negative classes, combined with a
deep CNN for classification.
One of the pieces of COVID-SDNet is the CNN-based classifier. We have selected Resnet-50 initialized with ImageNet
weights for a transfer learning approach. To adapt this CNN to
our problem, we have removed the last layer of the net and added
a 512 neurons layer with ReLU activation and a two or four
neurons layer (according to the considered number of classes)
with softmax activation.
Let X be the set of n images and K the total number of classes.
Each image xi ∈ X has a true label yi with i = 1, 2,...,n.
The softmax function computes the probability that an image
belongs to class k with k = 1,...,K. Let w = (w1,...,wK)
be the output of the last fully connected layer before the softmax activation is applied. Then, this function is defined as:
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3599
TABLE II
SUMMARY OF RELATED WORKS THAT ANALYZE VARIATIONS OF COVIDX WITH CNN
TABLE III
A BRIEF SUMMARY OF COVIDGR-1.0 DATASET. ALL SAMPLES IN COVIDGR 1.0 ARE SEGMENTED CXR IMAGES CONSIDERING ONLY PA VIEW
softmax : RK → [0, 1]K,
softmax(w)j = exp(wj )
K
k=1 exp(wk) .
Let yi be the class prediction of the network for the image xi,
then yi = argmax(softmax(w)), where w is the output vector
of the last layer before softmax is applied for the input xi.
All the layers of the network were fine-tuned. We used a batch
size of 16 and SGD as optimizer.
The main stages of COVID-SDNet are three, two associated
to pre-processing for producing quality data (smart data stages)
and the learning and inference process. A flowchart of COVIDSDNet is depicted in Fig. 2.
1) Segmentation-Based Cropping: Unnecessary Information
Elimination: Different CXR equipment brands include different
extra information about the patient in the sides and contour of
CXR images. The position and size of the patient may also imply
the inclusion of more parts of the body, e.g., arms, neck, stomach.
As this information may alter the learning of the classification
model, first, we segment the lungs using the U-Net segmentation
model provided in [24], pre-trained on Tuberculosis Chest X-ray
Image datasets [25] and RSNA Pneumonia CXR challenge
dataset [12]. Then, we calculate the smallest rectangle that
delimits the left and right segmented-lungs. Finally, to avoid
eliminating useful information, we add 2.5% of pixels to the left,
right, up and down sides of the rectangle. The resulting rectangle
is cropped. An illustration with example of this pre-processing
is shown in Fig. 3.
2) Class-Inherent Transformations Network: To increase the
discrimination capacity of the classification model, we used,
FuCiTNet [10], a Class-inherent transformations (CiT) Network
inspired by GANs (Generative Adversarial Networks). This
transformation method is actually an array of two generators
GP and GN, where P refers to the positive class and N refers to
the negative class. GP learns the inherent-class transformations
of the positive class P and GN learns the inherent-class transformations of the negative class N. In other words, GP learns the
transformations that bring an input image from its own k domain,
with k ∈ {P, N}, to the P class domain. Similarly, GN learns
the transformations that bring the input image from its k space,
with k ∈ {P, N}, to the N class space. The classification loss is
introduced in the generators to drive the learning of each specific
k-class transformations. That is, each generator is optimized
based on the following loss function:
Lgenk = lMSE + 0.006 · lPerceptual + λ · lCE(y == k) (1)
Where lMSE is a pixel-wise Mean Square Error, lPerceptual is
a perception Mean Square Error and lCE is the classifier loss.
The weighted factor λ indicates how much the generator must
change its outcome to suit the classifier. More details about these
transformation networks can be found in [10].
The architecture of the generators consists of 5 identical residual blocks. Each block has two convolutional layers with 3 × 3
kernels and 64 feature maps followed by batch-normalization
layers and Parametric ReLU as activation function. The last
residual block is followed by a final convolutional layer which
reduces the output image channels to 3 to match the input’s
dimensions. The classifier is a ResNet-18 which consists of an
initial convolutional layer with 7 × 7 kernels and 64 feature
maps followed by a 3 × 3 max pool layer. Then, 4 blocks of
two convolutional layers with 3 × 3 kernels with 64, 128, 256
and 512 feature maps respectively followed by a 7 × 7 average
pooling and one fully connected layer which outputs a vector of
N elements. ReLU is used as activation function.
Once the generators learn the corresponding transformations,
the dataset is processed using GP and GN. Two pair of images (x+
i , x−
i ) will be obtained from each input image xi, i =
1,...,n, where x+
i and x−
i are respectively the positively and
negatively transformed images of xi. Note that, once the entire
dataset is processed, we have four classes (P+,P−, N+, N−)
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3600 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 2. Flowchart of the proposed COVID-SDNet methodology.
instead the original P and N classes. Let yi be the class of xi,
yi ∈ {P, N}. If yi = P, GP and GN will produce the positive
transformation x+
i with y+
i = P+ and the negative transformation x−
i with y−
i = P−, respectively. If yi = N, GP and GN
will produce the positive transformation x+
i with y+
i = N+ and
the negative transformation x−
i with y−
i = N−, respectively.
Fig. 4 illustrates with example the transformations applied by
GN andGP. Notice that these transformations are not meant to be
interpretable by the human eye but rather help the classification
model better distinguish between the different classes.
3) Learning and Inference Based on the Fusion of CNN
Twins: The CNN classification model described above in
this section (Resnet-50) is trained to predict the new four
classes: P+,P−, N+, N−. The output of the network (after softmax is applied) for each transformed image associated to the original one is a vector θ = (θP+, θP−, θN+, θN−),
where θj is the probability of the transformed image to
belong to class j ∈ {P+,P−, N+, N−}. Herein, we propose an inference process to fuse the output of the two
transformed images x+
i and x−
i to predict the label of the
original image xi. In this way, for each pair (x+
i , x−
i ),
the prediction of the original image yi will be either P
or N. Let y
+
i = argmax θ = argmax (θP+, θP−, θN+, θN−)
and y
−
i = argmax ψ = argmax (ψP+, ψP−, ψN+, ψN−) be the
ResNet-50 predictions for x+
i and x−
i respectively. Then:
1) If y
+
i = N+ and y
−
i = N−, then yi = N.
2) If y
+
i = P+ and y
−
i = P−, then yi = P.
3) If none of the above applies, then
yi =
⎧
⎨
⎩
N if max(θNj , ψNj ) > max(θPj , ψPj ),
j ∈ {+, −}
P otherwise .
Experimentally, we used a batch size of 16 and SGD as
optimizer.
V. EXPERIMENTS AND RESULTS
In this section we (1) provide all the information about
the used experimental setup, (2) evaluate two state-of-the-art
COVID classification models and FuCiTNet alone [10] on our
dataset then, analyze (3) the impact of data pre-processing and
(4) Normal-PCR+ severity level on our approach.
A. Experimental Setup
Due to the high variations between different executions, we
performed 5 different 5 fold cross validations in all the experiments. Each experiment uses 80% of COVIDGR-1.0 for
training and the remaining 20% for testing. To choose when
to stop the training process, we used a random 10% of each
training set for validation. In each experiment, a proper set of
data-augmentation techniques is carefully selected. All results,
in terms of sensitivity, specificity, precision, F1 and accuracy, are
presented using the average values and the standard deviation of
the 25 executions. The used metrics are calculated as follows:
recall(positive class) = sensitivity = TP
actual positives
recall(negative class) = specificity = TN
actual negatives
precision(positive class) = TP
predicted positives
precision(negative class) = TN
predicted negatives
accuracy = TP+TN
total predictions
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3601
Fig. 3. The segmentation-based cropping pre-processing applied to the input X-ray image.
Fig. 4. Class-inherent transformations applied to a negative sample. a) Original negative sample; b) Negative transformation; c) Positive
transformation.
F1 = 2 ·
precision · recall
precision + recall
TP and TN refers respectively to the number of true positives
and true negatives.
B. Analysis of COVIDNet and COVID-CAPS
We compare our approach with the two most related approaches to ours, COVIDNet [16] and COVID-CAPS [19].  COVIDNet: Currently, the authors of this network provide
three versions, namely A, B and C, available at [26]. A has
the largest number of trainable parameters, followed by B
and C. We performed two evaluations of each network
in such a way that the results will be comparable to
ours.
 First, we tested COVIDNet-A, COVIDNet-B and
COVIDNet-C, pre-trained on COVIDx, directly on our
dataset by considering only two classes: Normal (negative), and COVID-19 (positive). The whole dataset
(426 positive images and 426 negative images) is evaluated.We report inTable IV recall and precision results
for Normal and COVID-19 classes.
 Second, we retrained COVIDNet on our dataset. It is
important to note that as only a checkpoint of each
model is available, we could not remove the last layer
of these networks, which has three neurons. We used
5 different 5 fold cross validations. In order to be
able to retrain COVIDNet models, we had to add a
third Pneumonia class into our dataset. We randomly
selected 426 images from the Pneumonia class in
COVIDx dataset. We used the same hyper-parameters
as the ones indicated in their training script, that is, 10
epochs, a batch size of 8 and a learning rate of 0.0002.
We changed covid_weight to 1 and covid_percent to
0.33 since we had the same number of images in all
the classes. Similarly, we report in Table IV recall and
precision of our two classes, Normal and COVID-19,
and omit recall and precision of Pneumonia class. The
accuracy reported in the same table only takes into
account the images from our two classes. As with our
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3602 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE IV
COVIDNET AND COVID-CAPS RESULTS ON OUR DATASET
TABLE V
RESULTS OF COVID-19 PREDICTION USING RETRAINED COVIDNET-CXR A, RETRAINED COVID-CAPS, RESNET-50 WITH AND WITHOUT SEGMENTATION,
FUCITNET AND COVID-SDNET. ALL FOUR LEVELS OF SEVERITY IN THE POSITIVE CLASS ARE TAKEN INTO ACCOUNT
models, we report here the mean and standard deviation
of all metrics.
Although we analyzed all three A, B and C variations of
COVIDNet, for simplicity we only report the results of the
best one.
COVID-CAPS: This is a capsule network-based model
proposed in [19]. Its architecture is notably smaller than
COVIDNet, which implies a dramatically lower number
of trainable parameters. Since the authors also provide a
checkpoint with weights trained in the COVIDx dataset,
we were able to follow a similar procedure than with
COVIDNet:
 First, we tested the pretrained weights using COVIDx
on COVIDGR-1.0 dataset. COVID-CAPS is designed
to predict two classes, so we reused the same architecture with the new dataset and compute the evaluation
metrics shown in Table IV.  Second, COVID-CAPS architecture was retrained over
the COVIDGR-1.0 dataset. This process finetunes the
weights to improve class separation. The retraining
process is performed using the same setup and hyperparameters reported by the authors. Adam optimizer is
used across 100 epochs with a batch size of 16. Class
weights were omitted as with COVIDNet, since this
dataset contains balanced classes in training as well as
in test. Evaluation metrics are computed for five sets
of 5-fold cross-validation test subsets and summarized
in Table IV.
The results from Table IV show that COVIDNet and COVIDCAPS trained on COVIDx overestimate COVID-19 class in our
dataset, i.e., most images are classified as positive, resulting in
very high sensitivities but at the cost of low positive predictive
value. However, when COVIDNet and COVID-CAPS are retrained on COVIDGR-1.0 they achieve slightly better overall
accuracy and a higher balance between sensitivity and specificity, although they seem to acquire a bias favoring the negative
class. In general, none of these models perform adequately for
the detection of the disease from CXR images in our dataset.
C. Results and Analysis of COVID Prediction
The results of the baseline COVID classification model considering all the levels of severity, with and without segmentation,
FuCiTNet [10], and COVID-SDNet are shown in Table V.
In general, COVID-SDNet achieves better and more stable
results than the rest of approaches. In particular, COVID-SDNet
achieved the highest balance between specificity and sensitivity
with 76.94 ± 2.82 F1 in the negative class and 75.71 ± 3.35
F1 in the positive class. Most importantly, COVID-SDNet
achieved the best sensitivity 72.59 ± 6.77 and accuracy with
76.18 ± 2.70. FuCiTNet provides in general good but lower
and less stable results than COVID-SDNet. When comparing
the results of the baseline classification model with and without
segmentation, we can observe that the use of segmentation improves substantially the sensitivity, which is the most important
criteria for a triage system. This can be explained by the fact
that segmentation allows the model to focus on most important
parts of the CXR image.
C. Analysis Per Severity Level
To determine which levels are the hardest to distinguish by
the best approach, we have analyzed the accuracy per severity level (S), with accuracy(S) = Correct predictions(S)
Total number(S) , where
S ∈ {Normal-PCR+, Mild, Moderate, Severe}. The results are
shown in Table VI.
As it can be seen from these results, COVID-SDNet correctly
distinguish Moderate and Severe levels with an accuracy of
86.90% and 97.72%, respectively. This is due to the fact that
Moderate and Severe CRX images contain more important
visual features than Mild and Normal-PCR+ which ease the
classification task. Normal-PCR+ and Mild cases are much more
difficult to identify as they contain few or none visual features.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3603
TABLE VI
RESULTS OF COVID-SDNET PER SEVERITY LEVEL
TABLE VII
RESULTS OF THE BASELINE CLASSIFICATION MODEL WITH SEGMENTATION, COVID-SDNET, RETRAINED COVIDNET-CXR-A AND RETRAINED
COVID-CAPS. ONLY THREE LEVELS OF SEVERITY ARE CONSIDERED, MILD, MODERATE AND SEVERE
TABLE VIII
RESULTS OF COVID-SDNET BY SEVERITY LEVEL WITHOUT CONSIDERING
NORMAL-PCR+
These results are coherent with the clinical studies provided in
[5] and [2] which report that expert sensitivity is very low in
Normal-PCR+ and Mild infection levels. Recall that the expert
eye does not see any visual signs in Normal-PCR+ although
the PCR is positive. Those cases are actually considered as
asymptomatic patients.
D. Analysis of the Impact of Normal-PCR+
To analyze the impact of Normal-PCR+ class on COVID-19
classification, we trained and evaluated the baseline model,
FuciTNet, COVID-SDNet classification stage, COVIDNetCXR-A and COVID-CAPS, on COVIDGR-1.0 by eliminating
Normal-PCR+. The results are summarized in Table VII.
Overall, all the approaches systematically provide better results when eliminating Normal-PCR+ from the training and test
processes, including COVIDNet-CXR-A and COVID-CAPS.
In particular, COVID-SDNet still represents the best and most
stable approach.
E. Analysis Per Severity Level
A further analysis of the accuracy at the level of each severity
degree (see Table VIII) demonstrates that eliminating NormalPCR+ decreases the accuracy in Mild and Moderate severity
levels by 15.8% and 1.52% respectively.
These results show that although Normal-PCR+ is the hardest
level to predict, its presence improves the accuracy of lower
severity levels, especially Mild level.
VI. INSPECTION OF MODEL’S DECISION
Automatic DL diagnosis systems alone are not mature yet to
replace expert radiologists. To help clinician making decisions,
these tools must be interpretable so that clinicians can decide
whether to trust the model or not [27]. We inspect what led
our model make a decision by showing the regions of the input
image that triggered that decision along with its counterfactual
explanation by showing the parts that explain the opposite class.
We adapted Grad-CAM method [28] to explain the decision of
the negative and positive class.
Figs. 5, 6, and 7 show (a) the original CXR image, (b) visual
explanation by means of a heat-map that highlights the regions/pixels which led the model to output the actual prediction
and (c) its counterfactual explanation using a heat-map that
highlights the regions/pixels which had the highest impact on
predicting the opposite class. Higher intensity in the heat-map
indicates higher importance of the corresponding pixel in the
decision. The larger higher intensity areas in the heat-map
determine the final class. However, Fig. 8(b) represents first the
counterfactual explanation and Fig. 8(c) represents the explanation of the actual decision.
As expected, negative and positive interpretations are complementary, i.e, areas which triggered the correct decision are
opposite, in most cases, to the areas that triggered the decision towards negative. In CXR images with different severity levels, the heat-maps correctly point out opaque regions
due to different levels of infiltrates, consolidations and also to
osteoarthritis.
In particular, in Fig. 5(b), the red areas in the right lung points
out a region with infiltrates and also osteoarthritis in the spine
region. Fig. 6(b) correctly shows moderate infiltrates in the right
lower and lower-middle lung fields in addition to a dilation of
ascending aorta and aortic arch (red color in the center). Fig. 5(c)
shows normal upper-middle fields of both lungs (less important
on the left due to aortic dilation). Fig. 7(b) indicates an important
bilateral pulmonary involvement with consolidations.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3604 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 5. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 6. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 7. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 8. Heatmap that explains the parts of the input image that triggered the counterfactual explanation (b) and the negative actual prediction (c).
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3605
As it can be observed in Fig. 8(c), the explanation of the
negative class correctly highlights a symmetric bilateral pattern
that occupies a larger lung volume especially in regions with
high density. In fact, a very similar pattern is shown in the
counterfactual explanation of the positive class in Fig. 5(c), 6(c)
and 7(c).




NEW_PAPER




BIG DATA MINING AND ANALYTICS
ISSN 2096-0654 06/07 pp116–123
Volume 4, Number 2, June 2021
DOI: 10.26599/BDMA.2020.9020016

C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Prediction of COVID-19 Confirmed, Death, and Cured Cases in
India Using Random Forest Model
Vishan Kumar Gupta
, Avdhesh Gupta, Dinesh Kumar, and Anjali Sardana
Abstract: A novel coronavirus (SARS-CoV-2) is an unusual viral pneumonia in patients, first found in late December
2019, latter it declared a pandemic by World Health Organizations because of its fatal effects on public health. In this
present, cases of COVID-19 pandemic are exponentially increasing day by day in the whole world. Here, we are
detecting the COVID-19 cases, i.e., confirmed, death, and cured cases in India only. We are performing this analysis
based on the cases occurring in different states of India in chronological dates. Our dataset contains multiple classes
so we are performing multi-class classification. On this dataset, first, we performed data cleansing and feature
selection, then performed forecasting of all classes using random forest, linear model, support vector machine,
decision tree, and neural network, where random forest model outperformed the others, therefore, the random
forest is used for prediction and analysis of all the results. The K-fold cross-validation is performed to measure the
consistency of the model.
Key words: coronavirus; COVID-19; respiratory tract; multi-class classification; random forest
1 Introduction
The virus of coronaviruses (CoV) is a special kind
of virus that itself is a disease and it enhances the
existing disease in humans body which makes it a
very dangerous virus. This virus results in wheezing,
hard to breathe, bad digestive system, and liverwort,
effects badly human nervous system (center), and also
harms animals like cows, horses, and pigs that are kept,
raised, and used by people and different wild animals. In
 Vishan Kumar Gupta is with Department of Computer
Science and Engineering (CSE), Graphic Era Deemed
to be University, Dehradun 248002, India. E-mail:
vishangupta@gmail.com.
 Avdhesh Gupta and Anjali Sardana are with Department
of CSE, IMS Engineering College, Ghaziabad 201009,
India. E-mail: avdhesh.gupta@imsec.ac.in; anju.sardana@
gmail.com.
 Dinesh Kumar is with Department of CSE, KIET
Group of Institutions, Ghaziabad 201206, India. E-mail:
dineshvashist@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-17; revised: 2020-08-10;
accepted: 2020-08-21
2002–2003 the epidemic of Severe Acute Respiratory
Syndrome (SARS) and in 2012 the burst of the Middle
East Respiratory Syndrome (MERS) have illustrated the
probability of transferrable newly arrived COVID-19 in
human to human and animal to human and vice versa,
though there are very fewer cases of this kind, they
do exists. In late December 2019, the effect of secret
pneumonia in the whole world is a noticeable topic of
study[1]
.
In India, the first case of coronavirus disease 2019
(COVID-19) was announced on 30th January 2020. This
virus extends to the whole of India (in their different
districts) till April 2020 end. In India, the total cases
announced were 5734 in which 472 were recovered and
166 people were dead till 9th April 2020. In India, the
total cases announced were 236 184 in which 113 233
were recovered and 6649 people were dead till 6th June
2020. After this date, fresh cases are still coming into
light daily which is around 10 000. In India, the infection
rate of COVID-19 is lesser than that in some other
countries till date. The website worldometers[2] gives
us all these details in a precise manner. Figure 1 is
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 117
Fig. 1 Structure of coronavirus.
showing the structure of COVID-19, this structure looks
like a crown. The different parts of this virus are also
introduced in this diagram[3]
.
The objectives of this surveillance are the following:
(1) Monitor trends in COVID-19 disease at national
levels.
(2) Rapidly detect new cases in countries where
the virus has started to circulate and monitor cases in
countries where the virus is not circulating.
(3) Provide epidemiological information to conduct
risk assessments at the national and state level.
(4) Provide epidemiological information to guide
preparedness and response measures.
1.1 Transmission
In China, COVID-19 first case was reported in Huanan
Seafood Wholesale Market, Wuhan. The main reason
which was supposed for the spread of this virus is
the transmission from animal-to-human. Even so, the
upcoming COVID-19 cases were not related to the
subjection method. Hence the conclusion is that virus
transmission is from humans to humans, and people with
viruses indicative are the main recurrent reason for the
spread of COVID-19. Before the symptoms progress,
the transmission probability of COVID-19 appears to be
very rare, even though, this virus transmission can not
be prohibited. Besides these, the advice for every person
is that the people who are symptomless or asymptomatic
could pass on the virus and social distancing is the only
way to be secure from this virus[4]
.
Including rhinovirus and flu, additional wheezing
bacterium, it is believed that the droplets of sneeze
and cough of a person are the main reason for virus
imparting. In closed places, aerosol transmission is also
possible in case of long exposure to deep-mouthed
aerosol concentrations. In China, the result of data
analysis of SARS-CoV-2 spread is that the close contact
of two people is the demanded condition for the spread
of the virus. The virus extension is mainly restricted to a
person’s family members, other nearly contacted people
and healthcare experts[4]
.
1.2 Treatment and prevention
Currently, there is no isolated particular antiviral
treatment for COVID-19 virus and their treatments are
reassuring. The effects of recombination of IFN with
ribavirin are very less against the infection of COVID-19.
After the SARS and MERS pandemic, several valuable
efforts have been provided for the development of new
antivirals targeting the CoV proteases, polymerases, and
entry proteins, nevertheless, none of them has been
proven to be worthwhile in clinical trials, nevertheless, of
them has been proven to be worthwhile in clinical trials.
The patient who can already be recovered from COVID19 can donate their plasma and antibodies, because it has
been proved beneficial in the treatment of COVID-19[1]
.
As well, diverse vaccine schemes, like the use of
disabling viruses, live attenuated viruses, a vaccine based
on viral vector, subunit injection, recombinant proteins,
and DNA vaccines, have been evolved, but they are
tested only in the animals so far.
Till now there is not any effective injection or therapy
available for COVID-19, but only the finest measures
are to control the source of infection, early diagnosis,
reporting, isolation, supportive treatments, and on-time
producing outbreak details to keep away from inessential
anxiety. For every person, a fine exclusive hygiene,
wearing a shaped or suitable mask, ventilation, and
keeping away from massed areas will assist to block
COVID-19 virus or its inflammation[1]
.
The guidance and directions issued by the World
Health Organization (WHO) and other corporations are
as follows:
 Keep away from adjacent correspondence with
people suffering from serious CoV inflammation.
 Clean your hands regularly, mainly when you come
in close contact with CoV-infected people and the place
where they live.
 Keep away from unsafe connections with wild and
farm animals.
 Persons having symptoms of critical air shaft
inflammation should maintain a distance from other
peoples, enfold wheeze or sneezes with a throwaway
paper napkin or material, and clean their hands from
time to time.
 Specifically, in the department of a medical
emergency, proper arrangement of strict hygiene
measures are required for the prevention and control
of infections.
 Individuals that are immunocompromised should
118 Big Data Mining and Analytics, June 2021, 4(2): 116–123
avoid public gatherings.
This paper proposes machine learning schemes based
on a data-driven approach. This approach gives a
prediction about the number of infected people with
COVID-19 in the upcoming days using the available
data. This paper proposes a model, which can easily
forecast the count of fresh COVID-19 cases, so that the
management can make a preparation to handle these
cases.
Figure 2 shows the general diagram of the prediction
model, where the various features are taken, and their
multiple cases (classes) are predicted through random
forest prediction model.
This paper is organized as follows. Section 2
explains methodology and materials for the prediction
of COVID-19, where we present dataset and its features,
feature selection, and all the classes. The procedure
of the prediction model is clarified in Section 3. The
description of various machine learning models used
in this work and their performance metric is presented
in Section 4. Sections 5 present the result analysis,
comparison of reported and estimated cases. At long
last, the conclusion is exhibited in Section 6.
2 Methodology and Material
2.1 Dataset and its features
Coronaviruses are a large family of viruses that
may cause illness in animals or humans. In humans,
several coronaviruses are known to cause respiratory
infections ranging from the common cold to more severe
diseases, such as MERS and SARS. The most recently
discovered coronavirus causes coronavirus disease in
2019 (COVID-19)[5]
.
The number of new cases is increasing day by day
around the world. This dataset has information from the
Confirmed, death, and cured cases
Confirmed Indian National
Dataset features
Observation date, time,
and State/Union Territory
Prediction model
Confirmed Foreign National
State
Time
Observation date
Fig. 2 Prediction method.
states and union territories of India daily. The effect of
preventing measures, like social distancing, face mask,
and the lockdown, has also been considered.
The dataset consists of features of COVID-19
data which are taken from https://www.kaggle.com/
sudalairajkumar/covid19-in-india/ and also from the
Ministry of Health & Family Welfare. The dataset
consists only of 2342 samples of COVID-19 cases in
India from 30 January 2020 to 26 May 2020. Table 1
shows the attributes/features used in this study and
glimpse of dataset is presented in Table 2.
2.2 Feature selection
During the process of model building, feature selection
is used to select most relevant features out of all the
features. It reduces the complexity of the prediction
model. Here, we performed feature selection using
random forest importance algorithm in R programming
language[6]. The classification model features are
calculated using the above algorithm, whose input
parameters are all the features of dataset of COVID-19
cases in India.
So, we got three features, which were used for
the building of multi-class classification model using
a random forest importance algorithm. These are
“Obervation date”, “Time”, and “State/Union Territory”
out of five, only two features have been discarded,
that are “Confirmed Indian National” and “Confirmed
Foreign National”. These features are discarded, because
they impact only at the beginning of COVID-19
infection, when patients were coming from abroad, later
Table 1 Feature for the prediction of COVID-19 cases in
India.
Name Description
Observation date It is the date on which how many
COVID-19 positive cases have
occurred.
Time It is the time of that particular date
at which how mang COVID-19
positive cases have occurred.
State/Union Territory It is the name of the state/union
territory of India where COVID-19
cases were found.
Confirmed Indian National It is the total number of confirmed
COVID-19 cases found in India
itself at the starting of SARS-CoV-2
in India.
Confirmed Foreign National It is the total number of confirmed
COVID-19 cases found in India,
which came from any foreign
countries at the beginning of SARSCoV-2 cases in India.
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 119
Table 2 Dataset on SARS-CoV-2 in India.
Date Time State/Union
Territory
“Confirmed Indian
National” case
“Confirmed Foreign
National” case
Cured
case
Death
case
Confirmed case
30-01-2020 6:00 PM Kerala 1 0 0 0 1
04-03-2020 6:00 PM Rajasthan 1 14 0 0 15
07-03-2020 6:00 PM Telengana 1 0 0 0 1
07-03-2020 6:00 PM Tamil Nadu 1 0 0 0 1
08-03-2020 6:00 PM Ladakh 2 0 0 0 2
08-03-2020 6:00 PM Telengana 1 0 0 0 1
10-03-2020 6:00 PM Jammu and Kashmir 1 0 0 0 1
11-03-2020 7:00 PM Maharashtra 2 0 0 0 2
11-03-2020 7:00 PM Delhi 5 0 0 0 5
29-03-2020 7:30 PM Andhra Pradesh – – 1 0 19
10-04-2020 5:00 PM Maharashtra – – 125 97 1364
29-04-2020 5:00 PM Gujarat – – 434 181 3774
01-05-2020 5:00 PM Madhya Pradesh – – 482 137 2719
26-05-2020 8:00 PM West Bengal – – 1414 278 3816
CoV cases are arisen only based on internal infection
due to COVID-19’s communicable property. Therefore,
the values of these fields are not considered.
2.3 Target classes used in prediction dataset
Our dataset contains three target classes, which have
multiple discrete instances. These target classes are the
following:
(1) Confirmed cases: Number of confirmed cases at
any particular date. It may be increased or decreased
according to next date, time, and location-specific to the
Indian states only.
(2) Death cases: Number of death cases at any
particular date. It may be increased or decreased
according to next date, time, and location-specific to
the Indian states only.
(3) Cured cases: Number of cured cases at any
particular date. It may be increased or decreased
according to the next date, time, and location-specific to
the Indian states only.
3 Procedure of Prediction Model
We are developing a machine learning-based
methodology, which has the following four steps.
This methodology is also depicted in Fig. 3.
Step 1: Building multi-class classification model
using the training-testing concept. The dataset of
COVID-19 features of date-wise, time-wise, and statewise were taken from Kaggle and then trained and tested
at 70% and 30%, respectively.
Step 2: Feature selection. Before going to the model
formation, we selected only important features for the
reduction of the complexity of the model. For the same,
1. Data collection from Kaggle
2. Data cleansing
3. Feature selection
4. Model building
5. Result analysis
Fig. 3 Methodology of work.
we applied the random forest importance algorithm.
Section 2.2 describes it in detail. The formulas for the
prediction model in the confirmed, death, and cured
cases are the following:
Confirmed f .Observation Date C TimeC
State/Union Territory/ (1)
Death f .Observation Date C TimeC
State/Union Territory) (2)
Cured f .Observation Date C TimeC
State/Union Territory/ (3)
Step 3: Training the dataset using the multi-class
classification. The dataset is then modeled using random
forest, Support Vector Machine (SVM), decision tree,
multinomial logistic regression, and neural network at
70% training dataset.
Step 4: Testing the dataset using the multi-class
120 Big Data Mining and Analytics, June 2021, 4(2): 116–123
classification: 30% data are tested using these all five
models, the results from all the five models are collected
and found that the random forest model outperformed the
other models for the prediction of confirmed, death, and
cured cases, individually. Therefore, we have considered
the random forest model for the prediction of this multiclass classification model.
4 Machine Learning Models Used in This
Study and Their Performance Metrics
These are the following models used for the prediction of
the cases of COVID-19 using multi-class classification:
(1) Decision tree (rpart): To build decision trees, we
used rpart() method of R programming language[7, 8]
.
(2) Random forest (randomForest): It is an
ensemble tree-based learning algorithm. The random
forest classifier is a set of decision trees from a randomly
selected subset of the training set. It aggregates the votes
from different decision trees to decide the final class of
the test object. We used randomForest() method of R
programming language for this algorithm[9, 10]
.
(3) Multinomial logistic regression (multinome):
In statistics, multinomial logistic regression is a
classification method that generalizes logistic regression
to multi-class problems, i.e., with more than two possible
discrete outcomes. We used multinome() method of
nnet package of R programming language for this
algorithm[11]
.
(4) Neural networks (nnet): Neural networks are
used just for classification as well as for regression.
We are using here feed-forward neural networks with a
single hidden layer, possibly with skip-layer connections.
We used nnet() method of R programming language for
this algorithm[7, 11]
.
(5) Support vector machine (svm): SVM can be
used for classification or regression. It represents the
input features as vectors, which are projected onto
higher-dimensional space. An optimal hyperplane is
then constructed for separating the different instances of
confirmed, death, or cured cases. We have used svm()
method of e1071 package of R programming language
for this algorithm[7, 12]
.
4.1 Performance tuning of the prediction models
Table 3 shows the popular prediction models, which are
used in our study, and the packages used by these models
are open source libraries in R programming language,
licensed under GNU GPL. All packages are used here
having some appropriate method for model formation,
Table 3 Machine learning models and their tuning
parameters.
Model Method Required
package
Tuning
parameter
Random forest randomForest randomForest mtry=2,
ntree=500
SVM svm e1071 kernal=radial,
degree=3
Decision tree rpart rpart usesurrogate=0
Neural
network nnet nnet size=10
Multinomial
logistic
regression
multinome nnet maxit=1000
which are tuned for better results[13]
.
4.2 Accuracy
The accuracy is computed as the percentage deviation
of the predicted target concerning the actual target
with some acceptable error. It is the main performance
evaluation parameter of any machine learning
model[7, 14]
.
Accuracy D
100
n
Xn
iD1
qi
;
qi D
(
1; if abs.pi  ai/ 6 2I
0; otherwise
(4)
where pi
is a predicted target, ai
is an actual target, and
qi
is an arbitrary variable, which contains the absolute
difference of predicted target value and actual target
value.
5 Result Analysis and Comparison of
Reported and Estimated Cases
The number of the total sample for training and testing is
2342 according to different date, time, and states, which
are taken from the website of Kaggle. This is the dataset
of multi-class classification to foresee confirmed, death,
and recovered/cured cases calculated through various
decision models, like decision tree, multinomial logistic
regression, neural network, SVM, and random forest.
The distribution of data in the training and testing
experiments has been set to 70% and 30%, respectively,
for all the methods used. Comparative performance of
all the methods in the prediction of confirmed, death, and
cured cases on accuracy has been highlighted. Accuracy
is computed as the percent deviation of the predicted
target concerning the actual target. The accuracy has
been calculated using Eq. (4), and Table 4 lists the
accuracy of all the models. The results show tha
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 121
Table 4 Multi-class classification accuracy calculated by
various machine learning models. (%)
Model name Confirmed cases Death cases Cured cases
Random forest 83.54 72.79 81.27
Decision tree 77.69 69.11 79.62
Multinomial logistic
regression 67.69 66.52 71.96
Neural network 70.28 63.18 69.16
SVM 71.35 70.12 68.27
the random forest method outperforms other machine
learning models. Random forest is an ensemble model
that uses bagging for sampling, therefore, we found
its overwhelming performance in comparison to other
models.
In the prediction of confirmed, death, and cured cases
on the testing dataset, random forest has the highest
accuracy of 83.54%, 72.79%, and 81.27% on confirmed,
death, and cured cases, respectively.
Figures 4, 5, and 6 show the histogram for the
comparison of accuracy of confirmed, death, and cured
cases, respectively, using the random forest model as
well as some other models. These results show that
the random forest model has outperformed the other
machine learning models.
Fig. 4 Performance comparison of random forest model
with other models in confirmed cases prediction.
Fig. 5 Performance comparison of random forest model
with other models in death cases prediction.
Fig. 6 Performance comparison of random forest model
with other models in cured cases prediction.
5.1 K-fold cross-validation
The K-fold cross-validation technique shows the robust
performance for the accuracy of any machine learning
model[7]. Here, we have used 7-fold cross-validation for
the prediction of confirmed, death, and cured cases. In
this case, at a time six data frames are used for training
and one data frame is used for testing. Table 5 describes
the accuracy of random forest model for the different
folds of dataset, and Fig. 7 shows the accuracy of the
random forest model in the form of a line graph for the
prediction of all the target classes, which depicts the
consistent performances of random forest model[15]
.
5.2 Comparison of total reported and estimated
confirmed, death, and cured cases
For this data-driven estimations, the data has been taken
from 30 January 2020 to 26 May 2020 from different
states of India. The comparison has also been made
for the daily reported positive confirmed cases with
estimated cases (by data-driven model) for some dates
and states. Tables 6, 7, and 8 are showing the comparison
made by us for the confirmed, death, and cured cases,
respectively.
6 Conclusion
We tend to explore five machine learning models with
three important features for estimating the confirmed,
Table 5 Accuracy provided by 7-fold cross-validation.
(%)
Fold Confirmed cases Death cases Cured cases
1 83.29 72.97 82.52
2 84.98 70.81 81.63
3 81.71 72.35 79.92
4 84.83 72.67 81.17
5 82.65 72.19 81.06
6 84.72 72.88 80.22
7 81.40 70.63 82.44
122 Big Data Mining and Analytics, June 2021, 4(2): 116–123
(a) Confirmed cases
(b) Death cases
(c) Cured cases
Fig. 7 Results of K-fold cross-validation.
Table 6 Comparison of total reported and estimated
confirmed cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 1596 1520 4:76
09-05-2020 Bihar 297 305 2.62
21-05-2020 Maharashtra 10 318 10 386 0.60
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 5897 5912 0.25
Table 7 Comparison of total reported and estimated death
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 97 88 9:27
09-05-2020 Bihar 5 5 0
21-05-2020 Maharashtra 1390 1376 1:01
22-05-2020 Gujarat 773 740 4:26
23-05-2020 Delhi 208 256 2.30
death, and cured cases of COVID-19 in the various states
of India. The qualitative measures are the confirmed,
death, and cured cases. Here, machine learning methods
do not embody any additional information from different
models or different templet structures. All the models
are evaluated on accuracy. Through the intensive
experiments, it is found that the random forest method
Table 8 Comparison of total reported and estimated cured
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 3427 3514 2:53
09-05-2020 Bihar 571 601 5.25
21-05-2020 Maharashtra 39 297 38 920 0.90
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 12 319 12 356 0.30
outperforms other machine learning methods, therefore,
we considered it as a final prediction model for the
prediction of our various cases. The K-fold crossvalidation is used to measure the consistency of random
forest model, which provided nearly linear performance
to the prediction of all these cases.
Acknowledgment
We are very much thankful to the Indian Ministry of
Health and Family Welfare (MoHFW) for making the data
available to the general public. Thanks to covid19india.org
for providing the individual states level details to the
general public. We are also thankful for Kaggle and the
worldometer website, which provide huge data in datewise to perform data analytics.




NEW_PAPER


Predictive Modeling of Covid-19 Data in the
US: Adaptive Phase-Space Approach
Vasilis Z. Marmarelis , Fellow, IEEE
Abstract—There are currently intensified efforts by the
scientific community world-wide to analyze the dynamics
of the Covid-19 pandemic in order to predict key epidemiological effects and assist the proper planning for its
clinical management, as well as guide sociopolitical
decision-making regarding proper mitigation measures.
Most efforts follow variants of the established SIR
methodological framework that divides a population into
“Susceptible”, “Infectious” and “Recovered/Removed”
fractions and defines their dynamic inter-relationships with
first-order differential equations. Goal: This paper proposes
a novel approach based on data-guided detection and
concatenation of infection waves – each of them described
by a Riccati equation with adaptively estimated parameters.
Methods: This approach was applied to Covid-19 daily
time-series data of US confirmed cases, resulting in
the decomposition of the epidemic time-course into five
“Riccati modules” representing major infection waves to
date (June 18th). Results: Four waves have passed the
time-point of peak infection rate, with the fifth expected
to peak on July 20th. The obtained parameter estimates
indicate gradual reduction of infectivity rate, although the
latest wave is expected to be the largest. Conclusions:
This analysis suggests that, if no new waves of infection
emerge, the Covid-19 epidemic will be controlled in the
US (<5000 new daily cases) by September 26th, and
the maximum of confirmed cases will reach 4,160,000.
Importantly, this approach can be used to detect (via
rigorous statistical methods) the emergence of possible
new waves of infections in the future. Analysis of data from
individual states or countries may quantify the distinct
effects of different mitigation measures.
Index Terms—Adaptive modeling of Covid-19 time-series
data, epidemiological predictive modeling, riccati-based
phase-space modeling, statistical detection of Covid-19 infection waves.
Impact Statement—Analysis of US Covid-19 data yielded
five RMs representing the dynamics of five infection waves.
The further application of this approach could allow interregional comparison of the obtained RM-decompositions.
Manuscript received May 29, 2020; revised June 22, 2020; accepted
July 1, 2020. Date of publication July 9, 2020; date of current version July
24, 2020. This work was supported by NIH under Grant R01-AG058162
awarded to the Biomedical Modeling & Simulations Center at the University of Southern California.
The author is with the Department of Biomedical Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail:
vzm@usc.edu).
Digital Object Identifier 10.1109/OJEMB.2020.3008313
I. INTRODUCTION
MANY efforts have been made recently to analyze the
time-course of the Covid-19 pandemic daily data in
various countries or regions and to predict key aspects of its eventual growth in order to assist the proper planning for healthcare
resources and related socioeconomic decision-making. Among
them, dominant role is played by the SIR class of compartmental
epidemiological models, introduced about a century ago by
Kermack and McKendrick [1], and its many variants over
the years [2]–[5] that generally utilize compartments of
“Susceptible”, “Infectious” and “Removed” fractions of the
population, which are interconnected with dynamic relationships described by nonlinear ordinary differential equations. Another commonly used approach employs linear Auto-Regressive
Integrated Moving-Average (ARIMA) models that have been
popular in econometrics [6]. From the policy-planning point of
view, practical importance is attained by predictive modeling
methods that can provide reliable estimates of key parameters
of the unfolding infectious process at each point in time on an
adaptive basis, as well as offer useful insights into the dynamic
structure of the infectious process. For example, such adaptive
methods can offer useful predictions of the maximum number of
total infections and an upper bound of the daily confirmed new
cases for the purpose of planning the proper clinical management
of the epidemic. Furthermore, the obtained model should be
interpretable in terms of the dynamic characteristics of the epidemic process (e.g. infectivity rate etc.) in order to assist policy
planning and operational implementation. From these observations arise two key aspects of a desirable modeling approach:
1) Suitable model form: The employed model form must
capture the essential dynamic characteristics of the epidemic process at each time-point in a manner that is
scientifically interpretable and operationally useful.
2) Robust estimation and adaptive modeling:Robust estimation of the model parameters at each time-point must be
feasible using tested statistical methods in a manner that
can detect possible changes in the underlying modeling
assumptions over time and offer the means for model
adaptation.
If these two key aspects can be secured, then it would be
possible to predict the maximum spread of anticipated infections
and the maximum rate of infections (as well as their respective
timing) in order to assist rational decision-making.
This paper presents one such approach that employs an
adaptive modeling/estimation strategy based on the use of
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 207
208 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
concatenated Riccati-type modules (each described by a
parabolic phase-space representation) and suitable adaptive statistical estimation methods. The potential utility of this approach
is initially demonstrated with the adaptive analysis of daily data
of reported Covid-19 confirmed cases in the US up to the present
time (June 18, 2020).
The extensive literature on the subject of epidemiological
modeling is not reviewed here in the interest of space, but
some basic comparisons of the proposed approach with the
most widely-used SIR class of models will be discussed. Some
representative recent modeling applications to Covid-19 data
that may be of interest to the readers include: a simulation study
of the SEIR model (a variant of the SIR model that includes a
compartment for “Exposed” individuals) for Covid-19 in Northern Italy [7], a model that seeks to estimate the transmission risk
of the epidemic [8], and a model for the spread of the epidemic
in China [9]. There are many Covid-related modeling studies
that have been posted as “preprints under review”, thus more
citations will soon be available.
II. MATERIALS AND METHODS
The key modeling element of the proposed approach is the
“Riccati module” (RM) that is defined by the Riccati Equation
(1) with constant coefficients A and B (defining a quadratic relation between the rate of change and the number of infectionsX(t)
at each time) [10]. The additive stochastic term R(t) represents
all unknown random influences (unknown external factors and
errors/noise) affecting the reported time-series data [11]–[15]:
dX(t)/dt = AX(t) − BX2(t) + R(t) (1)
This equation captures the essential self-limiting aspect of an
infectious process (due to the gradually acquired “herd immunity” and countervailing factors) in a relatively simple manner
by considering the “effective rate” (which relates the derivative
to the function) being reduced linearly with rising X(t) as: [A –
BX(t)], instead of being a constant as in the conventional rate
processes of the form: dX(t)/dt = AX(t).
Thus, the parameter A is the initial “infectivity rate constant”
that is dominant in the initial exponential-like growth of the
infection and quantifies the degree of contagiousness of an
infectious agent along with the level of contagious interactions
in a given “infection pool” (IP). On the other hand, the parameter
B depends on the size of susceptible population in the IP and
also quantifies the degree to which the aforementioned acquired
“herd immunity” and countervailing factors (both natural and
socially or administratively imposed by the infected community) constrain the initial rapid growth of the infection and
eventually achieve its control. This process is described by a
sigmoidal curve defined by Equation (2), which is the general
solution of the Riccati Equation (1) (in the absence of random
perturbations R(t)), where the maximum number Xmax of total
infections anticipated by the Riccati model (i.e. the plateau of
the sigmoidal curve) is given by the ratio of the two parameters
Xmax = (A/B):
X (t) = Xmax/ [1 + K exp (−At)] (2)
where K = [(Xmax/Xin) − 1], with Xin being the initial value
of X(t) at the start of the respective RM single-pool infection.
The two parameters, A and B, of each RM attain useful interpretations that offer insights into the dynamic characteristics of the
infectious process, which is generally decomposed into a cascade of RMs estimated via the proposed adaptive methodology
and representing the ongoing “recruitment” of distinct/major
IPs. This model-derived knowledge may assist the effective
management of an epidemic describable by a model composed
of such concatenated (latent) RMs.
It is clearly desirable to obtain reliable “running” estimates of
these parameters from time-series data (e.g. daily Covid-19 data)
at any given point in time. The Riccati-equation model has been
shown previously to represent self-limiting infectious processes
that are confined within single isolated “infection pools” (IPs)
[11]–[15]. The challenge in the study of the Covid-19 epidemic
is that, due to its highly contagious nature, there are multiple
communicating IPs that are recruited during the course of the
epidemic and contribute to the reported data at the respective national, international or multi-community level. This presents us
with the daunting task of separating the superimposed sigmoidal
time-courses of multiple RMs corresponding to the various IPs
(without the benefit of separate data from individual IPs). To
perform this task, we propose a methodology that utilizes an
adaptive estimation procedure to detect (via a “running” statistical Hypothesis test) and separate the concatenated parabolic
phase-space representations of the RMs that are present in the
data up to a given time-point.
The phase-space representation of a dynamic process X(t)
pertains to the relation between X(t) and its derivative over time
(in the absence of random perturbations). The Riccati Equation
(1) indicates that this relation is parabolic. For discrete-time data
(i.e. Covid-19 confirmed cases) up to time-step n, a cascade of
parabolic phase-plots can be fitted to the available phase-space
data, and estimates of all the parameters A and B at each timestep n can be obtained. These parameter estimates can be used to
predict the multi-sigmoidal time-course of the infectious process
according to a superposition of cascaded sigmoidal curves,
each described by Equation (2) with its distinct parameters.
This estimation task begins with the statistical detection and
estimation of the first RM that is described by the discretized
Riccati-model:
ΔX (n) /ΔT = AX (n) − BX2 (n) + R (n) (3)
where: ΔX(n) = [X(n) − X(n − 1)], and ΔT denotes the fixed
time-step (1 day in this case). Following adaptive estimation
of the first RM (see below), we perform statistical Hypothesis
testing (using a properly constructed F-statistic) at each timestep to detect the possible emergence of another RM and, if
such is detected, then estimate the distinct parameters of the two
RMs and separate the contributions to the total reported cases
(see below). This procedure is repeated at each time-step n until
all daily data have been analyzed to obtain adaptive estimates
of the distinct RM parameters A and B that correspond to all
detected RMs.
Regarding the robust estimation of the parameters A and
B, initial analysis indicated that the standard deviation of the
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 209
residual valuesR(n) depends roughly linearly onX(n). This nonstationary residual variance implies that least-squares fitting of
the model of Equation (3) would yield unreliable parameter
estimates. However, reliable estimates of A and B may be
obtained via least-squares regression of the “Normalized Rate of
Change”: ΔX(n)/X(n), (equivalent to the logarithmic derivative)
upon X(n) according to the equation:
ΔX (n) /X (n) = A − BX (n) + R (n) /X (n) (4)
when ΔT in Equation (4) is set to 1 (one day). Since the residual
term: R(n)/X(n), is expected to have (approximately) stationary
standard deviation, reliable parameter estimates can be obtained
at each time-step n. Furthermore, the “slope parameter” B in
Equation (4) can be evaluated for statistical significance at
each time-step n (by testing the Null Hypothesis that the slope
parameter is not significantly different from zero at a specified
confidence level) to assess whether Equation (4) remains an
appropriate representation of the data. When this Null Hypothesis gets rejected at some time-step n, then adaptive parameter
estimates can begin to be used for adaptive prediction of the
sigmoidal course of the infection accounted by the respective
RM.
This adaptive estimation procedure can be repeated at each
time-point n, until the linear relationship expressed by Equation
(4) ceases to represent the time-evolution of the data – an event
identified adaptively by examining the statistical significance
of the reduction in Residual Variance (using Hypothesis testing
with an F-statistic) of the regression of the “Normalized Rate
of Change” values: [ΔX(n)/X(n)] upon the linear relationship
of Equation (4) versus a second-degree polynomial expression
that would indicate the emergence of a new RM. Note that a
second-degree polynomial expression like the one in Equation
(5) (starting with a positive value at X = 0, since A must be
positive) may not have a zero-crossing in the phase-plot of the
“Normalized Rate of Change”, but this is not necessary because
it simply quantifies the divergence from the Null Hypothesis
(as an Alternative Hypothesis) and does not seek to represent
the dynamic characterisitcs of the infectious process. Thus,
we construct an adaptive statistical test using the Alternative
Hypothesis that the Normalized Rate of Change follows the
quadratic model of Equation (5):
ΔX (n) /X (n) = A − BX (n)
− CX2 (n) + R (n) /X (n) (5)
to be tested at each time-point against the Null Hypothesis of
the linear model of Equation (4). For this statistical Hypothesis
testing, we use the following F-statistic (with 1 and (N-3) degrees
of freedom) that represents the normalized reduction in Residual
Variance between the linear and the quadratic expressions (4)
and (5):
F1,N−3 = (N − 3) Q1/(Q2 (6)
where Q1and Q2denote the computed Residual Variances for
the linear and the quadratic expression, respectively, and N is
the number of data-points used in the regression.
TABLE I
ESTIMATED PARAMETERS OF THE RM MODEL COMPONENTS
The computed F1,N−3 is compared at each time-point to the
proper critical value Fcrit (for a significance level of 95%).
When F1,N−3 > Fcrit, the Null Hypothesis is rejected (at 95%
confidence level) and a new RM is deemed to be emerging
and included in the model by separating its contributions (and
parameters) from those of all other previous RMs. The contributions of all concatenated RM model components are included
in the total model prediction. The application of this approach is
demonstrated in the following section using daily reported data
of Covid-19 confirmed cases in the US from March 11 until June
18 (the completion date of this manuscript), while the epidemic
is still ongoing.
III. RESULTS
We analyzed the publicly reported data of daily new Covid-19
confirmed cases in the US (database curated by Johns Hopkins
University) and the cumulative number of confirmed cases since
March 11th 2020 (the day the cumulative cases first exceeded
1000 in the US) until June 18th 2020 (the completion date of this
manuscript), a period that covers a total of 100 days. Application
of the aforementioned methodology identified five latent Riccati
modules (RM) with distinct parameters A and B that are given
in Table I, along with the parameters K of Equation (2) and the
respective predictions of the maximum number of anticipated
cumulative cases due to each RM model component. Some other
key parameters of the five component RMs (e.g. the size and
timing of the peak infection rate for each RM) are also reported
in Table I. The timing of the peak infection rate (PIR) for each
RM is given by the expression:
T PIR = ln (K) /A (7)
and the corresponding PIR is determined by A and B as:
PIR = A2/ (4B) (8)
Equation (8) indicates the strong dependence of PIR on
A. Since the PIR value is critical for planning the clinical
management of the pandemic (lest the finite resources of the
healthcare system be temporarily overwhelmed). Equation (8)
underlines the importance of minimizing (i.e. controlling) A for
a given IP size Xmax = A/B. All these parameter estimates are
given in Table I for the five RMs, along with the time of their
earliest detection T det by the proposed algorithm. The units of
these parameter values are the following: A (days−1), B (days−1
210 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
Fig. 1. Cumulative confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and total concatenated-RM
model prediction (red), along with the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
cases−1), K (unitless), Xmax (cases), PIR (cases/day), T PIR
and T det (days since March 11th 2020).
The declining values of the estimated parametersAfor the five
RMs indicate that there is gradual reduction of the infectivity
rate, which may be partially due to the effect of the imposed
social-distancing and other mitigation measures (see Discussion). These parameter values are updated on a daily basis but
were shown to be rather stable away from the days of introduction of new RMs. The estimated parameters B for the five
RMs depend inversely on the size of the susceptible and exposed
population in the respective “infection pool” in combination
with the effect of mitigation measures (see Discussion). This
is consistent with the model-predicted maximum numbers of
confirmed cases for the five RMs. The total maximum number
of cumulative confirmed cases that is predicted by these five
RM components of the model is: 4,160,000 (substantially higher
than the current cumulative total of 2,191,100 cases). Of course,
this prediction is contingent upon the assumption that no new
infection waves will occur and be detected by the algorithm in
the future. In connection with this assumption, we note that the
F-statistic is rising recently and is approaching the critical value
that may trigger the detection of a new emergent infection wave.
Fig. 1 shows the cumulative number of confirmed cases in the
US since March 11th 2020 along with the total model prediction
and the predictions of the five RM components. The depicted
RM-decomposition of the time-course of the cumulative number
of confirmed cases offers useful insight into the time-course of
the epidemic unfolding over five major IPs (defined as the source
of statistically significant RMs) in the US between March 11th
and the present time (June 18th). Consistent with the estimates
shown in Table I, Fig. 1 indicates that the last RM model
component is expected to make the largest contribution to the
total number of confirmed cases, relative to the previous four
RMs (see Discussion).
The analysis of the daily new confirmed cases offers an
informative RM-decomposition that is shown in Fig. 2, along
with the actual time-series data and the total model prediction.
This result demonstrates the ability of the proposed approach to
Fig. 2. New daily confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and the total concatenatedRM model prediction (red), along with the predictions of the five RM
components (green-dashed, blue-dotted, purple-dot-dashed, browndotted, and black-dashed).
model multi-modal patterns of dynamic changes in the infectious
process due to merging of distinct infection pools – unlike
the unimodal patterns of the widely used SIR models. This
also allows the timely detection of emerging distinct waves of
infection (see Discussion).
The number of daily new confirmed cases due to each RM is
given by the expression:
ΔX (n) = A2K exp (−An) /{B[1 + K exp (−An)]2}
(9)
that exhibits a single peak at the PIR time-point T PIR (see
Equations (7) and (8)), which corresponds to the inflection point
of the respective sigmoidal curve and is half-way to the level
of the sigmoidal plateau (i.e. foretells the maximum value of
cumulative cases to be reached by each RM).
It is evident in Fig. 2 that the first four RMs have passed their
PIR time-points (see Table I). The last RM is expected to reach
its PIR time-point on Day 132 (i.e. on July 20th). This RM-based
model predicts that, unless a new IP is recruited in the near future,
the Covid-19 infection in the US will dip below 5,000 new daily
confirmed cases on Day 194 (i.e. on September 20th), as marked
with an arrow in Fig. 3 that shows the simulated prediction of
the five RM model components over the next 100 days (until
September 26th). It is evident in Fig. 3 that the infection wave
of the last RM is expected to be larger than the combined total
of the other four RMs (see Discussion).
The forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days
(provided that no new infection wave emerges) is shown in Fig. 4
and illustrates the dominant contribution of the last infection
wave that has not yet reached its inflection point (T PIR) that is
expected in 32 days (i.e. on July 20th).
A cyclical ripple is evident in the actual data of daily confirmed cases in Fig. 3 that is not accounted by the RM-based
model. It is probably due to time-varying influences related to the
weekly cycle of social life. The RM-based model is not expected
to account for such time-varying influences, although the use
of the fundamental Riccati Equation (1) can be extended in
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 211
Fig. 3. Forward prediction of the RM-based model for the new daily
confirmed cases in the US over the next 100 days (to September 26th)
made on June 18th (red line), along with the actual time-series data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
Fig. 4. Forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days (to September 26th) made on June 18th (red line), along with the actual data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
future work to time-varying coefficientsAin order to account for
these weekly variations. To examine the dominant frequencies
of these variations, Fig. 5 shows the frequency spectrum of the
residuals of the RM model prediction for the daily confirmed
cases that clearly depicts a 7-day spectral peak (located at
0.143 cycles/day).
Finally, since some take the view that simple curve-fitting
of the cumulative cases data to a sigmoidal expression may
be adequate, we examine whether a direct least-squares fitting
of the sigmoidal expression of Equation (2) to the time-series
data of cumulative confirmed cases may be able to yield a
reasonable approximation of the time-course of the data. The
result is shown in Fig. 6 and demonstrates the inferiority of
simple curve-fitting, both in terms of approximation accuracy
(by comparing with the RM-model approximation in Fig. 1)
and in terms of misleading parameter estimates: low infectivity
rate estimate of Asig = 0.065 and low prediction of maximum
number of confirmed cases: 2,120,000.
Fig. 5. The frequency spectrum of the residuals of the RM model
prediction for the new daily confirmed cases in the US that depicts a
7-day spectral peak at 143 millicycles/day.
Fig. 6. Direct least-squares fit (red line) of the cumulative cases of
confirmed Covid-19 patients in the US from March 11th to June 18th
(blue line with circles). The results are inferior to their counterparts from
the proposed RM-based modeling methodology that are shown in Fig. 1.
Fig. 7. Direct least-squares fit (red line) of the daily cases of confirmed
Covid-19 patients in the US from March 11th to June 18th (blue line with
circles). The results are inferior to their counterparts from the proposed
RM-based modeling methodology that are shown in Fig. 2.
For the data of daily confirmed cases, the direct least-squares
approximation is shown in Fig. 7 and demonstrates the inferiority of curve-fitting in terms of approximation accuracy (by
comparing with the RM-model approximation in Fig. 2) and the
fundamental inability of direct sigmoidal fitting to approximate
212 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
multi-modal phase-plots that can detect the emergence of new
major infection waves.
IV. DISCUSSION & CONCLUSION
A novel adaptive methodology for predictive modeling of the
time-course of daily and cumulative confirmed cases of Covid19 has been presented and its application to the reported data
for the US has been demonstrated. This methodology achieves
the decomposition of the time-course of the Covid-19 data in
terms of concatenated “Riccati Modules” (RM) and provides
potentially useful predictions as well as valuable insights into
the dynamic characteristics of the infectious process.
Specifically, the advocated approach detects the presence of
multiple overlapping “infection waves” that correspond to major
“infection pools” (IP) described by distinct and concatenated
RMs that are defined by the fundamental Riccati Equation (1) –
each with distinct parameters A and B that quantify the critical
dynamic aspects of the infectious time-course in the respective IP. The parameter A is the “infectivity rate constant” that
determines the initial exponential-like growth of the infection
and depends on the degree of contagiousness and the level of
contagious interactions in a given IP. In this sense, it is akin
to the “reproduction rate” of the conventional SIR models. The
parameter B depends on the size of the susceptible and exposed
population in each IP and also quantifies the degree to which
the gradually acquired “herd immunity” and mitigating factors/measures constrain the initial rapid growth of the infection
and eventually achieve its control according to the sigmoidal
time-course defined by Equation (2) reaching at its plateau the
maximum number of infections: Xmax = (A/B).
To achieve this RM-decomposition of the time-series data,
the proposed approach employs regression analysis in phasespace and statistical Hypothesis testing using an F-statistic (see
Methods) to detect the emergence of new infection waves at
a specified level of statistical significance. Running (adaptive)
estimates of the RM parameters are obtained at each time-point.
They were found to be rather stable away from the points where
new RMs are introduced into the model.
Analysis of Covid-19 daily data in the US from March 11th
to June 18th (when this manuscript was completed) yielded five
RMs that are concatenated as shown in Figs. 1 and 2. They
are deemed to represent the distinct dynamics of five infection
waves in major IPs that have the characteristics defined by
their respective parameters given in Table I. The small initial
RM-1 (possibly corresponding to the initial infection in the
Seattle area) is followed by the larger RM-2 and RM-3 (possibly corresponding to the rapid urban surge in New York City
and subsequently in other US urban centers and the Northeast,
respectively). The broader epidemic spread across smaller towns
and rural areas in the US, under local mitigation measures, may
correspond to RM-4 (slower growth and moderate size). The
emergence of the last and largest infection wave (described
by RM-5) was detected by the proposed algorithm on Day
60 (May 9th) and appears to coincide with the relaxation of
some mitigation measures across the US. The total number
of infections anticipated by the model is 4,160,000 (about
TABLE II
UNITS FOR MAGNETIC PROPERTIES
Vertical lines are optional in tables. Statements that serve as captions for the entire table do
not need footnote letters.
aGaussian units are the same as cg emu for magnetostatics; Mx = maxwell, G = gauss,
Oe = oersted; Wb = weber, V = volt, s = second, T = tesla, m = meter, A = ampere, J
= joule, kg = kilogram, H = henry.
double the current cumulative number), provided that there
will be no new RM added to the model because of Covid-19
spreading into a new IP or caused by significant change in the
current mitigation measures. Under the same key assumptions,
the current model predicts that the number of new confirmed
cases in the US will drop below 5,000 by September 20th (see
Fig. 3).
The results shown in Table I and Fig. 2 indicate an early
rapid reduction of the parameter A in successive RMs, which
plays a key role in determining the critical “stressor” of the
healthcare system, the Peak Infection Rate: PIR = A2/(4B),
provided that the parameter B is not drastically reduced. The last
RM anticipates its PIR to occur in 32 days (July 20th) without
exceeding the previous peaks of RM-1 and RM-2. It is worth
noting that the time between detection of a new infection wave
and its PIR increases with decreasing A.
Analysis of the daily confirmed cases shows the individual
contributions of the five RM components (see Fig. 2) and
demonstrates the versatility of the proposed approach to detect in
a statistically rigorous manner new emerging waves of infection
and be applicable to cases where the pattern of daily changes
is not unimodal. This constitutes an important advantage of
the proposed approach over the widely used SIR models and
other unimodal approaches. Another difference of the proposed
approach from the popular SIR model is that it does not take into
account the number of recovered cases and does not require full
immunity of the latter. To further explore this comparison, the
three equations of the classic SIR model can be combined in a
single nonlinear differential equation that takes the second-order
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 213
form:
d2Q/dt2 + k dQ/dt = s0b exp [−b Q (t)] (10)
where Q(t) is the integral from 0 to t of the infected fraction of
the population, k is the recovery rate, b is the infection rate and
s0is the initial size of the susceptible population. Equation (10)
indicates that the estimation of the unknown parameter b must
rely on iterative methods (which are far less robust and reliable
than regression utilized by the proposed approach) and that this
differential equation has only one stable equilibrium point when
Q(t)tends to infinity (a less flexible notion than the multiple finite
stable equilibrium points of the concatenated Riccati Equations
that are achieved by each RM when each reaches its individual
plateau for the respective Xmax = A/B). These comparisons
must be explored further in the future.
Regarding the cyclical variations that are evident in the timeseries data of daily confirmed cases, but not accounted by the
RM-based model (see Fig. 3), it is noted that the fundamental
Riccati Equation (1) can be extended in future work to timevarying coefficients that may account for the observed 7-day
cycle revealed in the spectrum of the residuals of the model
prediction (see Fig. 5). The 7-day cycle peaks at the end of each
week and may be due to increased social interactions during the
previous weekend (noting the average Covid incubation period
of 5 days).
It must be emphasized that the RM-based predictive modeling
is distinct from simple curve-fitting methods. This was demonstrated above by contrasting with the results of direct sigmoidal
least-squares fitting (see Figs. 6 and 7) and showing that the latter
may lead to serious mis-estimation of the key parameters of the
infectious process (e.g. much smaller infectivity rate estimate
and smaller predicted maximum number of confirmed cases) –
in addition to misconceptions regarding the dynamic structure
of the process (i.e. unimodal versus multi-modal phase-space
representation).
An interesting question arises with respect to the effect of
changing testing rates upon the obtained parameter estimates.
If the “true” incidence is Y(t), then the “apparent” incidence
due to a time-varying “testing rate function” f(t) is: X(t) =
f(t)Y(t). It can be shown that the “true” parameters A∗ and B∗
(corresponding to the unknown Y(t) values) are related to the
“apparent” parameter estimates A and B (obtained from the
available X(t) data) according to the expressions: A = A∗ +
f’(t)/f(t), and B = B∗/ f(t), where f’(t) = df(t)/dt. Since f(t)
ought to be positive and ≤1 for all times, then B is always an
overestimation of B∗, and A overestimates A∗ only when the
testing rate is increasing (f’(t) >0). For a constant testing rate,
A = A∗. For the estimated maximum number of cases, we have
the relation: Xmax = Y max [f(t) + f(t) / A∗].
This work (like others on Covid-19 predictive modeling) is
published under unique and unprecedented circumstances of an
ongoing pandemic, which render its validation open to the future
data that are publicly reported. The predictions made in this
paper will hold only if no new wave of infections occurs.
The proposed approach can be applied in the near future to
additional Covid-19 data from other countries or from various regions of the US in order to compare the obtained RMdecompositions (revealing the dynamic structure of infection
waves in these infectious processes) and the associated parameter estimates A and B of each RM. The distinct RMdecompositions for various countries/regions and the respective
parameter estimates may reveal valuable correlations with the
mitigation policies followed in each case to examine their effectiveness within each specific socio-cultural context in order
to guide future decision making by examining how much the
respective policies or socio-cultural conditions influence the estimated parameters A and B – and consequently Xmax = A/B
or PIR = A2/(4B).



NEW_PAPER


Diagnosis of COVID-19 from Chest X-Ray Images Using
Wavelets-Based Depthwise Convolution Network
Krishna Kant Singh and Akansha Singh
Abstract: Coronavirus disease 2019 also known as COVID-19 has become a pandemic. The disease is caused
by a beta coronavirus called Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). The severity of
the disease can be understood by the massive number of deaths and affected patients globally. If the diagnosis
is fast-paced, the disease can be controlled in a better manner. Laboratory tests are available for diagnosis, but
they are bounded by available testing kits and time. The use of radiological examinations that comprise Computed
Tomography (CT) can be used for the diagnosis of the disease. Specifically, chest X-Ray images can be analysed to
identify the presence of COVID-19 in a patient. In this paper, an automated method for the diagnosis of COVID-19
from the chest X-Ray images is proposed. The method presents an improved depthwise convolution neural network
for analysing the chest X-Ray images. Wavelet decomposition is applied to integrate multiresolution analysis in the
network. The frequency sub-bands obtained from the input images are fed in the network for identifying the disease.
The network is designed to predict the class of the input image as normal, viral pneumonia, and COVID-19. The
predicted output from the model is combined with Grad-CAM visualization for diagnosis. A comparative study with
the existing methods is also performed. The metrics like accuracy, sensitivity, and F1-measure are calculated for
performance evaluation. The performance of the proposed method is better than the existing methodologies and
thus can be used for the effective diagnosis of the disease.
Key words: coronavirus; COVID-19; deep learning; convolution neural network; X-Ray images
1 Introduction
A pandemic is an outbreak of a disease globally
affecting many populations. The world has witnessed
many pandemics in the 20th century. Flu viruses
are the major cause of pandemics. These viruses
show changing behaviour with the changing seasons
and thus their behaviour needs to be predicted for
 Krishna Kant Singh is with Department of ECE, KIET Group
of Institutions, Delhi-NCR, Ghaziabad 201206, India. E-mail:
krishnaiitr2011@gmail.com.
 Akansha Singh is with Department of CSE, ASET, Amity
University Uttar Pradesh, Noida 201310, India. E-mail:
akanshasing@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-05; revised: 2020-07-19;
accepted: 2020-07-28
prevention. Health professionals generally make the
correct predictions about most viruses. But some
viruses have exceptional behaviour and are difficult to
predict. Such viruses cause pandemics as humans do
not have the immunity to resist to such virus.
The latest coronavirus disease known as COVID-19
has appeared and spread extremely fast. Since its
discovery in December 2019 in Wuhan, China,
the disease has already spread over 199 countries
and territories. The Severe Acute Respiratory
Syndrome Coronavirus 2 (SARS-CoV-2) causes
COVID-19[1]. The virus is a Ribonucleic Acid (RNA)
virus from the Coronavirus family, most viruses from
this family cause common cold. The more severe
variety of coronaviruses is Severe Acute Respiratory
Syndrome Coronavirus (SARS-CoV) and Middle East
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 85
Respiratory Syndrome Coronavirus (MERS-CoV).
COVID-19 causes respiratory ailments ranging from
common cold to serious diseases like pneumonia. The
number of cases worldwide has reached 5 817 385
causing the deaths of 362 705 individuals as on May
30, 2020 as per the situation report published by
World Health Organization (WHO)[2]. The accurate
information about the emergence of COVID-19 is
still unknown. But the initial cases have established
links with the Huanan (Southern China) Seafood
Wholesale Market[3, 4]. The disease is contagious, and
the virus gets spread amongst humans via respiratory
droplets, physical contact, and also through fecal-oral
transmission[5]. Numerous cases of pneumonia of
unknown cause were reported in Wuhan, China in
December 2019. The cases showed similar clinical
characteristics with viral pneumonia[6]. The patients
suffering from COVID-19 infection are observed to
have serious pneumonia with abnormal observations
on chest Computed Tomography (CT) examination[7]
.
The unavailability of medicine for this disease requires
efficient diagnosis methods for controlling the disease.
Common cold to pneumonia is caused by a group
of viruses known as CoV. These diseases include
respiratory, enteric, renal, and neurological diseases.
These viruses are grouped into four genres namely
alpha-CoV, beta-CoV, gamma-CoV, and delta-CoV[8]
.
Figure 1 gives an overview of the disease.
The virus affects individuals from all age groups and
genders. A research study reveals that two groups of
people are specifically affected by this disease. The first
Fig. 1 Overview of COVID-19.
group of individuals are those who are above 60 years
old. The second group is of those individuals who
have some underlying medical condition like diabetes,
cardiovascular disease, and hypertension. The common
symptoms of COVID-19 include fever, dry cough, and
respiratory problems like shortness of breath, muscular
soreness, and fatigue. In some cases, diarrhoea and
vomiting are also reported. The severity of the disease
ranges from mild flu to pneumonia causing respiratory
ailments. The advance stage of the disease even
causes organ failures and Acute Respiratory Distress
Syndrome (ARDS) leading to the deaths of the patients.
The fast-paced human to human transmission of the
disease is a matter of great concern for the regulatory
authorities globally. The control of COVID-19 largely
depends on the diagnosis at the right time. The available
methods for diagnosis comprise of laboratory tests
like Reverse-Transcription Polymerase Chain Reaction
(RT-PCR), real-time RT-PCR (rRT-PCR), and Reverse
Transcription Loop-mediated isothermal Amplification
(RT-LAMP) test[9, 10]. The laboratory tests have some
limitations. Firstly, the test requires testing kits which
have limited availability in the supply chain. Secondly,
the test is time consuming due to the laboratory
processes involved. The X-Ray facilities are easily
accessible in all parts of the world and the results are
also produced at a fast pace. Therefore, the chest XRay images may be utilized for detecting the presence
of COVID-19. The development of an automated
method based on chest X-Ray images for support in
clinical decision making will be significant for the
disease control. According to WHO, the disease can
be controlled by stopping the chain of transmission.
Officials have reported that testing and isolation are the
two key actions that are useful in breaking the chain
of transmission. Therefore, the accurate diagnosis is
significant in controlling COVID-19.
The detection of COVID-19 can be done at an earlier
stage with chest images as compared to the PCR testing.
The chest X-Ray images can be analyzed by using
artificial intelligence techniques[11]
.
Numerous techniques for diagnosis of COVID-19
using machine learning techniques on radiological
images are available in the literature. A transfer learning
model for diagnosis of coronavirus from chest X-Ray
images is presented in Ref. [12]. Another method with
improved accuracy presented a segmentation-based
approach. The method classified the input images as
86 Big Data Mining and Analytics, June 2021, 4(2): 84–93
normal, viral pneumonia, and COVID-19[13]. A deep
learning-based model is applied on CT images for
detection of COVID-19. Some researchers have also
developed public datasets comprising of chest X-Ray
images of COVID-19 patients[14, 15]. A method named
COVID-Net is developed and applied on these public
datasets for diagnosis of COVID-19[14]. The use of deep
learning for diagnosis from the chest X-Ray images
provides good results. Deep learning models are being
widely used for medical image processing. In Ref. [16],
the detection of pneumonia is done using convolution
neural networks. In this paper, an automated method
for the diagnosis of COVID-19 from a deep network
is proposed. The proposed network utilizes the feature
generated by multiresolution analysis. The combination
of wavelet transforms along with the deep network
brings multiple advantages. The wavelet decomposition
is fed into the network. The network used is not the
traditional Convolutional Neural Network (CNN). A
depthwise separable network is utilized in this work.
2 Background
In this section, the wavelet technique and depthwise
convolution neural network are discussed.
2.1 Wavelet
Wavelet theory is a transform-based image processing
technique that makes use of Wavelet transforms.
Wavelets are derived from small waves of changing
frequency and limited duration[17]. These are useful
as they provide both temporal as well as frequency
information for images.
The 2D scaling functions, including '.x; y/,

H .x; y/,
V
.x; y/, and
D.x; y/, are required for
two-dimensional multiresolution analysis. All these
scaling functions are obtained by multiplying the onedimensional functions. The product of these produces
four two-dimensional separable scaling function and
separable “directionally sensitive” wavelets:
'.x; y/ D '.x/'.y/ (1)

H .x; y/ D .x/'.y/ (2)

V
.x; y/ D '.x/ .y/ (3)

D.x; y/ D .x/ .y/ (4)
These functions record the variance in horizontal,
vertical, and diagonal directions. The separabilty in
Eqs. (1)–(4) is the major cause of the directional
sensitivity. The computational complexity of the 2D
transform remains the same. The scaled and translated
basis functions are defined as
'j;m;n.x; y/ D 2
j=2'.2j
x  m; 2j y  n/ (5)

i
j;m;n.x; y/ D2
j=2
i
.2j
x  m; 2j y  n/;
i D fH; V; Dg (6)
The discrete wavelet transform of an image f .x; y/
of size M  N is
W' .jo; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/ 'jo;m;n.x; y/
(7)
W i
 .j; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/
i
j;m;n.x; y/;
i D fH; V; Dg (8)
where jo is an arbitrary starting scale and the
W' .jo; m; n/ coefficients define an approximation of
f .x; y/ at scale jo. W i

.j; m; n/ coefficients add
horizontal, vertical, and diagonal details for scales
greater than jo. Generally, jo D 0 is selected and N D
M D 2
j
so that j D 0; 1; 2; : : : ; j  1, and m D n D
0; 1; 2; : : : ; 2j  1.
Given W' and W i

of Eqs. (7) and (8), f .x; y/
is obtained by performing inverse discrete wavelet
transform:
f .x; y/D
1
p
MN
X
m
X
n
W'.jo; m; n/'jo;m;n.x; y/C
1
p
MN
X
iDH;V;D
X1
jDjo
X
m
X
n
W i
 .j; m; n/ i
j;m;n.x; y/
(9)
2.2 Depthwise separable convolution neural
network
The standard convolution layer of a neural network
has large number of parameters. This leads to
over fitting of the network. Depthwise convolution
and depthwise separable convolution layers overcome
this problem. These convolution layers reduce the
computational cost as well as the number of parameters.
The depthwise convolution layers can reduce the
computational cost and the parameter space. The
reduction in parameters in no way reduces the efficiency
of the network. The standard convolution is divided into
depthwise and pointwise convolution[18]. The depthwise
convolution is responsible for applying convolution on
every input. The output of depthwise convolution is
merged using pointwise convolution. The l-th layer of
the network having a 3D input tensor x
l
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 87
x
l 2 I
HlW lDl
where H; W; and D represent the
height, weight, and depth of the input vector. The
convolution layer output .yi
lC1j
lC1;d / represents the
point at location .i; j / in d-th channel and l C 1 layer.
This can be computed using
yi
lC1j
lC1;d D
X
D
dD0
fd
X
H
iD0
X
W
jD0
fi:j  x
l
i
lC1j
lC1;d
(10)
where fd is a pointwise filter of size 1  1.
The depthwise separable convolution performs the
operation in two steps. In the first step, a depthwise
convolution is applied on the input. Thereafter, the
pointwise convolution is applied on the output of
the depthwise convolution. The spatial correlations
are obtained from depthwise convolution and the
channel wise correlations are obtained from pointwise
convolution. The combination of these two forms the
feature map.
3 Proposed Method
The proposed method is based on depthwise separable
convolution network and spectral pooling using wavelet
transforms. The network is formulated by combining
multiresolution analysis with deep learning. The
traditional CNN layers suffer from over fitting and high
computational cost due to large number of parameters
generated at each layer. Powerful properties of the
Discrete Wavelet Transform (DWT), spectral domain,
spectral pooling, and spectral parameterization of
convolutional layers are utilized as a means to improve
CNNs by improving training convergence, allowing
flexible pooling dimensions, and retaining or improving
competitive classification accuracies.
The filters in the network learn from the spectral
domain instead of the spatial domain. The low
frequency spectrum of the input contains most of
the details and the high frequency spectrum contains
noise information. This non-uniformity of spectrum
power enables the removal of high frequencies do
minimal damage of input information. Spectral pooling
truncates the spectral representation of an image–kernel
product. Simply put, spectral pooling is simple lowpass filter. This technique is desirable because it can
be combined with the convolution theorem to achieve
fast training results. The convolution theorem states
that convolution can be used considerably by being
performed in the spectral domain as element-wise
multiplication. The details of the proposed network are
discussed in the following section. Given an image x,
it can be divided into four subbands xLL; xLH; xHL;
and xHH using the Discrete Wavelet transform with
convolution filters fLL; fLH; fHL; and fHH. These filters
have fixed parameters and a stride of 2. The stride of
two provides the down sampling of the result obtained
from convolution. These four sub-bands are fed into
the depthwise separable network for further processing.
The flow chart of the proposed method is shown in
Fig. 2.
The proposed method comprises of the following
steps:
(1) Input image: The COVID-19 dataset comprises
of the chest X-Ray images. These images are used for
the detection. The images are of different sizes, thus
they are resized to 3  224  224 .
(2) Image normalization: The input images are
normalized prior to any further processing. Normalized
images are enhanced images with no errors due to
lightening conditions.
(3) Image decomposition with wavelet: This step is
one of the most significant steps that convert the spatial
domain input to frequency domain. The input images
are decomposed into four sub-bands. Haar Wavelet
transform is used to decompose the image into sub
bands. The dataset is augmented and split into training
and testing set.
(4) Convolution layers: This step comprises of three
standard convolution blocks. The input is convolved in
these three blocks.
(5) Spectral pooling and batch normalization:
Next layer is the pooling layer which combines the
features from the output of the different layers. In
this paper, average pooling is performed in which the
convolution is followed by down sampling.
(6) Output layer: The next layer is the fully
connected layer. The softmax optimizer is applied in the
last layer to predict the output.
(7) Grad-CAM output visualization: The
prediction output obtained from the network needs
to be visualized for building trust on the network for
making diagnosis decision. The Grad-CAM utilizes the
gradient information from the last layer of the network
to visually represent the class activation map.
(8) Diagnosis decision: Finally, any given input
chest X-Ray image is classified into one of three classes,
i.e., normal, COVID-19, or viral pneumonia.
The details of the network architecture are discussed
in the following sections.
88 Big Data Mining and Analytics, June 2021, 4(2): 84–93
Fig. 2 Proposed methodology.
3.1 Network architecture
The input layer of the network is fed with chest X-Ray
images. The network comprises of eighteen convolution
layers. The network comprises of a mix of regular and
depthwise convolution layers. The batch size is fixed
to eight. There are six regular and twelve depthwise
layers. Multiresolution analysis is integrated into the
network after the first convolution block. Between the
convolution layers, max pooling layers are added. The
batch normalization layers are used to solve the local
minima problem by mapping the activations to the mean
of zero and unit variance. It also makes the convergence
for the network fast[19]. The over fitting problem is
solved by using a dropout of 0.2[20]. The specifications
of the network layers are given in Table 1.
3.1.1 Convolution layer
Given an input vector with n components X D fx1;
x2; x3; : : : ; xng 2 R
n
, the output vector Y D fy1;
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 89
Table 1 Model summary.
Layer type Output shape Number of parameters Kernel size Dropout Number of filters
Input .224; 224; 3/ 0  0
Wavelet Lambda .112; 112; 12/ 0 3  3 0 4
Separable Conv 2dx2 (ReLU) .14; 14; 256/ 3436 3  3 0 32
Batch normalization .14; 14; 256/ 1024  0
Maxpooling 2d .7; 7; 256/ 0  0
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 68 096 3  3 0 64
Batch normalization .7; 7; 256/ 68 096  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 1024 3  3 0 128
Batch normalization .7; 7; 256/ 512  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 102 272 3  3 0 256
Batch normalization .7; 7; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 256/ 133 888 3  3 0 256
Batch normalization .3; 3; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 512/ 267 264 3  3 0 512
Batch normalization .3; 3; 512/ 2048  0
Maxpooling 2d .1; 1; 512/ 0  0.2
FC1 (ReLU) (512) 262 656 0.7 512
FC2 (ReLU) (128) 65 664 0.5 128
FC3 (ReLU) (64) 8256 0.3 64
FC4 (ReLU) (32) 2080 0.2 32
FC5 (ReLU) (3) 99 0 3
y2; y3; : : : ; yng 2 R
n
.
yi D
X
j2Ni
wj xj (11)
where Ni
is a set of indices of neighbours xi and
the weight wj . The computation of yi
is equivalent to
convolution operation of the input by the weight vector.
Thus it can be written using the convolution operator
as
y D x  w (12)
where w D .w0; w1; : : : :; wn1/ 2 R
n
.
3.1.2 Pooling layer
After the convolution layer is the pooling layer. In
this paper, average pooling is used in connection with
multiresolution analysis. The output of the pooling layer
is the vector with fewer number of components as
compared to the input vector. The output of the pooling
layer is defined as
yj D
1
p
p
X1
kD0
xpjCk; y 2 R
m (13)
where p is the support of pooling and m D
n
p
.
The value of p defines the value by which the number
of parameters is reduced. For example, if the value of
p is 3, then the number of parameters is reduced to
one third by taking triplets in average. Pooling can be
written in the form of down sampling as follows:
y D .x  p/ # l (14)
Average pooling performs convolution by p followed
by down sampling by l.
3.2 Activation function
The activation function used is the ReLU function.
Activation function is significant in the convergence
of the network. ReLU is the rectified linear activation
function, and is the most used activation function[21]
.
This function overcomes the vanishing gradient
problem and makes the model more efficient and faster.
Mathematically, it can be expressed as
f .x/ D max .0; x/ (15)
Thus, the function brings all negative values to
zero whereas positive values remain as it. The ReLU
function is used in the hidden layers. In the last
layer, softmax activation function is used. The softmax
function is
Softmax .xi/ D
e
90 Big Data Mining and Analytics, June 2021, 4(2): 84–93
where xi
is the observed output and divided by the sum
of all possible output.
3.3 Training method
The training of the network is one of the most
significant tasks. The weight vector of the network is
updated to minimize the value of the cost function.
The probabilities over the classes for classification
are computed. The loss function used in this paper
is categorical cross entropy[22]. The other important
task in training is to balance the dataset. The data are
balanced with the help of data augmentation. With data
augmentation, new samples are generated. A rotation
angle of 15 degrees to C15 degrees is used for
augmenting the dataset. The optimization method used
here is Adam optimization with weight decay. This
leads to faster convergence and higher performance
of the network. The other parameters are number of
epochs which are chosen to be 100 and the batch
size is set to 8. The model is evaluated using metrics
like F1-score, precision, validation accuracy, sensitivity,
specificity, etc., which is detailed in Section 5.
4 Dataset
The dataset used for the experiments comprises of chest
X-Ray images of COVID-19, viral pneumonia patients,
and healthy individuals. The annotated Post Anterior
(PA) view of chest X-Ray images is used[23, 24]. A total
of 1439 images from the three classes are available in
the dataset. The number of images of COVID-19 is 132;
viral pneumonia is 629; and the number of images of
normal case is 678. The images are of both males and
females from all over the world. For model building
process, we split the dataset into training and test set
that 80% for training the model and 20% for validation
purpose. Table 2 presents the distribution of the images
present in the dataset. The sample images depicting
normal, viral pneumonia, and COVID-19 patients are
shown in Fig. 3[19]
.
Table 2 Distribution of images in train and test sets.
Image type Train Test
Normal 542 136
Viral pneumonia 503 126
COVID-19 106 26
Total 1151 288
5 Experiment and Result
The implementation of the proposed network is done
using Keras library in Python. The experimental setup
and results are presented in this section. The model
was tuned to obtain the best results. The decomposition
of the image was done using Haar wavelet transform.
A total of twelve separable and six convolution layers
are used. Adam optimizer with weighted decay is
used for optimization of the network. The quantitative
analysis of the results obtained is done using sensitivity,
precision, and F1-score[25]. These metrics are computed
using Eqs. (17) – (20). Sensitivity represents the
correctness of classification. It can be computed as
Sensitivity D
TP
TP C FN
 100% (17)
The misclassifications are reported by precision. If
there are no misclassifications, the precision will be
100%. F1-score is the harmonic mean of precision and
sensitivity. The F1-score of value one represents perfect
precision and sensitivity.
Precision D
TP
TP C FP
 100% (18)
F1-score D 2
precision  sensitivity
precision C sensitivity
 100% (19)
Accuracy D
TP C TN
TP C TN C FP C FN
 100% (20)
where TP; FP, and FN represent the true positive,
false positive, and false negative, respectively. The
confusion matrix for the three classes normal, COVID19, and viral pneumonia is shown in Table 3. The values
Fig. 3 Sample images of normal, viral pneumonia, and COVID-19 infected patients[9]

Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 91
Table 3 Confusion matrix.
Disease type Predicted result
Normal COVID-19 Viral pneumonia
Normal 130 1 5
COVID-19 1 24 1
Viral pneumonia 3 1 122
obtained for the proposed method are summarized in
Table 4.
Figure 4 shows the Grad-CAM for the three classes.
The Grad-CAM visualization is used along with the
classifier predictions for diagnosis of the disease
accurately.
The performance of the proposed method is
Table 4 Value for the proposed method. (%)
Disease type Accuracy Precision Sensitivity F1-score
Normal 96.53 97 96 96
COVID-19 98.61 92 92 92
Viral pneumonia 96.53 95 97 96
Fig. 4 Grad-CAM visualization of (a) normal, (b) COVID19, and (c) viral pneumonia.
compared with other existing methods. The results are
compared with four latest techniques that have used
deep learning models for the diagnosis of COVID-19
using chest X-RAY images. The results are summarized
in Table 5. The analyses of the results reveal that the
proposed method outperforms the existing methods.
DarkCovidNet uses You Only Look Once (YOLO)
network with 17 layers for detection of COVID-19
from chest X-Ray images[26]. The performance of
DarkCovidNet is average with an overall accuracy of
approximately 87%. The second and third methods are
based on EfficientNet[27]. Two variations of the method
are presented namely flat and hierarchical. These two
methods have an overall accuracy of approximately
93%. The DeTraC-ResNet18 performs better than these
methods and has an overall accuracy of 95.12%. The
proposed method has further improved the overall
accuracy. The overall accuracy of the proposed method
is 95.83%. The bar graph of the comparative study is
shown in Fig. 5.
6 Conclusion
The paper presented an automated method for
detection of COVID-19 from chest X-Ray images. An
improved depthwise convolution network is designed
that incorporates spectral analysis. The convolution and
pooling layers are reformulated as a generalized case of
filtering and down sampling. With this reformulation,
multiresolution analysis is integrated with depthwise
Table 5 Comparative analysis. (%)
Method Accuracy Precision Sensitivity F1-score
DarkCovidNet 87.02 89.96 85.35 87.37
Flat-EfficientNet B3 93.34 93.93 93.96 93.94
HierarchicalEfficientNet B3 93.51 93.93 93.55 93.73
DeTraC-ResNet18 95.12 93.36 97.91 95.58
Proposed 95.83 95.67 96.07 95.63
Fig. 5 Comparative study.
92 Big Data Mining and Analytics, June 2021, 4(2): 84–93
network. The input images are decomposed using
Haar wavelet for multiresolution analysis. The wavelet
is applied in the form of fixed weight filters. The
developed model is applied on chest X-Ray images for
detection of COVID-19 disease. The model classifies
the images into three classes: normal, viral pneumonia,
and COVID-19. A comparative study is also performed
to evaluate the performance of the proposed method.
The developed methodology can be used for diagnosis
of COVID-19 from chest X-Ray images. The use of XRay images will help in controlling the disease.



NEW_PAPER



Effect of E-Learning on Public Health and Environment During
COVID-19 Lockdown
Avani Agarwal, Sahil Sharma, Vijay Kumar, and Manjit Kaur
Abstract: E-learning is the most promising venture in the entire world. During the COVID-19 lockdown, e-learning is
successfully providing potential information to the students and researchers. In developing nations like India, with
limited resources, e-learning tools and platforms provide a chance to make education available to middle and low
income households. This paper gives insights about three different online services, namely Google Classroom,
Zoom, and Microsoft Teams being used by three different educational institutions. We aim to analyze the efficiency
and acceptability of e-learning tools among Indian students during the COVID-19 lockdown. The paper also aims to
evaluate the impact of e-learning on the environment and public health during COVID-19 lockdown. It is found that
e-learning has potential to reduce carbon emissions, which has beneficial impact on the environment. However, the
mental health is impacted as e-learning may lead to self-isolation and reduction in academic achievements that may
lead to anxiety and mental depression. Due to usage of electronic devices for learning, the eyes and neck muscles
may be put in strain, having deleterious effects on physical health.
Key words: e-learning; environment; health; COVID-19
1 Introduction
E-learning and online education provide an opportunity
for students to increase their knowledge base in a
flexible environment while using limited resources
and capital. For a developing country like India,
online tools can help students achieve productive and
diverse education by incorporating various themes in
different areas of interest. The online platforms are
slowly gaining popularity due to the improvements in
design, visuals, ease of navigation, and quality content.
 Avani Agarwal and Sahil Sharma are with the Department
of Computer Science, Thapar Institute of Engineering and
Technology, Patiala 147001, India.
 Vijay Kumar is with Department of Computer Science and
Engineering, National Institute of Technology, Hamirpur,
Himachal Pradesh 177005, India.
 Manjit Kaur is with Department of Computer Science
Engineering, School of Engineering and Applied Sciences,
Bennett University, Greater Noida 201310, India. E-mail:
manjit.kaur@bennett.edu.in.
To whom correspondence should be addressed.
Manuscript received: 2020-06-15; accepted: 2020-08-05
Many studies have shown that e-learning can help
improve the knowledge base and make understanding
of concepts easier by providing bite-sized, collaborative,
and interactive content. Studies have proven that a
personalized and assisted learning-based curriculum is
better than the traditional curriculum. The best quality
of education can be provided through e-learning tools by
personalizing the guidance and mentorship according to
the needs of students[1, 2]. The e-learning platforms give
students flexibility and empower students by allowing
them to learn at their own pace and schedule. A student
can choose the time and day to learn or consume the
content provided on these various platforms. We have
material available at our disposal, which can be either
free of cost or paid, open for a lifetime or a limited
amount of time.
Moreover, the content consumed on an online platform
is consistent and standardized in comparison to the
different teaching styles of professors. A diverse range
of options are provided to users by e-learning[3, 4]. Open
online course providers are edX, Udacity, and Coursera,
and Udemy provides both free and paid online courses
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 105
that cover various topics from diverse fields. These
online platforms not only fulfill the current need of
educators but also create new demands which then
help improve the current services being provided to
students[5]. There are websites like GeeksforGeeks
and Tutorials point which enjoy popularity among
engineering students. YouTube also provides the content
to students pursuing different majors and fields, for
example, Khan Academy is one of such YouTube
Channels that helped build basic concepts of high school
students by keeping the material easy to understanding,
participation, and interaction. The YouTube channel
posts videos after thoroughly researching the topics to
help students understand even the small and hidden
concepts of mathematics[6]
.
In India, universities and colleges integrate the Internet
and web pages into classroom teaching. Teaching
staff makes lecture slides, assignments, and important
notifications available to the students via a course site.
The study material may be downloadable as a PDF file
or a PowerPoint file. Students may participate via onlinediscussion forums and examinations may be conducted
by using an e-learning tool. However, despite the
advancing technologies in higher education, institutes
have failed to incorporate the e-learning practices in
main-stream activities and tap the benefits of online
learning[7, 8]. The teachers may be interested in adopting
online tools, however the student’s attitude and aptitude
learning towards online platforms, standardization, and
interactive content of an online platform play critical
roles in determining the behavior roles of students
towards the e-learning environment[9–12]
.
Usually the mode of instruction through e-learning
platforms is designed by professionals who lack the
knowledge of psychological aspects of the domain
on students. Quality of interactive content needs to
be controlled and updates regularly to capture the
interests of the students. A learning context model helps
realize adaptive technological implementations and
personalizing learning environments. Such environments
improve the quality and increase the quantity of learnings
of the students[13]. In the recent years, robots have helped
increase learning in Science, Technology, Engineering,
and Mathematics (STEM) concepts. A constructionbased approach which collaborates educational robots
can be used to teach complex principles and algorithms
like that of computer science programming languages.
LEGO multi-robots may be used for construction-based
approach towards collaborating learning[14]
.
The main objective of this paper is to evaluate the
impact of e-learning on the environment. This paper
also evaluates the effects of e-learning on health of
the students and researchers. Finally, the case study
of e-learning tools adopted in India during COVID-19
lockdown is also considered.
The remaining paper is organized as follows: Section
2 discusses the impact of e-learning on environment.
Section 3 discusses the implication of e-learning on
social life. Section 4 presents the case study of e-learning
during COVID-19 lockdown. Section 5 concludes the
paper.
2 Impact of E-Learning on Environment
E-learning can effectively reduce the energy usage and
emission of carbon dioxide. According to a study in the
Netherlands, e-learning not only has potential to reduce
carbon emissions but also helps decrease the carbon
footprint and carbon impact of students and travel staff.
Moreover, e-learning not only reduces cost and time
but also is helpful to restore the environment. It is also
helpful to eliminate the necessity of traveling from one
place to another. There are some impacts on environment
due to e-learning[15]
.
2.1 Impact on forest
According to National Wildlife Foundation, 60% of
schools and universities’ waste is paper. Sixteen trees
are needed to generate the one-ton paper. The recycling
of ten tons paper is equivalent to the use of 100 barrels
crude oil[16]. E-learning not only reduces the cutting of
trees for paper generation but also reduces the resource
required for recycling the paper. The registration,
administration, curriculum, and study materials are
digitalized and will also reduce 50% of students’ cost.
2.2 Impact on air
University of West Georgia studied that if hundred
students did not travel to schools/universities, carbon
dioxide emissions may be reduced by 10 tons. The
study of the Netherlands reported that e-learning reduced
the percentage of carbon dioxide emissions and carbon
footprint of students and staff[15]. As per literature, 350
million printer’s cartridges became dead every year
and 1000 years are required to decay these cartridges.
These materials can be easily eliminated through the
e-learning[16]
.
3 Implication of E-Learning on Social Life
The e-learning contents are responsible for solving the
environmental issues. However, it can significantly affect
106 Big Data Mining and Analytics, June 2021, 4(2): 104–115
the social and mental health of students[16]
.
3.1 Impact on mental health
The excessive exposure of electronic device greatly
affected the mental health of users. According to
American Psychiatric Association, the extreme use of
e-learning may lead to social isolation. The e-learning
not only reduces the academic achievement but also is
responsible for mental depression. The e-learning is also
responsible for sleep deprivation due to the deadline of
assignment submissions. According to Harvard analysis,
it is observed that sleep deprivation has direct relation
with the academic outcomes.
3.2 Impact on physical health
The study of materials and completion of assignment on
digital media require a lot of time on electronic devices.
The excessive use of electronic device has a great effect
on physical health of users. These are responsible for
mortality rate due to over-sitting on electronic gadgets.
The eyestrain and muscle injuries may be possible due
to overuse of computers.
4 E-Learning Tools Adopted During
COVID-19 Lockdown in India
On March 25th, 2020, India’s Prime Minister
Mr. Narendra Modi imposed a nationwide lockdown as
a countermeasure to control the coronavirus pandemic.
The lockdown was later extended on April 11th, 2020
in various states of India due to the increase in the
number of coronavirus patients across different regions
of the country. Universities, schools, and educational
institutions were closed, and students went back to their
homes. Hence, the educational institutions had to rely
on e-learning and online education tools to provide
students the necessary study material, schedule lectures,
and to conduct examinations. The lockdown acted as a
catalyst to help teachers adopt online tools. As of April
2020, according to the Ministry of Human Resource
Development, India, platforms like Diksha, e-pathshala,
NROER, NIOS, e-yantra, and FOSSEE are endeavors
of the government to help educate the masses online.
SWAYAM, an initiative by the Indian government, gets
50 000 views daily. Some other online methods adopted
in different universities across India are (1) video and
audio meetings, tools like Zoom, Loom, Gotomeeting,
Skype, Bluejeans, Webex, and Google meet are being
used; (2) discussion and collaboration boards make use
of slack and flock; (3) storage and sharing files are
supported by Dropbox and Nextcloud; and (4) document,
presentation, spreadsheet, and videos are made using
G-suite, Prezi, GitBook, Confluence, Office365, and
Adobe Acrobat. With teachers adopting and using elearning techniques and tools to educate students, we
aim to analyze the efficacy and acceptability of teaching
aids provided and adopted among students of educational
institutions, during the COVID-19 lockdown in India,
by conducting a survey in three different educational
institutions — Google Classroom, Zoom, and Microsoft
Teams. The objective was to analyze the students are
willing to adopt e-learning practices as a part of their
classroom learning by conducting surveys in various
educational institutions.
While conducting the surveys at the three educational
institutions, it was presumed that the students had an
internet connection, access to a mobile or a laptop,
previous knowledge to operate a mobile phone or
personal digital device, understood the default language
of the platform, and the sampling done can be mapped
to larger scales with minimum errors.
Case study 1: Thapar Institute of Engineering and
Technology (TIET), Patiala, India
Thapar Institute of Engineering and Technology is a
private engineering college located in Patiala, Punjab,
India. The educational institution offers various courses
in different fields of engineering. The traditional methods
used for classroom teaching are whiteboard, blackboard,
and a smart board that enable teachers to display
presentations and write notes. In the laboratories,
computers and necessary hardware and software
are provided to students for experimentation and
performing assignments. 75% attendance is mandatory
to pass a course. Each course has an official website
where course coordinators post important information,
syllabus, marking scheme, lecture slides, and laboratory
assignments. Details regarding quizzes and tests are
notified to students via group representatives or via
an update on the course site. Mid-semester tests and
end-semester tests are conducted every semester, which
are scheduled according to a date sheet that is made
available on the web portal— Webkiosk, which is
allocated to every student. Apart from these official
websites, students have access to myHerupa, an initiative
taken by Thapar students, where updates regarding
coursework for each subject are made available for
the first-year, second-year, and third-year engineering
students. During the COVID-19 lockdown, the college
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 107
was temporarily shut down. All classroom activities
and lectures were suspended on campus. Students
and teaching faculty members went back to their
homes; many situated far from college. The teachers
of the university used e-learning tools and methods to
provide education online for students. Lectures were
pre-recorded and shared via WhatsApp and Google
Drive links. Videos of laboratory assignments were prerecorded and uploaded on course sites. Many teachers
scheduled live online lectures using Zoom application
to make material accessible to students. Zoom Video
Communication provides a remote conferencing service.
It allows video conferencing of 100 participants up to
forty minutes free of cost. Paid subscriptions are also
available to allow more participants and to increase the
time limit. The service also allows one-to-one video
conferencing and group conferencing, and allows users
to message all members of a meeting at once or message
a selective group of people, providing stimuli to activate
students’ auditory and visual senses, thus enhancing and
replicating their in-person interactions[9, 10]. Slides were
uploaded on the course site, and students were notified.
For the courses, Image processing (UCS615) and
Innovation and Entrepreneurship (UTA012), the thirdyear students pursuing the BEng degree in computer
science submitted their assignments via Google forums.
A Google form was then circulated among the students
of the Thapar Institute of Engineering and Technology,
where students answered questions regarding the elearning platforms used by educators to impart education
online (see Figs. 1–3).
Case study 2: National Institute of Technology,
Hamirpur (NIT-H), India
National Institute of Technology is a public college
located at Hamirpur, Himachal Pradesh, India. The
Ministry of Human Resource Development, India
funds it. It is an engineering college for undergraduate
students in various engineering courses. The on-campus
practices include classroom teaching using tools such
as whiteboards and blackboards. Teachers sometimes
use slides to deliver their lectures. Apart from these
tools, there is a web portal for students, which
notifies them about their semester grades. All relevant
information is circulated using messaging applications
like WhatsApp. The use of smartphones helps make
material accessible to students[11]. To make study
material available and to conduct tests for the first-year
students pursuing the MEng degree in Computer
Vision and Image Processing during the COVID-19
lockdown, Google Classroom has been adopted by
Fig. 1 Most important feature of e-learning for Thapar Institutes.
Fig. 2 Mode of preference for learning during COVID-19 lockdown.
108 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Fig. 3 Response to the question of whether e-learning
methods should be adopted in daily classroom teaching.
the institute. To use this platform, a user has to sign
into the Google Classroom. While using the G Suite
for education account, the user clicks on whether they
are a teacher or a student. The G Suite account is set
up by an accredited college. Using Google Classroom
services, slides are uploaded, and assignments are
given to the students. This study material is available
to the students via Google Classroom, and they turn
in their assignments by submitting them to a private
electronic mail account. Video links are also provided
using Google Classroom. The marks and grades of
students are made available on the platform. Timed and
pre-scheduled quizzes are also being conducted via this
platform. Computer Vision and Image Understanding
assignments were submitted via the Google Classroom
platform. A survey was conducted by circulating a
Google forum among the first-year students pursuing the
MEng degree in computer vision to gain the feedback
and viewpoint of students on e-learning tools and
teaching aids being provided during the COVID-19
lockdown (see Figs. 4–6).
Case study 3: Manav Rachna International School,
Mohali, India
Manav Rachna International School is a private school
for primary and secondary education. The school has
traditional tools like whiteboards and blackboards to
teach students from Class One to Class Ten. The
school also has smart boards, smart class, and projector,
which allow teachers to display slides, play videos,
and make interactive content for the students. The
pupils of a class make notes in their notebooks. These
notebooks may be evaluative or checked by an assigned
teacher. During the COVID-19 lockdown, the online
Fig. 4 Best feature of Google Classroom according to the National Institute of Technology, Hamirput students.
Fig. 5 Online education tool preferred by NIT-H students.
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 109
Fig. 6 Response towards the e-learning methods in NIT-H.
education tool used is Office365, a solution provided
by Microsoft. The products provided by Office365
to educators and teachers include Outlook, Teams,
Excel, Word, PowerPoint, OneNote, Publisher, and
Access, according to the official Office365 website.
The school is using the e-learning tool Teams provided
by Office365. The lockdown initiated the process of
providing official IDs to teachers and students using
manavrachna.net. The teachers can make various teams
for different classes. The chat option allows teachers
to chat with parents and students either one to one,
or by making a group of all students or selected
students. The assignment section provided by Teams
allows teachers to post assignments. Its design notifies
teachers if a student has viewed the assignment, has
turned in the assignment, and if the student has not
opened the assignment by displaying view, turned in
and not turned in, respectively. The students can submit
their assignments by clicking on the add work button
to upload their solved assignments. The class notebook
section allows students to solve mathematics questions
easily due to user-friendly design. It allows the teachers
to view all the notebooks at once. However, students can
only view their notebook. The quizzes and tasks assigned
may be timed, and time bounds are facilitated by the
class notebook section. The files tab allows the teachers
to post relevant study material or reading material for
students to view. Along with these tabs and options,
the post tab is used to view all the notifications, tasks,
and assignments uploaded by the teachers of different
subjects for a team. The students from Class One to
Class Nine were surveyed to gain insight about the
acceptability of e-learning tools being used to combat
COVID-19 lockdown among young children, aged 5 – 15
years old.
4.1 Results from case study 1: Thapar Institute of
Engineering and Technology
The students pursuing the BEng degree in different
majors at the Thapar Institute of Technology were
surveyed. Out of 167 students surveyed, 126 were males
and 41 females. 43.1% of students surveyed were thirdyear students going to the fourth year while 31.1%,
21%, and 4.8% of students surveyed were the firstyear, second-year, and fourth-year students, respectively.
Although the number of female students surveyed is
significantly less than that of male students, the modal
choice of preferences for every question asked on the
survey was the same for the two genders. Hence, it can
be said that gender does not influence e-learning.
The survey was conducted in April 2020 and questions
included the most important feature for students for an
e-learning platform, there preferred choice of online
education tools, how often were users using Zoom
application to view live college lectures on a weekly
basis, if users were satisfied with the e-learning methods
adopted by their institution, and if the user thinks that
educational institutions should adopt tools provided
by e-learning platforms on a daily basis. 118 students
out of 167 students regarded the quality of services
provided by e-learning platforms as an important feature,
while 101 students and 81 students were in support of
ease of accessibility and user interface, respectively.
Other students regarded the price point of e-learning
tools to be the most important feature of an e-learning
platform. 70.7% of students surveyed preferred prerecorded video lectures provided via YouTube links
as the most convenient e-learning tool. Pre-recorder
lectures provided via Google Drive links and Slides
uploaded on course sites enjoyed a majority of 71
students and 77 students, respectively. It is observed
that 33.5% of students are satisfied with e-learning tools.
However, 32.9% of students are not satisfied with these
tools. 52.7% of students agreed on using the Zoom
application to view live lectures at least three times
a week. The majority of the students (60.5%) were
not satisfied with the e-learning methods adopted by
the institute. However, 49.7% of students thought that
educators should try to utilize tools provided by online
education platforms daily (see Table 1).
110 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 1 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Thapar Institute
of Engineering and Technology.
Item No. Item in detail
Number of
students
(max nD 167)
Number
of males
(nD126)
Number of
females
(nD41)
Model
Distribution of
students
1 First-year students 52 32 20
–
2 Second-year students 35 25 10
3 Third-year students 72 61 11
4 Fourth-year students 8 8 0
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
User interface is the most important feature of
e-learning platforms 81 61 20
Quality of service is
the most important
feature of elearning platforms
2
Quality of service is the most important feature
of e-learning platforms 118 93 25
3
Ease of access is the most important feature of
e-learning platforms 101 77 24
Preferred choice
of e-learning tool
during COVID-19
lockdown. (Multiple
choice correct)
1
Pre-recorded lectures shared via YouTube links
are a preferred choice of online education tools
during COVID-19 lockdown.
118 95 23
Pre-recorded
lectures shared
via YouTube links
are a preferred
choice of online
education tools
during COVID-19
lockdown.
2
Pre-recorded lectures shared via Google Drive
links are a preferred choice of online education
tools during COVID-19 lockdown.
70 55 15
3
Google Slides uploaded on the official course
site are a preferred choice of online education
tools during COVID-19 lockdown.
77 60 17
4
Live lectures using Zoom application are the
preferred choice of online education tools
during COVID-19 lockdown.
37 29 8
How frequently
was the Zoom
application used
weekly to access
lectures? (Single
choice correct)
1
Zoom application used at least thrice a week to
access live lectures. 88 65 23
Zoom application
used at least thrice
a week to access
live lectures.
2
Zoom application used twice a week to access
live lectures. 30 22 8
3
Zoom application used once a week to access
live lectures. 49 39 10
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Not satisfied with the e-learning methods
adopted by the institute during COVID-19
lockdown.
101 79 22
Not satisfied with
the e-learning
methods adopted
by the institute
during COVID-19
lockdown.
2
Satisfied or may be satisfied with the elearning methods adopted by the institute
during COVID-19 lockdown.
66 47 19
Should e-learning
tools be adopted
in daily classroom
teaching? (Single
choice correct)
1
E-learning tools should be or may be adopted
in daily classroom teaching. 128 98 30 E-learning tools
should be or may
be adopted in daily
classroom teaching. 2
E-learning tools should not be adopted in daily
classroom teaching. 39 28 11
4.2 Results from case study 2: National Institute of
Technology, Hamirpur
Sixteen first-year students pursuing computer vision at
NIT-H, were surveyed in April 2020. Out of 16 students,
5 were females, and 11 were males. Table 2 shows the
survey of Google Classroom services were being used
during the COVID-19 lockdown. The questions included
in the survey were if Google Classroom was helpful
in teaching outside the classroom, what was the best
feature of Google Classroom according to the students, if
students were satisfied with Google Classroom teaching,
if the submission of assignment for Computer Vision
and Image Processing using the Google Classroom
was convenient, was it easy to conduct quizzes on the
online platform, if it is easy to access Google Classroom
material, if the laptop or mobile devices were preferred
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 111
Table 2 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of National
Institution of Technology, Hamirpur.
Item No. Item in detail
Number of students
(n D 16/
Number of males
.n D 11/
Number of females
.n D 5/
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
Ease of accessibility is the most
critical feature of e-learning platforms. 13 8 5
2
User Interface is the essential feature
of e-learning platforms. 7 5 2
3
Quality of services is the most crucial
feature of e-learning platforms. 9 7 2
Preferred choice of
e-learning tool during
COVID-19 lockdown,
other than Google
Classroom. (Multiple
choice correct)
1
Pre-recorded lectures shared via
YouTube links are a preferred choice
of online education tools during
COVID-19 lockdown.
13 8 5
2
Pre-recorded lectures shared via
Google Drive links are a preferred
choice of online education tools
during COVID-19 lockdown.
2 2 0
3
Live lectures via Zoom or Google
meet are a preferred choice of online
education tools during COVID-19
lockdown.
1 1 0
What are the benefits
of e-learning?
(Multiple choice
correct)
1
With online learning, there is the ease
of access. 11 7 4
2
With online learning, there is
consistency. 7 5 2
3
With online learning, the schedule is
flexible. 13 8 5
4
With online learning, there is the use
of limited resources. 8 5 3
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Satisfied or may be satisfied with the
e-learning methods adopted by the
institute during COVID-19 lockdown.
16 11 5
2
Not satisfied with the e-learning
methods adopted by the institute
during COVID-19 lockdown.
0 0 0
Should the features
of online learning be
adopted into daily
classroom teaching?
(Single choice correct)
1
Some features of online learning
should be or may be adopted in daily
classroom teaching.
15 10 5
2
Some features of online learning
should not be adopted in daily
classroom teaching.
1 1 0
to access Google Classroom, what was the best feature
of the platform provided according to students, what was
another online educational tool that students preferred,
what were the advantages of online education according
to students, if the students were satisfied with the online
learning tool adopted by the university, and if students
wanted to incorporate few features of online education
with daily classroom teaching. For a few questions,
responses were recorded on a scale of 1–5, one being
unsatisfactory, and five being satisfactory. 81.3% of the
students surveyed thought that the ease of accessibility
was the best feature of Google Classroom and prerecorded lectures shared via YouTube links enjoyed a
majority of 13 students out of 16 as the preferred online
education tool (see Table 3). The majority of students
voted for the flexibility of schedule as the advantage of
online education.
4.3 Results from case study 3: Manav Rachna
International School
Table 4 shows the survey conducted in Manav Rachna
112 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 3 Students’ response to survey conducted regarding Google Classroom practices adopted by teaching faculty of National
Institute of Technology, Hamirpur on a scale of 1 – 5, with five being maximum. The values are averaged.
No. Item Number of students
(max n D 16)
Number of males
.n D 11/
Number of females
.n D 5/
1
Google Classroom helped in teaching outside of
the classroom. 4.125 4.182 4
2
Students are satisfied with Google Classroom
as an e-learning tool during the COVID-19
lockdown.
4.187 4.273 4
3
Submission of digital image processing
assignments using Google Classroom was
convenient.
4.500 4.636 4.2
4
It was convenient to answer quizzes on Google
Classroom. 4.187 4.272 4
5
It is easy to access learning material in Google
Classroom. 4.812 4.818 4.8
6
It was easier to use Google Classroom on the
laptop than on Mobile. 3.937 3.909 4
Table 4 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Manav Rachna
International School, Mohali.
Item No. Item in detail
Number of
students
(nD91)
Number of
males
(nD49)
Number of
females
(nD42)
Students division among
various levels from nursery
to Class 9.
1 Nursery and Kindergarten 42 21 21
2 Grades 2–5 31 15 16
3 Grades 6–9 18 5 13
Are students satisfied with
the Microsoft Teams tool
being used during COVID19 lockdown? (Single
answer correct)
1
Students are satisfied or may be satisfied by the
Microsoft Team tool being used during COVID-19
lockdown.
90 48 42
2
Students are not satisfied with the Microsoft Teams
tool being used during COVID-19 Lockdown. 1 1 0
Features of Microsoft
Teams preferred by
students. (Multiple answers
correct)
1
Students like the Chat/Call Tab feature supported
by Teams. 70 37 33
2
Students like the Assignment Tab feature
supported by Teams. 56 29 27
3
Students like the Post Section Tab feature
supported by Teams. 23 11 12
4
Students like the Files Section feature supported
by Teams. 21 10 11
5
Students like the Class notebook Tab feature
supported by Teams. 35 20 15
Are students able to achieve
their learning outcomes
through e-learning? (Single
choice correct)
1
You will be or may be able to achieve the required
learning outputs from these sessions? 82 41 41
2
You will not be able to achieve the required
learning outputs from these sessions. 9 8 1
What are the benefits of elearning? (Multiple choice
correct)
1 With online learning, there is the ease of access. 45 25 20
2 With online learning, the schedule is flexible. 39 18 21
3
With online learning, there can be interactive
content.
36 16 20
Should the features of online
learning be adopted into
daily classroom teaching?
(Single choice correct)
1
Some features of online learning should be or may
be adopted in daily classroom teaching. 77 41 36
2
Some features of online learning should not be
adopted in daily classroom teaching. 14 8 6
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 113
International School, Mohali, India. Out of 91 students
surveyed, 49 students (53.85%) were males, and 42
students (46.15%) were females. 98.90% of students
were satisfied with the Microsoft Teams tool being used
during the COVID-19 lockdown. Students preferred
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application. 61.54%, 25.27%, 23.07%, and 38.46% of
students liked the assignment tab, post section tab, files
tab, and class notebook tab feature, respectively. 90.10%
of students felt that they could achieve their learning
outcomes via Microsoft Teams application being used
during COVID-19 lockdown. 49.45%, 42.85%, and
39.5% of students felt that ease of access, the flexibility
of schedule, and interactive bite-sized content are the
benefits of e-learning platforms. 84.61% of students were
in favor of the adoption of online learning tools into daily
classroom teaching (see Table 5).
4.4 Results from the three case studies
For all three institutions, the majority agreed with
adopting some e-learning practices with daily classroom
education. For TIET students, mode of preference
for e-leaning was pre-recorded lectures via YouTube
links. The students of NIT-H also gave preference to
pre-recorded lectures via YouTube links apart from
Google Classroom as a preferred choice of e-learning
tool. Majority of students of Manav Rachna International
School and NIT-H found ease of access as the best
advantage of e-learning platforms. From the surveys,
it can be seen that the students of all three educations
would like some features of e-learning tools to be
adopted in daily classroom education.
5 Conclusion
In this paper, initially, the impact of the COVID-19
lockdown is discussed on the environment. Thereafter,
the impact of COVID-19 lockdown is discussed on
the health of the students and researchers. Finally, elearning environment for three educational institutions
during COVID-19 lockdown is discussed. Zoom,
Google Classroom, and Microsoft Teams were not
being previously used by TIET, NIT-H, and Manav
Rachna International School, respectively. The student’s
preferences and choices were successfully identified and
noted in the three institutions by conducting surveys.
From the surveys, it can be seen that the students
of all three educations would like some features of
e-learning tools to be adopted in daily day to day
classroom teaching. For NIT-H and Manav Rachna
International School, it was successfully identified that
students enjoyed the ease of access of material via
e-learning tools. Such tools can be thought to be
incorporated in daily classroom teaching. For TIET,
students already have online portals where information
is updated regularly. Apart from TIET, students at NIT-H
and Manav Rachna International School were satisfied
with the e-learning platforms being used during the
COVID-19 lockdown. From the survey conducted at
Thapar Institution of Engineering and Technology, we
came to know that even if 60.4% of students were not
satisfied with the e-learning practices being used by
their institution during COVID-19 lockdown, 49.7%
of students were still willing to incorporate e-learning
practices in their daily classroom education. From
the three surveys conducted, it can be seen that the
majority of students are eager to adopt the e-learning
platform features in their regular classroom teaching.
Out of 274 students, 220, that is, 80.2% of students
felt that e-learning platforms’ features should be or may
be integrated with the daily classroom teaching. The
maximum number of students, that is, 73.59% of both
the universities preferred pre-recorded lectures being
provided via YouTube links as the preferred means of
e-learning practice during COVID-19. YouTube links
allow students to access the videos any time they like,
making the material easily accessible and providing the
flexibility of the schedule. Out of the students who
answered what they prefer feature of online education,
52.3% supported ease of access, and 48.5% supported
the flexibility of the schedule. Students preferred
Table 5 Students from three institutions respond to the adoption of e-learning practices in daily classroom education.
Item No. Item in detail Number of students
.n D 274/
Number of
males .n D 186/
Number of
females .n D 88/ Mode
Should the features
of online learning
be adopted into
daily classroom
teaching? (Single
choice correct).
1
Some features of online learning
should be or may be adopted in
daily classroom teaching.
220 149 71
Some features of
online learning
should be or may
be adopted in
daily classroom
teaching.
2
Some features of online learning
should not be adopted in daily
classroom teaching.
54 37 17
114 Big Data Mining and Analytics, June 2021, 4(2): 104–115
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application at Manav Rachna International School. At
the National Institute of Technology, Hamirpur, 100%
of students were satisfied with the Google Classroom
practices adopted by their institution. At Manav Rachna
International School, Mohali, 98.90% of students were
satisfied with the Microsoft Teams’ platform adopted
during the COVID-19 platform.
To access these platforms, a mobile device and an
internet connection are required. It is necessary for
the student to be proficient in the English language,
which is the standard or default language for many
e-learning platforms. There are 560 million internet
connections in India, making it the second-largest online
market in the world after China[12]. During the COVID19 lockdown in India, institutions have adopted many
e-learning practices. With the world moving towards
digitization, COVID-19 may act as a catalyst to make
education online. With students and teachers using
these services to educate themselves and masses, new
problems and solutions may be discovered, which may
help popularize online education in India. In the future
studies, from the three case studies, the choices and
preferences of the students should be implemented in
e-learning platforms and in-depth analysis of student
behavior and their choices regarding user interface and
flexibility should be underscored.



NEW_PAPER



A Proactive and Practical COVID-19
Testing Strategy
—KUAN SONG
Gago Ltd., Beijing 100870, China
—SHIQI JIAO
Gago Ltd., Beijing 100870, China
—QIANG ZHU
Gago Ltd., Beijing 100870, China
—HUITAO WU
Zhejiang Lab, Hangzhou 311122, China
(Corresponding author: Kuan Song.)
IEEE DOI 10.1109/EMR.2020.3017648
Abstract—To reopen the economy safely during the COVID-19 pandemic,
governments need the capability to proactively identify new and often
asymptomatic infections, as well as contact tracing. Policymakers and public
health professionals need a sampling-testing method that can achieve broad
population coverage without overwhelming medical workers. We observe that
COVID-19 high-risk groups are located in the hubs and cliques of our geosocial network, formed by the close encounters of people during daily life.
These individuals are the de facto “canary in a coal mine”. We propose that
nations offer free and anonymous testing service to them. With open-source
computer algorithms and datasets, only a small fraction of the population
selected for COVID-19 testing can cover the majority of high-exposure-risk
individuals. A 0.3% sampled testing for a megacity covers 3/4 of its entire
population. A 3% sampled testing for a rural town covers 3/4 of its entire
population. With government oversight and public consent, this approach can
serve each province/state or city/township for decentralized daily testing
planning. However, to protect privacy, we recommend constructing the geosocial network of anonymized cellphones, not named individuals. This
infrastructure should be dismantled once the pandemic is largely over. This
can be achieved by policymakers, health workers, and engineers together in
solidarity.
Key words: COVID-19, decisions under risk and uncertainty, geo-social
networks, network theory, sampling strategy
PROBLEM FORMULATION
THE COVID-19 pandemic puts
global governments in a dilemma.
Before social distancing and stay-athome orders, rapid chain infection
happened. Strict stay-at-home orders
save lives but risk economic
recession. Public opinions are
growing increasingly polarized and
led to armed protesting [1]. If the
economy collapses in any nation, the
ensuing mass unemployment and
social unrest can expose the most
fragile families to the pandemic.
Reopening the economy safely is,
thus, a necessary public health policy.
However, recklessly loosening
stay-at-home policies and reopening
the economy in hard-hit nations can
be risky. Asymptomatic COVID-19
patients can infect others in offices or
onboard public transportation.
Droplets and aerosols from people
talking can carry the virus [2]. If the
chain of community infection goes
undetected, it can grow like wildfire.
Hospitals will again be overwhelmed
and the pandemic can become
endemic. Thus, a prerequisite to
reopening the economy is the ability
to rapidly identify new cases among
the asymptomatic population [3]. That
enables contact tracing of community
infection, and subsequent containing
local outbreaks. There are other
prerequisites such as a declining
number of patients, universal
availability of PPEs, which are as
important but will not be discussed in
this study.
To that end, Mr. B. Gates prescribed a
drastically increase of nucleic testing
capability for COVID-19 [4].
IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020 63
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/Meanwhile, a Harvard panel report
proposed daily proactive testing of 5–
20 million people in the United States
alone or 2–6% of the total population
[5]. The study did not specify how
they come to that estimation nor how
good that estimation is. The
challenge to that testing capability lies
not only in the production and
distribution of test kits but more
crucially in the logistics of the actual
tests. There might not be enough
medical workers and lab technicians
in the US to conduct 20 million tests a
day. Peto et al. [3] advocate universal
weekly random testing of 13% of the
U.K. population to reach 90%
coverage. That translates to 2%
daily testing of the entire population.
This is a huge logistic challenge for
the U.K. as well. Similar random
sampling schemes are being
developed for India [6]. However,
none of these testing schemes
materialized since their conception.
This probably is because
governments deem them impractical.
This logistical challenge can be
readily solved, if only a selected
0.1–0.3% sample of the total
population is needed to tested
daily or weekly. As of now, megacities
in the United States, Europe, and
China already have that testing
capacity.
We propose the daily testing of only a
small subset of the asymptomatic
population, specifically targeting the
hubs and cliques in a geo-social
network of anonymous cellphones. If
any result comes back positive, then
the people around them need further
testing as contact tracing. The geosocial network of anonymous
cellphones in a given area during a
given time period consists of vertices
and links. The vertices are the
cellphones, carried by their owners
active in the economy. The links
among them indicate significant close
encounter, such as working in the
same office, living in the same house,
and sharing the same ride.
The following graph illustrates a
simple geo-social network of three
young working professionals. Mary,
Giuseppe, and Lee work in a small
consulting firm. Mary shares her
house with a partner and jogs with a
group of X (5 to 20) people to the
office daily. Giuseppe shares a house
with his parents and 2 siblings and
drives alone to the office daily. Lee
lives alone in his condo and takes a
40-min metro ride to the office daily
with Y (10 to 50) people in a train car.
In the geo-social network graph, we
use F to denote family members, and
C to denote commuters they meet
daily. For simplicity we assume that
other family members stay strictly at
home, the commuters interact with no
one else, and all the people in this
graph are asymptomatic.
Given such a geo-social network,
who should we administer COVID-19
tests to if we only have three test kits
available every day? What about two
test kits? Or even just a meager one
test kit per day? We might want to
reserve testing to the people who are
most exposed to the virus, and who
have the highest potential to infect
others. Very often the same people
meet both criteria. Naturally, we
would choose to first test Mary,
Giuseppe, and Lee because they
connect to more people than others.
Lee has the highest exposure risk
because of the packed subway ride
with dozens of commuters, and thus,
he should get the test if only one test
kit is available. In our opinion, each
municipality and/or CDC office should
have the tools to automatically
analyze such geo-social networks
and provide testing service to the
individuals with the highest exposure
risks.
There exists no full-scale study on
COVID-19 exposure on individuals.
Patients of old age or with preexisting medical conditions have the
highest death rate once infected, but
not necessarily the highest exposure
chances before getting ill. We
observed that two types of people
might be the most exposed to
COVID-19 due to their distinctive geosocial network niches. We could
focus our limited testing capabilities
on them.
Around the world, senior government
officials have been disproportionately
hit by COVID-19. The list includes
prime ministers of Britain and Russia,
the first Ladies of Spain and Canada,
the first family of Brazil, and countless
ministers around the world. Likely this
situation resulted from their busy daily
schedule to meet with a large number
of people, often internationally. In
other words, the “hubs” in our geosocial network are most exposed to
infection risks. In a sense, they are
the canary in a coal mine. Timely
testing for them could buy time for
their local communities.
People spending long hours in
close quarters have seen horrendous
local outbreaks of COVID-19.
Well-known cases include the
Diamond Princess, USS Theodore
Roosevelt, USS Kidd, and many
hospital wards, retirement homes,
factories [7], and prisons [8] around
the world. In a geo-social network,
these communities are known as
clique’s because each member is
within close vicinity of all other
members and, therefore, geo-socially
interconnected. Such cliques are
often exposed to airborne droplets
carrying the virus, which leads to
unusually high percentages of local
infection.
Thus, our goal is to identify, in each
geo-social network of a workforce
embracing economic reopening, the
hub’s and clique’s people for daily
COVID-19 testing even though they
are asymptomatic. If any hub’s or
clique’s individual turns up positive
for COVID-19, the geo-social network
of his/her immediate daily interaction
circle needs to be tested, and the
patients quarantined. We argue that
this is an efficient sampling strategy
64 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020for COVID-19 testing in a reopened
economy.
Each city has its own logistical
constraints on testing. Some cities
can afford to test daily 1% of its
workforce, others may afford to test
0.1%, which testing percentage is
sufficient? How to measure
sufficiency? How can each city
perform its own rapid assessment on
a daily basis?
METHODOLOGY AND
EXPERIMENT
To address the abovementioned
questions, we conducted a pilot study
using existing social network tools on
two real-world social network
datasets. The simplest approach is to
single out individuals with the most
links in the geo-social network for
testing. But the problem with that
approach is that those individuals are
often in the same local community
and, thus, have highly overlapped
geo-social networks [9]. For example,
doctors and nurses working in the
same ER room, or the congress
members of the same nation. If we
concentrate our testing resources on
them, we will miss out on the big
picture in the population and have a
social inequality issue.
Thus, we aim to find the individuals
with the most links in the geo-social
network, while the individuals directly
linked to them cover the maximum
percentage of the population. This
can be achieved by dividing the geosocial network of mega-cities like
Wuhan or NYC into small
communities or cliques. We can then
identify the hub’s in each community.
Unfortunately, in mathematics and
computer science, this problem is
NP-hard. To find the exact optimal
solution takes exponentially
computation time as the size of the
population grows. There exist
heuristic solutions that can produce
imperfect yet useable solutions with a
limited time budget. These solutions
were developed over the past two
decades not just to analyze social
networks and internet traffic [9].
These algorithms are also the
workhorses behind Internet search
engines such as Google [10] and
Microsoft Bing [11].
The heuristic algorithms examined
here are developed in academia and
open-source. We also share crude
yet simple Python snippets [12], [13]
to make use of these models with
real-world datasets. We hope that the
public health sector can integrate
these methods without hiccups. In our
pilot study, both algorithms can
analyze geo-social networks with
millions of vertices (people) in several
minutes on a Linux workstation. This
indicates the feasibility of
decentralized day-to-day operations
in each municipality without additional
charges.
The Louvain algorithm was created
by Blondel et al. [14] from the
University of Louvain, Belgium. It is a
bottom-up clustering algorithm to find
communities large or small, often very
different in size. The METIS algorithm
[15],[16] was created by G. Karypis
and V. Kumar from the University of
Minnesota, USA. It enables parallelprocessing to partition social
networks into communities of similar
Figure 2. Selecting the hubs from a sample geo-social network. sizes.
Figure 1. Sample geo-social network of a small consulting company.
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 65The first dataset we tested on is a
Googleþ social network dataset [17],
including 107 614 people, and 13 673
453 links among them. On average
each person is connected to 127
others. This number is comparable to
the number of people a working
professional meets daily in a busy
metropolis using public
transportation. It is a densely
connected network.
The second dataset we tested on is
an Internet server topology dataset
[18] originally assembled to study the
transmission of computer viruses. It
has 1 696 415 vertices (machines)
and 11 095 298 links among them. On
average each machine is connected
to 6.5 others. This number is
comparable to the number of people
a working professional meets daily in
a small town without using public
transportation. It is a sparsely
connected network.
To be clear, we do not assume that
COVID-19 transmits along with cybersocial networks. We consider the two
datasets previously because they
have network structures similar to
geo-social networks of the workforce,
which has close-range physical
interactions daily in a reopened
economy.
Our study is designed in the following
four steps. First, we partition the
network datasets into U clusters
using the METIS algorithm and the
Louvain algorithm. Then in each
cluster, we single out K individuals
who have the most connections
within the cluster. In total, we have
U
K individuals chosen for COVID-19
testing. As a simpler baseline choice,
we single out the top U
K individuals
with the most connection links in the
complete geo-social network. We
adopted the value of parameter U as
the total number of individuals S
divided by 100 or 1000. In this way,
the total amount of individuals chosen
[U
K] will be a percentage of the total
population. The evaluation metric is
the coverage of the tested individuals,
defined as the number of individuals
immediately linked to the tested
individuals divided by the total
number of individuals. The four steps
are illustrated in Figure 2 using the
sample described in Figure 1.
FINDINGS
The following two tables list the
coverage rates from three different
algorithms on two real-world
datasets. They can tell us to an extent
how well the geo-social network
sampling and testing cover the
population in a reopened economy.
The “Coverage” percentages are
calculated as the percentage of
people who had close contacts with
the COVID-19 test subjects, out of the
general population.
On both datasets and all sampling
percentages, the METIS algorithm
steadily outperforms other algorithms
in terms of coverage rate. This does
not indicate that the Louvain
algorithm is inferior. It was designed
to identify natural-looking
subcommunities large and small. Its
most suitable use would be to
visualize and trace local community
transmission.
On the densely connected Googleþ
dataset, we are indeed running a
simulation of busy urban life such as
that in NYC, or Wuhan. Results listed
in Table 1 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
Table 2. Coverage Percentage out of Geo-Social Network Sampling
Test on Skitter Dataset.
Table 1. Coverage Percentage out of Geo-Social Network Sampling
Test on Googleþ Dataset.
66 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020an immediate-connection coverage of
74.1% of the population. By sampling
2% of the population, we can
effectively represent an immediateconnection coverage of 92.3% of the
population. Beyond 2% sampling,
extra sampling and testing work offer
marginal benefit.
On the sparsely connected Skitter
dataset, we are indeed running a
simulation of quiet small-town life
such as that in Ithaca upstate NY, or
Suifenhe China. Results listed in
Table 2 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
an immediate-connection coverage of
51.4% of the population. By sampling
3% of the population, we can
effectively represent an immediateconnection coverage of 77.7% of the
population. Beyond 3% sampling,
extra sampling and testing work offer
marginal benefit.
DISCUSSIONS
In summary, our study shows that a
highly efficient sampling, testing, and
tracing scheme can be achieved by
constructing the geo-social network of
a city or township, safeguarding the
economy reopening. The busier the
city is, the smaller percentage we
need to test for COVID-19. We
estimate that 0.3% to 3% can monitor
COVID-19 transmission covering the
majority of the population. This is not
to say that our sampling can keep
COVID-19 from happening, but rather
a realistic managed low-occurrence
live-with-COVID approach. Also
arguably this is also not as important
as the universal wearing of masks as
PPE.
This pilot study assumes that a geosocial network dataset for each city/
township can be constructed every
day. Indeed it can, only if with public
consensus and government
oversight. Our cellphones currently
produce multiple location-tracking
data streams, including
telecommunication tracking,
operating system tracking, and map
API-based tracking. In each nation,
the cellphone service providers
acquire coarse-resolution tracking
data streams via the triangulation of
3G/4G base stations. Operating
system tracking data stream exists in
each Android phone and IPhone as
an essential service by integrating
GPS and WiFi signals. In addition,
most of the cellphone apps on the
market call various precision map/
location service APIs from Google
Map, Amap, Bing Maps, Baidu maps,
HERE maps, or Tencent maps for
location upon App use. That tracking
computes the 3G/4G signal along
with GPS and WiFi. The current data
records link location to each unique
cellphone, but not to individual
persons. These data records are
highly confidential and literally
guarded by laws like the European
GDPR against wanton usage.
Societies already embraced some of
their usages in real time, such as
Google traffic alert [33]. Hence, a
geo-social network of anonymous
cellphones can be quickly computed
out of existing data streams, with the
right permission clearance. This
study does not advocate collecting
cellphone location data with personal
IDs.
Geo-social network could be
constructed through another
process, arguably less intrusive.
Google and Apple are developing a
Bluetooth contact-alert service [19].
It can tell the user whether his/her
phone was within Bluetooth
distance of a COVID-19 patient’s
phone recently. However, this
feature is only valid if everyone
turns Bluetooth on and, thus, may
not eventually work out. By now,
this effort has largely died OFF.
With location data sitting idle with the
telecommunication service providers
and tech giants, the general public,
and national governments may want
to discuss and decide whether or not
to make use of it during the pandemic
[20], [21]. People have valid reasons
to worry about privacy,[22] but these
are not normal times [23]. Safe and
moral usages of this data flow require
mandatory erasure of any and all
personal details from the dataset and
render it anonymous except to
oneself. For example, only the citizen
him/herself can know that he/she is a
hub of the geo-social network. If he/
she wants to show up for work without
endangering coworkers, he/she
needs to have a free COVID-19 test.
When a patient’s test comes back
positive, then the people who had a
recent interaction with him/her have
the right to be notified via their
phones. Automatic contact tracing
can be done with technology instead
of spreading thin our medical
workforce in the field. When the
pandemic is about to be fully
eliminated, this “war-time”
infrastructure should be dismantled
so as not to be abused in peacetime.
We find it is logistically feasible for
local facilities to operate a daily
routine. First, every night, the local
locational data flows from either
telecommunication providers or tech
giants are used to construct the geosocial network of the previous day.
Residents who are the identified
0.3%–3% hubs in that network wake
up the next morning with a text
message notification for a quick test
before showing up for work. Testing
capacities vary from region to region.
Some developed nations might afford
to test them every day. Developing
nations might afford to test once a
week. Either way helps.
To further alleviate the pressure on
logistics, nations can consider a
recent practice [30] in Wuhan,
China during May 13–22, 2020.
Nasal swabs from multiple persons
from the same neighborhood are
mixed into one testing. This is
known as pooled testing. It reduces
logistics pressure of testing to 1/5
or even 1/10, compared to
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 67conducting 1 test for each
individual. In the United States, the
importance of pooled testing is just
gaining recognition [31], but not yet
implemented en masse.
Pooled testing and geo-social
network sampling can boost each
other in many ways. First, each batch
in pooled testing can consist of
individuals from the same “clique” of
the geo-social network because they
share similar risks of infection.
Second, when testing resources are
very scarce, pooled testing of
selected “hubs” in the geo-social
network can be highly efficient. Third,
tracing of infection chains can be
achieved with geo-social networks
after pooled testing.
Another possibility to improve this
approach is to integrate the infection
rate of population groups into the geosocial network. A vanilla geo-social
network can measure the chance of
exposure to infection. When
multiplied by the infection rate of age
groups, it can measure the chance of
infection.
Around the world, pilot experiments
on locational tracking to fight the
pandemic are sprouting, for example
in Israel [24], South Korea [21], and
China [25]. In China, Alibaba and
Tencent scrambled to work with
government oversight creating
location-based health-checkup Apps
starting in late January 2020. The
initial version went online on February
11 after 2 weeks of intensive
development [26]. It can only trace
location down to city blocks and tell
the user whether they have been to
COVID-19 hot zones in the past 14
days. The majority of the Chinese
public chose to adopt this
infrastructure. Along with other
measures such as universal maskwearing and quarantines, it
contributed significantly to the
Chinese effort of containing and
almost total elimination of COVID-19.
This effort released openly its
technical whitepapers [25] on May 1,
2020. However, at the time being
there is yet no reported effort to use
that infrastructure for proactive
nucleic or antibody testing for the
general public.
On April 27, Science Magazine
recently called for the utilization of
mobile phone data for modeling and
contact tracing [27]. Gradually,
policymakers, scientists, and
engineers globally are coming to
realize that data from mobile phones
can help them combat COVID-19. It is
important that peoples are aware of
this option, can debate about it, and
make a decision for their own nation.
We do not yet know how long this
pandemic lasts and how bad it can
go. Therefore, all options should stay
on the table. For epicenters of the
pandemic, government might want to
integrate all possible measures
together to turn the tide against the
pandemic.
This pilot study is a baby step to
introduce to the field of public health
the importance of social network
analyses. We have already seen the
use of traditional S-I-R modeling for
infectious diseases since the onset of
the pandemic. The S-I-R models
assume equal infection risk for all
individuals and, thus, is insufficient
alone. Social network analyses
provide insights into exposure risks of
each individual and, thus, can be
integrated into S-I-R models for
S-E-I-R modeling. We assume that
everyone has equal immunity in our
model because of limited data. If
possible to collect more detailed
information about individuals, we
hope to improve our model
considering the covariates affecting
personal immunity. To battle the
pandemic and potentially endemic
COVID-19 as a planetary challenge,
interdisciplinary teamwork among
epidemiologists, computer scientists
and data scientists, and lawmakers is
needed. We hope to see our model
revised and applied in policies and
day-to-day operations [28]. Modeling
can only tell us so much. Politics does
the rest [29]. The bottom line against
dystopian use of location data is to
construct a geo-social network of
anonymous cellphones, not of people
without privacy. Make this a service
instead of surveillance. And this
service should only be temporary
during the pandemic. Our planet after
the pandemic does not need
Geoslavery [22].
CONTRIBUTORS
Conceptualization: KS/HW;
Programming and Analysis: ZQ/SJ/
KS; Writing: KS/HW.
ACKNOWLEDGMENT
The authors would like to thank L. Yu,
C. Deng, C. Pei, W. Jiang, L. Xu, and
K. Dong for many rounds of fruitful
discussions. The open access fee for
this article was provided by Gago
Inc,. Beijing, China.



NEW_PAPER

Received May 13, 2020, accepted June 17, 2020, date of publication June 19, 2020, date of current version July 1, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3003810
Iteratively Pruned Deep Learning Ensembles
for COVID-19 Detection in Chest X-Rays
SIVARAMAKRISHNAN RAJARAMAN 1
, (Member, IEEE), JENIFER SIEGELMAN2
,
PHILIP O. ALDERSON3
, LUCAS S. FOLIO4,5, LES R. FOLIO6
,
AND SAMEER K. ANTANI 1
, (Senior Member, IEEE)
1Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD 20894, USA
2Takeda Pharmaceuticals, Cambridge, MA 02139, USA
3School of Medicine, Saint Louis University, St. Louis, MO 63104, USA
4Functional and Applied Biomechanics Section, Clinical Center, National Institutes of Health, Bethesda, MD 20892, USA
5Walt Whitman High School, Bethesda, MD 20817, USA
6Radiological and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, MD 20894, USA
Corresponding author: Sivaramakrishnan Rajaraman (sivaramakrishnan.rajaraman@nih.gov)
This work was supported by the Intramural Research Program of the National Library of Medicine (NLM), and the U.S. National Institutes
of Health (NIH).
ABSTRACT We demonstrate use of iteratively pruned deep learning model ensembles for detecting
pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus
(2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are
trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific
feature representations. The learned knowledge is transferred and fine-tuned to improve performance
and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or
COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and
improve memory efficiency. The predictions of the best-performing pruned models are combined through
different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that
the weighted average of the best-performing pruned models significantly improves performance resulting in
an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The
combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning
resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening
using chest radiographs.
INDEX TERMS COVID-19, convolutional neural network, deep learning, ensemble, iterative pruning.
I. INTRODUCTION
Novel Coronavirus disease 2019 (COVID-19) is caused
by the new Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2) that originated in Wuhan in
the Hubei province in China and has spread worldwide.
The World Health Organization (WHO) declared the outbreak a pandemic on March 11, 2020 [1]. The disease is
rapidly affecting worldwide population with statistics quickly
falling out of date. As of April 12, 2020, there are over
1.8 million confirmed cases reported globally with over
100,000 reported deaths. Lung disease that causes difficulty
in breathing has been reported as an early indicator along
with hyperthermia in the COVID-19 infected population [1].
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque .
The lung abnormalities caused by non-2019-nCOV viruses
are observed as peripheral or hilar and visually similar to,
yet often distinct from, viral pneumonia and other bacterial
pathogens [2].
Reverse transcription-polymerase chain reaction
(RT-PCR) tests are performed to detect the presence of
the virus and are considered the gold standard to diagnose
COVID-19 infection. However, they are reported to have
variable sensitivity and in some geographic regions may not
be widely available [3]. While not currently recommended
as primary diagnostic tools, chest X-rays (CXRs) and computed tomography (CT) scans have been used to screen for
COVID-19 infection and evaluate disease progression in
hospital admitted cases [3], [4]. While chest CT offers greater
sensitivity to pulmonary disease, there are several challenges
to its use. These include the non-portability, the requirement
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 115041S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 1. Graphical abstract of the proposed study.
to sanitize the room and equipment between patients followed
by a delay of at least an hour [4], the risk of exposing
the hospital staff and other patients, and persons under
investigation (PUIs) to the virus. Although not as sensitive,
portable CXRs are considered as an acceptable alternative
[4] since the PUIs can be imaged in more isolated rooms,
limiting personnel exposure and because sanitation is much
less complex to obtain than with CT.
Automated computer-aided diagnostic (CADx) tools
driven by automated artificial intelligence (AI) methods
designed to detect and differentiate COVID-19 related thoracic abnormalities should be highly valuable given the heavy
burden of infected patients. This is especially important in
locations with insufficient CT availability or radiological
expertise and CXRs produce fast, high throughput triage such
as in a mass casualty [5]. Automated approaches, once validated, have been shown to reduce inter- and intra-observer
variability in radiological assessments [6]. Additionally,
CADx tools have gained immense significance in clinical
medicine by supplementing medical decision making and
improving screening and diagnostic accuracy [7]. These tools
combine elements of radiological image processing with
computer vision for identifying typical disease manifestations and localizing suspicious regions of interest (ROI).
At present, recent advances in machine learning, particularly
data-driven deep learning (DL) methods using convolutional
neural networks (CNNs), have shown promising performance
in identifying, classifying, and quantifying disease patterns
in medical images. This is particularly true for CT scans
and CXRs [7]. These models learn the hierarchical feature
representations from medical images to analyze for typical
disease manifestations and localize suspicious densities for
ROI evaluation [7].
In this study, we highlight the benefits offered through the
use of an ensemble of iteratively pruned DL models toward
distinguishing CXRs showing COVID-19 pneumonia-related
opacities, from bacterial pneumonia, and normals using publicly available CXR collections. Fig. 1 shows the graphical abstract of the proposed study. Fig. 2 shows instances
of CXRs being normal, showing bacterial pneumonia, and
COVID-19-related pneumonia.
A custom CNN and a selection of pretrained CNN models are trained on a large-scale selection of CXRs to learn
CXR modality-specific feature representations. The learned
knowledge then is transferred and fine-tuned to classify the
normal and abnormal CXRs. We leverage the benefits of
modality-specific knowledge transfer, iterative pruning, and
FIGURE 2. CXRs showing (A) clear lungs, (B) bacterial pneumonia
manifesting as consolidations in the right upper lobe and retro-cardiac
left lower lobe, and (C) COVID-19 pneumonia infection manifesting as
peripheral opacities in the left lung.
ensemble strategies to reduce model complexity, improve
robustness, generalization, and inference capability of the DL
model.
The remainder of the manuscript is organized as follows:
Section II discusses prior works. Section III discusses
the datasets and methods used toward modality-specific
knowledge transfer, iterative pruning, and ensemble learning. Section IV elaborates on the results obtained, and
Section V concludes the study with a discussion on the merits
and limitations of the proposed approach and future work
directions.
II. PRIOR WORK
A. COVID-19 DETECTION
A study of the literature reveals several AI efforts for
COVID-19 screening. The authors of [3] distinguished
COVID-19 viral pneumonia manifestations from that of other
viral pneumonia on chest CT scans with high specificity.
It was observed that COVID-19 pneumonia was found to be
peripherally distributed with ground glass opacities (GGO)
and vascular thickening. The authors of [8] established
a publicly available collection of 275 CT scans showing
COVID-19 pneumonia manifestations and trained a deep
CNN to achieve 0.85 F-score in classifying CTs as normal or showing COVID-19 pneumonia-related opacities.
The authors of [9] used a customized CNN and pretrained
AlexNet model to classify CXRs as normal or showing
COVID-19 pneumonia with 94.1% and 98% accuracy respectively. The authors of [10] used a ResNet-50 [11] CNN to
classify normal, pneumonia, and COVID-19 viral pneumonia manifestations in CXRs and achieved an accuracy of
98.18 % and F-score of 98.19. CXRs are also commonly
analyzed to diagnose and differentiate other types of pneumonia including bacterial and non-COVID-19 viral pneumonia
[2]. The authors of [12] proposed a custom CNN model
that was designed by combining manual design prototyping with a machine-driven designing approach to classify
CXRs as normal or showing non-COVID-19 or COVID-19
pneumonia-related opacities with 92.4% accuracy.
B. MODALITY-SPECIFIC KNOWLEDGE TRANSFER
With limited amounts of COVID-19 pneumonia CXR data,
traditional transfer learning strategies offer promise [13]
where the learned feature representations are fine-tuned to
115042 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
improve performance. However, unique challenges posed
in the appearance of medical images [6] including high
inter-class similarity and low intra-class variance lead to
model bias and overfitting resulting in reduced performance and generalization. These issues can be alleviated
through modality-specific knowledge transfer by retraining
CNN models on a large CXR image collection to learn
modality-specific feature representations. Modality-specific
model knowledge transfer [14] and ensembles [15] have
demonstrated superior disease ROI localization compared to
individual constituent models.
C. MODEL PRUNING
To alleviate burdens from computing resources, DL models
can be pruned to reduce the inference cost and facilitate
deployment in low-resource conditions with no loss or even
improvement in performance. Reed [16] performed a neural model pruning to decrease computational complexity.
Hassibi et al. [17] deleted network parameters by leveraging
the second derivative term in the Taylor series and improved
model generalization. The authors of [18] found that the
earlier layers in the neural networks have low activations
that can effectively be excluded from the network without
affecting the model performance. They proposed an iterative
optimization method to gradually eliminate the neurons with
the least activations toward reducing the memory and power
requirements and promoting faster model inference. When
applied to medical imaging, the authors of [19] proposed a
genetic algorithm-based pathway evolution strategy to prune
DL models. This resulted in a 34% reduction in the network
parameters and improved the mass classification performance
in breast mammograms. A systematic weight pruning strategy [20] was used to prune a YOLO-model [21] based pneumonia detector for classifying CXRs as normal or showing
pneumonia-like manifestations using the Radiological Society of North America (RSNA) [22] CXR collection. However,
there is room for further research in this area.
D. ENSEMBLE CLASSIFICATION
CNNs are non-linear models that learn complex relationships
from the data through error backpropagation and stochastic
optimization, making them highly sensitive to random weight
initializations and the statistical noise present in the training
data. These issues can be alleviated by ensemble learning
by training multiple models and combining their predictions
where an individual model’s weaknesses are offset by the
predictions of other models. Combined predictions are shown
to be superior to individual models [23]. There are several
ensemble strategies reported in the literature including max
voting, simple and weighted averaging, stacking, boosting,
blending, and others that are shown to minimize the variance
error and improve generalization and performance of CNN
models. Applied to CXRs, the authors of [7], [14], and [24]
leveraged the use of an ensemble of CNN models toward
improving TB detection in CXRs. An averaging ensemble
of pretrained CNNs was used by the authors of [25] toward
improving cardiomegaly detection using CXRs.
TABLE 1. Dataset characteristics. Numerator and denominator denotes
the number of train and test data respectively (N = Normal,
UP = Pneumonia of unknown type, BP = Bacterial (proven)
pneumonia, CP = COVID-19 pneumonia).
III. MATERIALS AND METHODS
A. DATA COLLECTION AND PREPROCESSING
Table 1 shows the distribution of CXRs across different
categories. We used the following four publicly available
CXR collections in this retrospective analysis:
1) PEDIATRIC CXR DATASET [2]
The authors collected from Guangzhou Women and
Children’s Medical Center in Guangzhou, China, the anteriorposterior (AP) CXRs of children from 1 to 5 years of
age, showing normal lungs, bacterial pneumonia, and
non-COVID-19 viral pneumonia. Expert radiologists curated
the CXR collection to remove low-quality chest radiographs.
2) RSNA CXR DATASET [22]
This multi-expert curated dataset includes images from the
National Institutes of Health (NIH) CXR-14 dataset [26].
The dataset was released for the Kaggle pneumonia detection challenge, organized jointly by RSNA and NIH. The
collection includes normal CXRs and abnormal images with
non-pneumonia and pneumonia-like opacities. The images
are made available at 1024×1024 pixel resolution in DICOM
format.
3) TWITTER COVID-19 CXR DATASET
A cardiothoracic radiologist from Spain made available a
collection of 134 CXRs with 2K×2K pixel resolution in
JFIF format via Twitter of SARS-CoV-2 positive subjects.
(https://twitter.com/ChestImaging)
4) MONTREAL COVID-19 CXR DATASET [27]
A publicly available periodically updated GitHub repository
that includes COVID-19 CXR cases and other pulmonary
viral disease manifestations in AP, posterior-anterior (PA),
and AP-Supine views. As of April 7, 2020, the repository had
179 CXRs showing COVID-19 pneumonia-related opacities.
We performed patient-level splits of these CXR collections
to allocate 90% for training and 10% for testing at different stages of learning discussed in this study. We randomly allocated 10% of the training data to validate the DL
models. The ground truth (GT) for the test set, comprising
of 27 CXRs showing COVID-19 pneumonia-related opacities
is set by the verification of publicly identified cases from
expert radiologists who annotated the test set.
B. LUNG ROI SEGMENTATION
While mild COVID-19 cases mimic common upper
respiratory viral infections, advanced disease results in
VOLUME 8, 2020 115043S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 3. The segmentation approach showing U-Net based mask
generation and Lung ROI cropping.
FIGURE 4. Architecture of the customized CNN model. (I/P = Input,
CONV = Convolution, GAP = Global average pooling, DO = Dropout,
D = Dense with Softmax activation, N = Normal predictions,
A = Abnormal Predictions).
respiratory dysfunction and is the principal cause for
triggering mortality. In developing DL solutions for detecting
the disease, it is important to guard them against irrelevant
features that could severely affect reliable decision-making.
For this study, we performed U-Net based semantic segmentation [28] to segment the lung pixels from the background.
We used a U-Net with Gaussian dropout layers [29] added to
the U-Net encoder. A dropout ratio of 0.2 was empirically
determined and used in this study. Fig. 3 illustrates the
segmentation steps performed in this study.
We used a collection of CXRs with lung masks from
[30] to train the U-Net model to generate lung masks of
256 × 256 pixel resolution for the aforementioned datasets.
We used model checkpoints to monitor its performance and
stored only the best model weights to generate the final lung
masks. These masks then are superimposed on the CXR
images to crop them as a bounding box containing the lung
pixels. The cropped lungs are resized to 256×256 pixel resolution. The lung crops are further preprocessed by performing
pixel rescaling, median filtering for noise removal and edge
preservation, normalization for mean, and standardization for
identical feature distribution. The preprocessed lung crops are
used for model training and evaluation at different stages of
learning discussed in this study.
C. MODELS AND COMPUTATIONAL RESOURCES
We evaluated the performance of a customized CNN and
a selection of ImageNet pretrained CNN models, viz.,
a) VGG-16 [31], b) VGG-19 [31], c) Inception-V3 [32], d)
Xception [33], e) InceptionResNet-V2 [32]; f) MobileNet-V2
[34], g) DenseNet-201 [35], and h) NasNet-mobile [36].
Our customized CNN is a linear stack of strided separable
convolution layers, global average pooling (GAP), and a
dense layer with Softmax activation. Fig. 4 shows the architecture of the custom CNN used in this study. We used
Dropout to reduce issues due to model overfitting by providing restricted regularization and improving generalization
by reducing the model sensitivity to the specifics of the
training input [29]. We used strided convolutions that were
shown to improve performance on several visual recognition
benchmarks, compared to max-pooling layers [37]. Separable
convolutions were used to reduce model parameters [33] and
FIGURE 5. Architecture of the pretrained CNNs. (I/P = Input,
PCNN = truncated model, ZP = Zero-padding, CONV = Convolution,
GAP = Global Average Pooling, DO = Dropout, D= Dense with Softmax
activation, O/P = Output).
improve performance compared to conventional convolution
operations. The number of separable convolutional filters are
initialized to 32 and increased by a factor of two in the
successive convolutional layers. We used 5 × 5 filters and
a stride length of 2 in all convolutional layers. We added a
GAP layer to average the spatial feature dimensions that are
fed into the final dense layer with Softmax activation.
We used the Talos optimization package [38] to optimize
the parameters and hyperparameters of the customized CNN
that include a) dropout ratio, b) optimizer and c) non-linear
activation function. The model is trained and evaluated
with the optimal parameters to classify the CXRs to their
respective categories.
We instantiated the pretrained CNN with their ImageNet
weights and truncated them at the fully-connected layers.
The following layers are added to the truncated model:
(a) zero-padding, (b) a strided separable convolutional layer
with 5 × 5 filters and 1024 feature maps, (c) GAP layer,
(d) Dropout layer with an empirically determined dropout
ratio of 0.5, and (e) final dense layer with Softmax activation.
Fig. 5 shows the customized architecture of the pretrained
models used in this study.
We optimized the following hyperparameters of the
pretrained CNNs using a randomized grid search method
[39]: (a) momentum, (b) L2-regularization, and (c) initial
learning rate of the Stochastic Gradient Descent (SGD) optimizer. The search ranges were initialized to [0.85 0.99],
[1e−10 1e−3], and [1e−9 1e−2] and for the momentum,
L2-regularization, and the initial learning rate respectively.
The pretrained CNNs were retrained with smaller weight
updates to improve generalization and categorize the CXRs
to their respective classes. Class weights were used during
model training to penalize the overrepresented classes to
prevent overfitting and improve performance [40]. We used
model checkpoints to store the best model weights for further
analysis.
D. MODALITY-SPECIFIC TRANSFER LEARNING
AND FINE-TUNING
We performed modality-specific transfer learning where
the customized CNN and ImageNet pretrained models are
retrained on the RSNA CXR collection to learn CXR
modality-specific features and classify the CXRs into
normal and abnormal categories. The RSNA CXR collection includes normal CXRs and abnormal images containing pneumonia-related opacities. In this way, the weight
layers are made specific to the CXR modality through
learning the features of normal and abnormal lungs. The
learned knowledge is transferred and fine-tuned to a related
task of classifying CXRs that are pooled from pediatric,
115044 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
Twitter COVID-19, and Montreal COVID-19 CXR collections, respectively, as normal, or showing bacterial pneumonia, or COVID-19 pneumonia-related opacities, to improve
classification performance.
The top-3 performing modality-specific CNNs are
instantiated and truncated at their deepest convolutional
layer and added with the following layers: (a) zero-padding,
(b) a strided separable convolutional layer with 5 × 5 filters and 1024 feature maps, (c) GAP layer, (d) Dropout
layer and (e) final dense layer with Softmax activation. The
modified models are fine-tuned to classify CXRs as being
normal or showing bacterial pneumonia or COVID-19 viral
pneumonia. Class weights were used during model training to
award higher weights to the under-represented class to reduce
issues due to class imbalance and improve generalization
and performance. Fine-tuning is performed through SGD
optimization and model checkpoints were used to store the
best weights for further analysis.
E. ITERATIVE MODEL PRUNING
We iteratively pruned the fine-tuned models to find the
optimal number of neurons in the convolutional layers to
reduce model complexity with no loss in performance.
We gradually eliminated the neurons with fewer activations
at each time step through iterative pruning and model retraining. We used the average percentage of zeros (APoZ) [18],
the percentage of zero neuron activations observed with the
validation dataset, as the measure to rank the neurons in each
convolutional layer. We iteratively pruned a percentage of
neurons with the highest APoZ from each layer at each time
step and retrained the pruned model. The process is repeated
until the maximum percentage of pruning is achieved. The
best-pruned model is then selected from the collection of
iteratively pruned models based on their performance with
the test set. The retrained pruned model is expected to achieve
similar or better performance than the unpruned models with
reduced model complexity and computational requirements.
The algorithm for iterative pruning performed in this study is
described below:
F. LEARNING ITERATIVELY PRUNED ENSEMBLES
The best performing pruned models are selected to construct
the ensemble to improve prediction performance and generalization as compared to any individual constituent model.
We used several ensemble strategies including max voting,
averaging, weighted averaging, and stacking to combine the
predictions of the pruned models toward classifying CXRs as
normal or showing bacterial or COVID-19 viral pneumoniarelated opacities. For the stacking ensemble, we used a neural
network-based meta-learner that learns to optimally combine the predictions of the individual pruned models. The
meta-learner consisting of a single hidden layer with nine
neurons is trained to interpret the multi-class input from
the top-3 pruned models and a final dense layer outputs
the predictions to categorize the CXRs to their respective
classes.
Algorithm 1 Iterative Pruning
Input: B = {(xi, yi)|xi ∈ X, yi ∈ Y }, pruning percentage
(P), maximum pruning percentage (M)
1. Train and evaluate the base models on B and store the
best model weights
2. while percent pruned (PP) <= M do
a. Calculate the number of filters in each convolutional layer
b. Identify and delete P percentage of filters in each
convolutional layer with the highest average percentage of zeros
c. Retrain and evaluate the pruned model on B and
store the best-pruned weights
d. PP + = P
e. Incrementally prune the network, retraining it each
time and save the pruned model
end while
Return: M + 1 number of pruned models
G. VISUALIZATION STUDIES
Visualizing the learned behavior of the DL models is a
debated topic, particularly in medical visual recognition
tasks. There are several visualization strategies reported in
the literature that include (a) visualizing the overall network structure and (b) gradient-based visualization that
performs gradient manipulation during network training.
Gradient-weighted class activation mapping (Grad-CAM)
is a gradient-based visualization method that computes the
scores for a given image category concerning the feature maps of the deepest convolutional layer in a trained
model [41]. The gradients that are flowing backward are
pooled globally to measure the importance of the weights
in the decision-making process. In this study, we verified
the learned behavior of the pruned models by comparing
salient ROI with consensus GT annotations from experienced
radiologists.
H. STATISTICAL ANALYSES
We analyzed the model’s performance for statistical
significance at different stages of learning. We used confidence intervals (CI) as the measure to analyze the skill
of the CNN models. A shorter CI infers a smaller margin
of error or a relatively precise estimate while a larger CI
allows more margin for error and therefore results in reduced
precision [42]. We computed the 95% CI values for the
AUC at different learning stages to explain the models’
predictive performance. The CI values are computed to be
the Clopper–Pearson exact interval that corresponds to the
separate 2-sided interval with individual coverage probabilities of (0.95)1/2
. We used StatsModels version 0.11.0 to
compute CI measures. The codes associated with this study
are made available at https://github.com/sivaramakrishnanrajaraman/Iteratively-pruned-model-ensembles-for-COVID19-detection-in-CXRs.
VOLUME 8, 2020 115045S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 2. Optimal values for the parameters and hyperparameters for the
custom and pretrained models obtained through optimization tools
(M = Momentum, ILR = Initial learning rate, L2 = L2-weight decay,
and D = Dropout ratio).
TABLE 3. Performance metrics achieved during modality-specific transfer
learning using the RSNA CXR dataset (Acc. = Accuracy; Sens. = Sensitivity,
Prec. = Precision, F = F-score, MCC = Matthews correlation coefficient,
and Param. = trainable parameters). The values in square brackets show
the 95% CI that are computed to be the Clopper–Pearson exact interval
corresponding to the separate 2-sided interval with individual coverage
probabilities of (0.95)1/2.
IV. RESULTS AND DISCUSSION
The optimal values for the parameters and hyperparameters
obtained for the customized and pretrained CNNs with
the Talos optimization tool and randomized grid search,
respectively, are shown in Table 2.
Table 3 shows the performance achieved through
modality-specific knowledge transfer, by the customized and
pretrained CNNs using the RSNA CXR dataset.
It can be observed that the VGG-16, VGG-19, and
Inception-V3 models were more accurate than the other models under study. The aforementioned models demonstrated
promising AUC values with a shorter CI and hence a smaller
margin of error, thereby offering precise estimates compared
to the other models. This is because the architecture depths
of the VGG and Inception-V3 models are optimal to learn
the hierarchical representations of features from the CXR
data and classify them into normal and pneumonia classes.
Considering the F-score and MCC that give a balanced
measure of precision and recall, the aforementioned models
delivered performance that was superior to the other models.
TABLE 4. Performance metrics achieved by the top-3 modality-specific
knowledge transfer models on the target tasks.
The top-3 performing modality-specific knowledge
transfer models (VGG-16, VGG-19, and Inception-V3) are
instantiated with their modality-specific weights and truncated at their fully connected layers and appended with the
task-specific heads. Table 4 shows the performance achieved
by the task-specific models toward the following classification tasks: (a) binary classification to classify CXRs as
normal or COVID-19 pneumonia and (b) multi-class classification to classify CXRs as normal or as showing bacterial
pneumonia or COVID-19 pneumonia.
It can be observed that for the binary classification task, all
the models are 100% accurate, however, VGG-16 has the least
number of trainable parameters. For multi-class classification, it can be observed that the Inception-V3 model was more
accurate with a shorter CI for the AUC metric, signifying that
it has the least margin for error and hence provides a more precise estimate. Considering F-score and MCC, the InceptionV3 model delivered superior performance compared to
VGG-16 and VGG-19 models.
For the multi-class classification task, the predictions
of the task-specific models (VGG-16, VGG-19, and
Inception-V3) are combined through several ensemble
methods including max voting, simple averaging, weighted
averaging, and model stacking. We didn’t perform ensemble
learning for the binary classification task since the individual models are 100% accurate in classifying CXRs as
normal or showing COVID-19 pneumonia-related opacities.
Table 5 shows the performance achieved for the multi-class
classification with different ensemble strategies. It can be
observed that a simple average of the models’ predictions
is more accurate with a shorter CI for the AUC metric,
signifying a smaller margin of error and therefore, higher
precision, compared to other ensemble methods. Considering
the F-score and MCC, the averaging ensemble outperformed other ensemble strategies in classifying CXRs as
normal, or as showing bacterial pneumonia or COVID-19
viral pneumonia.
For the multi-class classification task, we iteratively
pruned the task-specific models (VGG-16, VGG-19, and
115046 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 5. Performance metrics achieved by the unpruned models through
different ensemble strategies for the multiclass classification task.
TABLE 6. Performance metrics achieved by the best iteratively pruned
models and compared with the baseline unpruned models from Table 4
(U-unpruned and P-pruned).
Inception-V3) by removing 2% of the neurons with the
highest APoZ in each convolutional layer at a given time
step and retrained the pruned model to evaluate its performance on the validation set. We used model checkpoints to
store the best-pruned model that gave a superior performance
with the validation set. The process is repeated until the
maximum pruning percentage of 50% is reached. We then
evaluated the performance of all the pruned models on the test
set. The pruned model that achieved superior performance
with the test set is used for further analysis.
Table 6 shows a comparison of the performance achieved
by the pruned models to that of the baseline, unpruned
task-specific models shown in Table 4. It can be observed
that the pruned models are more accurate than their unpruned
counterparts. Considering the F-score and MCC metrics,
the pruned models are found to deliver superior performance than the unpruned models. It is interesting to note
that the performance improvement is achieved with a significant reduction in the number of parameters. As can
be seen, the number of parameters in the pruned VGG16 model reduced by 46.03% compared to its unpruned
counterpart. Similarly, the number of trainable parameters
reduced by 16.13% and 36.1% for the pruned VGG-19 and
Inception-V3 models, respectively, with the added benefit of
FIGURE 6. Grad-CAM Visualizations showing salient ROI detection by
different pruned models. (A) CXR showing COVID-19 viral
pneumonia-related opacities with GT annotations, (B) VGG-16 pruned
model, (C) VGG-19 pruned model, and (D) Inception-V3 pruned model.
Bright red corresponds to the pixels carrying higher importance and
hence weights for categorizing the test sample to the COVID-19 viral
pneumonia category.
performance improvement in terms of accuracy, F-score, and
MCC metrics, compared to their unpruned counterparts.
Fig. 6 shows the results of performing Grad-CAM
visualizations to localize the salient ROIs used by the different pruned models to classify a sample test CXR into the
COVID-19 viral pneumonia category. The visualizations are
compared with consensus GT annotations provided by the
expert radiologists. The predictions of the pruned models are
decoded for the test sample. Two-dimensional heat maps are
generated in bright red, which corresponds to the pixels carrying higher importance and hence weights for categorizing
the test sample to COVID-19 pneumonia infected category.
Distinct color transitions are observed for varying ranges
of pixel importance toward making the predictions. Salient
ROIs are localized by superimposing the heat maps on the
input sample CXR. It is observed that the pruned models
precisely localize the salient ROI. This underscores the fact
that the pruned models have learned the implicit rules that
generalize well and conform to the experts’ knowledge about
the problem.
Table 7 shows a comparison of the performance metrics
achieved with the different ensemble strategies for the
unpruned and pruned models toward classifying the CXRs as
normal or showing bacterial pneumonia, or COVID-19 viral
pneumonia.
While performing weighted averaging ensemble for both
unpruned and pruned models, the predictions are awarded the
importance based on their F-score and MCC measures that
offer a balanced measure of precision and sensitivity. From
Table 6, it can be observed that the pruned and unpruned
VOLUME 8, 2020 115047S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 7. Comparing the performance metrics achieved with the pruned
and unpruned model ensembles from Table 4.
FIGURE 7. Confusion matrix obtained with the weighted-average pruned
ensemble.
Inception-V3 model delivered superior performance, followed by VGG-19 and VGG-16 models. In this regard, we
assigned weights of 0.5, 0.3, and 0.2 to the predictions of
Inception-V3, VGG-19, and VGG-16 models, respectively.
It can be observed that the weighted averaging ensemble
of the predictions of the pruned models delivered superior
performance in all aspects. Fig. 7 and Fig. 8 shows the confusion matrix and AUC curves, respectively, obtained with the
weighted-averaging pruned ensemble.
The 95% CI for the AUC metric has the shortest error
margin with a more precise estimate than that obtained with
the other ensemble methods. Considering the F-score and
MCC, the weighted averaging ensemble outperformed the
other ensemble strategies in classifying CXRs as normal,
bacterial pneumonia, or COVID-19 viral pneumonia.
FIGURE 8. ROC curves showing micro/macro-averaged and class-specific
AUC obtained with the weighted-average pruned ensemble.
V. CONCLUSION
The COVID-19 pandemic has had an enormously negative
impact on population health and national economies worldwide. Early diagnosis has often been suboptimal and serological tests have not been widely available. The opportunity to
utilize CXRs as part of the diagnostic approach could add an
important and nearly universally available tool to the battle
against COVID-19 or other respiratory viruses that might
emerge in the future. In the current study, we demonstrate
that this can be done by applying ensemble DL to findings
seen in CXRs.
Modality-specific transfer learning performed with a
large-scale CXR collection with a diversified data distribution helped in learning CXR modality-specific features. The
learned feature representations served as a good weight initialization and improved model adaptation and generalization
compared to ImageNet pretrained weights, when transferred
and fine-tuned for a related CXR classification task.
Iterative pruning of the task-specific models and selection
of the best performing pruned model not only improved
prediction performance on the test data but also significantly
reduced the number of trainable parameters. This is because
there are redundant network parameters (neurons) in a deep
model that do not contribute to improving the prediction
performance. If these neurons with lesser activations can be
identified and removed, it results in a faster and smaller model
with similar or improved performance than the unpruned
models. This would facilitate deploying these models on
browsers and mobile devices.
We further improved the performance by constructing
ensembles of the pruned models. By empirically evaluating
the performance of the pruned models and awarding weights
based on their predictions, we observed that the weighted
averaging ensemble of the pruned models outperformed the
other ensemble methods.
We performed visualization studies to validate the
pruned model localization performance and found that the
pruned models precisely localized the salient ROI used in
categorizing the input CXRs to their expected categories.
115048 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
We observe that combined use of CXR modality-specific
knowledge transfer, iterative model pruning, and ensemble learning reduced prediction variance, model complexity,
promoted faster inference, performance, and generalization.
However, the success of this approach is controlled by two
broad factors: (i) dataset size and inherent variability, and
(ii) computational resources needed for successful deployment and use. With dataset size, we specifically refer to the
minimum number of topically relevant images, in this case,
CXRs with viral pneumonia that are distinct from bacterial and normal images, that are needed to build confidence
into the ensemble. With computational resources, we recognize the training time and memory constraints required for
practicable deployment. However, low-cost GPU solutions,
high-performance computing (HPC), and cloud technology
would address the feasibility in this regard. Future studies
could explore visualizing and interpreting the learned behavior of the pruned model ensembles and their application
to other screening situations like COVID-19 detection and
localization in 3D CT scans, etc. At present, we expect that
the proposed approach can be quickly adapted for detection
of COVID-19 pneumonia using digitized chest radiographs.



NEW_PAPER



Received August 21, 2020, accepted August 26, 2020, date of publication September 18, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025010
DL-CRC: Deep Learning-Based Chest Radiograph
Classification for COVID-19 Detection: A Novel
Approach
SADMAN SAKIB 1
, TAHRAT TAZRIN 1
, MOSTAFA M. FOUDA 2,3, (Senior Member, IEEE),
ZUBAIR MD. FADLULLAH 1,4, (Senior Member, IEEE),
AND MOHSEN GUIZANI 5
, (Fellow, IEEE)
1Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada
2Department of Electrical and Computer Engineering, College of Science and Engineering, Idaho State University, Pocatello, ID 83209, USA
3Department of Electrical Engineering, Faculty of Engineering at Shoubra, Benha University, Cairo 11629, Egypt
4Thunder Bay Regional Health Research Institute (TBRHRI), Thunder Bay, ON P7B 7A5, Canada
5Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar
Corresponding author: Sadman Sakib (ssak2921@lakeheadu.ca)
This work was supported in part by the MITACS Accelerate under Grant IT18879, and in part by the Natural Sciences and Engineering
Research Council of Canada (NSERC) under Discovery Grant RGPIN-2020-06260.
ABSTRACT With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians
continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities.
Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely
available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be
used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the
COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph
classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other
abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available
sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal
cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI)
algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and
generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train
a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our
customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection
accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few
actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify
our customized CNN model by extensively comparing it with widely adopted CNN architectures in the
literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based,
and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it
can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence
of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.
INDEX TERMS COVID-19, convolutional neural network (CNN), deep learning, generative adversarial
network (GAN), pneumonia.
I. INTRODUCTION
The severe acute respiratory syndrome coronavirus 2 (SARSCoV-2), first observed in Wuhan, China, turned into a global
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
pandemic of COVID-19 (coronavirus disease 2019) [1].
COVID-19 has a destructive impact on the well-being of people, particularly senior citizens and patients with underlying
health conditions and compromised immunity levels. By midJuly 2020, the COVID-19 pandemic already contributed to
over 570,000 mortalities and more than 13 million cases
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 171575S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
of COVID-19 infection [2]. A critical step to combat the
pandemic is to effectively detect COVID-19 infected patients
as early as possible so that they may receive appropriate
attention and treatment. Early detection of COVID-19 is
also important to identify which patients should isolate to
prevent the community spread of the disease. However,
considering the recent spreading trend of the COVID-19,
an effective detection remains a challenging task, particularly
in communities with limited medical resources. While the
reverse transcription polymerase chain reaction (RT-PCR)
test-kits emerged as the main technique for COVID-19 diagnosis, chest X-ray (chest X-ray), computed tomography (CT)
scans, and biomarkers (i.e. high C-reactive protein (CRP),
low procalcitonin (PCT), low lymphocyte counts, elevated
Interleukin-6 (IL6), and Interleukin-10 (IL10)) are also being
increasingly considered by many nations to aid diagnosis
and/or provide evidence of more severe disease progression [3]–[5].
As depicted in Fig. 1, the existing system for detecting
COVID-19 using the aforementioned virus and antibody testing modalities is time-consuming and requires additional
resources and approval, which can be a luxury in many developing communities. Hence, at many medical centers, the test
kits are often unavailable. Due to the shortage of kits and
false-negative rate of virus and antibody tests, the authorities
in Hubei Province, China momentarily employed radiological scans as a clinical investigation for COVID-19 [6].
FIGURE 1. Challenges of existing system and our research focus for
COVID-19 screening in rural areas.
Motivated by this, several researchers and sources
recommend the use of chest radiograph for suspected
COVID-19 detection [7]–[9]. Therefore, radiologists can
observe COVID-19 infected lung characteristics (e.g., ground
glass opacities and consolidation) by harnessing non-invasive
techniques such as CT scan or chest X-ray. However, it is
difficult to differentiate the COVID-19-inflicted features
from those of community acquired bacterial pneumonia [10].
Therefore, for many patients, manual inspection of the radiograph data and accurate decision making can be overwhelming for the radiologists, and an automated classification technique needs to be developed. In addition, radiologists may get
infected and need to isolate that may impact rural communities with a limited number of hospitals, radiologists, and
caregivers. Moreover, as the second wave of COVID-19 is
anticipated in the fall of 2020, preparedness to combat such
scenarios will involve increasing use of portable chest X-ray
devices due to widespread availability and reduced infection
control issues that currently limit CT utilization [10]. Therefore, as depicted in Fig. 1, in this paper, to automate the
COVID-19 detection using X-ray images, we aim to develop
an artificial intelligence (AI)-based smart chest radiograph
classification framework to distinguish the COVID-19 cases
with high accuracy from other abnormal (e.g., pneumonia)
and normal cases. In this vein, the main contributions of the
paper can be summarized as follows:
• A deep learning-based predictive analytics approach is
employed to propose a smart and automated classification framework for predicting COVID-19, pneumonia,
and normal cases. Our proposed deep learning-based
chest radiograph classification (DL-CRC) framework
consists of a data augmentation of radiograph images
(DARI) algorithm and a customized convolutional neural network model.
• A uniquely compiled dataset from multiple publicly
available sources is prepared with radiographs of healthy
(normal), COVID-19, and pneumonia cases reported to
date. The limited number of COVID-19 instances in
the dataset is identified as the prime reason for training bottleneck of deep learning algorithms. As a solution, our proposed DARI algorithm essentially combines
a customized generative adversarial network (GAN)
model with several generic augmentation techniques
to generate synthetic radiograph data to overcome the
COVID-19 class imbalance problem due to limited
dataset availability.
• We train a customized CNN model based on combined
real and synthetic radiograph images that contributes to
significantly improved accuracy of 93.94% in contrast
with 54.55% when only actual COVID-19 instances in
public datasets are used for training. While chest X-ray
is regarded as a less sensitive modality in detecting
COVID-19 infection in lungs compared to CT scans
in the literature [10], we demonstrate the good performance of our custom CNN model in identifying
COVID-19 cases in the real dataset with high accuracy implying that our approach nullifies the need
for using expensive CT scan machines because the
COVID-19 detection accuracy using our custom CNN
model is much higher compared to the reported baseline [10].
• We rigorously analyze the computational complexity
of the DARI, training, and running/inference steps of
our proposed DL-CRC framework. The analyses, further corroborated by experimental results, reveal that
our proposed methodology leads to significantly lower
training time, and particularly much improved inference time, which is crucial for deploying the trained
model into portable X-ray devices for fast and reliable
COVID-19 feature detection in lung radiographs.
171576 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
• The performance of our customized CNN model is
extensively compared with the state-of-the-art CNN
architectures in the literature (i.e., depth-based CNNs,
multi-path-based CNNs, and so forth) [11]. Our proposal
is demonstrated to substantially outperform the contemporary models in terms of classification efficiency.
The remainder of the paper is organized as follows.
Section II surveys the relevant research work regarding
COVID-19 and the relevant use of AI. The problem of traditional COVID-19 detection and challenges associated with it
to apply in developing communities is discussed in section III.
Our proposed input representation and deep learning model
are presented in section IV. The performance of our proposal
is evaluated in section V and extensively compared with those
of well-known CNN architectures. Some of the limitations of
the study is briefly explored in section VI. Finally, section VII
concludes the paper.
II. RELATED WORK
This section explores the relevant research work in the literature from two perspectives, i.e., imaging modalities for
COVID-19 detection, and AI-based analysis of radiograph
samples.
A. IMAGING MODALITIES FOR COVID-19 DETECTION
Most nations had to take measures to react to the sudden
and rapid outbreak of COVID-19 within a relatively short
period of time. According to [12], radiology departments
have started to focus more on preparedness rather than diagnostic capability, after sufficient knowledge was gathered
regarding COVID-19. The study in [5] stated the resemblance
of COVID-19 with other diseases caused by other coronavirus variants such as the severe acute respiratory syndrome
(SARS) and the middle east respiratory syndrome (MERS).
The importance of a tracking the lung condition of a recovering coronavirus patient using CT scans was also mentioned
in the study. Chest imaging techniques were highlighted to be
a crucial technique for detecting COVID-19 by capturing the
bilateral nodular and peripheral ground glass opacities in the
lung radiograph images [13].
B. AI-BASED RADIOGRAPH ANALYSIS
The application of AI, for early detection, diagnosis, monitoring, and developing vaccines for COVID-19, were elaborately discussed in [14]. Several research work exist in the
literature that exploited various deep learning techniques on
X-ray data to demonstrate reasonable performance [15]–[18].
In [19], a model, referred to as DarkCovidNet, for early
detection of COVID-19 was proposed which utilized 17 convolutional layers to perform binary and multi-class classification involving normal, COVID, and pneumonia cases.
While the model reported an overall accuracy of 98.08%
for the binary classification and 87.02% for multi-class classification, our reconstruction of the DarkCovidNet using
multiple datasets indicated overtraining and much lower
accuracy when non-biased test data are presented to the
model. Several other papers applied deep learning models on
CT scan images to detect and monitor COVID-19 features
in the radiograph data [20], [21]. Ardakani et al. in [22]
employed implemented the state-of-the-art CNN architectures such as AlexNet, ResNet-18, ResNet-50, ResNet-101,
SqueezeNet, VGG-16, VGG-19, MobileNet-V2, GoogleNet,
and XceptionCT to differentiate between COVID-19 and
non-COVID-19 cases. Their experiments showed that deep
learning could be considered as a feasible technique for identifying COVID-19 from radiograph images. To avoid poor
generalization and overfitting due to lack of COVID-19 samples in available datasets, a GAN model was used in [23]
to generate synthetic data, which achieved a dice coefficient
of 0.837. The applicability of GAN for COVID-19 radiograph
data synthesis can be confirmed from the broader spectrum of
GAN applications on various medical data according to the
survey in [24]. The survey identified various unique properties of GAN such as domain adaptation, data augmentation,
and image-to-image translation that encouraged researchers
to adopt it for image reconstruction, segmentation, detection,
classification, and cross-modality synthesis for various medical applications.
III. PROBLEM STATEMENT
With the rapidly surging pandemic, the demand for efficient
COVID-19 detection has dramatically increased. The lack of
availability of COVID-19 viral and antibody test-kits, and the
time required to obtain the test results (in the order of days
to weeks) in many countries are posing a great challenge in
developing/rural areas with less equipped hospitals or clinics.
For instance, in many developing countries, hospitals do
not have sufficient COVID-19 test-kits, and therefore, they
require the assistance of more advanced medical centers to
collect, transport, and test the samples. This creates a bottleneck in mass testing for COVID-19. Therefore, to meet
the daily demand for an enormous amount of new test cases,
an automated and reliable complementary COVID-19 detection modality is necessary, particularly to confront the second wave of the pandemic. Radiograph image utilization for
initial COVID-19 screening may play a pivotal role in areas
with inadequate access to a viral/antibody testing. In several
studies, CT scans were used for analyzing and detecting features of COVID-19 [25] due to higher resolution of features
of ground glass opacities and lung consolidation compared
to chest X-ray images. However, due to infection control
matters associated with patient transport to CT suites, relatively high cost (for procurement, operation and maintenance
of CT equipment), and the limited number of CT machines
in developing/rural areas, CT scan is not a practical solution for detecting COVID-19 [10]. On the other hand, chest
X-ray can be employed to identify COVID-19 or other pneumonia cases as a more practical and cost-effective solution
because X-ray imaging equipment are pervasive at hospital
ERs, public healthcare facilities, and even rural clinics. Even
for trained radiologists, detecting chest X-ray images pose
VOLUME 8, 2020 171577S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
challenges to distinguish between features of COVID-19 and
community acquired bacterial pneumonia [10]. Moreover,
the influx of patients into hospital ERs during pandemic,
manual inspection of radiograph data and accurate decision
making can lead to a formidable tradeoff between detection
time and accuracy that can overwhelm the radiologist department. Therefore, an automated classification technique needs
to be designed. As the second wave of COVID-19 is expected
in many countries, preparedness to combat the pandemic
will involve increasing use of portable chest X-ray devices
due to widespread availability and reduced infection control
issues that currently limit CT utilization [10]. In the following
section, we address the aforementioned problem and present
a deep learning-based approach to effectively solve the problem.
FIGURE 2. Our customized generative adversarial network (GAN) model
for data augmentation.
IV. PROPOSED DEEP LEARNING-BASED CHEST
RADIOGRAPH CLASSIFICATION (DL-CRC) FRAMEWORK
Deep learning in smart health analytics is a prominent interdisciplinary field that merges computer science, biomedical engineering, health sciences, and bioinformatics. Various
medical imaging devices have a dedicated image and signal
analysis and processing module, on which deep learningbased models can be implemented to provide accurate, realtime inferences. Motivated by this, we conceptualize a deep
learning-based chest radiograph classification (DL-CRC)
framework, which can used for automating COVID-19 detection from radiograph images.
Our proposed DL-CRC framework consists of two components: (i) the data augmentation of radiology images (DARI)
algorithm, and (ii) a deep learning model. Our proposed
DARI algorithm generates synthetic X-ray images by adaptively switching between a customized GAN architecture
and generic data augmentation techniques such as zoom and
rotation. The synthetic X-ray images are combined with the
actual radiograph data to build a robust dataset for efficiently
training the deep learning model, i.e., the second component
of our DL-CRC framework. A custom CNN architecture is
designed to construct the deep learning model to carry out
automated feature extraction and classification of the radiograph images.
Next, the details of the proposed DARI algorithm and
custom CNN model of our envisioned DL-CRC framework
are presented, followed by a rigorous complexity analysis of
the proposed methodology in training and inference phases.
A. PROPOSED DARI ALGORITHM
Here, we propose an adaptive data augmentation of radiograph images algorithm, referred to as DARI. Our proposed
DARI algorithm performs an on-demand generation of synthetic X-ray images, triggered by class imbalance in the original dataset. The generated synthetic images are combined
with actual radiograph images to construct a robust training
dataset. This is essential, in the COVID-19 context, where
enough representative samples of COVID-19 chest X-ray
images are not sufficient in the currently available datasets.
DARI leverages a custom GAN model, as depicted in Fig. 2,
along with generic data augmentation techniques such as
zoom and rotation. The GAN model is invoked if the number
of samples in a class is less than a certain pre-defined threshold (δ). In the GAN model, a generator (G) and a discriminator (D) are trained simultaneously until the discriminator
is unable to separate the generated data samples from the
original ones. The generator receives random noise as input
and produces chest X-ray images, which are, in turn, received
by the discriminator. Thus, the GAN can be regarded as a
two-player minimax game between a discriminative model
(D) and a generative model (G) [26]. By exerting a noisy
sample nx with the data distribution of p(nx ) as the input,
the generative network G outputs new data X
0
, distribution
of which, denoted by p(X
0
), is supposed to be identical to that
of the distribution of original data, p(X). The discriminative
network, D, is employed to distinguish the true data sample X
with the distribution of p(X) and the generated sample X
0 with
a distribution of p(X
0
). Then, this adversarial training process
can be formulated as follows,
minG maxDV(D, G) = EX∼p(X)
log(D(X))
+ Enx∼p(nx )
log(1 − D(nx )). (1)
We customize the GAN model for chest X-ray image
augmentation as follows. The generator is constructed with
a stack of ng hidden layers. Each layer comprises a dense
layer, followed by Leaky Rectified Linear Unit (LeakyReLU)
as the activation function. In each successive layer (i
th) of the
generator, the number of neuron units (i.e., nodes) is twice
the number of nodes in the preceding layer. On the other
hand, in the discriminator model, it receives collections of
original (X) and generated (X
0
) X-ray radiograph data with
COVID-19 infected lung images. Here, the inputs to the discriminator are X = [x1, x2, . . . xn] and X
0 = [x
0
1
, x
0
2
, . . . x
0
n
],
where each xi represents an original image while each x
0
i
denotes an augmented chest X-ray image. Similar to the
171578 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
generator, the discriminator’s structure also consists of nd
hidden layers, and each i
th layer contains a sequence of a
dense layer with LeakyReLU as the activation function [27].
A dropout layer is then included. Let pi denote the dropout
rate. The number of nodes in each i
th layer is denoted by Di
.
Note that Di =
1
2
· Di−1. The discriminator aims to optimize
the loss function by distinguishing generated images from the
original ones. Our custom GAN model is trained for ξmax
number of iterations, where ξmax ∈ Z
+. The detailed steps of
our proposed DARI algorithm are presented in Algorithm 1.
Here, we either invoke the GAN or a more generic type of
data augmentation, based upon a given condition as illustrated
in Algorithm 1. This procedure takes two inputs: (i) type
of augmentation, and (ii) data for augmentation. For one
condition, the proposed GAN model gets executed from steps
2 to 22. When the other condition is fulfilled, the generic data
augmentation is performed as described in steps 23 to 25,
which includes enlarging the image by Z quantity and rotating
by θ amount.
B. PROPOSED CUSTOM CNN MODEL FOR
COVID-19 DETECTION IN X-ray IMAGES
Next, we need to train a deep learning model which can take
advantage of the robust dataset obtained from our proposed
DARI algorithm in section IV-A. Since the problem can
be regarded as a classification task of normal, COVID-19,
and other abnormal cases (e.g., pneumonia), we investigate
the contemporary deep learning architectures suited for classification. In contrast with other variants of deep learning
architectures (i.e., long-short term memory (LSTM), deep
belief networks, and so forth) and extreme learning machines,
CNNs are regarded as the most powerful deep learning
architecture for image classification. Therefore, we explore
the robust CNN models recently employed to gain reasonable classification accuracy with chest X-ray data [19].
By applying the contemporary CNN models on the latest
dataset compiled from four public repositories, we realize that
their reported performances are constrained by overfitting
and influenced by biased test data. To address this issue,
we propose a two-dimensional (2-D), custom CNN model
for classifying X-ray images to predict COVID-19 cases as
depicted in Fig. 3. The 2-D CNN structure is utilized to learn
the discriminating patterns automatically from the radiograph
images.
The proposed CNN model consists of three components.
The first component is a stack of nc convolution layers while
the second segment consists of nd fully connected layers.
The final component is responsible for generating the output
probability. At first, the convolution layers (i.e., the first component of the model) receive radiograph images (X) as input,
identify discriminative features from the input examples, and
pass them to the next component for the classification task.
Each i
th layer among the nc convolution layers consists of a
filter size of z
i
. Initially, the filter size is set to xir
in the 1st
layer, and it is decreased by λ in each successive layer. In the
Algorithm 1 Data Augmentation of Radiograph Images
(DARI)
Input: type (type of data augmentation,
possible values ‘generic’,
‘GAN’), D (collection of data
for augmentation)
Output: γ (augmented sample data)
1 γ ← ∅
2 if (type=‘GAN’) then
3 Initialize ξmax (maximum number of
epochs), B (mini-batch size), and
naug (number of data to augment)
4 mg ← construct generator model as
depicted in Fig. 2
5 md ← construct discriminator model
as depicted in Fig. 2
6 foreach e ∈ ξmax do
7 for (i=1 to B) do
8 nx ← generate naug samples of
random noise to initialize
the generator
9 gi ← generate image by
passing nx to the generator mg
10 ri ← select random set of
samples from D
11 X
∗ ← construct collection
from generated (gi) and
original samples (ri)
12 md ← update the discriminator
model by batch training using
X
∗
13 end
14 nx ← generate naug samples of
random noise
15 mg ← update the generator model
parameters
16 if e=ξmax then
17 γ ← generate collection of
augmented images by using nx
18 foreach img ∈ γ do
19 save img to corresponding
directory
20 end
21 end
22 end
23 else
24 γ ← augment data by applying
zooming rate of Z and rotation of θ
on each item from data collection D
25 end
26 return γ
forward pass, the convolution operation is performed between
the input image and the filter coefficients using Eq. 2. Here,
VOLUME 8, 2020 171579S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 3. Proposed DL-CRC framework consisting of our envisioned
DARI algorithm and custom CNN model. (1) The test data is obtained by
splitting the original images that are not used for training. (2) DARI
algorithm adaptively uses GAN and generic data augmentation
techniques to generate synthetic chest X-ray images which are combined
with the remaining original radiograph images to construct a robust
training dataset. (3) The training input is passed to our customized CNN
model, which performs automated feature extraction and classification.
x
l
ij and w
l
ij denote the output and the filter weights of the l
th
layer, respectively.
x
l
ij =
X
i∈xir
,j∈xic
(x
l−1
ij × w
l
ij). (2)
Hyper-parameter tuning is conducted to select the optimal
activation function, , as shown in in Eq. 2. The activation
function considers a constant, denoted by α > 0.
Next, we apply a dropout of rate pi as the regularization
technique that will assist the network in evading overfitting and achieve better model generalization by randomly
disregarding randomly selected neurons in the hidden layers [28]. To reduce the feature size and computational power
need, we introduce the max-pooling layer with a pool size
of ki = (k
i
r
, k
i
c
) in the hidden layers where ki
is set to a
fraction µ of the initial dimension of the input xi
. The maxpooling layers assist the model in capturing abstract spatial
information more robustly and enhancing the model’s generalization ability of the model [29]. The output features of
the convolution layers are converted into a one-dimensional
(1-D) vector by flattening the layer, and then forwarded to the
stack of nd fully-connected or dense layers for the automated
classification stage. The number of nodes in the first dense
layer is equal to xir
, and it is decreased by a factor of λ in each
successive i
th layer with respect to the number of nodes in the
previous layer. The output of the n
th dense layer is propagated
through a dropout layer of rate pi
.
Finally, the output layer computes the probability of the
input xi belonging to each class. The learning is set to a
constant ηc throughout the training of the model. The classification task receives radiograph samples as input X =
[x1, x2, . . . xn], and outputs a sequence of labels Y =
[y1, y2, . . . yn]. Here, each xi corresponds to the pixel values
of the input images. On the other hand, each yi denotes a
distinct class. Each xi has the dimension of (xir
, xic
, ϑi). In this
case, xir
, xic
, and ϑi denote the image height, width, and the
number of channels for the i
th sample. The augmented and
real samples are passed to the training data during the training
phase, and some part of the real samples are considered as the
test dataset during the testing phase.
C. TRAINING AND RUNNING PHASES OF PROPOSED
DL-CRC
From hereon, we discuss the steps of the training and running
phases of our proposed DL-CRC algorithm.
The steps of the training phase of our proposed DL-CRC
framework is presented in Algorithm 2. The training stage of
DL-CRC commences from Algorithm 2, which takes C, k, B,
λ, and δ as inputs to our custom CNN model. The description
of each input parameter is provided in the input section of the
algorithm. Steps 1 to 3 of Algorithm 2 initialize the required
parameters. In steps 4 to 10, all data are loaded from location,
and the test data are split by the ratio of λ to be utilized in the
running phase for evaluating the model. Initially, all data are
171580 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
Algorithm 2 Training Phase (DL-CRC)
Input: C (collection for training,
testing, and validation data
location), k (number of fold
in cross-validation), ξ
(number of epoch), B
(mini-batch size), λ (test
ratio), δ (threshold value for
class imbalance ratio), N
(total number of samples
across all classes)
Output: Mt (Trained model)
1 Mt ← ∅
2 X ← []
3 Y ← []
4 X
∗ ← read all data from C[train]
5 if (len(X
∗
)> 0) then
6 I
∗ ← generate random values in
range[0, λ × len(X
∗
)]
7 foreach index i ∈ I
∗ do
8 move C[train] + X
∗
[i] to C[test] + X
∗
[i]
9 end
10 end
11 foreach class ci ∈ C[train] do
12 x
∗
i ← read all data from ci
13 if (len(x
∗
i
)/N < δ) then
14 x
∗
i
+= DARI(‘gan’, x
∗
i
)
15 end
16 foreach class data ∈ x
∗
i
do
17 X+=data
18 Y+=ci
19 end
20 end
21 for (fold no. j=1 to k) do
22 Xtrain, ytrain, Xval, yval ← set data and
labels of j
th fold from X, Y
23 Xtrain += DARI(‘generic’, Xtrain)
24 Xval += DARI(‘generic’, Xval)
25 Mt ← update the CNN model depicted
in Fig. 3 by training it using Xtrain
for ξ and B
26 evaluate Mt by using Xval, yval
27 end
28 save the model parameters of Mt
29 return Mt
stored in the training directory. Hence, they are loaded from
the location of training data. Steps 11 to 20 are responsible for
checking whether any data augmentation is required or not,
and accordingly preparing all the training and validation data
from the dataset. Specifically, steps 13 to 15 check whether
the training data in any class is less than a predefined threshold δ or not, based on the condition if it can exploit the
Algorithm 3 Running Phase (DL-CRC)
Input: testPath (location of test
images)
Output: ypred (prediction of testing
samples)
1 Xtest ← read all data from testPath
2 Mt ← load the saved pre-trained model
3 yprob ← predict the probabilities of
each data from Xtest
4 ypred ← argmax(yprob)
5 return ypred
proposed data augmentation of radiograph images (DARI)
algorithm described in Algorithm 1. Our customized CNN
model is trained in steps 21-27, utilizing the model structure
illustrated in Fig. 3. At the penultimate step, the trained
model (Mt) is stored for further testing and validation. Finally,
in step 29, the algorithm returns the trained model.
Next, in the running phase, the CNN model of our proposed
DL-CRC framework follows Algorithm 3. It receives the
location of sample data for inference and returns the predicted
class labels (ypred) for the corresponding data. After reading
the data from step 1, the pre-trained model (Mt) is loaded in
the following step. In step 4, the model Mt
is employed to
predict the probabilities for a sample test data to be in each of
the possible classes. Finally, in the last step, the class with the
maximum probability is identified for each sample data, and
then returned as a collection of predictions for all the data.
D. COMPUTATION OVERHEAD ANALYSIS
In the remainder of the section, we rigorously analyze the
computational overhead of our proposed model in terms of
time-complexity. The analyses are divided into training and
running phases.
1) TRAINING PHASE
The training phase includes both our proposed DARI (Algorithm 1) for data augmentation and training our customized
CNN model (Algorithm 2). Particularly for the analysis
of Algorithm 2, we consider that the appropriate hyperparameters of our CNN model are already selected after
hyperparameter tuning. We partition the analysis of the training phase into three main segments, i.e., DP (required data
preparation), DA (data augmentation), and CNN (the execution of the CNN model). Therefore, the total computational
complexity can be expressed as follows.
C(T ) = O(DP) + O(DA) + O(CNN). (3)
In the first three steps (1-3) of Algorithm 2, where initialization is conducted, the time complexity can be denoted as
constant time, O(1). In the 4th step, all the data from the train
path are read. So, if there are fn number of data available to
train, the time complexity will be O(fn). Steps 5-9 split the test
data by the λ ratio. Therefore, the complexity associated with
VOLUME 8, 2020 171581S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
these steps is O(λ). Hence, the computational complexity of
the data preparation phase can be denoted as:
O(DP) = O(3) + O(fn) + O(λ) ≈ O(fn) + O(λ). (4)
The data augmentation part of the complexity analysis mainly consists of our proposed DARI (Algorithm 1),
invoked in steps 13-15 of Algorithm 2. This requires loading
data from each class in step 12 that results in the computational complexity of O(cl × f
i
n
). Here, cl denotes the number
of classes while f
i
n
refers to the number of data read from
i
th class. Then, through steps 13-15, the DARI algorithm is
invoked and its complexity is denoted as ODARI. Suppose
that ng and nd denote the numbers of layers in the generator and discriminator, respectively. Then, the computations
required by the generator and the discriminator models can
be denoted as Gc (Eq. 5) and Dc (Eq. 6), respectively:
Gc = 2(Xng
i=1
x
i
g × w
i
g + b
i
g
), (5)
Dc = 2(Xnd
i=1
x
i
d × w
i
d + b
i
d
). (6)
Combining the previous two expressions of Gc and Dc,
the overall overhead of DARI (Algorithm 1) is evaluated as
follows.
O(DARI) = O(cl×ξmax×B×(Gc+Dc))+O(cl × naug),
(7)
where naug, ξmax, and B denote the number of data to augment,
maximum number of epochs, and mini-batch size, respectively.
In steps 16-19 of the training algorithm, assuming the
length of each x
∗
i
as lx∗
i
, the computational overhead is O(lx∗
i
).
Therefore, the overall complexity of the data augmentation
stage can be expressed as:
O(DA) = O(cl × f
i
n
) + O(DARI) + O(lx∗
i
). (8)
From steps 21 to 27, the training algorithm invokes the
adopted 2-D CNN structure. The computational overhead for
this part can be derived from Eq. 9:
O(CNN) = O(CNNcl) + O(CNNdl), (9)
where O(CNNcl) and O(CNNdl) denote the computational
overheads in the convolutional layers and dense layers,
respectively. If we consider for a layer i, the number of filters
in the i
th layer z
i
, input image x
i with the dimension of
(x
i
r
, x
i
c
) and kernel k
i with the dimension of (k
i
r
, k
i
c
), then the
computational complexity of the convolutional layers can be
expressed as:
O(CNNcl) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
))). (10)
After the convolutional layers, for n layers, assuming w
i
and b
i
are the weight vector and the bias of i
th layer, the complexity of the fully connected layers is given by:
O(CNNdl) = O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (11)
Hence, combining the aforementioned equations, to finalize the computational complexity of the proposed CNN,
we can re-write Eq. 9 as follows:
O(CNN) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
)))
+ O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (12)
Finally, to determine the total time complexity of the training phase of the DL-CRC algorithm, we can substitute the
corresponding values from Eqs. 4, 8, and 12 into Eq. 3.
2) RUNNING PHASE
The running phase is conducted to infer classes of each test
data using the pre-trained model and then evaluate the model.
As shown in Algorithm 3, if we consider the number of test
data to be ntest, the computational overhead in the testing
phase can be given by:
C(R) = O(ntest). (13)
Eq. 13 demonstrates that the model is able to produce results in linear time. This implies that our proposed
DL-CRC framework comprising DARI algorithm and the
customized CNN model can be deployed on clinical-grade
X-ray machines with image processing capability, computing
resources having access to digitized radiograph images from
analog X-ray machines, and even portable X-ray machines
in movable booths and trucks with adequate shielding and
power supply. Thus, our model is viable for automating the
radiograph image classification with fast turn-around time for
COVID-19 detection.
V. PERFORMANCE EVALUATION
To evaluate the performance of our proposed DL-CRC framework, in this section, we describe the collected datasets used
to train our customized CNN model, followed by extensive
experimental results and discussion.
A. DATASET PREPARATION
The dataset employed for the supervised radiograph image
classification using our proposed DL-CRC framework consists of three classes: COVID-19, pneumonia, and normal
chest X-ray images. We collected the dataset using four different existing datasets of Posteroanterior (PA) chest X-rays,
and combined those into a single dataset to utilize it for the
classification purpose. We developed the dataset from GitHub
for COVID-19 X-rays [30], X-ray data collected in this study
for cases of pneumonia, and normal images [31], CheXpert
171582 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 1. Brief description of the used dataset for X-ray image
classification.
dataset collected by Stanford ML group [32], and the rest of
the normal and pneumonia chest X-ray images were collected
from the dataset in [33]. Table 1 lists the initial class distribution of the collected chest X-ray dataset. The number of
samples collected for COVID-19 is significantly lower than
the other two classes because this is a novel disease, and at this
moment, data regarding COVID-19 is challenging to obtain.
In other words, the number of COVID-19 class samples in
the merged dataset is lower than the threshold value for class
imbalance ratio, δ. Therefore, to overcome the effect of the
low amount of COVID-19 data, we employed our proposed
DARI algorithm to increase the number of samples. We then
applied our proposal along with contemporary CNN models
to verify which one yields the best COVID-19 detection
performance.
B. PERFORMANCE INDICATORS
To evaluate the classification results, we primarily adopted
the combination of three measurement indicators, accuracy,
weighted precision, and weighted F1 score. The accuracy of
a test is its ability to correctly differentiate the three cases.
Assume that C denotes the number of classes in the considered classification task, |yi
| refers to the number of samples
in the i
th class, and |Y | indicates the total number of samples
in all the classes. Then, the accuracy can be represented as
follows.
Accuracy =
PC
i=1
(TPi)
|Y |
. (14)
Next, we define the weighted precision. Our aim is to
measure how precise the model is in terms of the number of
samples actually present in the i
th class out of those predicted
to be in that class. This number is multiplied by the weight of
the i
th class to obtain the weight precision as follows.
Weighted precision =
X
C
i=1
(
|yi
|
|Y |
×
TPi
TPi + FPi
). (15)
Next, the weighted F1 score is defined as the weighted
average of precision and recall. Although we did not use
recall directly as a performance measure, because of using
the F1 score, it is implicitly used. The weighted F1 score can
be obtained as follows,
Weighted F1 score =
X
C
i=1
(
|yi
|
|Y |
× 2
Pi × Ri
Pi + Ri
). (16)
Here, Pi and Ri are the precision and recall of i
th class,
respectively. Pi can be expressed as TPi/(TPi + FPi) and
Pi can be denoted as TPi/(TPi + FNi). TPi
, FPi
, and FNi
denotes True Positive, False Positive, and False Negative
for i
th class respectively. TPi
indicates the number of cases
correctly identified to be in the i
th class; FPi represents the
number of cases incorrectly identified to be in the i
th class,
and FNi denotes the number of cases incorrectly identified
as a class other than the i
th class. In addition, for evaluating
our results more comprehensively we also employed class
specific classification accuracy (i.e., normal, COVID-19, and
pneumonia detection accuracy) for all three classes.
C. RESULTS AND DISCUSSION
We have followed a systematic approach by applying different techniques to find the optimal model for the classification
task. All the experiments were conducted on a workstation
with Intel Core i7, 3.00GHz CPU, 16 GB RAM, powered
by Nvidia RTX 2060 Graphics Processing Unit (GPU). The
simulations were implemented employing Python’s Keras
and TensorFlow library. The visualization of the experimental
results was achieved by utilizing Python’s Matplotlib library.
During the simulations, we have resized the image samples by
setting both xir
and xic
to 100 to keep the images consistent in
terms of size. The number of channels of the samples (ϑi) was
set to 1 as the input images were grayscale in nature. The values of xir
and xic were selected based on manual tuning. Using
our proposed DARI algorithm, on-demand data augmentation
is performed by adaptively employing GAN, rotation (θ) of 5
degrees, and zooming (Z) rate of 0.50. The value of δ was
set to 0.1. We systematically constructed three experimental
scenarios to conduct a comprehensive performance comparison of our proposed DL-CRC framework consisting of DARI
algorithm and our customized CNN models with the stateof-the-art CNN models which have been recently reported to
provide reasonable accuracies for COVID-19 detection. The
three scenarios, constructed in an incremental fashion, are
described below.
1) In our first scenario, we designed our customized deep
CNN model architecture depicted in Fig. 3. The parameters of the model were selected based on the results of
the grid search technique.
2) In the second scenario, we implemented the proposed
DARI algorithm to analyze the effect of the generic and
GAN-based data augmentation to train the CNN-based
model in a robust fashion to significantly improve the
COVID-19 detection accuracy.
3) In the third and final scenario, we trained several stateof-the-art CNN models using different deep learning
paradigms on our compiled dataset. The same test data
(unknown chest X-ray original images with normal,
COVID-19, and pneumonia cases) were presented to
the customized CNN model of our proposed DL-CRC
framework as well as the contemporary CNN models.
The results were used to compare the performances of
our proposal and these contemporary models in terms
of COVID-19 and pneumonia detection efficiency.
VOLUME 8, 2020 171583S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 4. Performance in terms of accuracy for different combinations of
activation functions and optimizers.
FIGURE 5. Performance in terms of precision for different combinations
of activation functions and optimizers.
FIGURE 6. Performance in terms of F1 score for different combinations of
activation functions and optimizers.
In the first scenario, we implemented the customized CNN
model of our proposed DL-CRC framework and carried out
a grid search to achieve the optimal model parameters (i.e.,
FIGURE 7. Performance comparison for diverse ratios of the
COVID-19 X-ray images generated by the GAN with respect to the existing
number of samples in the dataset.
the best activation functions and optimizer). It is worth noting that other customized CNN models revealed a performance bottleneck in terms of validation accuracy and we
found the model in Fig. 3 to be the most lightweight yet
efficient for automating the chest X-ray classification task.
Figs. 4, 5, and 6 demonstrate the results obtained from the
hyper-parameter tuning in terms of accuracy, precision, and
F1 score, respectively. These performances were extensively
evaluated across six optimizers (Stochastic Gradient Descent
(SGD), Adaptive Moment Estimation (Adam), Root Mean
Square Propagation (RMSProp), Adaptive Delta (AdaDelta),
Nesterov and Adam (Nadam), and Adaptive Gradient Algorithm (Adagrad)) and five activation functions (tanh, sigmoid, Scaled Exponential Linear Unit (SELU), Rectified
Linear Unit (ReLU), and Exponential Linear Unit (ELU)). As
depicted by the results in these figures, SELU demonstrated
better performances on average when compared with the
other activation functions. However, the best performance
was exhibited when ELU is adopted as the activation function
with the value of constant α = 1.0 and the optimizer set to
Adagrad with the learning rate of 0.001. For this first experimental setting for selecting the optimal hyper-parameters
of the deep learning-based model, the mini-batch size (B)
was set to 8, and the number of epochs (ξ ) was set to 20.
With this configuration, the validation accuracy, precision,
and F1 score were found to be 97.25%, 97.24%, and 97.21%,
respectively. Therefore, for further analysis, we applied this
configuration in the customized CNN model of our DL-CRC
framework. Furthermore, in the max-pooling layer of our
proposed CNN architecture, we conducted manual parameter
tuning, and the pool size ki was assigned as µ, where µ = 2%
of the initial size of the input xi
.
In the second experimental scenario, as the number of
COVID-19 samples in the collected dataset was lower than
the pre-defined threshold δ, we applied our proposed DARI
algorithm to increase the number of COVID-19 samples so
that the model can be trained with a robust training data
171584 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 8. Confusion matrix of testing phase employing 5-fold stratified cross-validation.
and eventually predict positive COVID-19 cases with high
accuracy. In Fig. 7, we altered the proportions for our customized GAN model in the DARI algorithm with respect to
the original sample size of the COVID-19 class. The ratios
of GAN-generated samples of the proposed approach were
varied from 50% to 200% with respect to the number of
COVID-19 examples in the original dataset. The number of
iterations for producing the augmented samples using the
GAN-based method was set to 200. Among the proportions
mentioned earlier, the COVID-19 detection performance of
our customized CNN model was found to be the highest
(with an accuracy of 93.94%) when the number of newly
generated samples was 100% of the size of the original
COVID-19 samples. Therefore, we picked this configuration to be used in our conducted experiments in the next
scenario.
After producing the augmented samples for the COVID-19
class, we analyzed the effect of combining the adaptive
generic data augmentation and GAN-based DARI algorithm
with the CNN architecture to fully implement and fine-tune
the DL-CRC framework, and compared the performance with
the base CNN model only (i.e., without adopting DARI
algorithm). The experiment was conducted utilizing a fivefold stratified cross-validation. Using the stratification technique, the samples are rearranged so that each fold has a
stable representation of the whole dataset by maintaining
the percentage of samples for each class [34]. In our third
experimental setup, the number of epochs (ξ ) was set to
100, and the mini-batch size (B) was set to 8. The number of convolutional layers, nc, was set to five. The number of fully-connected/dense layers, nd , was also fixed to
five. Note that these hyperparameter values were manually
tuned. To analyze the results more critically in terms of
COVID-19 detection efficiency, in this experimental setting,
we also investigated the normalized and non-normalized values of the confusion matrices of our customized CNN model
TABLE 2. Performance comparison of the proposed DL-CRC and CNN
with generic and GAN-based data augmentation.
without (i.e., CNN-only model) and with the proposed DARI
algorithm (i.e., the complete DL-CRC framework). Fig. 8
represents the normalized confusion matrix where the proposed CNN model is implemented without applying the data
augmentation, and Fig. 8 depicts the same for the combined
CNN and DARI algorithm. Despite similar performances of
both approaches, the normalized confusion matrix demonstrates that our proposed DL-CRC framework is much more
robust for classifying positive COVID-19 and pneumonia
cases. The proposed DL-CRC exhibited 93.94% and 88.52%
accuracies while detecting positive COVID-19 and pneumonia cases, respectively. The encouraging classification
performance indicates that our proposed deep learningbased DL-CRC framework is able to classify the radiograph images with high efficiency, specifically for COVID-19
detection.
Furthermore, we analyzed the impact of generic and GANbased data augmentation separately combined with our customized CNN model and compared the COVID-19 detection
accuracy with the proposed DL-CRC framework. Table 2
exhibits the simulation results, which proves that both the
generic and GAN-based data augmentation had significant
influence in enhancing the COVID-19 detection efficiency.
The simulation results in the table show that our CNNonly base model achieved 54.5%, CNN with generic data
augmentation obtained 63.4%, and CNN with the proposed
VOLUME 8, 2020 171585S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 3. Performance comparison of our proposed DL-CRC architecture
with the existing CNN architectures for all three classes.
GAN-based data augmentation delivered 84.5% COVID-19
detection accuracy. On the other hand, the proposed DL-CRC
framework demonstrated the highest COVID-19 detection
accuracy (93.94%). This good performance is attributed to
the combination of our customized CNN model with the proposed DARI algorithm where both generic and GAN-based
data augmentation are adaptively performed, Therefore, it is
evident from these results that our proposed DL-CRC framework made the customized CNN model much more robust
with DARI algorithm.
In the third experimental scenario, we compared the performance of our customized CNN model with the performances
of the state-of-the-art CNN models such as Inception-Resnet
V2, Resnet, and DenseNet. The reason behind choosing these
contemporary models is their good performances reported
in the recent literature for COVID-19 detection. It is worth
noting that Inception-ResNet v2 and DenseNet belong to the
depth-based and multi-path-based CNN paradigms, respectively. On the other hand, ResNet combines both depthbased and multi-path-based CNN architectures. Table 3
demonstrates the comparative analysis, which indicates
the efficiency of our proposed DL-CRC framework in
terms of COVID-19 and pneumonia detection using chest
X-ray images. Our proposed model, outperformed ResNet,
Inception-ResNet v2, and DenseNet. Although Densenet
achieves 98.01% prediction performance for normal test
cases, its accuracy is only 72.42% for pneumonia detection
while it exhibits the poorest performance of 60.61% for
identifying COVID-19 cases. This implies that multi-pathbased structure, although reported in recent work, is not suitable for COVID-19 detection. On the other hand, Inception
ResNet v2, using the depth-based CNN modeling paradigm,
achieves improved COVID-19 detection accuracy (69.70%).
The combination of these two modeling paradigms is incorporated in ResNet, which is able to predict test cases having
COVID-19 samples slightly elevated accuracy of 72.72%.
On the other hand, our proposed DL-CRC framework, combining our envisioned DARI algorithm and customized CNN
model, is able to detect the COVID-19 cases with a significantly high accuracy of 93.94%. Note that the pneumonia (the other abnormal case) present in the test dataset is
also detected with much higher accuracy (88.52%) compared
to the contemporary models. Even though the performance
slightly drops for normal case identification, the accuracy
is still close to 96% in case of our proposal. Furthermore,
in the final column of Table 3, the AUC (area under the ROC
(receiver operating characteristic) curve) values are also listed
for the proposed DL-CRC and contemporary models. The
AUC score of our proposed DL-CRC is 0.9525 which demonstrates the reasonable accuracy of identification across all
samples in the test data. Thus, the encouraging performance
of the proposed DL-CRC algorithm over prominent CNN
models clearly demonstrates that the proposed technique can
be useful for detecting COVID-19 and pneumonia cases with
a significantly high (i.e., reliable) accuracy.
Furthermore, we compare the performance of our proposal
with a recent custom model, referred to as DarkCovidNet
[19]. For multi-class classification, the accuracy of DarkCovidNet was reported to be 87.02%, which is considerably
lower than that of our proposed model’s performance
(93.94%), which we believe ensures the effectiveness of our
proposed model. In addition, we have conducted two-fold
experiments to validate and compare our proposed technique (DL-CRC) with DarkCovidNet. Table 4 demonstrates
the results obtained when our proposed model is tested on
both datasets, and the DarkCovidNet model is tested on
both datasets. Both models were trained by employing the
respective dataset used by the work in [19] and our current work. These experimental results presented in Table 4
were produced after training the models for 25 epochs for
each case, and then the trained models were tested on both
datasets. Our proposed technique outperformed DarkCovidNet for detection accuracies for both normal and COVID-19
cases. In addition to the classification efficiency, our proposed DL-CRC framework is more lightweight than that of
used in DarkCovidNet. Our customized CNN model of DLCRC consists of 5 convolutional layers while the DarkCovidNet model comprises 17 convolutional layers, making our
model’s training phase more lightweight and computationally
less expensive than the DarkCovidNet model.
Moreover, while some researches reported overall accuracy, they did not mention the COVID-19 detection accuracy.
On the other hand, most researches applying deep learning
techniques did not report the AUC score, which is a robust
representative performance metric for practically evaluating
the COVID-19 detection ability of the model. In summary,
by applying various contemporary CNN models (Inception
with Resenet V2, Resnet, Densenet) and a recent customized
model (DarkCovidNet) for COVID-19 detection on the latest
dataset compiled from four public repositories, we realized
that their reported performances are constrained by overfitting and influenced by biased test data. Thus, the accuracy
bottleneck of those existing models justifies why we required
to build a customized CNN model in this research and combine it with the DARI algorithm to perform robust training
and avoid overfitting to ensure high COVID-19 detection
accuracy and a significantly high AUC score.
VI. LIMITATIONS OF THE STUDY
In this section, we briefly discuss some limitations and possible future work that can be conducted to extend the study.
171586 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 4. Comparison of the performance our proposed model with that of DarkCovidNet [19] on both datasets.
• Our study and experiments have been conducted at a
very critical stage and time-sensitive manner to combat the COVID-19 pandemic with a proof-of-concept
COVID-19 using radiograph images. Despite compiling
datasets from multiple sources with X-ray images containing COVID-19 samples, the used data was considerably small in size. Therefore, synthetic images were
generated using our customized GAN-assisted data augmentation technique that were used to train a robust
CNN model to perform binary (normal and COVID-19)
and three-way classification (normal, pneumonia, and
COVID-19) with significantly high accuracy. Due to
the lack of real datasets consisting of other diseases
(e.g., SARS, MERS, and so forth) which exhibit acute
respiratory distress syndrome (ARDS) and pneumonialike conditions in the lungs, more class labels were not
considered in our work.
• From a physician’s perspective, it is important to diagnose the severity of COVID-19. However, due to the lack
of labeled data, in this work, our model could not be
used to classify the various stages of COVID-19 such
as asymptomatic, mild, high and severe.
• The proposed technique performed efficiently when we
utilized it to analyze X-ray samples. However, the study
can be extended to evaluate the system’s performance
in COVID-19 detection while using other radiograph
techniques such as CT scan, lung ultrasound, and lung
PET (positron emission tomography) scan.
• The dataset used in this study is limited by only
one modality type, i.e., X-ray images containing
COVID-19 features. Further customization in our CNN
model will be required if we want to combine multiple
imaging modalities (e.g., lung CT scan, ultrasound, PET
along with X-ray images), other modalities (e.g., body
temperature, ECG, MCG, diabetes level, renal function,
and so forth), and patient parameters (e.g., age, gender, ethnicity, travel history, and contact history) to perform an in-depth COVID-19 classification. Therefore,
a multi-modal input characterization and corresponding
AI model customization will be needed in the future for
interpreting and explaining the classification results.
VII. CONCLUSION
In this paper, we addressed the emerging challenges of
detecting COVID-19. Due to the shortage of efficient diagnosis equipment and personnel in many areas, particularly
in developing and/or rural zones, numerous people remain
non-diagnosed. This results in a substantial gap between the
number of confirmed and actual cases. Radiographs such as
chest X-ray images and CT scans have been demonstrated
to have the potential for detecting COVID-19 infection in
the lungs that can complement the time-consuming viral
and antibody testing. While CT scans have higher resolution or fine-grained details compared to X-ray images, X-ray
machines are pervasive in hospital emergency rooms, public
health facilities, and even rural health centers or clinics.
In addition, because X-ray is a much cheaper alternative
and an appealing solution for portability in mobile trucks
and COVID-19 screening booths with adequate shielding
and power supply, how to identify COVID-19 infection of
the lung by recognizing patterns such as glass opacities and
lung consolidations raised a formidable research problem,
that we addressed in this paper. Also, we discussed why
it is necessary to automate the X-ray image classification
to be well prepared for the next wave of COVID-19 pandemic, when radiologists and caregivers are expected to be
overwhelmed by patient influx as well as the need to selfisolate in case they themselves become infected. This means
there is a pressing need to automate the classification of
radiographs, particularly X-ray images, to minimize the turnaround time for COVID-19 detection. Therefore, to leverage
the availability and cost-efficiency of chest X-ray imaging,
in this paper, we proposed a framework called DL-CRC
(Deep learning-based chest radiograph classification) to automate COVID-19 detection that can complement existing viral
and antibody testing methods.
Our proposed DL-CRC framework consists of two parts:
the DARI algorithm (which adaptively employs a customized
generative adversarial network and generic data augmentation techniques such as zoom and rotation) and a twodimensional convolutional neural network (CNN) model. We
employed a unique dataset for multiple publicly available
sources, containing radiograph images of COVID-19 and
pneumonia infected lungs, along with normal lung imaging.
The classification accuracy significantly increased to 94.61%
by adopting our proposed DL-CRC framework. Our proposal was compared with existing deep learning models from
diverse categories such as depth-based CNN (e.g., InceptionResNet v2), multi-path-based CNN (DenseNet), and hybrid
CNN (ResNet) architectures. Extensive experimental results
demonstrated that our proposed combination of DARI and
custom CNN-based DL-CRC framework significantly outperformed the existing architectures. Thus, incorporating our
proposed model with significantly high accuracy into the
VOLUME 8, 2020 171587S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
clinical-grade as well as portable X-ray equipment can allow
an automated and accurate detection of COVID-19 in the
scrutinized patients.




NEW_PAPER


C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Collaborative City Digital Twin for the COVID-19 Pandemic:
A Federated Learning Solution
Junjie Pang, Yan Huang, Zhenzhen Xie, Jianbo Li
, and Zhipeng Cai
Abstract: The novel coronavirus, COVID-19, has caused a crisis that affects all segments of the population. As the
knowledge and understanding of COVID-19 evolve, an appropriate response plan for this pandemic is considered
one of the most effective methods for controlling the spread of the virus. Recent studies indicate that a city Digital
Twin (DT) is beneficial for tackling this health crisis, because it can construct a virtual replica to simulate factors,
such as climate conditions, response policies, and people’s trajectories, to help plan efficient and inclusive decisions.
However, a city DTsystem relies on long-term and high-quality data collection to make appropriate decisions, limiting
its advantages when facing urgent crises, such as the COVID-19 pandemic. Federated Learning (FL), in which
all clients can learn a shared model while retaining all training data locally, emerges as a promising solution for
accumulating the insights from multiple data sources efficiently. Furthermore, the enhanced privacy protection
settings removing the privacy barriers lie in this collaboration. In this work, we propose a framework that fused city
DT with FL to achieve a novel collaborative paradigm that allows multiple city DTs to share the local strategy and
status quickly. In particular, an FL central server manages the local updates of multiple collaborators (city DTs),
providing a global model that is trained in multiple iterations at different city DT systems until the model gains the
correlations between various response plans and infection trends. This approach means a collaborative city DT
paradigm fused with FL techniques can obtain knowledge and patterns from multiple DTs and eventually establish a
“global view” of city crisis management. Meanwhile, it also helps improve each city’s DT by consolidating other DT’s
data without violating privacy rules. In this paper, we use the COVID-19 pandemic as the use case of the proposed
framework. The experimental results on a real dataset with various response plans validate our proposed solution
and demonstrate its superior performance.
Key words: COVID-19; Digital Twin (DT); Federated Learning (FL); deep learning
 Junjie Pang is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, and is also with
the Business School, Qingdao University, Qingdao 266000, China. E-mail: pangjj18@163.com.
 Yan Huang is with the College of Computing and Software Engineering, Kennesaw State University, Atlanta, GA 30060, USA.
E-mail:yhuang24@kennesaw.edu.
 Zhenzhen Xie is with the College of Computer Science and Technology, Jilin University, Changchun 130012, China. E-mail:
xiezz14@mails.jlu.edu.cn.
 Jianbo Li is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, E-mail:
lijianbo@188.com.
 Zhipeng Cai is with the Department of Computer Science, Georgia State University, Atlanta, GA 30303, USA. E-mail: zcai@gsu.edu.
To whom correspondence should be addressed.
Manuscript received: 2021-02-26; accepted: 2021-03-18760 Tsinghua Science and Technology, October 2021, 26(5): 759–771
1 Introduction
Coronavirus (COVID-19), an infectious disease
caused by the recently discovered coronavirus, was
identified on December 31th 2019[1] (https://www.who.
int/emergencies/diseases/novel-coronavirus-2019). The
virus has spread worldwide in less than three months,
infected more than 116 million people, and caused
over 2 575 196 deaths (https://www.worldometers.info/
coronavirus/). This widespread coronavirus outbreak
received tremendous attention from the research and
medical perspective. However, a specific antiviral
treatment of COVID-19 remains unavailable. Therefore,
an early and radical government response can be
considered the most effective method when facing a
novel infectious disease. However, determining the
response plan properly can be challenging because of a
lack of experience and efficient data sources.
A mathematical model is a possible solution for
the intervention and surveillance of the infectious
disease[2]. For example, the Susceptible-InfectedSusceptible (SIS) epidemic model is widely used in
describing the spreading process for a virus in a static
network with an assumption of a constant population.
This model can also combine with a time-varying
dynamic network to describe more complex propagation.
We also observe that the significant proliferation of
machine learning techniques has resulted in the rapid
development of intelligent forecasting models[3]. Recent
works demonstrate their comparable performance in
capturing non-trivial atypical trends and typical patterns
for epidemic control, such as the Wiener-series-based
machine learning model for measuring the H1N1 virus
spread after an intervention[4], and the representation
learning model that generates interpretable epidemic
forecasting results for seasonal influenza forecasting[5]
.
However, these models still have several challenges
and limitations in predicting infection trends of a novel
infectious disease, such as COVID-19:
Uncertain influence: In contrast to other pandemic
predictions, the prediction model of unknown infectious
diseases, such as COVID-19, must learn the influence
of various response plan settings, such as mask-wearing,
shelter in place, and statewide school closures.
Cold start problem: When a new virus starts to
spread, the local health department always needs a long
time to properly collect sufficient data to generate a
response to the pandemic. Note that the same response
plan could have varied effects in different locations: a
radical response plan may only bring economic risks
to a low-risk areas, while the same actions could result
in losing control of the spreading virus and economic
damage for severely affected areas.
Privacy protection: The data resources related to a
health crisis, such as COVID-19 pandemic, unavoidably
contain sensitive information. This situation means that
we cannot collaboratively share these data unless we can
provide a strong privacy guarantee[6]. However, medical
institutions and local governments may expect a highperformance model for epidemic control, which means
massive data collection is required for deep learningbased models. Because of privacy and confidentiality
concerns, these applications can possibly be prevented,
such that data silos emerge[7]. These silos are isolated
islands of data, which can make health data management
disorganized and inefficient. Moreover, they make it
prohibitively costly for the local agencies to extract
knowledge, share insights, and realize collaborations
with other regions[8]
.
As shown in Fig. 1, we proposes a Digital Twin
(DT) enabled collaborative training framework based
on a federated learning paradigm to resolve the
above problems. We use a city DT to build a virtual
replica of the city/state that provides a digital view of
Federated Learning (FL) central server
City DT
Real world
Fig. 1 Overview of the collaborative framework for a multiple city DT.Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 761
city/state facilities, human activities, and other types
of information to enable information convergence in
multiple aspects of infection trend, thus enabling the
prediction of the uncertain influence caused by different
events. City DT allows each region to accumulate
historical data efficiently, while demonstrating a
remarkable potential for offering continuous interaction
with the physical world to refine prediction[9, 10]
.
Specifically, Time Convolutional Networks (TCN) is
adopted to implement a city DT, ensuring superior
performance for modeling the temporal information
dynamics and the future infection trend prediction under
a local response plan.
To further resolve the cold start problem and privacy
concerns, FL[11] is introduced as the collaborative
training paradigm. It only involves the parameters
shared among multiple parties in training collaborative
machine learning models. Thus, FL can significantly
lower the privacy risks in collaborative knowledge
exchange[12]. These features, combined with the highquality contribution from local city DT, are essential
for establishing a prediction model and accumulating
knowledge and insights for an unknown virus, such as
COVID-19, in a short period.
Our contributions can be summarized as follows:
 To resolve the uncertain influence challenge for
COVID-19 pandemic management, we are among the
first to propose a novel collaborative learning framework
with city DT embedding.
 The proposed TCN-based city DT helps determine
the effects of various local response plans for each
city/area, which is the first attempt to utilize a nontrivial deep learning model for epidemic forecasting
considering fine-granularity time pattern features.
 Considering the cold start problem and privacy
concerns, we use the FL as the solution, which offers
collaborative learning via only parameter-sharing not to
disturb each city DT’s privacy rules.
 Extensive simulations with a real dataset reveal that
our proposed framework significantly outperforms the
non-trivial baseline and the non-FL city DT solution
with a strong privacy guarantee.
The remainder of the paper is organized as
follows. Section 2 introduces related works. The basic
definitions and problem statements are presented in
Section 3. Section 4 explains the detailed structure
and methodology of the proposed framework. The
experiments and results are analyzed in Section 5.
Finally, conclusions and future work are presented in
Section 6.
2 Related Work
In this section, we start with a brief review of traditional
methods for epidemic prediction, and then discuss the
related techniques and the need for the collaborative
training framework.
Deep learning-based epidemic control: Historical
insights from temporal infection data have been
crucial for epidemic control and prevention, and could
benefit other problems in smart city systems[13, 14] or
enhanced social network analysis[15]. Deep learningbased techniques have demonstrated a remarkable
performance to model such temporal correlations and
recognize multiple patterns[16, 17], including the deep
neural network-based short-term and high-resolution
epidemic forecasting for influenza-like illness[18], the
semi-supervised deep learning framework that integrates
computational epidemiology and social media mining
techniques for epidemic simulation, called SimNest[19]
and EpiRP[20], which use representational learning
methods to capture the dynamic characteristics of
epidemic spreading on social networks for epidemicsoriented clustering and classification.
Moreover, recent breakthroughs in infectious disease
modeling, forecasting, and real-time disease surveillance
have further convinced us that these activities mitigate
the effects of disease outbreaks. In addition, with
the rapid growth of cloud computing and wireless
data communication architectures[21, 22], deep learningmodels demonstrate constantly improving efficiency.
Given various application scenarios and objectives,
deep learning-based models can be different. A typical
solution for localized flu “nowcasting” and flu activity
inferring is ARGONet[23], which is a network-based
approach leveraging spatio-temporal correlations across
different states to improve the prediction accuracy.
ARGONet uses a spatial network to capture the
spatio-temporal correlations across different states and
produces more precise retrospective estimates based on
the information from influenza-related Google search
frequencies, electronic health records, and historical
influenza trends. Instead of leveraging multiple data
source, such as ARGONet, the studies in Ref. [24]
proposed a multi-task learning-based model that is only
uses user-generated content (Web search data). They
investigate linear and nonlinear model capabilities and
find that disease rate estimates can be significantly762 Tsinghua Science and Technology, October 2021, 26(5): 759–771
improved in the case study of an influenza-like illness.
However, these successful attempts are based on largescale data sources or massive historical information
of the disease with similar spreading patterns, which
means that high-dimensionality, irregularity forms,
noise, privacy concerns, or sparsity problems may
affect these learning-based models’ performance[25, 26]
,
especially when we face unexpected infectious disease
outbreaks, such as the COVID-19 pandemic.
For filling the data gap, the city DT is proposed as
a promising solution. It is a virtual representation of a
device or a specific application scenario that can interact
with the target environment to collect data continuously
for real-time decision-making. Several successful
research attempts include a disaster city DT[27, 28]
,
energy management[29], and city-scale Light Detection
and Ranging (LiDAR) point clouds[30]. Furthermore,
Singapore[31] and Germany[32] have launched the cityscale DT to monitor and improve utilities, which enhance
the transparency, sustainability, and availability of a DT.
In this way, the city DT offers us a high-quality and
real-time data resource to describe the spread of an
epidemic, whereas data silos naturally emerge because
of privacy barriers[33, 34]. To maintain the advantages of
DT and tolerate the data sparsity challenge, FL, which
allows multiple stack-holders to share data and train a
global model, has become a preferred scheme[11]. In
typical FL scheme settings, each data owner (FL client)
engages in a collaborative training process without
transferring the raw data to the others. Through FL,
the central server manages each client’s local training
updates and aggregates their contributions to enhance the
global model’s performance. Several concrete scenarios,
including Google’s Gboard[35], health AI[36], and smart
banking[37], show the advantages of FL in handling
collaborative training issues and data difficulties among
diverse data owners. Therefore, we are motivated
to utilize FL techniques to resolve the data sparsity
challenges and design a collaborative city DT for
COVID-19 pandemic control.
3 Preliminary and System Model
In this section, we first explain the preliminaries of
the proposed framework. The structural design, which
combines DT and FL for COVID-19 pandemic control,
will be explained with a mathematical definition of
the problem objective. The detailed methodology and
proposed solution will be illustrated in Section 4.
3.1 Preliminaries
TCN: Given these advantages and a delicate-designed
convolutional architecture, TCN can handle variable
length inputs, such as those of Recurrent Neural Network
(RNN)-based methods[38], and convincingly outperform
baseline recurrent architectures across various sequence
modeling tasks. By leveraging a much simpler, 1-D
fully-convolutional network, TCN can build a very
long sufficient history size for a variable length of a
input sequence, avoiding large memory requirements
and intricate network architecture, such as those of
gated RNNs. Its model pipeline has two distinguishing
features: causal convolution and dilated convolution.
The causal convolutions consider that the output at time
t is convoluted only with elements that occurred before t,
which suggests that current spatial-temporal information
depends only on the past and not on any future inputs.
Then, to further achieve longer history data without
introducing an extremely deep network or very large
filters, a TCN uses a dilated convolution to enlarge
the sequence data’s maximum length (receptive field).
Notably, the receptive field can be changed by stacking
more dilated convolution layers or increasing the filter
sizes, which fully explain the robustness and flexibility.
FL: FL is a privacy-enhanced distributed learning
framework with an emphasis on using mobile and edge
devices for collecting data and scaling the computation
resources[11]. Unlike previous research handling with
training data in a centralized manner, FL’s essential
property uses a “parameter-only” collaborative training
to avoid disturbing each FL clients’ privacy rules. Thus,
various participating clients can solve the learning task
through a hub-and-spoke topology for model aggregation
while maintaining the raw data on their devices. In
particular, for a new FL training task, (1) the FL
central server trains a global model for initialization,
then distributes this model to the existing collaborators
(clients); (2) after receiving the global model, each
collaborator uses the local dataset to update the local
parameters and generates the local updates; (3) based
on specified synchronization settings, all these updates
are sent to the FL central server for aggregation, and the
global model is improved; (4) these distributed update
iterations are repeated until the global model converges
or achieves the expected performance.
DT: A DT is a digital representation of a physical
asset, environment, or system, that was initially
developed to automatically aggregate, analyze, andJunjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 763
visualize complex information through continuous
interactions with the physical world.
3.2 City DT for COVID-19 pandemic control
From the above facts, we observe explicit advantages
of using FL to establish the collaborative training
framework of multiple city DTs. First, by separating
local model training and global model updates, FL
offers a strong capability to deal with the isolated data
island problem between multiple DTs. Secondly, with
enhanced privacy settings, each city DT can obtain the
collaboration achievements without violating its privacy
rules. These properties are essential for COVID-19
pandemic control, because different regions need a
collaboration paradigm with lower privacy risks to
quickly realize an effective response plan. Furthermore,
for each city DT using a TCN as the time-series data
modeling method, the shared global model can provide
more temporal correlation perspectives, which is a
complementary approach to make the city DT quickly
converge to a robust performance.
In our proposed work, a city DT has three primary
components: the physical environment of the city,
a virtual replica describing the city’s architecture,
functions, and behaviors, and active communications
between the two to obtain real-time spatiotemporal
data from various infrastructure and human systems[39]
.
According to the three components, we compose a city
DT for COVID-19 pandemic control using the following
metrics:
COVID-19 case number: The COVID-19 case
number is the number of identified confirmed cases. It
is the direct evidence to describe the characteristics of
human-to-human transmission. Daily updates of case
numbers represent infection trend changes and show
whether a response plan is operated efficiently. In our
framework, each DT model is from a specific area, so
that the case number is bounded with the area and time
information.
COVID-19 testing number: This metric measures
how many individuals get tested of COVID-19 in the
affected regions. The actual total number of people
infected with COVID-19 cannot be obtained. In this
situation, the number of confirmed cases depends on the
testing number, because it can be used to further interpret
and revise the COVID-19 case number. Meanwhile,
the positive rate, computed as the testing number in
a particular time window, is an essential metric for
describing if the target area controls the spread properly.
Therefore, we must use both numbers to estimate the
current infection status and mitigate the risks of underreporting cases and deaths.
COVID-19 confirmed death number: The
confirmed death number describes the ability of
COVID-19 to cause death, which is another direct piece
of evidence of how a region is affected. Furthermore, it
is an important metric for identifying at-risk populations
and guiding the response plan to adjust the medical
resource allocations. The confirmed death number and
case number can have very different trends because the
same response plan may affect these metrics differently.
For example, several infected regions can bring the
number of deaths down for the same response plan, but
other areas may only lower the case number. Thus, the
death rate helps us understand the severity of this virus
and evaluate each response plan’s fine-grained function.
Response plan: For COVID-19 pandemic control,
various organizations and governments develop several
local-level response plans or even a country-level
response plan to prepare for and respond to COVID-19.
In our DT model, we use Ri D .li
; tst; tend / to represent
a response plan, where li
is the location, with tst and
tend denoting the starting time and end time of Ri
. We
include the following response plans in the proposed
model: 14-day quarantine, domestic travel limitations,
gathering limits and stay-at-home orders, nonessential
business closures, reopening plans, mask policy, etc.
The effectiveness of different response plans can vary
because they may be affected by several external factors,
such as a sudden emergency, adverse weather conditions,
or vaccinations.
Temporal effects: In our work, two types of temporal
effects are considered as the primary factors in each city
DT model: temporal effects of historical infection status
(e.g., historical case numbers and historical deaths) and
external factors (e.g., selected response plans, events,
and gatherings). Note that our proposed city DT
model’s primary goal is to determine whether the specific
response plan can flatten the infection curve and evaluate
the period of validity of the plan. We thus need a robust
epidemic forecasting model that can consider multiple
temporal factors and hidden periodicity.
Historical infection status: For a fast-evolving
pandemic, such as the COVID-19 pandemic, the
historical case numbers are direct evidence of the
correlation between past conditions and the current
infection status. In Fig. 2, we take the historical daily
case information of three states (NV: Nevada, UT: Utah,764 Tsinghua Science and Technology, October 2021, 26(5): 759–771
Fig. 2 Correlation between the current infection trend and
the historical infection numbers.
and WI: Wisconsin) as examples of these temporal
effects. From the early March data of all three states, we
observe the same immediate effect of historical infection
numbers, because they lead to a continuously increasing
number of infections until April 2nd, which indicates
that the temporal correlations can play an essential role
in explaining and predicting future infection trends.
External factors: To determine whether external
factors can have an immediate or delayed effect on future
infection trends, we observe the correlation between
each specific factor and the infection status in the next
few days. In our work, the response plans are considered
the primary external factor, because the choice of a
specified response plan can also significantly affect
the number of infections. This effect can be various,
depending on the strictness of that policy, people’s
acceptance of it, and many other factors, such as
various climate conditions or the population density.
For example, in Fig. 2, we observe that after taking
a specified response plan, such as domestic travel
limitations or gathering limits, the infection trend of
all three states can be significantly decreased. However,
for different reasons, the validity period of the response
plan can vary, so all three states exhibit an increasing
infection trend over time. Thus, the temporal effect of
a specific response plan can be complicated because
external factors, such as the 14-day time window, the
indeterminate period that a response plan starts to
take effect, and a paroxysmal public crisis, may also
lead to infection trend changes, which suggests that
it is a challenge to estimate the temporal effects of a
specific response plan from such a complicated physical
environment.
3.3 Problem statement
To place the COVID-19 pandemic under control,
different local agencies in each city/region may choose
their own strategy to meet the local requirements. This
divergence occurs mainly because different regions
should consider the local intrinsic properties. For
instance, Area A, which is a thinly populated district
with very low infection rates, would prefer to choose
a less radical response plan; while the another Area
B, where has severe infection conditions, is very
likely to choose a less radical response plan, like
restricting activities and closing most of the facilities.
This situation means that each region can only obtain
knowledge by trial-and-error operation schemes for
seeking an effective response plan, and the increasing
time cost could lead to a delayed response plan with
poor performance. Moreover, to train a city DT model
to predict future infection trends after a response plan,
enough features must be used to construct the temporal
correlations, which suggests that a collaborative city
DT-training framework must be considered instead.
In coping with these challenges and limitations,
the FL protocol is used in our collaborative city DT
framework. In this paper, we study the problem of
forecasting future infection trends for specific response
plans. Formally, this problem is stated as follows:
Given multiple city DTs, D D D1; D2; : : : ; Di
, each
expects collaborations and is bounded with a local data
sensing method to generate individualize data source
si;1; si;2; : : : ; si;mi
, our federated training problem is to
optimize the following function:
min
w
(
F .w/ ,
X
N
iD1
piFi.w/
)
;Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 765
where N is the number of city DTs, w represents the
parameter of FL global model, pi D mi=m, where m
is the number of data points in all city DT’s data source
and mi
is the number of data points of i-th city DT. For
city DT Di
, f ./ is the loss function of a data point, so
that the local objective Fi./ of Di can be defined as
Fi.w/ ,
1
mi
Xmi
jD1
f




NEW_PAPER



Received November 25, 2020, accepted December 8, 2020, date of publication December 14, 2020,
date of current version December 31, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3044858
Artificial Intelligence Applied to Chest X-Ray
Images for the Automatic Detection of COVID-19.
A Thoughtful Evaluation Approach
JULIÁN D. ARIAS-LONDOÑO 1
, (Senior Member, IEEE), JORGE A. GÓMEZ-GARCÍA 2
,
LAUREANO MORO-VELÁZQUEZ3
, (Member, IEEE), AND
JUAN I. GODINO-LLORENTE 2
, (Senior Member, IEEE)
1Department of Systems Engineering, Universidad de Antioquia, Medellín 050010, Colombia
2Bioengineering and Optoelectronics Laboratory (ByO), Universidad Politécnica de Madrid, 28031 Madrid, Spain
3Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD 21218, USA
Corresponding author: Juan I. Godino-Llorente (ignacio.godino@upm.es)
This work was supported in part by the Ministry of Economy and Competitiveness of Spain under Grant DPI2017-83405-R1, and in part
by the Universidad de Antioquia, Medellín, Colombia.
ABSTRACT Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or
antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the
significant number of false negatives of these tests and provide complementary evidence about the presence
and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest
X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence
for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network.
These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to
differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed
to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from
different sources, including more than 8, 500 COVID-19 examples. Three different experiments following
three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to
evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical
analysis of different variability issues that might compromise the system and its effects is performed. With
the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for
the worst but most explainable experiment, which requires a previous automatic segmentation of the lung
region.
INDEX TERMS COVID-19, deep learning, pneumonia, radiological imaging, chest X-ray.
I. INTRODUCTION
COVID-19 pandemic has rapidly become one of the biggest
health world challenges in recent years. The disease spreads
at a fast pace: the reproduction number of COVID-19 ranged
from 2.24 to 3.58 during the first months of the pandemic
[1], meaning that, on average, an infected person transmitted
the disease to 2 or more people. As a result, the number
of COVID-19 infections dramatically increased from just
a hundred cases in January –most of them concentrated in
The associate editor coordinating the review of this manuscript and
approving it for publication was Wenming Cao .
China– to more than 43 million in November spread all
around the world [2].
COVID-19 is caused by the coronavirus SARS-COV2, a
virus that belongs to the same family of other respiratory
disorders such as the Severe Acute Respiratory Syndrome
(SARS) and Middle East Respiratory Syndrome (MERS).
The symptomatology of COVID-19 is diverse and arises
after incubation of around 5.2 days. The symptoms might
include fever, dry cough, and fatigue; although, headache,
hemoptysis, diarrhea, dyspnoea, and lymphopenia are also
reported [3], [4]. In severe cases, an Acute Respiratory Distress Syndrome (ARDS) might be developed by underlying
pneumonia associated with COVID-19. For the most severe
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 226811J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
cases, the estimated period from the onset of the disease to
death ranges from 6 to 41 days (with a median of 14 days),
being dependent on the patient’s age and the patient’s immune
system status [3].
Once the SARS-COV2 reaches the host’s lung, it gets
into the cells through a protein called ACE2, which serves
as the ‘‘opening’’ of the cell lock. After the virus’s genetic
material has multiplied, the infected cell produces proteins
that complement the viral structure to produce new viruses.
Then, the virus destroys the infected cell, leaves it, and
infects new cells. The destroyed cells produce radiological
lesions [5]–[7] such as consolidations and nodules in the
lungs, that are observable in the form of ground-glass opacity
regions in the X-Ray (XR) images (Fig. 1c). These lesions
are more noticeable in patients assessed 5 or more days after
the onset of the disease, and especially in those older than
50 [8]. Findings also suggest that patients recovered from
COVID-19 have developed pulmonary fibrosis [9], in which
the connective tissue of the lung gets inflamed, leading to a
pathological proliferation of the connective tissue between
the alveoli and the surrounding blood vessels. Given these
signs, radiological imaging techniques –using plain chest
XR and thorax Computer Tomography (CT)– have become
crucial diagnosis and evaluation tools to identify and assess
the severity of the infection.
Since the declaration of the COVID-19 pandemic, the
World Health Organization identified four major key areas
to reduce the impact of the disease in the world: to prepare
and be ready; detect, protect, and treat; reduce transmission;
and/or innovate and learn [10]. Concerning the area of detection, significant efforts have been undertaken to improve the
diagnostic procedures of COVID-19. To date, the gold standard in the clinic is still a molecular diagnostic test based on a
polymerase chain reaction (PCR), which is precise but timeconsuming, requires specialized personnel and laboratories,
and is in general limited by the capacities and resources
of the health systems. An alternative to PCR is the rapid
tests such as those based on real-time reverse transcriptasepolymerase chain reaction (RT-PCR), as they can be more
rapidly deployed, decrease the load of the specialized laboratories and personnel, and provide faster diagnosis compared
to traditional PCR.
Other tests, such as those based on antigens, are now
available but are mainly used for massive testings (i.e. for
non-clinical applications) due to a higher chance of missing
an active infection. In contrast with RT-PCR, which detects
the virus’s genetic material, antigen tests identify specific
proteins on the virus’s surface, requiring a higher viral load,
which significantly shortens the sensitivity period.
In clinical practice, the RT-PCR test is usually complemented with a chest XR, in such a manner that the combined analysis reduces the significant number of false negatives and, at the same time, brings additional information
about the extent and severity of the disease. In addition to
that, thorax CT is also used as a second-row method for
evaluation. Although the evaluation with CT provides more
accurate results in the early stages and have been shown to
have greater sensitivity and specificity [11], XR imaging has
become the standard in the screening protocols since it is fast,
minimally-invasive, low-cost, and requires simpler logistics
for its implementation.
In the search for rapid, more objective, accurate and sensitive procedures, which could complement the diagnosis and
assessment of the disorder, a trend of research has emerged
to employ clinical features extracted from thorax CT or chest
XR with automatic detection purposes. A potential benefit of
studying the radiological images is that these can characterize pneumonic states even in asymptomatic population [12].
However, more research is needed in this field as the lack
of findings in infected patients is also reported [13]. The
consolidation of such technology will permit a speedy and
accurate diagnosis of COVID-19, decreasing the pressure
on microbiological laboratories in charge of the PCR tests
and providing more objective means of assessing the disease’s severity. To this end, techniques based on deep learning have been employed to leverage XR information with
promising results. Although it would be desirable to employ
CT for detection purposes, some significant drawbacks are
often present, including higher costs, a more time-consuming
procedure, thorough hygienic protocols to avoid infection
spread, and the requirement of specialized equipment that
might not be readily available in hospitals or health centers.
By contrast, XR imaging procedures are available as first
screening tests in many hospitals or health centers, at lower
expenses.
Several approaches for COVID-19 detection based on
chest XR images and different deep learning architectures
have been published in the last few months, reporting classification accuracies around 90% or higher. However, the central
analysis in most of those works is focused on the variations
of network architectures, whereas there is less attention to
the variability factors that a real solution should tackle before
it can be deployed in the medical setting. In this sense, no
analysis has been provided to demonstrate the reliability of
the networks’ predictions, which in the context of medical
solutions acquires particular relevance. Moreover, most of
the works in state of the art have validated their results with
data sets containing dozens or a few hundreds of COVID-19
samples, limiting the proposed solutions’ impact.
With these antecedents in mind, this paper uses a deep
learning algorithm based on CNN, data augmentation, and
regularization techniques to handle data imbalance for the
discrimination between COVID-19, controls, and other types
of pneumonia. The methods are tested with the most extensive
corpus to date, to the authors’ knowledge. Three different
sets of experiments were carried out in the search for the
most suitable and coherent approach. To this end, the paper
also uses explainability techniques to gain insight about the
manners on how the neural network learns, and interpretability in terms of the overlapping among the regions of interest
selected by the network and those that are more likely affected
by COVID-19. A critical analysis of factors that affect the
226812 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 1. Experiments considered in the paper. First row: raw chest XR images belonging to the control, pneumonia, and
COVID-19 classes. Second row: Grad-CAM activation mapping for the XR images. Despite the high accuracy, the model
focuses its attention on areas different from the lungs in some cases. Third row: Grad-CAM activation mapping after
zooming in, cropping to a squared region of interest and resizing. Zooming to the region of interest forces the model to
focus its attention to the lungs, but errors are still present. Fourth row: Grad-CAM activation mapping after a zooming and
segmentation procedure. Zooming in and segmenting force the model to focus attention in the lungs. The black background
represents the mask introduced by the segmentation procedure.
VOLUME 8, 2020 226813J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
performance of automatic systems based on deep learning is
also carried out.
This paper is organized as follows: section II presents some
background and antecedents on the use of deep learning for
COVID-19 detection. section III presents the methodology,
section IV presents the results obtained, whereas V presents
the discussions and main conclusions of this paper.
II. BACKGROUND
A large body of research has emerged on the use of Artificial
Intelligence (AI) to detect different respiratory diseases using
plain XR images. For instance, in [14] authors developed
a 121-layer Convolutional Neural Network (CNN) architecture, called Chexnet, which was trained with a dataset of
100, 000 XR images for the detection of different types of
pneumonia. The study reports an area under the Receiving
Operating Characteristic (ROC) curve of 0.76 in a multiclass
scenario composed of 14 classes.
Directly related to the COVID-19 detection, three CNN
architectures (ResNet50, InceptionV3 and InceptionResNetV2) were considered in [15], using a database of just
50 controls and 50 COVID-19 patients. The best accuracy
(98%) was obtained with ResNet50. In [16], seven different
deep CNN models were tested using a corpus of 50 controls
and 25 COVID-19 patients. The best results were attained
with the VGG19 and DenseNet models, obtaining F1-scores
of 0.89 and 0.91 for controls and patients. The COVID-Net
architecture was proposed in [17]. The net was trained with
an open repository, called COVIDx, composed of 13, 975 XR
images, although only 358 -from 266 patients– belonged to
the COVID-19 class. The attained accuracy was of 93.3%. In
[18] a deep anomaly detection algorithm was employed for
the detection of COVID-19, in a corpus of 100 COVID-19
images (taken from 70 patients), and 1, 431 control images
(taken from 1008 patients). 96% of sensitivity and 70% of
specificity was obtained. In [19], a combination of a CNN for
feature extraction and a Long Short Term Memory Network
(LSTM) for classification were used for automatic detection
purposes. The model was trained with a corpus gathered from
different sources, consisting of 4, 575 XR images: 1, 525 of
COVID-19 (although 912 come from a repository applying
data augmentation), 1, 525 of pneumonia, and 1, 525 of controls. In a 5-folds cross-validation scheme, a 99% accuracy
was reported. In [20], the VGG16 network was used for
classification, employing a database of 132 COVID-19, 132
controls and 132 pneumonia images. Following a hold-out
validation, about 100% accuracy was obtained identifying
COVID-19, being lower on the other classes.
Authors in [21] adapted a model for the classification of
COVID-19 by using transfer-learning based on the Xception
network. Experiments were carried out in a database of 127
COVID-19, 500 controls, and 500 patients with pneumonia gathered from different sources, attaining about 97%
accuracy. A similar approach, followed in [22], used the
same corpus for the binary classification of COVID-19 and
controls; and for the multiclass classification of COVID-19,
controls, and pneumonia. With a modification of the Darknet
model for transfer-learning and 5-folds cross-validation, 98%
accuracy in binary classification and 87% in multiclass classification was obtained. Another Xception transfer-learningbased approach was presented in [23], but considering two
multi-class classification tasks: i) controls vs. COVID-19
vs. viral pneumonia and bacterial pneumonia; ii) controls
vs. COVID-19 vs. pneumonia. To deal with the imbalance
of the corpus, an undersampling technique was used to
randomly discard registers from the larger classes, obtaining 290 COVID-19, 310 controls, 330 bacterial pneumonia,
and 327 viral pneumonia chest XR images. The reported
accuracy was 89% in the 4-class problem and 94% in the
3-class scenario. Moreover, in a 3-class cross-database experiment, the accuracy was 90%. In [24], four CNN networks
(ResNet18, ResNet50, SqueezeNet, and DenseNet-121) were
used for transfer learning. Experiments were performed on
a database of 184 COVID-19 and 5, 000 no-finding and
pneumonia images. Reported results indicate a sensitivity of
about 98% and a specificity of 93%. In [25], five state-of-theart CNN systems –VGG19, MobileNetV2, Inception, Xception, InceptionResNetV2– were tested on a transfer-learning
setting to identify COVID-19 from control and pneumonia
images. Experiments were carried out in two partitions: one
of 224 COVID-19, 700 bacterial pneumonia, and 504 control
images; and another that considered the previous normal and
COVID-19 data but included 714 cases of bacterial and viral
pneumonia. The MobileNetV2 net attained the best results
with 96% and 94% accuracy in the 2 and 3-classes classification. In [26], the MobileNetV2 net was trained from
scratch and compared to one net based on transfer-learning
and to another based on hybrid feature extraction with finetuning. Experiments performed in a dataset of 3905 XR
images of 6 diseases indicated that training from scratch
outperforms the other approaches, attaining 87% accuracy
in the multiclass classification and 99% in the detection
of COVID-19. A system, also grounded on the InceptionNet and transfer-learning, was presented in [27]. Experiments were performed on 6 partitions of XR images with
COVID-19, pneumonia, tuberculosis, and controls. Reported
results indicate 99% accuracy, in a 10-folds cross-validation
scheme, in the classification of COVID-19 from other classes.
In [28], fuzzy color techniques were used as a preprocessing stage to remove noise and enhance XR images
in a 3-class classification setting (COVID-19, pneumonia,
and controls). The pre-processed images and the original
ones were stacked. Then, two CNN models were used to
extract features: MobileNetV2 and SqueezeNet. A feature
selection technique based on social mimic optimization and a
Support Vector Machine (SVM) was used. Experiments were
performed on a corpus of 295 COVID-19, 65 controls and 98
pneumonia XR images, attaining about 99% accuracy.
Given the limited amount of COVID-19 images, some
approaches have focused on generating artificial data to train
better models. In [29], an auxiliary Generative Adversarial
Network (GAN) was used to produce artificial COVID-19
226814 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
XR images from a database of 403 COVID-19 and 1, 124
controls. Results indicated that data augmentation increased
accuracy from 85% to 95% on the VGG16 net. Similarly,
in [30], GAN was used to augment a database of 307
images belonging to four classes: controls, COVID-19, bacterial and viral pneumonia. Different CNN models were
tested in a transfer-learning-based setting, including Alexnet,
Googlenet, and Restnet18. The best results were obtained
with Googlenet, achieving 99% in a multiclass classification approach. In [31], a CNN based on capsule networks
(CapsNet), was used for binary (COVID-19 vs. controls)
and multi-class classification (COVID-19 vs. pneumonia
vs. controls). Experiments were performed on a dataset of
231 COVID-19, 1, 050 pneumonia and 1, 050 controls XR
images. Data augmentation was used to increase the number of COVID-19 images to 1, 050. On a 10-folds crossvalidation scheme, 97% accuracy for binary classification,
and 84% multi-class classification were achieved. The CovXNet architecture, based on depth-wise dilated convolution
networks, was proposed in [32]. In the first stage, pneumonia (viral and bacterial) and control images were employed
for pretraining. Then, a a refined model of COVID-19 is
obtained using transfer learning. In experiments using twodatabases, 97% accuracy was achieved for COVID-19 vs.
controls, and of 90% for COVID-19 vs. controls vs. bacterial and viral cases of pneumonia. In [33], an easy-to-train
neural network with a limited number of training parameters was presented. To this end, patch phenomena found on
XR images were studied (bilateral involvement, peripheral
distribution, and ground-glass opacification) to develop a
lung segmentation and a patch-based neural network that
distinguished COVID-19 from controls. The basis of the
system was the ResNet18 network. Saliency maps were also
used to produce interpretable results. In experiments performed on a database of controls (191), bacterial pneumonia
(54), tuberculosis (57) and viral pneumonia (20), about 89%
accuracy was obtained. Likewise, interpretable results were
reported in terms of large correlations between the saliency
maps’ activation zones and the radiological findings found
in the XR images. The authors also indicate that when the
lung segmentation approach was not considered, the system’s
accuracy decreased to about 80%. In [34], 2D curvelets transformations were used to extract features from XR images. A
feature selection algorithm based on meta-heuristic was used
to find the most relevant characteristics, while a CNN model
based on EfficientNet-B0 was used for classification. Experiments were carried out in a database of 1, 341 controls, 219
COVID-19, and 1, 345 viral pneumonia images, and 99%
classification accuracy was achieved with the proposed
approach. Multiclass and hierarchical classification of different types of diseases producing pneumonia (with 7 labels and
14 label paths), including COVID-19, were explored in [35].
Since the database of 1, 144 XR images was heavily imbalanced, different resampling techniques were considered. By
following a transfer-learning approach based on a CNN architecture to extract features, and a hold-out validation with
5 different classification techniques, a macro-avg F1-Score of
0.65 and an F1-Score of 0.89 were obtained for the multiclass
and hierarchical classification scenarios, respectively. In [36],
a three-phases approach is presented: i) to detect the presence
of pneumonia; ii) to classify between COVID-19 and pneumonia; and, iii) to highlight regions of interest of XR images.
The proposed system utilized a database of 250 images of
COVID-19 patients, 2, 753 with other pulmonary diseases,
and 3, 520 controls. By using a transfer-learning system
based on VGG16, about 0.97 accuracy was reported. A
CNN-hierarchical approach using decision trees (based on
ResNet18) was presented in [37], on which a first tree classified XR images into the normal or pathological classes;
the second identified tuberculosis; and the third COVID-19.
Experiments were carried out on 3 partitions obtained after
having gathered images from different sources and data augmentation. The accuracy for each decision tree –starting from
the first– was about 98%, 80%, and 95%, respectively.
A. ISSUES AFFECTING RESULTS IN THE LITERATURE
Table 1 presents a summary of state of the art in the automatic detection of COVID-19 based on XR images and deep
learning. Despite the excellent results reported, the review
reveals that some of the proposed systems suffer from certain
shortcomings that affect the conclusions extracted in their
respective studies, limiting the translational possibilities to
the clinical environment. Likewise, variability factors have
not been deeply studied in these papers and their study can
be regarded as necessary.
For instance, one of the issues that affect most of the
reviewed systems to detect COVID-19 from plain chest XR
images is the use of very limited datasets, which compromises
their generalization capabilities.
Indeed, to date and from the authors’ knowledge, the
paper employing the largest database of COVID-19 considers
1, 525 XR images gathered from different sources. However,
912 images belong to a data augmented repository, which
does not include additional information about the initial number of files or the number of augmented images. In general
terms, most of the works employ less than 300 COVID-19
XR images, having systems that use as few as 50 images.
However, this is understandable given that some of these
works were published during the onset of the pandemics when
the number of available registers was limited.
On the other hand, a good balance in the patients’ age is
considered essential to avoid the model to learn age-specific
features. However, several previous works have used XR
images from children to populate the pneumonia class.1 This
might be biasing the results given the age differences of
COVID-19 patients.
Despite many works in the literature report a good performance in detecting COVID-19, most of the approaches follow
1First efforts used the RSNA Pneumonia Detection Challenge dataset,
which is focused on the detection of pneumonia cases in children.
https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview
VOLUME 8, 2020 226815J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 1. Summary of the literature in the field.
a brute force approach exploiting deep learning’s potentiality
to correlate with the outputs (i.e., the class labels) but provide
low interpretability and explainability of the process. It is
unclear if the good results are due to the system’s actual
capability to extract information related to the pathology or
because it leart other aspects during training that are biasing
and compromising the results. As a matter of example, just
one of the studies reported in the literature follows a strategy that forces the network to focus on the most significant
areas of interest for COVID-19 detection [33]. It does so by
proposing a methodology based on semantic segmentation of
the lungs. In the remaining cases, it is unclear if the models
are analyzing the lungs or if they are categorizing given
any other information available, which might be interesting
for classification purposes but might lack diagnostic interest. This is relevant, as in all the analyzed works in literature, pneumonia and controls classes come from a certain
repository, whereas others such as COVID-19 comes from
a combination of sources and repositories. Having classes
generated in different conditions might undoubtedly affect
the results, and as such, a critical study about this aspect is
needed. In the same line, other variability issues such as the
sensor technology employed, the type of projection used, the
sex of the patients, and even age, require a thorough study.
Finally, the literature review revealed that most of the
published papers showed excellent correlation with the disease but low interpretability and explainability (see Table 1).
Indeed, it is often more desirable in clinical practice to
obtain interpretable results that correlate with pathological
conditions or a particular demographic or physiological variable than a black box system that yields a binary or a multiclass decision. From the revision of literature, only [33] and
[32] partially addressed this aspect. Thus, further research on
this topic is needed.
With these ideas in mind, this paper addresses these aspects
by training and testing with a wide corpus of RX images,
proposing and comparing two strategies to preprocess the
images, analyze the effect of some variability factors, and
provide some insights to more explainable and interpretable
results. The primary goal is to present a critical overview
of these aspects since they might be affecting the modeling
capabilities of the deep learning systems for the detection of
COVID-19.
III. METHODOLOGY
The design methodology is presented in the following
section. The procedure followed to train the neural network
is described first, along with the process that was followed to
create the dataset. The network and the source code to train
it are available at https://github.com/jdariasl/COVIDNET, so
results can be readily reproduced by other researchers.
A. THE NETWORK
The core of the system is a deep CNN based on the
COVID-Net2 proposed in [17]. Some modifications were
2Following the PyTorch implementation available at
https://github.com/IliasPap/COVIDNet
226816 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
made to include regularization components in the last two
dense layers and a weighted categorical cross-entropy loss
function to compensate the class imbalance. The network
structure was also refactored to allow gradient-based localization estimations [38], which are used after training in the
search for an explainable model.
The network was trained with the corpus described in III-B
using the Adam optimizer with a learning rate policy: the
learning rate decreases when learning stagnates for some time
(i.e., ’patience’). The following hyperparameters were used
for training: learning rate = 2
-5, number of epochs = 24,
batch size = 32, factor = 0.5, patience = 3. Furthermore,
data augmentation for pneumonia and COVID-19 classes was
leveraged with the following augmentation types: horizontal
flip, Gaussian noise with a variance of 0.015, rotation, elastic
deformation, and scaling. The variant of the COVID-Net
was built and evaluated using the PyTorch library [39]. The
CNN features from each image are concatenated by a flatten
operation, and the resulting feature map is fed to three fully
connected layers to generate a probability score for each
class. The first two fully connected layers include dropout
regularization of 0.3 and ReLU activation functions. Dropout
was necessary because the original network tended to overfit
since the very beginning of the training phase.
The network’s input layer rescales the images keeping the
aspect ratio, with the shortest dimension scaled to 224 pixels.
Then, the input image is cropped to a square of 224 × 224
pixels located in the center of the image. Images are normalized using a z-score function with parameters mean =
[0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225], for
each of the three RGB channels respectively. Even though we
are working with grayscale images, the network architecture
was designed to be pre-trained on a general-purpose database
including colored images; this characteristic was kept in case
it would be necessary to use some transfer learning strategy
in the future.
The network’s output layer provides a score for each of
the three classes (i.e. control, pneumonia, or COVID-19),
which is converted into three probability estimates –in the
range [0, 1]– using a softmax activation function. The class
membership’s final decision is made according to the highest
of the three probability estimates obtained.
B. THE CORPUS
The corpora used in the paper have been compiled from a set
of Posterior-Anterior (PA) and Anterior-Posterior (AP) XR
images from different public sources. The compilation contains images from participants without any observable pathology (controls or no findings), pneumonia, and COVID-19
cases. After the compilation, two subsets of images were
generated, i.e., training and testing. Table 2 contains the
number of images per subset and class. Overall, the corpus
contains more than 70, 000 XR images, including more than
8, 500 images belonging to COVID-19 patients.
The repositories of XR images employed to create the corpus used in this paper are presented next. Most of these conTABLE 2. Number of images per class for training and testing subsets.
tain solely registers of controls and pneumonia patients. Only
the most recent repositories include samples of COVID-19
XR images. In all cases, the annotations were made by a
specialist as indicated by the authors of the repositories.
The COVID-19 class is modelled compiling images coming from three open data collection initiatives: HM Hospitales COVID [40], BIMCV-COVID19 [41] and Actualmed
COVID-19 [42] chest XR datasets. The final result of the
compilation process is a subset of 8, 573 images from more
than 3, 600 patients at different stages of the disease.3
Table 3 summarizes the most significant characteristics of
the datasets used to create the corpus, which is presented next:
1) HM HOSPITALES COVID-19 DATASET
This dataset was compiled by HM Hospitals [40]. It contains all the available clinical information about anonymous
patients with the SARS-CoV-2 virus treated in different centers belonging to this company since the beginning of the
pandemic in Madrid, Spain.
The corpus contains the anonymized records of 2, 310
patients and includes several radiological studies for each
patient corresponding to different stages of the disease. A
total of 5, 560 RX images are available in the dataset, with
an average of 2.4 image studies per subject, often taken in
intervals of two or more days. The histogram of the patients’
age is highly coherent with the demographics of COVID-19
in Spain (see Table 3 for more details).
Only patients with at least one positive PCR test or positive
immunological tests for SARS-CoV-2 were included in the
study. The Data Science Commission and the Research Ethics
Committee of HM Hospitales approved the current research
study and the data for this purpose.
2) BIMCV COVID19 DATASET
BIMCV COVID19 dataset [41] is a large dataset with chest
radiological studies (XR and CT) of COVID-19 patients
along with their pathologies, results of PCR and immunological tests, and radiological reports. It was recorded by the
Valencian Region Medical Image Bank (BIMCV) in Spain.
The dataset contains the anonymized studies of patients with
at least one positive PCR test or positive immunological tests
for SARS-CoV-2 between February 26th and April 18th,
2020. The corpus is composed of 3, 013 XR images, with an
average of 1.9 image studies per subject, taken in intervals
of approximately two or more days. The histogram of the
patients’ age is highly coherent with the demographics of
3Figures at the time the datasets were downloaded. The datasets are still
open, and more data might be available in the next future.
VOLUME 8, 2020 226817J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 3. Demographic data of the datasets used. Only those labels confirmed are reported.
COVID-19 in Spain (Table 3). Only patients with at least
one positive PCR test or positive immunological tests for
SARS-Cov-2 were included in the study.
3) ACTUALMED SET (ACT)
The actualmed COVID-19 Chest XR dataset initiative [42]
contains a series of XR images compiled by Actualmed and
Universitat Jaume I (Spain). The dataset contains COVID-19
and control XR images, but no information is given about the
place or date of recording and/or demographics. However, a
metadata file is included. It contains an anonymized descriptor to distinguish among patients and information about the
XR modality, type of view, and the class to which the image
belongs.
4) CHINA SET - THE SHENZHEN SET
The set was created by the National Library of Medicine,
Maryland, USA, in collaboration with the Shenzhen No.3
People’s Hospital at Guangdong Medical College in Shenzhen, China [43].
The dataset contains normal and abnormal chest XR with
manifestations of tuberculosis and includes associated radiologist readings.
5) THE MONTGOMERY SET
The National Library of Medicine created this dataset in
collaboration with the Department of Health and Human
Services, Montgomery County, Maryland, USA. It contains
data from XR images collected under Montgomery County’s
tuberculosis screening program [43], [44].
6) ChestX-ray8 DATASET (CRX8)
The ChestX-ray8 dataset [45] contains 12, 120 images from
14 common thorax disease categories from 30, 805 unique
patients, compiled by the National Institute of Health (NIH).
For this study, the images labeled with ’no radiological findings’ were used to be part of the control class, whereas the
images annotated as ’pneumonia’ were used for the pneumonia class.
7) CheXpert DATASET
CheXpert [46] is a dataset of XR images created for an
automated evaluation of medical imaging competitions and
contains chest XR examinations carried out in Stanford Hospital during 15 years. For this study, we selected 4, 623 pneumonia images using those annotated as ’pneumonia’ with
and without additional comorbidity. COVID-19 never caused
these comorbidities. The motivation to include pneumonia
with comorbidities was to increase the number of pneumonia
examples in the final compilation for this study, increasing
this cluster’s variability.
8) MIMIC-CXR DATABASE
MIMIC-CXR [47] is an open dataset complied from 2011 to
2016, and comprising de-identified chest RX from patients
admitted to the Beth Israel Deaconess Medical Center. In
our study, we employed the images for the pneumonia class.
The labels were obtained from the agreement of the two
methods indicated in [47]. The dataset reports no information
about gender or age; thus, we assume that the demographics are similar to those of CheXpert dataset and those of
pneumonia [48].
C. IMAGE PRE-PROCESSING
XR images were converted to uncompressed grayscale ’.png’
files, encoded with 16 bits, and preprocessed using the
DICOM WindowCenter and WindowWidth details (when
needed). All images were converted to a Monochrome 2
photometric interpretation. Initially, the images were not rescaled to avoid loss of resolution in later processing stages.
Only AP and PA views were selected. No differentiation
was made between erect, either standing or sitting, or decubitus. This information was inferred by a careful analysis of
the DICOM tags and required manual checking due to certain
labeling errors.
D. EXPERIMENTS
The corpus collected from the aforementioned databases was
processed to compile three different datasets of equal size
to the initial one. Each of these datasets was used to run a
different set of experiments.
1) EXPERIMENT 1. RAW DATA
The first experiment was run using the raw data extracted
from the different datasets. Each image is kept with the original aspect ratio. Only a histogram equalization was applied.
226818 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
2) EXPERIMENT 2. CROPPED IMAGE
The second experiment consists of preprocessing the images
by zooming in, cropping to a squared region of interest, and
resizing to a squared image (aspect ratio 1 : 1). The process
is summarized in the following steps:
1) Lungs are segmented from the original image using
a U-Net semantic segmentation algorithm.4 The algorithm used reports Intersection-Over-Union (IoU) and
Dice similarity coefficient scores of 0.971 and 0.985
respectively.
2) A black mask is extracted to identify the external
boundaries of the lungs.
3) The mask is used to create two sequences, adding
the grey levels of the rows and columns respectively.
These two sequences provide four boundary points,
which define two segments of different lengths in the
horizontal and vertical dimensions.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated with the lungs,
taking advantage of the higher added values outside the
lungs (Fig. 2). The process to obtain the squared region
requires identifying the middle point of each of the
identified segments and cropping in both dimensions
using the length of the longest of these two segments.
5) The original image is cropped with a squared template
placed in the centre of the matrix using the information
obtained in the previous step. No mask is placed over
the image.
6) Histogram equalization of the image obtained.
This process is carried out to decrease the variability of the
data, to make the training process of the network simpler, and
to ensure that the region of significant interest is in the centre
of the image with no areas cut.
3) EXPERIMENT 3. LUNG SEGMENTATION
The third experiment consists of preprocessing the images by
masking, zooming in, cropping to a squared region of interest,
and resizing to a squared image (aspect ratio 1 : 1). The
process is summarized in the following steps:
1) Lungs are segmented from the original image using
the same semantic segmentation algorithm used in
experiment 2.
2) An external black mask is extracted to identify the
external boundaries of the lungs.
3) The mask is used to create two sequences, adding the
grey levels of the rows and columns respectively.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated to the lungs,
taking advantage of the higher added values outside
them (Fig. 2).
4Following the Keras implementation available at https://github.com
/imlab-uiip/lung-segmentation-2d
FIGURE 2. Identification of the squared region of interest. Plots in the top
and left represent the normalized accumulated gray level in the vertical
and horizontal dimension respectively.
5) The original image is cropped with a squared template
placed in the center of the image.
6) The mask is dilated with a 5 × 5 pixels kernel, and it is
superimposed to the image.
7) Histogram equalization is applied only to the segmented area (i.e. the area corresponding to the lungs).
This preprocessing makes the training of the network much
simpler and forces the network to focus the attention on
the lungs region, removing external characteristics –like the
sternum– that might influence the obtained results.
E. IDENTIFICATION OF THE AREAS OF SIGNIFICANT
INTEREST FOR THE CLASSIFICATION
The areas of significant interest used by the CNN for
discrimination purposes are identified using a qualitative
analysis based on a Gradient-weighted Class Activation
Mapping (Grad-CAM) [38]. This is an explainability method
that serves to provide insights about the manners on how
deep neural networks learn, pointing to the most significant
areas of interest for decision-making purposes. The method
uses the gradients of any target class to flow until the final
convolutional layer, and to produce a coarse localization map
which highlights the most important regions in the image
identifying the class. The result of this method is a heat map
like those presented in Fig. 1, in which the colour encodes the
importance of each pixel in differentiating among classes.
IV. RESULTS
The model has been quantitatively evaluated computing
the test Positive Predictive Value (PPV), Recall, F1-score
(F1), Accuracy (Acc), Balanced Accuracy (BAcc), Geometric
Mean Recall (GMR) and Area Under the ROC Curve (AUC)
for each of the three classes in the corpus previously described
in section III-B. The performance of the models is assessed
using an independent testing set, which has not been used
VOLUME 8, 2020 226819J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 4. Performance measures for the three experiments considered in the paper.
FIGURE 3. ROC curves and confusion matrices for each one of the experiments, considering each one of the classes separately. Top: ROC curves. Bottom:
Normalized confusion matrices. Left: Original images (experiment 1). Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
during development. A 5-folds cross-validation procedure
has been used to evaluate the obtained results (Training/Test
balance: 90/10 %). The performance of the CNN network on
the three experiments considered in this paper is summarized
in Table 4. Likewise, the ROC curves per class for each of the
experiments, and the corresponding confusion matrices are
presented in Fig. 3. The global ROC curve displayed in Fig. 4
for each experiment summarizes the global performance of
the experiments.
Considering experiment 1, and although slightly higher for
controls, the detection performance remains almost similar
for all classes (the PPV ranges from 91-93%) (Table 4). The
remaining measures per class follow the same trend, with
similar figures but better numbers for the controls. ROC
curves and confusion matrices of Fig. 3a and Fig. 3d point out
that the largest source of confusion for COVID-19 is the pneumonia class. The ROC curves for each one of the classes reach
in all cases AUC values larger than 0.99, which, in principle
is considered excellent. In terms of global performance, the
system achieves an Acc of 91% and a BAcc of 94% (Table 4).
This is also supported by the average ROC curve of Fig. 4,
which reveals the excellent performance of the network and
226820 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 4. Average ROC curves for each experiment, including AUC values.
the almost perfect behaviour of the ROC curve. Deviations
are small for the three classes.
When experiment 2 is considered, a decrease in the performance per class is observed in comparison to experiment 1.
In this case, the PPV ranges from 81-93% (Table 4), with a
similar trend for the remaining figures of merit. ROC curves
and confusion matrices in Fig. 3a and Fig. 3d report AUC
values in the range 0.96-0.99, and an overlapping of the
COVID-19 class mostly with pneumonia. The global performance of the system -presented in the ROC curve of Fig. 4
and Table 4- yields an AUC of 0.98, an Acc of 87% and a
BAcc of 81%.
Finally, for experiment 3, PPV ranges from 78% − 96%
(Table 4). In this case, the results are slightly worse than those
of experiment 2, with the COVID-19 class presenting the
worse performance among all the tests. According to Fig. 3c,
AUCs range from 0.94 to 0.98. Confusion matrix in Fig. 3f
reports a large level of confusion in the COVID-19 class
being labelled as pneumonia 18% of the times. In terms of
global performance, the system reaches an Acc of 91% and a
BAcc of 87% (Table 4). These results are consistent with the
average AUC of 0.97 shown in Fig. 4.
A. EXPLAINABILITY AND INTERPRETABILITY OF THE
MODELS
The regions of interest identified by the network were analyzed qualitatively using Grad-CAM activation maps [38].
Results shown by the activation maps, permit the identification of the most significant areas in the image, highlighting
the zones of interest that the network is using to discriminate.
In this regard, Fig. 1, presents examples of the Grad-CAM
of a control, a pneumonia, and a COVID-19 patient, for each
of the three experiments considered in the paper. It is important to note that the activation maps are providing overall
information about the behaviour of the network, pointing to
the most significant areas of interest, but the whole image is
supposed to be contributing to the classification process to a
certain extent.
The second row in Fig. 1 shows several prototypical results
applying the Grad-CAM techniques to experiment 1. The
examples show the areas of significant interest for a control,
pneumonia and COVID-19 patient.
The results suggest that the detection of pneumonia or
COVID-19 is often carried out based on information that is
outside the expected area of interest, i.e. the lung area. In the
examples provided, the network focuses on the corners of the
XR image or in areas around the diaphragm. In part, this is
likely due to the metadata which is frequently stamped on
the corners of the XR images. The Grad-CAM plots corresponding to the experiment 2 (third row of Fig. 1), indicates
that the model still points towards areas which are different
from the lungs, but to a lesser extent. Finally, the Grad-CAM
of experiment 3 (fourth row of Fig. 1) presents the areas of
interest where the segmentation procedure is carried out. In
this case, the network is forced to look at the lungs, and
therefore this scenario is supposed to be more realistic and
more prone to generalizing as artifacts that might bias the
results are somehow discarded.
On the other hand, for visualization purposes, and in order
to interpret the separability capabilities of the system, a t-SNE
embedding is used to project the high dimensional data of the
layer adjacent to the output of the network, to a 2-dimensional
space. Results are presented in Fig. 5 for each of the three
experiments considered in the paper.
Fig. 5 indicates that a good separability exists for all
the classes in both training and testing data, and for all
experiments. The boundaries of the normal cluster are very
well defined in the three experiments, whereas pneumonia
and COVID-19 are more spread, overlapping with adjacent
classes.
In general terms, the t-SNE plots demonstrate the ability
of the network to learn a mapping from the input data to the
desired labels. However, despite the shape differences found
for the three experiments, no additional conclusions can be
extracted.
B. POTENTIAL VARIABILITY FACTORS AFFECTING THE
SYSTEM
There are several variability factors which might be biasing
the results, namely: the projection (PA vs. AP); the technology of the detector (Computed Radiography (CR) vs.
Digital Radiography (DX)); the gender of the patients; the
age; potential specificities of the dataset; or having trained
with several images per patient.
The use of several images per patient represents a certain
risk of data leak in the COVID-19 class due to its underlying
imbalance. However, our initial hypothesis is that using several images per COVID-19 patient but obtained at different
instants in time (with days of difference), would increase the
variability of the dataset, and thus that source of bias would
be disregarded. Indeed, the evolution of the associated lesions
often found in COVID-19 is considered fast, in such a manner
that very different images are obtained in a time interval
as short as one or two days of the evolution. Also, since
VOLUME 8, 2020 226821J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 5. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
TABLE 5. Performance measures considering the XR projection (PA/AP).
every single exploration is framed differently, or sometimes
even taken with different machines and/or projections, the
potential bias is expected to be minimized.
Concerning the type of projection, and to evaluate its
effectiveness, the system has been studied taking into
account this potential variability factor, which is considered to be one of the most significant. In particular,
Table 5, presents the outcomes after accounting for the
influence of the XR projection (PA/AP) in the performance of the system. In general terms, the system demonstrates consistency with respect to the projection used,
and differences are mainly attributable to smaller training and testing sets. However, significant differences are
shown for projection PA in class COVID-19/experiment 3,
decreasing the F1 up to 65.61%. The reason for the
unexpected drop in performance is unknown, but likely
226822 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 6. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3). Labels correspond to data sets and classes.
attributable to an underrepresented class in the corpus (see
Table 3).
Besides, Table 6 shows –for the three experiments under
evaluation and for the COVID-19 class– the error distribution with respect to the sex of the patient, technology of
the detector, dataset and projection. For the four variability
factors enumerated, results show that the error distribution
committed by the system follows –with minor deviations– the
existing proportion of the samples in the corpus. These results
suggest that there is no clear bias with respect to these potential variability factors, at least for the COVID-19 class which
is considered the worst-case due to its underrepresentation.
Similar results would be expected for control and pneumonia
classes, but these results are not provided due to the lack of
certain labels in some of the datasets used (see Table 3).
Concerning age, the datasets used are reasonably well
balanced (Table 3), but with a certain bias in the normal class:
COVID-19 and pneumonia classes have very similar average
ages, but controls have a lower mean age. Our assumption
has been that age differences are not significantly affecting
the results, but the mentioned difference might explain why
the normal cluster in Fig. 5 is less spread than the other two.
In any case, no specific age biases have been found in the
errors committed by the system.
An additional study was also carried out to evaluate the
influence of potential specificities of the different datasets
used to compile the corpus (i.e. the variability of the results
with respect to the datasets merged to build the corpus). This
variability factor is evaluated in Fig. 6 using different t-SNE
plots (one for each experiment in a similar way than in Fig. 5)
but differentiating the corresponding cluster for each dataset
and class.
Results for the different datasets and classes are clearly
merged or are adjacent in the same cluster. However, several datasets report a lower variability for certain classes
(i.e. variability in terms of scattering). This is especially
clear in Chexpert and NIH pneumonia sets, which are successfully merged with the corresponding class but appear
VOLUME 8, 2020 226823J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 6. Percentage of testing samples and error distribution with
respect to several potential variability factors for the COVID-19 class.
(% in hits represents the percentage of samples of every factor under
analysis in the correctly predicted set).
clearly clustered, suggesting that these datasets have certain
unknown specific characteristics different to those of the
complementary datasets. The model has been able to manage
this aspect but is a factor to be analyzed in further studies.
V. DISCUSSION AND CONCLUSION
This study evaluates a deep learning model for the detection
of COVID-19 from RX images. The paper provides additional evidence to the state of the art, supporting the potential of deep learning techniques to accurately categorize XR
images corresponding to control, pneumonia, and COVID-19
patients (Fig. 1). These three classes were chosen under the
assumption that they can support clinicians in making better
decisions, establishing potential differential strategies to handle patients depending on their cause of infection [17]. However, the main goal of the paper was not to demonstrate the
suitability of deep learning for categorizing XR images but to
make a thoughtful evaluation of the results and the different
preprocessing approaches, searching for better explainability
and interpretability of the results while providing evidence of
potential effects that might bias results.
The model relies on the COVID-Net network, which has
served as a basis for the developing a more refined architecture. This network has been chosen due to its tailored
characteristics and given the previous good results reported
by other researchers. The COVID-Net was trained with a
corpus compiled using data gathered from different sources:
the control and pneumonia classes –with 49, 983 and 24, 114
samples respectively– were collected from the ACT, Chinaset, Montgomery, CRX8, CheXpert, and MIMIC datasets;
and the COVID-19 class was collected from the information
available at the BIMCV, ACT, and HM Hospitales datasets.
Although the COVID-19 class only contains 8, 573 chest
RX images, the developers of the data sources are continuously adding new cases to the respective repositories, so the
number of samples is expected to grow in the future. Despite
the unbalance of the COVID-19 class, up to date, and to the
authors’ knowledge, this is the most extensive compilation of
COVID-19, images based on open repositories. Despite that,
the number of COVID-19 RX images is still considered small
compared to the other two classes. Therefore, it was necessary
to compensate for the class imbalance by modifying the
network architecture, including regularization components in
the last two dense layers. To this end, a weighted categorical
cross-entropy loss function was used to compensate for this
effect. Likewise, data augmentation techniques were used for
pneumonia and COVID-19 classes to generate more samples
for these two underrepresented classes automatically.
We stand that automatic diagnosis is much more than a
classification exercise, meaning that many factors have to be
considered to bring these techniques to clinical practice. In
this respect, there is a classic assumption in the literature
that the associated heat maps –calculated with Grad-CAM
techniques- provide a clinical interpretation of the results,
which is unclear in practice. In light of the results shown in
the heat maps depicted in Fig. 1, we show that experiment 1
must be carefully interpreted. Despite the high-performance
metrics obtained in experiment 1, the significant areas identified by the network are pointing towards certain areas with
no clear interest for the diagnosis, such as corners of the
images, the sternum, clavicles, etc. From a clinical point of
view, this is biasing the results. It means that other approaches
are necessary to force the network to focus on the lung
area. In this respect, we have developed and compared the
results with two preprocessing approaches based on cropping
the images and segmenting the lung area (experiment 2 and
experiment 3). Again, given the heat maps corresponding
to experiment 2, we also see similar explainability problems to those enumerated for experiment 1. The image area
reduction proposed in experiment 2 significantly decreases
the system’s performance by removing the metadata that
usually appears in the top left or right corner. This technique
removes areas that can help categorize the images but have
no interest from the diagnosis point of view. However, while
comparing experiments 2 and 3, performance results improve
in the third approach, which focuses on the same region
of interest but with a mask that forces the network to see
only the lungs. Thus, results obtained in experiments 2 and
3 suggest that eliminating the needless features extracted
from the background or non-related regions improves the
results. Besides, the third approach (experiment 3) provides
more explainable and interpretative results, with the network
focusing its attention only on the area of interest for the
disease. The gain in explainability of the last method is still
at the cost of a lower accuracy with respect to experiment
1, but the improvement in explainability and interpretability
is considered critical in translating these techniques to the
clinical setting. Despite the decrease in performance, the
proposed method in experiment 3 has provided promising
results, with an 91.53% Acc, 87.6 BAcc, 87.37% GMR,
and 0.97 AUC.
Performance results obtained are in line with those presented in [17], which reports sensitivities of 95, 94, and 91
for control, pneumonia, and COVID-19 classes respectively
–also modeling with the COVID-Net in similar conditions as
our experiment 1–, but training with a much smaller corpus
of 358 RX images from 266 COVID-19 patients, 8, 066
226824 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
controls, and 5, 538 RX images belonging to patients with
different types of pneumonia.
The paper also critically evaluates the effect of several
variability factors that might compromise the network’s performance. For instance, the projection (PA/AP) effect was
evaluated by retraining the network and checking the outcomes. This effect is important, given that PA projections are
often practiced in erect positions to observe pulmonary ways
better and are expected to be examined in healthy or slightly
affected patients. In contrast, AP projections are often preferred for patients confined in bed, and as such are expected
to be practised in the most severe cases. Since AP projections
are common in COVID-19 patients, in these cases, more
blood will flow to the lungs’ apices than when standing;
thus, not considering this variability factor may result in
a misdiagnosis of pulmonary congestion [49]. Indeed, the
obtained results have highlighted the importance of taking
into account this factor when designing the training corpus,
as PPV decreases for PA projections in our experiments with
COVID-19 images. This issue is probably due to an underrepresentation of this class (Table 5), which would require a
further specific analysis when designing future corpora.
On the other hand, results have shown that the error distribution for the COVID-19 class follows a similar proportion to
the percentage of images available in the corpus while categorizing by gender, the detector’s technology, the projection,
and the dataset. These results suggest no significant bias with
respect to these potential variability factors, at least for the
COVID-19 class, which is the less represented one.
An analysis of how the clusters of classes were distributed
is also presented in Fig. 5, demonstrating how each class
is differentiated. These plots help identify existing overlap
among classes (especially that present between pneumonia
and COVID-19, and to a lesser extent between controls and
pneumonia). Similarly, since the corpus used to train the
network was built around several datasets, a new set of t-SNE
plots was produced, but differentiating according to each
of the subsets used for training (Fig. 6). This test served
to evaluate the influence of each dataset’s potential specific
characteristics in the training procedure and, hence, possible
sources of confusion that arise due to particularities of the
corpora that are tested. The plots suggest that the different
datasets are correctly merged in general terms, but with some
exceptions. These exceptions suggest that there might be
certain unknown characteristics in the datasets used, which
cluster the images belonging to the same dataset together.
The COVID-Net has also demonstrated being a good starting point for the characterization of the disease employing XR
images. Indeed, the paper’s outcomes suggest the possibility
to automatically identify the lung lesions associated with
a COVID-19 infection (see Fig.1) by analyzing the GradCAM mappings of experiment 3, providing an explainable
justification about the way the network works. However,
the interpretation of the heat maps obtained for the control
class must be carried out carefully. Whereas the areas of
significant interest for pneumonia and COVID-19 classes are
supposed to point to potential lesions (i.e. with higher density
or with different textures in contrast to controls), the areas of
significant interest for the classification in the control group
are supposed to correspond to something complementary,
potentially highlighting less dense areas. Thus, in the control
class, these areas do not point towards any kind of lesion in
the lungs.
Likewise, the system developed in experiment 3 attains
comparable results to those achieved by a human evaluator
differentiating pneumonia from COVID-19. In this respect,
the ability of seven radiologists to correctly differentiate
pneumonia and COVID-19 from XR images was tested in
[50]. The results indicated that the radiologists achieved sensitivities ranging from 97% to 70% (mean 80%), and specificities ranging from 7% to 100% (mean 70%). These results
suggest that AI systems have a potential use in a supervised
clinical environment.
COVID-19 is still a new disease, and much remains
to be studied. The use of deep learning techniques
would potentially help understand the mechanisms on
how the SARS-CoV2 attacks the lungs and alveoli and
how it evolves during the different stages of the disease. Despite there is some empirical evidence on the
evolution of COVID-19 –based on observations made by
radiologists [6]–, the employment of automatic techniques
based on machine learning would help analyze data massively, guide research onto certain paths, or extract conclusions faster. Nevertheless more interpretable and explainable
methods are required to go one step forward.
Inline with the previous comment, and based on the empirical evidence respecting the evolution of the disease, it has
been stated that during the early stages of the disease, groundglass shadows, pulmonary consolidation and nodules, and
local consolidation in the centre with peripheral groundglass density are often observed. However, once the disease
evolves, the consolidations reduce their density resembling
a ground-glass opacity that can derive in a ‘‘white lung’’ if
the disease worsens or in a minimization of the opacities
if the course of the disease improves [6]. In this manner,
if any of these characteristic behaviours are automatically
identified, it would be possible to stratify the disorder’s stage
according to its severity. Computing the extent of the groundglass opacities or densities would also be useful to assess the
severity of the infection or to evaluate the evolution of the
disease. In this regard, the infection extent assessment has
been previously tested in other CT studies of COVID-19 [51]
using manual procedures based on observation of the images.
Solutions like the one discussed in this paper are intended
to support a much faster diagnosis and alleviate radiologists and specialists’ workload, but not to substitute their
assessment. A rigorous validation would open the door to
integrating these algorithms in desktop applications or cloud
servers for its use in the clinic environment. Thus, its use,
maintenance, and update would be cost-effective and straightforward and would reduce healthcare costs and improve
diagnosis response time and accuracy. [52]. In any case,
VOLUME 8, 2020 226825J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
the deployment of these algorithms is not exempt from
controversies: hosting the AI models in a cloud service
would entail uploading the images that might be subject
to national and international regulations and constraints to
ensure privacy [53].



NEW_PAPER


Received October 21, 2020, accepted November 16, 2020, date of publication November 24, 2020,
date of current version December 9, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3040245
A Two-Dimensional Sparse Matrix Profile
DenseNet for COVID-19 Diagnosis
Using Chest CT Images
QIAN LIU 1,2, CARSON K. LEUNG 2
, (Senior Member, IEEE), AND PINGZHAO HU 1,2,3
1Department of Biochemistry and Medical Genetics, University of Manitoba, Winnipeg, MB R3E 0J9, Canada
2Department of Computer Science, University of Manitoba, Winnipeg, MB R3T 2N2, Canada
3Research Institute in Oncology and Hematology, CancerCare Manitoba, Winnipeg, MB R3E 0J9, Canada
Corresponding author: Pingzhao Hu (pingzhao.hu@umanitoba.ca)
This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).
ABSTRACT COVID-19 is a newly identified disease, which is very contagious and has been rapidly
spreading across different countries around the world, calling for rapid and accurate diagnosis tools. Chest
CT imaging has been widely used in clinical practice for disease diagnosis, but image reading is still a
time-consuming work. We aim to integrate an image preprocessing technology for anomaly detection with
supervised deep learning for chest CT imaging-based COVID-19 diagnosis. In this study, a matrix profile
technique was introduced to CT image anomaly detection in two levels. At one-dimensional level, CT images
were simply flatted and transformed to a one-dimensional vector so that the matrix profile algorithm could be
implemented for them directly. At two-dimensional level,a matrix profile was calculated in a sliding window
way for every segment in the image. An anomaly severity score (CT-SS) was calculated, and the difference
of the CT-SS between the COVID-19 CT images and Non-COVID-19 CT images was tested. A sparse
anomaly mask was calculated and applied to penalize the pixel values of each image. The anomaly weighted
images were then used to train standard DenseNet deep learning models to distinguish the COVID-19 CT
from Non-COVID-19 CT images. A VGG19 model was used as a baseline model for comparison. Although
extra finetuning needs to be done manually, the one-dimensional matrix profile method could identify the
anomalies successfully. Using the two-dimensional matrix profiling method, CT-SS and anomaly weighted
image can be successfully generated for each image. The CT-SS significantly differed among the COVID-19
CT images and Non-COVID-19 CT images (p − value < 0.05). Furthermore, we identified a potential
causal association between the number of underlying diseases of a COVID-19 patient and the severity
of the disease through statistical mediation analysis. Compared to the raw images, the anomaly weighted
images showed generally better performance in training the DenseNet models with different architectures for
diagnosing COVID-19, which was validated using two publicly available COVID-19 lung CT image datasets.
The metric Area Under the Curve(AUC) on one dataset were 0.7799(weighted)vs. 0.7391(unweighted),
0.7812(weighted) vs. 0.7410(unweighted), 0.7780(weighted) vs. 0.7399(unweighted), 0.7045(weighted)
vs. 0.6910(unweighted) for DenseNet121, DenseNet169, DenseNet201, and the baseline model VGG19,
respectively. The same trend was observed using another independent dataset. The significant results revealed
the critical value of using this existing state-of-the-art algorithm for image anomaly detection. Furthermore,
the end-to-end model structure has the potential to work as a rapid tool for clinical imaging-based diagnosis.
INDEX TERMS Rare pattern mining, matrix profile, COVID-19 CT images, risk score, DenseNet, mediation
analysis.
I. INTRODUCTION
Unsupervised anomaly detection using rare pattern mining
is one of the most intuitive medical imaging–based disease
The associate editor coordinating the review of this manuscript and
approving it for publication was Yudong Zhang .
diagnosis methods [1]. People without medical expertise
could find an obvious lesion in a medical image if the lesion
is extremely different from other parts in the image. Actually,
even radiologists also read the images in that way. As the
most obvious lesion is so conspicuous that it can be noticed
immediately by radiologists at their first glance of the image.
213718 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
This step is unsupervised, and it depends only on the intrinsic
information in the image itself. Then using the normal human
sectional anatomy knowledge, radiologists could further tell
whether this lesion is critical or not [2].
COVID-19 is a newly identified disease that is very
contagious and has been rapidly spreading across different
countries around the world [3]. Common symptoms from
COVID-19 are fever, dry cough, but in more serious cases,
patients can experience difficulty in breathing [4]. At present,
the NA-PCR (Nucleic Acid Polymerase Chain Reaction)
testing is considered as the most effective, cheap and rapid
detection method of COVID-19. However, a bottleneck to use
this technique is that there are a short of supplies of NA-PCR
in some countries [5]. Several alternative methods have been
considered for individuals to test positive for COVID-19,
including CT (computed tomography) scans of the lungs.
Lung CT scanning is fast and easy to detect COVID-19.
As the number of infected patients increases exponentially,
it can be hard to provide testing scans for patients because of
the limited number of doctors. It is recommended that artificial intelligence (AI) systems can be developed to analyse the
lung CT scans of patients to determine COVID-19 status [6].
To build the AI system, we used a two-step strategy: detection and enhancement of CT image anomaly and modelling
of the anomaly enhanced CT images. For the first step,
we used a naïve two-dimensional sliding window approach
to calculate the matrix profile of the image. Summing up
this matrix profile could make an image-specific severity
score (SS) indicating the severity of the image anomalous.
This CT-SS can be computed automatically as compared to
the manually calculated CT-SS [7], [8], and it has the potential
to rapidly identify COVID-19 patients. At the same time,
the matrix profile could be easily used to generate a salience
map [9] for each CT image to detect lung anomaly. A saliency
map is a topographic map that represents visual saliency of
an image [10]. Overlapping the image and its salience map
could further give us a weighted CT image to enhance the
anomaly; For the second step, the weighted CT images could
be input into a deep convolutional neural network for further
classification or regression tasks. This naïve two-dimensional
method is easy to apply, but the benefits of those ultra-fast
Fourier algorithms developed by Keogh et al. [11] are lost
in this situation. To speed up the calculation, raw images
were pooled to a lower resolution and the stride of the sliding
window was set to the same as the length of the image
segment. In this way, the nearest neighbour, matrix profile,
and deep learning technologies were effectively integrated
together. The proposed algorithm was tested using two publicly available COVID-19/Non-COVID-19 lung CT image
sets [12], [13], respectively. Please be noted that the NonCOVID-19 group contains the images from both healthy
controls and other types of lung disease cases.
The main contribution of this study could be divided into
two parts. The first one is the innovative application of a
classic low-dimensional time-series rare pattern mining technique to unsupervised high-dimensional medical imaging
anomaly detection. Another contribution is the application of
dense deep learning networks for COVID-19 diagnosis using
the anomaly enhanced CT images.
II. RELATED WORK
Unsupervised rare pattern mining in medical imaging has
been proved to be beneficial [14], but most of the classic rare pattern mining techniques (Apriori [15], [16] based
and FP-Growth [17] based) cannot be directly applied to
image data as it is two dimensional with space-related
information [18]. There are several methods developed
for unsupervised image anomaly detection. According to
Ehret et al., these unsupervised methods could be classified
as nearest neighbour-based anomaly detection, clusteringbased anomaly detection, statistical anomaly detection, spectral anomaly detection, and information theoretic anomaly
detection [19]. In fact, if applied in a static image situation,
they all belong to the first category to some extent [1],
since they all measure certain distances and try to identify
the discord distances of data instances. The assumption of
the nearest neighbour-based anomaly detection in a static
image is that normal pixel segments are always similar to
each other. Therefore they have a close distance with their
nearest neighbours, while anomalies are dislike their closest
neighbours [20].
If the aforementioned assumption of the nearest neighbourbased anomaly detection holds, then the problem of image
anomaly detection can be transformed as a problem of scanning of a given segment (or window) of images and the
retrieval of the nearest neighbours of the scanned segments.
This is exactly the same as the definition of a similarity
join problem defined by Yeh et al. [11]: given a collection
of data objects, retrieve the nearest neighbours for every
object. To solve the problem, Keogh et al. proposed a new
data structure called matrix profile and developed a series of
matrix profile based algorithms to solve the similarity join
problem for time series data [11], [21]–[24]. A matrix profile
consists of two components: a distance profile and a profile
index. The distance profile is a vector of minimum Euclidean
distances among the subsequences within the time-series. The
profile index contains the index of subsequences’ first nearest
neighbours. In other words, the profile index is the location
of a subsequence’s most similar subsequence. In order to
apply the matrix profile technique to large databases, Fast
Fourier transform was introduced to make the matrix profile
algorithm ultra-fast, therefore it can be applied to big timeseries data without sacrificing the time efficacy [11], [25].
These algorithms were proved to be efficient for onedimensional time series data. However, matrix profile technique has not been introduced to high dimensional data, such
as two-dimensional image data.
Besides the limitation of matrix profile in highdimensional data, there are also lack of studies exploring
its integration with advanced machine learning techniques.
Although nearest neighbour is a successful long-standing
technique, and the matrix profile provides us a strategy using
VOLUME 8, 2020 213719Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
FIGURE 1. Workflow of the proposed study. CT-SS refers to CT-severity score.
nearest neighbour technique for the anomaly detection, it has
not been well integrated with current advanced deep learning
techniques. A recent work designed a model to use nearest
neighbour for identifying anomaly at the image set level [26].
In their model, a set of normal images were input into a deep
learning-based feature extractor for building a feature library.
Once a new image is arrived, it would undergo the same
feature extractor. Then the nearest distances of these features
extracted from the new image with those features stored in the
feature library will be computed. By verifying if the distance
is larger than a predefined threshold, they could determine if
the new image is normal or anomalous [26], [27]. However,
as we mentioned, this design is at image set level which
could not detect the segment level anomalies. Moreover, it is
actually a semi-supervised approach as it needs the label
information to build the feature library.
CT-severity score(CT-SS) was proposed by a study for
COVID-19 rapid diagnosis [7]. In order to obtain the CT-SS,
the authors need to manually measure and access the groundglass opacity, interstitial opacity, and air trapping ratio of
the lungs in the CT images. These three features are typical pneumonia symptoms, and different doctors may obtain
different values of them even using the same image. Therefore, although the CT-SS has been proved to be significantly associated with the COVID-19 severity, the extra
manual measurement burden added to the radiologists and
the potential bias of their expertise limits its application in
clinic practice. Another consideration is the lack of theoretical analysis of why CT-SS is associated with COVID-19
severity. It was reported that medical image phenotypes,
such as CT-SS, could work as the mediators of genetic
variations or other basic clinical characteristics’ effects on
disease outcomes [28], [29]. Therefore, mediation analysis
could be used to test the significance of the indirect causal
relationship among patient’s clinical characteristics, CT-SS,
and COVID-19 severity.
Although there are no many studies on deep learning nearest neighbour-based image anomaly detection, supervised
deep learning has been widely involved in COVID-19 diagnosis. There were a lot of deep convolutional neural networks
(CNN) proposed by different studies on COVID-19 diagnosis [12], [13], [30]–[33]. In this study, we propose a stateof-the-art end-to-end matrix profile - based DenseNet [34]
model for COVID-19 diagnosis. We also compare the performance of different DenseNet architectures and the basic convolutional architecture called VGG (Visual geometry Group
Network) [35].
III. DATA AND METHODS
The whole workflow is summarized in Fig. 1. The proposed
anomaly detection algorithm first preprocesses the raw CT
images using the matrix profile technique, the CT-SS and the
213720 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
anomaly weighted images are then calculated. For the CT-SS,
differential analysis and mediation analysis are performed to
explore its potential application to diagnosis for COVID-19
and its clinical interpretability. The anomaly weighted images
are finally applied to build DenseNet-based deep learning
models for COVID-19 diagnosis.
A. ANOMALY DETECTION
Assume a chest CT image can be defined as a matrix P of
pixel values pij,
P =



p11 p12 · · · p1m
p21 p22 · · · p2m
.
.
.
.
.
.
.
.
.
.
.
.
pn1 pn2 · · · pnm



(1)
where m is the width of P, and n is the height of P. i ranges
from 1 to m, and j ranges from 1 to n. In principle, there are
two approaches to detect anomalies in the chest CT image.
The first method is to flatten the image matrix P into a long
vector. The vector could be treated as a time series, thus those
well-developed algorithms for the time series analysis could
be applied easily. The flattened operation could be done along
the row Prow as shown in Equation (2) or the column Pcol as
shown in Equation (3) of the P.
Prow = p11, p12, · · · , p1m, · · · , pn1, pn2, · · · , pnm (2)
Pcol = p11, p21, · · · , pn1, · · · , p1m, p2m, · · · , pnm (3)
For the flat image Pflat (Prow or Pcol), we can apply the
ultra-fast Fourier transform algorithms to speed up the calculation of the matrix profile to detect anomalies. The detailed
description of the algorithms can be found in the original
papers [11], [21]–[24]. After the anomalies are detected,
we could trace the anomalies back to the position in the matrix
P by joining them across the rows and columns. In this way,
the two-dimensional anomaly detection problem is transferred into two one-dimensional anomaly detection problems.
We could think of this as scanning the image along two
directions in a greedy snake way [36]. Then we can find the
overlapped anomalies detected by these two greedy snakes.
This is the proposed one-dimensional method to calculate the
matrix profile for a image.
The second method is to find the local anomaly
regions or two-dimensional segments of the image P directly.
We define a segment Pij,wh of P as a matrix, which has a size
of w × h and starts from Pij as shown in Equation (4).
Pij,wh =



pij · · · pi(j+w−1)
.
.
.
.
.
.
.
.
.
p(i+h−1)j
· · · p(i+h−1)(j+w−1)


 (4)
We define a sparse segment set S as shown in Equation (5)
of the P as an ordered set of sparsely selected segments of the
P obtained by a sliding window of size w × h and a stride s
across P. Where Sij could be used to denote Pij,wh.
S =





p11,wh p1(1+s),wh · · · p1(m−w+1),wh
p(1+s)1,wh p(1+s)(1+s),wh · · · p(1+s)(m−w+1),wh
.
.
.
.
.
.
.
.
.
.
.
.
p(n−h+1)1,wh p(n−h+1)(1+s),wh · · · p(n−h+1)(m−w+1),wh





(5)
We define a sparse two-dimensional matrix profile (2DM)
as a matrix of the Euclidean distances between each segment
Pij,wh in the sparse segments set S and its nearest neighbours
in S. The 2DM has the same size as S, but the elements
in S are matrices while the elements in 2DM are numbers.
To calculate 2DM, the pairwise Euclidean distance between
one element in S with every other element in S will be
calculated. The minimum of these distances will be stored
in the same position of 2DM as the element in S. According to the assumption of nearest neighbour-based anomaly
detection in a static image, a segment that has the smaller
nearest distance will probably be a normal segment,while a
segment that has the larger nearest distance will probably be
an anomaly. Therefore, the value of 2DM could represent the
anomaly level of the segments in S. The algorithm of building
the 2DM is shown in Algorithm 1.
Algorithm 1 Calculate 2DM
Input: an image P, window size w × h,stride s
Output: a matrix profile 2DM
1: 2DM ← inf
2: for Sij in SlidingWindow(P,s,w): do
3: for Si
0
j
0 in SlidingWindow(P,s,w): do
4: distance ← EuclideanDistance(Sij, Si
0
j
0)
5: if distance < 2DMij then
6: 2DMij ← distance
7: else
8: PASS
9: end if
10: end for
11: end for
After 2DM is calculated, the values in the 2DM matrix
are summed [8] and scaled to a range of 0 to 100 as CT-SS
of the image. The difference of the CT-SS between the
patient groups are tested using student t-test. And a statistic
mediation analysis [37] is performed to identify the indirect
effects of age, gender, and underlying diseases on COVID-19
severity through the two-dimensional matrix profile based
CT-SS using the R package ‘‘mediation’’. In the mediation
analysis model, the COVID-19 severity and CT-SS are treated
as dependent variable and mediator,separately. While the
age, gender, and the number of underlying diseases(how
many underlying diseases the patient has) are treated as
independent variable, separately. There are three steps for
conducting the mediation analysis. The first step is three
simple regression analyses with the dependent variable of
COVID-19 severity and the independent variable of the age,
VOLUME 8, 2020 213721Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 1. VGG and DenseNet architectures ∗ used in this study.
gender and the underlying diseases, respectively. The second
step is also three simple regression analyses predicting the
mediator, which is the two-dimensional matrix profile based
CT-SS, from the age, gender and the underlying diseases,
respectively. The third step is three multiple regression analyses predicting the dependent variable of COVID-19 severity
from the CT-SS and age, CT-SS and gender, CT-SS and the
underlying diseases, respectively.
An up-sampling step is performed to impute 2DM to the
same size of the image P. In this way, an anomaly mask is
made for P. This map is actually a salience map if we plot
it on top of the raw image P. The anomaly map is then used
as a weight matrix to be fed into a simple linear model for
making a weighted image Pw, which can potentially enhance
the anomaly in the raw CT image P.
Pw = P + 2DM · P (6)
Here, the 2DM is a matrix with the same dimension of
the raw image P. We calculate the dot product of these two
matrices (2DM and P). Then we add P with the product. Pw is
then passed to a classification-based deep learning model for
model training and testing.
B. VGG AND DenseNet
We treat the lung CT imaging-based diagnosis of COVID-19
as a binary classification problem (e.g. COVID-19 or NonCOVID-19). VGG and DenseNet model are applied to perform the classification. VGG has 16 convolutional layers and
3 fully connected layers and won the 2014 Large Scale Visual
Recognition Challenge. It is a CNN model with a deeper
architecture by increasing the number of convolutional layers
and reducing the size of convolutional layers [35].
DenseNet is a relatively new framework of convolutional
deep learning. The idea of DenseNet is to build a deeper architecture which has connections between each convolutional
layer to every other layer within the same dense block in a
feed-forward fashion. Unlike the ResNet [38], the connections of DenseNet are in feature-level instead of weight-level.
The parameters of each layer will be trained only once, and
the resulted feature-maps will be concatenated together as the
input of the layer they connect to. In this way, the weights
could be more efficient, and the gradients would not be
vanished. The performance of DenseNet has been estimated
on several benchmark datasets [34]. With different number
of convolutional layers in each dense block, DenseNet could
have different settings. The three architectures of DenseNet
(DenseNet121, DenseNet169, and DenseNet201) used in this
study are listed in Table 1.
The anomaly weighted images Pw are then used in the
training, validation and testing of the above mentioned VGG
and DenseNet models.
C. CHEST CT DATASETS
This proposed workflow of the deep learning models were
applied to analyse the weighted (Pw) and unweighted (P) raw
lung CT images, respectively. The raw data used in this study
came from two publicly available datasets. One was downloaded from a GitHub repository published by The University
213722 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 2. Data splits used in this study.
of California San Diego [12]. It contains 275 COVID-19 lung
CT images and 195 Non-COVID-19 lung CT images. This
dataset was built by reading the captions of the published
papers about COVID-19. The author of the dataset manually searched for quite a number of COVID-19 CT imaging
papers, and copied the CT images contained in those papers
as figures. The label information of these CT images, such as
whether they were obtained from COVID-19 patients or NonCOVID-19 patients, was collected by reading the captions of
the figures in those papers. The split of the training, testing,
and validation of this dataset followed the authors’ suggestion
(Table 2).
We did not borrow the data augmentation and transfer
learning steps as done by the authors of the dataset and our
training strategy is relatively simple in terms of the training
epochs and model structure because the goal of this work
is to test the effect of the anomaly detection-based image
preprocessing. The other dataset was published by Wuhan
Huazhong University of Science and Technology [13]. This
one has 4,001 COVID-19 lung CT images and 9,979 NonCOVID-19 lung CT images. The quality of this dataset is
better than the first one since it was directly obtained from
Wuhan’s hospitals. The images are all in DICOM (Digital
Imaging and Communications in Medicine) format with the
similar FOV (Field of View) and resolution (200K). We borrowed the lung parenchyma splitting algorithm from the
author of the dataset to split the lung regions from the other
body parts [13]. After this, we randomly selected 80% of
the images as a train set, 10% as a validation set, and 10%
as a test set. The detailed number of images are listed in
Table 2. We choose this data split strategy to be consistent
with the split strategy of the first data set. Images from both
datasets are resized to a uniform resolution of 224 × 224.
Training parameters are kept the same in both the anomaly
detection-based framework and anomaly detection-removed
framework.
D. PERFORMANCE EVALUATION
To evaluate our model performance, we used below performance measures: Accuracy (a ratio of correctly predicted
observations to the total observations), Precision (a ratio of
correctly predicted positive observations to the total predicted
positive observations), Recall (also called sensitivity, the ratio
of correctly predicted positive observations to the all observations in actual class), AUC (Area Under the Curve) and
F1 (a weighted average of Precision and Recall). All
performance metrics of anomaly weighted images were
stored in a vector, while all performance metrices of
raw images were stored in another vector. Then a ttest was done to test the significance between these two
vectors.
E. IMPLEMENTATION OF THE ALGORITHM
We made the data splits with our code publicly available
for reproducing our results (https://github.com/qianliu1219/
iMP). The raw data used in this study could be downloaded
from UCSD (https://github.com/UCSD-AI4H/COVID-CT)
and ICTCF (http://ictcf.biocuckoo.cn/index.php). The proposed two-dimensional matrix profile algorithm and the training of the VGG model and the three DenseNet models on the
two datasets took around 80 hours for a Nvidia GeForce GTX
1080 GPU machine.
IV. RESULTS
A. THE SPARSE MATRIX PROFILE AND CT-SS
After applying the ultra-fast matrix profile algorithm to the
one-dimensional flattened images, we could obtain meaningful patches, which indicate the potential anomaly pixels in the chest CT images. Fig. 2 showed one of the
examples.
FIGURE 2. Examples of sparse matrix profile. The row flattened image
(A) and the column flattened image (B). The one-dimensional matrix
profiles of A and B were plotted as black lines (C, D). The meaningful rare
patterns were highlighted using the red colours. Their overlap was traced
back to the raw image. A meaningful anomaly patch was observed (E).
However, the top discords (top smallest distances) require
to be carefully defined in order to find a meaningful patch
using the one-dimensional matrix profile algorithm. If we
VOLUME 8, 2020 213723Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
FIGURE 3. The results of CT-SS differential analysis and mediation
analysis. Top panel (A) is the density distributions of the two-dimensional
matrix profile algorithm-based CT severity scores (CT-SS) for COVID-19
and Non-COVID-19 groups, respectively. Bottom panel (B) is the causal
association analysis among the underlying diseases, CT-SS, and COVID-19
diagnosis. The total effect and its significance of underlying diseases on
COVID-19 diagnosis, the direct component of the total effect and indirect
effect through the CT-SS are showing on the paths.
select the top 1 discord, the highlighted patch sometimes
would present in the corner or along the edge of the
image or body parts in the image. Those meaningless
discords need to be manually filtered out, which is inconvenient. Therefore, the approach is not practical in clinical
reality.
Using the two-dimensional matrix profile algorithm,
we got an anomaly severity score (CT-SS) for each image.
The density distribution of the CT-SS is shown in Fig. 3A.
These CT-SS were significantly different between the
COVID-19 group and Non-COVID-19 group (p − value <
0.05).
The mediation analysis identified a significant causal relationship among the number of underlying diseases, CT-SS,
and COVID-19 severity as shown in Fig. 3B. The number of
underlying diseases has a total effect of 0.42 (p − value <
0.05) on COVID-19 severity. Five percentage of this effect,
which is 0.02 (0.02 ÷ 0.42 = 5%), could be explained by
the two-dimensional matrix profile based CT-SS. The rest
95% is the direct effect that needs to be explained by other
mechanisms.
Based on the two-dimensional matrix profile, we could get
a salience map pasted on the top of the raw image to suppress the meaningless pixel values without losing information
in meaningful regions such as the lung region and lesion
region (Fig. 4).
FIGURE 4. Examples of generation of salience maps. The raw image (A),
the lung regions (B), identified two-dimensional matrix profile
heatmap (C,D), and anomaly weighted image (E,F). In the weighted image,
valuable pixels in the lung regions and lesion regions were highlighted,
while meaningless regions were suppressed.
B. THE ANOMALY WEIGHTED LUNG CT IMAGES
IMPROVED THE COVID-19 DIAGNOSIS
We trained the VGG and DensNet models (Table 1) using
both the training sets of raw CT images and the anomaly
weighted CT images for the Datasets 1 and 2 (Table 2),
respectively, which were evaluated using their validation sets
(Table 2). As shown in Fig. 5 (Top), due to the small sample
size in Dataset 1, the performance of DenseNet121 on the raw
images and the anomaly weighted images is inconsistent for
different performance measures. Also due to the poor quality
(in terms of both the format (Normal image format, not medical image format) and the various of image resolutions(from
9K to 1.6M)) and small sample size, models trained on
Dataset 1 need more training epochs to converge than models
trained on Dataset 2. Except accuracy, the anomaly weighted
images have better performance than the raw images for
all other four performance measures in DenseNet121. For
Dataset 2, the anomaly weighted images have shown better
performance than the raw images for all the five performance
measures in Fig. 5 (Bottom). Other DenseNet architectures
as well as the VGG network as shown in Table 1 also showed
the similar trend (results were not shown). The overall performance winner was always the model trained with the anomaly
213724 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 3. Classification performance on testing sets.
FIGURE 5. The validation performances of the DenseNet121 models on
the Datasets 1 and 2.
weighted images instead of the model trained with the raw
images (p − value < 0.05) as shown in Table 3.
The trained DenseNet models and the VGG model were
applied to the testing sets of the Datasets 1 and 2, respectively.
We showed the model performance on the testing sets in
Table 3. We also showed the performance of DenseNet121 on
the validation set as example Fig. 5. The performance on
validation set is relatively higher than that of the testing
set (Table 3) in the Dataset 1, which means there is a
potential over-fitting no matter whether we used the raw
data or the anomaly weighted data. This is not surprising
since the sample size is very small and the image quality in
the Dataset 1 is various. We were expecting that the sparsity
introduced by the anomaly mask could help avoiding overfitting [39]. However, it turns out that the anomaly mask has
limited effect on preventing over-fitting. This might because
the main content of the weighted images is still from the
raw images, and only a small proportion comes from the
anomaly mask. The sparsity introduced by the mask might be
not enough for avoiding over-fitting. For the second dataset,
over-fitting was not observed as the performance was stable
during validation and testing. As shown in Table 3, we also
observed that the DenseNet models under different network
architectures (Table 1) have better performance than the VGG
model (Table 1). Generally speaking, The DenseNet and the
VGG models also showed the improved performance using
the anomaly weighted images than raw images using the
testing sets in both Datasets 1 and 2 (Table 3).
V. DISCUSSION
Matrix profile is a successful technique in unsupervised
rare pattern-based time-series anomaly detection [40]. It was
developed based on the nearest neighbour algorithm. In this
study, matrix profile was introduced to static image anomaly
detection at one-dimensional level and two-dimensional
level, separately. At one-dimensional level, image matrix
was flattened to a long vector which could be considered
as a time-series. With this transformation, the set of entire
subsequences could be scanned efficiently using fast Fourier
algorithms. This method works fine in identifying anomalies
within an image. However, extra manual operations need to be
done for choosing a suitable discord. And it is unnecessary to
visit an image pixel by pixel for anomaly detection. Instead,
VOLUME 8, 2020 213725Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
it is more reasonable to directly calculate the image matrix
profile at the two-dimensional level. In our two-dimensional
matrix profile method, a predefined size of sub-segment
is scanned and its nearest distance with other sub-segments is
calculated. The combination of all these nearest distances is
mapped to the same coordinates of the corresponding subsegments in the original images. The generated anomaly
mask has the ability to indicate the meaningful lesion pixels
in the original images. We further transformed each of the
images into a severity score as a fast tool to indicate the
normality of the images. This severity score showed significant difference between COVID-19 group and Non-COVID19 group, which means it could work as an automatic and
easy-calculated clinical tool to support COVID-19 diagnosis.
To understand the potential causal effect of the severity score
on COVID-19 diagnosis, we performed a statistical mediation analysis to examine the association between COVID-19
diagnosis and the number of underlying diseases through the
score. We identified the significant indirect effect of the number of underlying diseases on COVID-19 severity through this
severity score.
The anomaly mask can also be used to weight the original
image for completing further tasks. In this study, we evaluated
the performance of the anomaly weighted images to classify
the COVID-19 and Non-COVID-19 lung CT images using
a deep learning model. The anomaly weighted images were
shown to be better in training the deep classification model
than the raw images. This is likely due to the enhanced information introduced by the preprocessing. We made the whole
working flow connected so that it could be implemented
easily [41]. What’s more, unsupervised anomaly detection
and supervised deep convolutional neural network could be
combined together in an end-to-end manner.
To control the runtime of the algorithm, we downsized the
raw images to a smaller resolution. Although to obtain the
best classification performance of the deep learning model is
not the main task of this study, we realized the degradation
in resolution might decrease the performance of the deep
convolutional neural network based image classifier used in
this study [42]. It might be better to keep the original resolution if the runtime is not a consideration or the computer
configuration could be improved. Another potential future
direction of this study is to develop ultra-fast algorithms
for two-dimensional matrix profile calculation using a twodimensional fast Fourier transformation [43]. Also, for the
one-dimensional method, currently the one-dimensional fast
Fourier transformation (FFT) [44] involved in the core algorithm does not consider the sparsity of medical image data.
We could introduce sparse Fourier transform (SFT) [45] into
the core calculation of one-dimensional matrix profile algorithm. At the application level, this technique is not limited
to analysis of COVID-19 CT images, it could be extended
to other diseases and other image types. Although this study
focuses on the two-dimensional image anomaly detection
problem, the matrix profile technique could be potentially
further extended to analyze three-dimensional volume rendered CT scans which are more commonly used in medical
practice. The potential application of CT-SS could also be
explored if more clinical information are provided. For example, if the clinical outcomes (prognosis, treatment response,
etc.) of the patients are available, the associations of CT-SS
with these clinical outcomes could be further analysed [8].
Although this study is not intended to compete with the most
state-of-art work in completing a classification task, we could
integrate our sparse matrix profile method for enhancing
anomalies in images with other advanced deep learning models [46], [47] and some data augmentation techniques to
achieve the best classification performance.
VI. CONCLUSION
Inspired by the success of matrix profile in time-series data
anomaly detection, we attempted to extent its application
to image anomaly detection. Two possible clinical utilities
have been tested, which are the CT-SS and the anomaly
weighted images. The CT-SS could significantly distinguish
the COVID-19 and Non-COVID-19 patients. This ability
might come from the mechanism of its mediation effect on the
number of underlying diseases’ association with COVID-19
severity. The anomaly weighted images performed better in
training different settings of DensNet models than the raw
images. These significant results revealed its potential use for
the lung CT imaging-based COVID-19 rapid diagnosis. This
work has opened a window for raising the one-dimensional
rare pattern mining algorithm to solve two-dimensional rare
pattern detection problem. Unsupervised anomaly detection and advanced deep convolutional neural network were
utilized in an unbroken and connected manner. The proposed algorithm is also dimension-extendible and explainable, in terms of its nearest neighbour theory. Furthermore,
the implemented algorithm package might become a clinical
tool for COVID-19 rapid diagnosis and assessment.



NEW_PAPER


Technology
Detecting Regions At Risk for Spreading
COVID-19 Using Existing Cellular Wireless
Network Functionalities
Alaa A. R. Alsaeedy and Edwin K. P. Chong , Fellow, IEEE
Abstract—Goal: The purpose of this article is to introduce a new strategy to identify areas with high human density and mobility, which are at risk for spreading COVID-19.
Crowded regions with actively moving people (called at-risk
regions) are susceptible to spreading the disease, especially if they contain asymptomatic infected people together
with healthy people. Methods: Our scheme identifies at-risk
regions using existing cellular network functionalities—
handover and cell (re)selection—used to maintain seamless coverage for mobile end-user equipment (UE). The frequency of handover and cell (re)selection events is highly
reflective of the density of mobile people in the area because virtually everyone carries UEs. Results: These measurements, which are accumulated over very many UEs,
allow us to identify the at-risk regions without compromising the privacy and anonymity of individuals. Conclusions:
The inferred at-risk regions can then be subjected to further
monitoring and risk mitigation.
Index Terms—COVID-19, infectious diseases, tracking.
Impact Statement—Method to identify crowded regions
with actively moving individuals, at risk for spreading
COVID-19, by exploiting existing cellular-network functionalities. Requires no active participation by individuals and
introduces no privacy concerns.
I. INTRODUCTION
T HE global COVID-19 pandemic is easily spread by people in close proximity, especially in crowds with mobile
individuals (e.g., city centers). A widely accepted strategy to mitigate its spread is social distancing, avoiding crowded areas [1].
There is an urgent need for different mitigation strategies to slow
the spread of this disease. Spreading by “silent carriers” mostly
depends on how they move and gather, the two viral-spreading
risk factors motivating our new mitigation strategy.
Manuscript received May 3, 2020; revised May 15, 2020 and May 31,
2020; accepted June 7, 2020. Date of publication June 15, 2020; date of
current version July 2, 2020. Alaa A. R. Alsaeedy was supported by a
scholarship from the Iraqi Ministry of Higher Education and Scientific Research under Grant 4650/11/16/2014. Edwin K. P. Chong was supported
in part by the National Science Foundation under Grant CMMI-1638284.
(Corresponding author: Alaa Alsaeedy.)
The authors are with the Department of Electrical and Computer
Engineering, Colorado State University, Fort Collins, CO 80523 USA
(e-mail: alaa.alsaeedy@colostate.edu/outlook.com; edwin.chong@
colostate.edu).
This article has supplementary downloadable material available at
https://ieeexplore.ieee.org, provided by the authors.
Digital Object Identifier 10.1109/OJEMB.2020.3002447
Our strategy does not track individuals, unlike many existing contact-tracing mobile-phone apps [2], which require
widespread user adoption and have obvious privacy concerns.
Instead, we anonymously measure the aggregate density and mobility of mobile devices, without individual identities, as detailed
below. Moreover, these measurements do not require installation
of any app nor any other action on the part of mobile users.
II. MATERIALS AND METHODS
We exploit already existing cellular-network functionalities
intended to manage end-users’ mobility and to ensure seamless
coverage [3]. Because practically everyone carries cellular mobile devices (called user equipment (UE)), these serve as alwayson human trackers. More specifically, the higher the number and
mobility of UEs, the higher the number and mobility of people.
According to a recent study [4], SARS-CoV-2 can live in the
air for up to three hours (remaining viable in aerosols), exhaled
by infected people while speaking, coughing, or even breathing,
whether symptomatic or not [5]. We are particularly concerned
with the scenario where contagious people are present in areas
with many other continuously mobile people. Such areas, which
we call at-risk, naturally have high local basic reproduction
number (R0) [6]. Conversely, sparse areas with mostly stationary
people are not considered at-risk (e.g., residential areas with
people remaining at home). The main goal is to detect at-risk
areas, allowing prioritization for further monitoring and risk
management. Our strategy is based on inferring the crowdedness
and mobility using measurements of quantities already accessible to the cellular wireless network via UE mobility management
protocols.
A. UE Mobility Management
Our scheme detects at-risk regions by measuring UE mobility
and density over a day or more, to capture long-term behavior
rather than short-term transients. Specifically, we exploit existing network functionalities required to keep each UE connected
while moving, exchanging UE-specific information with the
network [7], as detailed below.
B. Handover and Cell Selection
Long Term Evolution (LTE) networks (and their 5G successors) have shifted toward ultra-dense small-cell deployment,
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 187188 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, 2020
TABLE I
CELL TYPES IN CELLULAR NETWORKS (ADAPTED FROM [3])
called Heterogeneous Networks (HetNets), comprising multiple
layers of different cell sizes: microcell, picocell, and femtocell;
see Table I [3]. HetNets need to accommodate the increasing
density of highly mobile UEs and keep power consumption low
in battery-limited UEs [8]—hence, small cells are deployed in
dense UE areas.
The mobility of each UE is handled by two essential protocols:
handover (HO) and cell (re)selection (CS) [9]. We use the
measurements from conventional HO/CS events only, intended
to handle moving pedestrians as they cross cell boundaries.
We exclude the HO/CS events triggered by moving vehicles,
handled by different procedures called fast HO/CS [10], who do
not contribute significantly to spreading COVID-19. Each UE.1
triggers these procedures while moving from one cell to another
(e.g., from femtocell to picocell), to maintain connectivity. As
UE density and mobility increases, so does the rate of HO/CS
events. Thus, measuring HO/CS rates can be used to identify
regions with high UE density and mobility, thereby identifying
at-risk regions. The higher the HO/CS rates, the higher the risk
of spreading COVID-19. Because crowded areas are likely to
have small cell sizes, the spatial resolution of the HO/CS measurements is also relatively high (10–20 meters in femtocells).
Continuously measuring HO/CS rates gives real-time updates of
regional at-risk status.
III. RESULTS
Fig. 1 depicts an example of multiple cell sizes of a HetNet, deployed according to a predefined network plan; i.e.,
where these cells are needed to accommodate UE connectivity
in high-density areas. While actively moving, UEs frequently
initiate HO/CS events. Typically, each cell (labeled m, p, and
f in Fig. 1) records these events to be used by the network as
key performance indicators (KPIs) [7], primary indicators used
to evaluate and measure network performance; e.g., handover
success/failure rate.
If the HO/CS rates from a certain cell are relatively high,
this cell should be classified at-risk, warranting further risk
mitigation. For example, the network might broadcast advisory
messages to the affected UEs: “Area A is at risk of COVID-19:
It has many actively moving people.”
For illustration, Fig. 2 shows that the HO/CS rates are higher
in busy areas than in areas with low UE density/mobility. In this
example, the following cells are at-risk: m3, m4, p1, f1, f2, f3,
f4, f21, f22, and f23 (also labeled in Fig. 1). When people tend to
stay home for a period of time, the corresponding HO/CS rates
1While moving, the UE triggers HO when it is in the CONNECTED state and
CS when it is in the IDLE state [11].
Fig. 1. Illustration of HetNet deployment in areas with healthy and
infected people.
Fig. 2. Illustration of HO/CS rates in regions with varying density and
mobility.
are lower than in crowded areas with high UE mobility (e.g., f8
and f10 in Fig. 2).
IV. DISCUSSION
A natural rule for deciding whether to classify an area as
at-risk is to compare the measured HO/CS rate with a threshold
value, prespecified according to the desired false-alarm probability. False alarms are not particularly problematic here because
of the need to be conservative. Dire consequences can result from
the presence of even a single carrier in an area with many actively
moving people. While our strategy aims to identify areas with
potentially high viral transmission, the HO/CS rates can also be
used to estimate, for example, the percentage of people staying
at home.
V. CONCLUSION
We have introduced a new strategy for identifying areas that
potentially contribute to the spread of COVID-19. Our strategyALSAEEDY AND CHONG: DETECTING REGIONS AT RISK FOR SPREADING COVID-19 189
exploits existing cellular network procedures, HO and CS, required to maintain connectivity for mobile UEs. The frequency
of HO/CS events reflects how the UEs move and gather within
the coverage area. High HO/CS rates imply at-risk areas—those
with high UE density and mobility over time. Measuring HO/CS
rates allows distinguishing high- from low-risk areas, enabling
prioritization of further risk mitigation.



NEW_PAPER


Received December 17, 2020, accepted January 5, 2021, date of publication January 11, 2021, date of current version January 20, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3050852
A Novel Bayesian Optimization-Based Machine
Learning Framework for COVID-19 Detection
From Inpatient Facility Data
MD. ABDUL AWAL 1
, MEHEDI MASUD 2
, (Senior Member, IEEE),
MD. SHAHADAT HOSSAIN 3
, ABDULLAH AL-MAMUN BULBUL 1
,
S. M. HASAN MAHMUD 4
, AND ANUPAM KUMAR BAIRAGI 5
, (Member, IEEE)
1Electronics and Communication Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
2Department of Computer Science, College of Computers and Information Technology, Taif University, Taif 21944, Saudi Arabia
3Department of Quantitative Sciences, International University of Business Agriculture and Technology, Dhaka 1230, Bangladesh
4School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China
5Computer Science and Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
Corresponding author: Md. Abdul Awal (m.awal@ece.ku.ac.bd)
This work was supported by Taif University Researchers Supporting Project number (TURSP-2020/10), Taif University,
Taif, Saudi Arabia.
ABSTRACT The whole world faces a pandemic situation due to the deadly virus, namely COVID-19. It takes
considerable time to get the virus well-matured to be traced, and during this time, it may be transmitted
among other people. To get rid of this unexpected situation, quick identification of COVID-19 patients is
required. We have designed and optimized a machine learning-based framework using inpatient’s facility
data that will give a user-friendly, cost-effective, and time-efficient solution to this pandemic. The proposed
framework uses Bayesian optimization to optimize the hyperparameters of the classifier and ADAptive
SYNthetic (ADASYN) algorithm to balance the COVID and non-COVID classes of the dataset. Although
the proposed technique has been applied to nine state-of-the-art classifiers to show the efficacy, it can be
used to many classifiers and classification problems. It is evident from this study that eXtreme Gradient
Boosting (XGB) provides the highest Kappa index of 97.00%. Compared to without ADASYN, our proposed
approach yields an improvement in the kappa index of 96.94%. Besides, Bayesian optimization has been
compared to grid search, random search to show efficiency. Furthermore, the most dominating features have
been identified using SHapely Adaptive exPlanations (SHAP) analysis. A comparison has also been made
among other related works. The proposed method is capable enough of tracing COVID patients spending
less time than that of the conventional techniques. Finally, two potential applications, namely, clinically
operable decision tree and decision support system, have been demonstrated to support clinical staff and
build a recommender system.
INDEX TERMS COVID-19, ADASYN, Bayesian optimization, classification, inpatient’s facility data.
I. INTRODUCTION
The world is currently experiencing a pandemic situation
due to the extensive spreading of the novel coronavirus
disease namely, COVID-19. It is an acute respiratory syndrome triggered by the Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2), which was primarily detected
in Wuhan under the Hubei province of China in late 2019.
The associate editor coordinating the review of this manuscript and
approving it for publication was Bilal Alatas .
Considering the alarming rate of infection and death from the
COVID-19, World Health Organization (WHO) announced
the COVID-19 as a pandemic disease in March 2020 [1]–[3].
As per the WHO report on the COVID-19 on
August 04, 2020, about 18,142,718 people have been infected
due to COVID-19 [4]. Among them, about 691,013 people
died so far. Due to its high contagious nature, both the
COVID-19 infection and death toll are rapidly increasing.
In most cases, this disease spreads from man to man
via respiratory droplets, transmitted from individual to
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10263M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
individual via air or any other surfaces. This virus lives
multiple hours to multiple days on a suitable surface at
room temperature [5], [6]. As suggested by WHO, the
COVID-patient should get himself isolated from others as
early as possible to resist its transmission. The COVID-19
should be detected as early as possible, reducing life, livelihood, and the economy. But a critical issue is the broad
maturation period of the COVID-19 that varies from 3 to
14 days. The usual symptoms of this disease include fever,
cough, dyspnea, loss of smell, loss of taste, diarrhoea,
etc. [7], [8]. People affected by COVID-19 should go through
a fruitful, real-time, fast, and accurate screening scheme to
ensure timely treatment, isolation, and safety for the patient.
Many pieces of research are going on to find out efficient
and speedy COVID-19 detection schemes in different dimensions. The Reverse Transcription Polymerase Chain Reaction
(RT-PCR) is a COVID-19 detection scheme that has shown its
efficiency and has been practised worldwide. Using samples
like the nasal or oral pharyngeal swab, this method can competently detect coronavirus and has attained the gold-standard
banner. However, these testing kits fail to meet the mounting
demand due to its limited supply, especially in developing
countries [9]. Another drawback of this method is that it
requires an extended period, ranging from one to two days.
Moreover, the situation is even worse in rural areas, because
people from remote areas get the results after two or more
days, even after a week [10]. This extended period increases
the vulnerability of the spreading of COVID-19 as the patient
does not usually keep himself isolated from others before
getting his result.
To optimize these limitations, the potentiality of Artificial
Intelligence (AI) and Machine Learning (ML) algorithms
in the analysis, characterization, and classification of different diseases have motivated the researchers to introduce
AI and ML in COVID-19 detection. Numerous researches
have already been carried out to design a COVID-19 detection model based on AI and ML [7]–[20]. Furthermore,
Rajaraman and Antani [10] proposed a COVID-19 detection model based on deep learning (DL) algorithms. Using
convolutional neural networks (CNNs), chest X-ray (CXR)
data from patients are analyzed in this model to evaluate the
presence of the SARS-CoV-2 virus. The model showed about
93% accuracy employing the VGG16 classifier. Another
DL and CNNs based automatic COVID-19 detection model
was proposed by Makris et al. [8]. Diagnosing the CXR
data, the model exhibited about 95.9% and 95.00% accuracy engaging VGG16 and the VGG19 classifiers, respectively. A transfer learning-based model was presented by
Abbas et al. [12] to trace COVID-19. This CNN based
model diagnosed the CXR images of patients to check the
COVID-19 presence, and the model attained about 97.5%
accuracy. He et al. [7] presented a DL model for the automatic
detection of COVID-19. This model employed the chest
computed tomography (CT) images from patients to detect
COVID-19. The anticipated 3D CNN model, MNas3DNet41,
revealed about 87% accuracy. Jim et al. [11] presented an
automatic COVID-19 detection model based on sequential CNN. This model took the CT images in its input to detect
COVID-19. The model attained almost 92.5% accuracy along
with 94.2% sensitivity and 95.6% specificity. A lot of more
automatic COVID-19 detection models have been proposed
so far based on the computer-based diagnosis of the CT and
CXR images.
Hence, all the anticipated models require CT or CXR
data of patients as the key input parameter, only available
from diagnostic centres. So, each patient or suspected patient
has to visit the diagnostic centre in person to check the
presence of COVID-19 in his body. Most of the families in
developing countries do not have private transport. Besides,
patients from rural areas have to travel a long distance to
reach a diagnostic centre. Therefore, they have to use public
transport to visit the diagnostic centre to check COVID-19.
This will create high vulnerability to COVID-19 spreading,
among others. From another point of view, a low percentage
of people tested for COVID-19 gets COVID-positive results
in most of the countries; as an example, as of July 30, 2020,
the positive rate is about 1.30% in France, 22.20% in
Bangladesh, 9.90% in Iran, 0.90% in Italy, 7.90% in
the USA, 11.10% in India, 2.10% in Russia, and 0.40% in the
UK [21]. Visiting the diagnostic or test centre, a large percentage of COVID-19 negative people may meet with COVID-19
positive patients, which will enhance the risk of getting contaminated by COVID-19 disease. So, an inpatient data-based
COVID detection will be the best option to avoid these types
of risks. Besides, this type of detection will be very user
friendly, cost-effective, and time-efficient.
Considering all the above issues, we have proposed a fast
and user-friendly model to detect the COVID-19 based on
machine learning. A large volume of data on COVID-19 is
available in different laboratories and test centres. The dataset
comprises other features like age, temperature, pulse rate,
systolic and diastolic pressure, fever, cough, loss of smell,
runny nose, diabetics, loss of taste, asthma, etc., which are
analyzed to design the automatic COVID-19 detection model.
The most promising advantage of this model is that it is
capable of detecting the COVID-19 within a few minutes as
well as help the doctors take adequate precautionary measures while treating the COVID patients. Different classification algorithms such as Linear Discriminant Analysis
(LDA), Quadratic-DA (QDA), Naive Bayes (NB), k-Nearest
Neighbors (KNN), Decision Tree (DT), Random Forest (RF),
eXtreme Gradient Boosting (XGB), Gradient Boosting (GB),
Support Vector Machine (SVM), etc. are used to characterize
the model. These classifiers have some hyper-parameters, and
proper tuning of these hyper-parameter improves the performance of the classification using state-of-the-art global optimizers such as Bayesian optimization [22], Gradient-Based
Optimizer (GBO) [23], Slime mould algorithm (SMA) [24],
and Harris hawks optimization (HHO) [25] etc. The evaluation of different performance metrics such as accuracy, specificity, sensitivity, etc. for the anticipated model
demonstrates higher efficiency in detecting COVID-19.
10264 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
The contribution and key topics covered by this study are as
follows:
• The proposed model can be easily tested on inpatients
or inhouse facilities discussed in Section II. Therefore,
the patient needs not to visit the clinic to test the
COVID-19.
• We have designed a machine learning framework
using Bayesian optimization adapted by the ADASYN
algorithm to detect COVID-19 which is presented in
Section II.D and II.E.
• The state-of-the-art machine learning technique is optimized using our method and compared with other commonly used Grid-search and random search techniques;
see Section III.H.
• The proposed method uses the ADASYN algorithm to
balance the model, and the effect of ADASYN has also
been demonstrated in III.A.
• Using SHapely Adaptive exPlanations (SHAP) analysis,
important features are calculated, and the SHAP values
are explained to interpret the model in Section III.F.
• A clinically operable decision tree is built that will
be helpful for the clinical staff stated in Section IV.A.
A decision support system has also been developed to assist the recommender system illustrated
in Section IV.B.
The remainder of the paper is organized as follows.
In Section II, we discuss the materials and methods used in
this work. We present the experimental results in Section III.
In Section IV, we present a systematic discussion and comparison of the work with other approaches. Finally, we draw
some conclusions in Section V.
II. MATERIALS AND METHODS
A. DATA SOURCE
The clinically-driven information on individuals who have
undergone through RT-PCR test was collected from the [26].
The dataset, containing 11169 person’s data with 2.82% of
patients’ COVID positive and 97.18% COVID negative tests
from the United States, was prepared by Carbon Health (CH)
and Braid Health (BH). The CH started RT-PCR testing of
a coronavirus in early April 2020. The dataset is compliant with the Health Insurance Portability and Accountability
Act (HIPAA) privacy rule’s de-identification standard. Five
clinical teams worked under the CH. The dataset prepared by
the CH covered multiple physiognomies on patients, including Epidemiological (Epi) Factors, comorbidity, vital signs,
lab technician-assessed symptoms, patient-stated symptoms.
Whereas, two clinical teams gathered the dataset under
the BH, which assembled the radiological information containing verdicts, CXR impressions, CXR labels, and CXR
link. We haven’t used radiological information as most of the
patient doesn’t have radiological details. The integration of
radiological information is beyond the scope of this study,
hence excluded from the analysis. The dataset consisted of
both positive and negative test results for patients having both
one or more symptoms and zero symptoms. In addition to
COVID-19 test results, the complete dataset, available on
the GitHub website, contains multiple features of patients
such as pulse rate, temperature, age, higher danger introducer
occupation, higher danger contacts, diabetics, cancer, asthma,
smoker, systole, diastole, diarrhoea, fatigue, fever, losing
smell, losing taste, runny nose, headache, muscle pain, pain
in the throat, cough, shortness of breath, etc. The vignette of
the entire data set has been illustrated through a tabular sketch
shown in Figure 1.
From the pictorial depiction (Figure 1), it is much clearer
that there are two types of data (numeric and boolean),
where the boolean variables are more than three times that of
the numeric data. Moreover, the highest age of the patients
in this data set is 90 years old, and the extreme values
of both systolic and diastolic pressures were dramatically
higher than the natural ones. It can be further added that
days_since_symptom_onset has about 68% missing data,
while the percentage of missing data in the entire data set is
around 17. Besides the tabular display, as shown in Figure 1,
the graphical example the green bars in Figure 2 efficiently
reveals that the variables cough, diabetes, chd, htn, cancer,
asthma, COPD, autoimmune_dis, and smoker have no missing data. In contrast, the variable days_since_symptom_onset
has the highest missing values compared to others.
B. DATA PRE-PROCESSING
The overall workflow of our study is presented in Figure 3.
For data pre-processing, the dataset has been imputed using
Multivariate Imputation by Chained Equations (MICE) algorithm [27]. After completing scaling, we used the ADASYN
algorithm to balance out COVID and non-COVID datasets.
ADAptive SYNthetic (ADASYN) algorithm [28] is an oversampling method where COVID positive is a rare instance.
It helped us generate synthetic data, solving the over-fitting
problem. In contrast, the under-sampling process is not
the right choice in COVID classification. The majority
class (i.e. COVID-no class) is downsampled to the amount
minority class (i.e., COVID-yes). This process will reduce
the amount of data that drastically cause data inefficiency,
and it loses the vital information of COVID-no class. Our
COVID data set is not a big dataset, and downsampling
could mislead the diagnosis and detection. Compared to
other correlated over-sampling methods such as AdaBoost
in conjunction with Over/Under-Sampling and Jittering of
the data (JOUS-Boost), Synthetic Minority Over-sampling
TEchnique (SMOTE), SMOTE-Boost and, DataBoost-IM
(DataBoost IMbalanced) algorithm, ADASYN can balance
the imbalanced dataset, for example, COVID-19 dataset by
reducing the bias introduced by the imbalanced data distribution [28]. Besides, ADASYN shifts the decision boundary
to harder to learn examples which ultimately improves the
classification accuracy. These two objectives, i.e. (i) bias
reduction and (ii) introducing harder to learn neighbourhoods
examples, are accomplished through the dynamic weight
adjustment and adaptive learning procedure [28].
VOLUME 9, 2021 10265M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 1. Characteristics of the Sample.
The Mathematical explanation behind the ADASYN algorithm is given below:
For illustration, if ml and ms represent the majority and
minority classes, respectively, then the Degree of imbalance
of the two classes can be figured as follows:
d =
ms
ml
. (1)
If d < dx (where dx is the preset threshold for the maximum
tolerated imbalance) then the total number of the synthetic
minority can be estimated as follows:
G = (ml − ms)d. (2)
Here d = 1 means there is a total balance between two
classes. If ri =
ml
k
, where k is the number of neighbours of
each minority, and rˆ = Pri
ri
such that Prˆ = 1, then the
amount of synthetic data to generate for each neighbourhood
can be calculated as:
Gi = Grˆ. (3)
If xi and xu are two minority examples within the same
neighbourhood, where xu is randomly selected, then the new
synthetic example,si can be enumerated using the followings:
si = xi + (xu − xi)λ, (4)
10266 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 2. Fill rate for all Variables.
where xu−xi
is the difference vector in n-dimensional spaces,
and λ is a random number over [0, 1].
C. CLASSIFICATION MODELS
These nine classifiers such as Linear Discriminant Analysis
(LDA), Quadratic Linear Discriminant Analysis (QLDA),
Naive Bayes (NB), KNN, DT, RF, XGB, GB, and SVM,
have been utilized in the proposed machine learning framework. Among nine classifiers LDA, QLDA, NB, KNN,
DT and, SVM are common classifiers and also used in
COVID-19 classification. RF, XGB and GBC are recent
state-of-the-art classifiers. For example, XGB is recently
applied to interpret the mortality prediction in COVID-19
patient and proposed a clinically operable simple tree-based
tool which can be suitable to take the right decision from an
expert point of view [56]. Considering the above rationale,
we have used both commonly used classifiers as well as
recently updated classifiers in this study. This will allow
us to compare the classification performance in different
classifiers. Moreover, RF, XGB and GBC classifiers can be
explained through SHAP analysis which is very useful to
clinical engineers. Finally, it can be seen from the results
that the XGB performed better in most of the classification
metrics, and we used SHAP to explain the XGB to interpret
the COVID-19 detection.
1) LINEAR DISCRIMINANT ANALYSIS (LDA)
The LDA, introduced by Ronald Aylmer Fisher in 1936 [29],
is a productive classification technique. It sorts-out
n-dimensional spaces into 2-dimensional spaces that split-up
by hyper-plane. The core objective of LDA is to trace the
mean function for each class, and the function is projected
on the directions that optimize between-groups variance and
reduces within-group variance. The LDA is generated from
the conditional distribution of the data P(X|Y = k) for
each class k, and it optimizes by taking the class k when
the measurements are made on standalone variables for each
observation are continuous quantities [30], [31].
2) QUADRATIC LINEAR DISCRIMINANT ANALYSIS (QLDA)
QLDA, an extension of LDA is exploited in machine learning and statistical analysis to classify two or more groups
by quadratic discernible using distance-based classification
techniques. There is no hypothesis like LDA that the covariance matrix for every class is identical. When the regularity
hypothesis is true, the best prospective test for the hypothesis
that an assumed measurement is from a given class is the
likelihood ratio test. QLDA can be found from the conditional
distribution like LDA of the data P(X|Y = k) like LDA, and it
maximizes by selecting the class k [30], [31]. More precisely,
for LDA and QLDA, P(X|Y = k) is resulting as a multivariate
Gaussian distribution with the following equation:
(Y = k) =

(2π)
d/2




X
k




1/2−1
exp
− 0.5(X − µk )
t X−1
k
(X − µk )

, (5)
where d is the number of features [32]. It needs to estimate
the class priors P(y = k) for using LDA and QDA model as
classifiers, e.g. the proportion of instances of class k from the
training data, the means µk and the covariance matrix.
3) NAIVE BAYES (NB)
NB classifier is authoritative and mainly useful in the large
dataset. It is used in both machine learning and medical
science, especially the diagnosis of different diseases like
COVID-19. It is a Bayes’ theorem, based on probabilistic
classifier objects with the strong independent supposition
between the features. It generates conditional probability
models that allocate class labels to a given problem [33]. Say,
P(Patient|Covid Positive)
=
P(Covid Positive|Patient) × P(Patient)
P(Covid Positive)
,
where, P(Patient|Covid Positive), a conditional probability is
the likelihood of the patient occurring that s/he is affected
VOLUME 9, 2021 10267M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 3. The overall workflow of the classification of COVID-19. The first phase is collecting raw data followed by pre-processing,
where the raw data is imputed, scaled, and most importantly, the imbalanced data is balanced using ADASYN algorithm. Secondly,
the pre-processed data are split into the train and test set used by different classifiers to measure the classification performance. In the
next step, Bayesian optimization has been implemented to tune the hyperparameters of the classifiers. This optimized classification
model is then tested, and different performance metrics (accuracy, precision, Confusion matrix, ROC, 10-fold cross-validation, ANOVA, and
multi-comparison test) have been used for evaluation. Finally, the important features have been efficiently traced using SHAP analysis.
with Covid; P(Covid Positive|Patient) is also a conditional
probability: the likelihood of the positive COVID occurring
that is truly a patient; P(Patient) is the prior probability of a
patient; P(Covid Positive) is the overall probability of observing COVID positive.
4) K-NEAREST NEIGHBOURS (KNN)
KNN is straightforward simplest algorithms in supervised
machine learning technique [34] uses data and classify new
data points based on similarity measures with the distance
function, be able to apply to solve both classification and
regression difficulty. It uses an integer number as 1, −1, or 0
for symbolizing the productivity (labels) of a classification
algorithm outputs. KNN is a memory-based classifier; for
example, it remembers all the training data-points to predict test data by computing the similarity between an input
sample and each training instance. For a given new data
point x0, it finds the k training points xr
,r = 1, . . . , k
closest in distance to x0 and then classify using majority vote
among the k neighbors [32]. For selecting k, it conducts the
KNN algorithm respective times with various values of k and
opts for the k that reduces the number of errors accurately.
5) DECISION TREE (DT)
DT is a hierarchical flow chart like structure that generate
some decision rules. The DT creates a model that predicts
the target variable by learning the decision rule from the data
feature [35]. The main hyper-parameters of DT are criterion,
max_depth, max_features. In DT, ‘‘Gini’’ or ‘‘entropy’’ is
used as a criterion. In contrast, the max_depth is utilized to
limit the number of nodes in the tree, and the max_features
represents the number of features to consider while searching
for the optimal split. By properly tuning the hyper-parameters
of DT (i.e., criterion, max_depth, max_features) applied on
the COVID training dataset, the classification performance
will be efficiently magnified.
6) RANDOM FOREST (RF)
RF is an ensemble learning technique for classification
that uses several DTs on different sub-samples of the
dataset to improve the classification performance and to
control over-fitting [36]. The main hyper-parameters of
RF are criterion, max_depth, max_features, n_estimators.
The criterion, max_depth, and max_features have already
been discussed in DT. Besides, n_estimators represent the
number of DTs in the forest. The performance of RF can
be increased by properly tuning the hyper-parameters of
RF through optimization.
7) GRADIENT BOOSTING CLASSIFIER (GBC)
GBC is also an ensemble classifier that combines different weak learners (typically DT) into a single strong
learner in a forward stage-wise fashion by optimizing the
differentiable loss function [37]. Generally, ‘deviance’ or
‘exponential’ is used as a loss function where ‘deviance’
refers to deviance (logistic regression) for classification with
probabilistic outputs. For thrashing, ‘exponential’ gradient
boosting recaptures the AdaBoost algorithm. Other controlling parameters of GBC contained different parameters
such as n estimators, learning rate, and max depth where
n estimators indicate individual boosting stages to accomplish; learning rate reduces the performance of each tree [32].
10268 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 1. Classifiers and their controlling parameters or hyperparameters.
8) eXtreme GRADIENT BOOSTING (XGB)
XGB is designed based on the principles gradient boosting
framework. It can be used for supervised learning tasks such
as regression, classification, and ranking; similarly, it generates a prediction model in the form of an ensemble of
weak prediction models. The model in a stage-wise approach
is compassed with it as other boosting methods do, and it
generalizes them by approving optimization of a random
differentiable loss function. The gradient descent is used
by ‘Gradient Boosting’ to generate new trees based on all
previous trees. It supervises the objective function toward
the minimum direction [38]. An objective function has a
form, and it divides into training loss and regularization. The
mathematical equation has been added as follows:
obj(θ) = L(θ) + (θ), (6)
where θ denotes the parameters,  symbolizes the regularization term, and L is the training loss. The main
hyper-parameters of XGB are N_estimators, learning_
rate, n_jobs, max_depth, Gamma, min_child_weight,
colsample_by_tree. The hyper-parameters such as
N_estimators, learning_rate, max_depth have already been
discussed. Besides, n_jobs are relevant to the number of
parallel threads used to run XGB; Gamma represents the
loss required to make a further partition on a leaf of the
tree. The min_child_weight denotes the minimum sum of
feature example, i.e., instance weight needed in a child, and
colsample_by_tree is used for the subsampling of columns.
9) SUPPORT VECTOR MACHINE CLASSIFIER (SVC)
SVC is one of the most powerful supervised classifiers and used mostly for data classification in medical
diagnosis [39], [40]. It aims to build a decision boundary
in such a way that it is as far as possible from the closest data points from each of the classes, which are known
as support vectors. For non-linear problems like COVID
detection, a Radial Basis function (RBF) kernel is used.
For RBF-SVC, the controlling hyper-parameters are Cost(C)
and Gamma(γ ). The Cost(C) represents the regularization
parameter that controls the misclassification of the training
instances. Gamma(γ ) controls the ‘‘spread’’ of RBF kernel and, therefore, the decision region. The lower value of
Gamma(γ ) will broaden the decision region and vice versa.
The proper value of C and γ will increase the classification
performance, which can be achieved by optimization.
D. REQUIREMENT OF OPTIMIZATION
Most of the classifiers used in our entire study have some
hyperparameters. The classifier itself is the function of hyperparameters, and these parameters control the hyper-plane.
As an exemplification, XGB requires 7 Hyperparameters,
while KNN and DT have one parameter each [Table 1].
Classifier performance indices, e.g., classification accuracy,
error, specificity, sensitivity, etc. depend on the proper choice
of these parameters. This is an optimization problem, whose
general framework can be written as:
lim
z∈Z
J(Clf (z); Z), (7)
where z ∈ Z denotes the hyper-parameters z1,z2,z3, . . . ..,zn
belongs to Z. Clf denotes the classifiers, e.g. RF, SVM,
DT, NB, etc. and J(.) represents the objective function. This
objective function is the user-defined function where users
can use different classifier metrics such as classification
error or accuracy or other metrics described in the following
section of statistical evaluation of classification measures.
The general framework of the optimization problem can be
interpreted as minimizing the classification objective J(.) as
a function of classifier’s hyperparameters z ∈ Z. In this
study; mean of the the 10-fold cross-validation error is used
as an objective function. We chose one of the state-of-the-art
optimization algorithms named Bayesian optimization. This
algorithm used a stochastic process, namely, as a Bayesian
process, and it tried to find the optimal parameters in a smaller
number of iterations saving both memory and time [41].
Although various meta-heuristic algorithms such as GWO,
GBO, SMA, and HHO etc. successfully integrated into
many applications [42]–[44], hyper-parameter optimization
in expensive-to-evaluate objective function e.g., 10-fold
cross-validation loss, used in this study, makes it more
complicated [45]. Besides, meta-heuristic algorithms require
a set of input parameters that need to be found out to
obtain an improved performance as the performance of
the meta-heuristic algorithms are very sensitive to the
VOLUME 9, 2021 10269M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
input parameters. Furthermore, comparison among various meta-heuristic algorithms is only valid if the proper
input parameters have been set, which requires domain
knowledge [46]. Bayesian optimization is used to set the
parameters of the meta-heuristic algorithm [45], [46].
The Bayesian optimization algorithm is a global optimization method that is specially designed to deal with
such expensive-to-evaluate objective function, which is the
population and genetic operator (mutation, cross-over, and
selection) free algorithm. Bayesian optimization utilizes a
Gaussian process to compute an acquisition function that
evaluates the objective function. Besides, Bayesian optimization memorizes its previous evolution and utilize these statistics towards good solutions. It has been recently used in
COVID-19 detection using x-ray images [22]. Considering
the above rationale, Bayesian optimization has been applied
in this study.
To justify further, the proposed Bayesian optimization is
compared with the recently proposed Harris Hawk Optimisation algorithm [25]. This popular swarm-based and
gradient-free optimization algorithm is based on the cooperative behaviour and chasing styles of Harris’ hawks in nature
called ‘‘surprise pounce’’ [25]. We have chosen this algorithm
for comparison as it is very recent and outperformed by many
popular meta-heuristic algorithms such as GWO, Multi-Verse
Optimizer, Moth-Flame Optimization, Whale Optimization Algorithm, Bat Algorithm, Cuckoo Search, Firefly
Algorithm.
E. BAYESIAN OPTIMIZATION
Bayesian optimization (BO) is superior to grid search, random search, and manual tuning and therefore used in this
study [47]. This algorithm keeps track of the past evaluation results and uses them to form a probabilistic Gaussian model of BO of the objective function and use it to
find out the most optimal hyper-parameters; as an exemplar, in the case of RBF-SVM, the hyper-parameters are
C and γ . The BO algorithm selects C and γ for which
objective function J(RBFSVM;(C, γ )) provides the minimum value. Note that, the classification error is used
as an objective function. The BO algorithm is given
below:
Step 1: Build a Gaussian probability model of the objective function. In this study, classification error is the
objective function.
Step 2: Find the controlling parameters or hyperparameters that perform best on the Gaussian process.
Step 3: Apply these hyper-parameters to the true objective function.
Step 4: Update the Gaussian model incorporating the
new results.
Step 5: Repeat Step 2-4 until maximum iteration is
reached.
The Mathematics behind the Bayesian Optimization for X =
(x1, x2, x3, . . . , xn) independent features and y target variable
is given below:
P(y|X) =
P(X|y)P(y)
P(X)
(8a)
=
P(x1|y)P(x2|y) . . . P(xn|y)P(y)
P(x1)P(x2) . . . P(xn)
(8b)
=
P(y)
Qn
i=1 P(xi
|y)
P(x1)P(x2) . . . P(xn)
(8c)
=

1
P(x1)P(x2) . . . P(xn)

× P(y)
Yn
i=1
P(xi
|y), (8d)
Since all the variables except the target variable are independent, P(x1)P(x2) . . . P(xn) = Constant, Then Eq. (8d) can
be simplified as:
P(y|x1x2 . . . xn) ∝ P(y)
Yn
i=1
P(xi
|y), (9)
Now, from Eq. (9), we find the probability of a given set of
inputs for all possible values of the target variable y and pick
up the output with maximum probability:
y = argmax
y
P(y)
Yn
i=1
P(xi
|y), (10)
F. STATISTICAL EVALUATION OF CLASSIFICATION METRICS
We have used several performance evaluation metrics to evaluate the performance of the proposed framework. The accuracy (ACC), error, false-positive rate (FPR), sensitivity (SE),
specificity (SP), positive predictive value (PPV), Matthew’s
correlation coefficient (MCC), F1_score, and Kappa index
can be calculated from confusion matrix [48], [49]. A lower
value of error and FPR, and a higher value of ACC, SE,
SP, PPV, MCC, F1_score, and Kappa index indicate a better
model. Besides, 10-fold cross-validation has been used [52]
on the overall dataset. The most significant point should
be mentioned here that the box-plot and Analysis of Variance (ANOVA) test are typically executed, relying on the
10-fold cross-validation result. The statistical significance
is determined by the p-value derived from the ANOVA
test [50], [51]. Furthermore, the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC)
has also been used to evaluate the performance of the classifier. The recall rate vs the decision boundary curve has been
used to examine the performance. In this study, we have used
the value of 0.5 as the decision boundary threshold to provide
the same importance to COVID-yes and COVID-no classes.
G. FEATURE IMPORTANCE USING SHAP VALUES
The SHapely Adaptive exPlanations (shortly known as
SHAP), proposed in recent papers by Lundberg and Lee [53],
are calculated for any tree-based model. The SHAP values from Game Theory to attribute φi value to each feature can be mathematically ascertained using the following
10270 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
formula [54]:
φi =
X
S∈N\i
|S|!(M − |S| − 1)!
M!
[fx (S ∪ {i}) − fx (S)], (11)
where M is the total input features, N is the set of all input
features, and S is a subset of the input features.
• In this plot, all the variables are ranked in descending
order.
• The horizontal line (x-axis) quantifies how much the
value is associated with a higher or lower prediction. All
the left-sided points represent the observations shifting
the predicted value in a negative direction. In contrast,
the points on the right contribute to shifting the prediction in a positive direction. All the features are on the
left y-axis.
• The color shows whether that variable is high (in red) or
low (in blue) for that observation.
III. EXPERIMENTAL RESULTS
In this paper, the Bayesian optimization has been used along
with and without the ADASYN algorithm. In the case of
ADASYN, sufficient adaptive synthetic data has been created to eliminate the imbalanced nature among the majority
and the minority classes. Firstly, the effect of ADASYN has
been evaluated along with ROC, shown in section III.A. The
balanced model has also been tested on the original test
data in section III.B. Box-plot and ANOVA are presented in
section III.C using cross-validation accuracy to evaluate the
statistical significance. The Recall rate vs. decision boundary
curve and Bootstrap ROC with ADASYN are discussed in
sections III.D and III.E, respectively. Then, the evaluation of
feature importance using SHAP and the analysis of SHAP
values have been presented in sections III.F and III.G, respectively. Finally, the performance of Bayesian optimization
has been compared with the Grid search and random search
in section III.H.
A. BAYESIAN OPTIMIZATION WITH AND WITHOUT
ADASYN
The newly obtained balanced dataset has been utilized; 67%
of the total dataset is used for training and validation, and
33% is used for testing. After that, multiple classifiers are
used, and various statistical measurements are presented. The
effect of ADASYN has been experimented and validated in
this subsection.
To begin, in the upper portion of Table 2, the performance analysis for the COVID Dataset with the utilization
of the ADASYN algorithm has been demonstrated. It can
be seen that; RF provides the highest classification performance. However, the performance of XGB and GBC is very
close to RF. LDA and QLD show the worst classification
performance among various classifiers presented in Table 2.
The same AUC value of 99.70% is observed among these
three classifiers, as shown in Figure 4. To demonstrate the
effect of the ADASYN algorithm, the original unbalanced
dataset is used. The dataset is also divided in the same manner,
FIGURE 4. ROC Curve with ADASYN.
i.e., 67% of the total dataset is used for training and validation,
and 33% is used for testing. We rerun the optimized code
on this dataset, and the results on the test dataset without
ADASYN is presented in the lower portion of Table 2. It can
be observed that the highest accuracy of 97.17% is obtained
by RF, which is close to the classification accuracy using RF
with ADASYN. This could happen in the imbalance dataset.
Therefore, accuracy is not a good performance indicator. The
Kappa index, MCC, and AUC are more robust and reliable
indicators in this case.
It can be seen that the highest Kappa, MCC, and AUC
values of 8.96%, 9.36% using NB, and 75.80% using XGB
(Figure 5), respectively, are obtained. Compared to the upper
portion of Table 2, i.e., results with ADASYN, the Kappa,
FIGURE 5. ROC curve without ADASYN. Note that the optimized model
has not been created by using a balanced dataset.
VOLUME 9, 2021 10271M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 2. Classification performance (in %) on the COVID dataset with and without ADASYN.
TABLE 3. Classification performance (in %) on the original test data of COVID.
MCC, and AUC values are 88.23%, 87.84%, and 23.90%
times lower ADASYN algorithm is not applied, respectively.
This can be happened due to an imbalanced model. This
significant improvement using ADASYN concludes that classification performance can significantly be improved through
directly applying the ADASYN algorithm.
B. RESULTS USING ORIGINAL TEST DATA ONLY
So far, we have seen the effect of ADASYN on classification
performance. The ADASYN is an oversampling method, and
the synthetic data is mixed with original test data during data
balancing. Therefore, it could be argued that what are the
results of the balanced model on the original test data only
where synthetic data is not mixed?
To answer this question, balanced and Bayesian-optimized
models have been applied to the original test data. Different performance measures, such as accuracy, sensitivity, specificity, and ROC, are presented in Table 3 and
Figure 6. It can be seen that XGB provides the highest
accuracy, error, F1_score, FPR, Kappa, MCC and sensitivity of 98.63%, 1.37%, 99.29%,24.21%,75.08%,75.08%, and
99.29%, respectively. In contrast, SVC provides the highest
PPV, specificity, and AUC of 99.94%, 97.89% and, 98.90%,
respectively. It can also be seen that XGB performs the best
in most of the classification metrics presented in Table 3.
10272 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 4. The accuracy score (in %) of the different optimized classifiers using 10-fold cross-validation.
FIGURE 6. ROC Curve for COVID on original test data only using each
model. The optimized model has been created by using a balanced
dataset and then applied to the original test dataset.
Furthermore, these results are mostly inclined with
ADASYN results (upper portion of Table 2), and results are
significantly better than without ADASYN in all classification measures. The ROC curve shown in Figure 6 is also
visually very close to Figure 4. Note that the same test dataset
has been used without ADASYN (i.e., in the lower portion of
Table 2) and in Table 3 for a fair comparison. Finally, it can
be concluded that a balanced model can significantly improve
the performance of the COVID dataset and XGB shows the
best classifiers. The confusion matrix of the best performing
balanced model with ADASYN and with original test data
have been presented in Figure 7 to show how much COVID
and Non-COVID patients are correctly classified.
C. K-FOLD CROSS-VALIDATION
In the standard train-test-split method, generally, a small portion of the data is taken as the test set, and the total dataset is
not tested. To overcome this issue, the k-fold cross-validation
(CV) is one of the helpful techniques exploited to test
the effectiveness of machine learning models. It is also a
re-sampling procedure to evaluate, and k = 10 is used in
this study. The first fold is used for testing, and the remaining
folds are used for training and repeated ten times to test the
total dataset fold-by-fold basis. The 10-fold cross-validation
result is presented in Table 4, where the classification result of
each fold is shown. The final row provides the average classification accuracy of the 10-fold results. From the Table 4, it is
observed that the least score has been obtained using QLDA,
whereas the XGB touched the mountain point, grabbing a
score of 96.70% and RF has attained an average accuracy
of 96.46%. On the other side, the classification performance
using Decision Tree, SVC, and GBC was less than XGB
and RF but above 90%. Note that, the data processed by
ADASYN is used only to train the classifier, but the original
test is used during testing and performance comparison.
Figure 8(a) showed the accuracy of different classifiers
using the COVID original dataset using a box-plot. Here
one-way ANOVA provided a p-value of 3.32 × 10−107 for
the original COVID test dataset, which is statistically significant (p < 0.005). It also provided an interactive plot of
multiple comparisons of means in Figure 8(b) that showed
the highest mean accuracy from XGB that is statistically
significant from seven classifiers (GBC, DT, SVC, NB, KNN,
QLDA, and LDA). In contrast, it is statistically not significant
from RF, because the mean of RF is almost identical. Note
that, Figure 8(b) is an interactive plot where the significance
of different classifiers can be visualized by clicking on the
specific classifier level. For instance, RF is blurred (shown
in grey) defining its insignificance as XGB is selected. Similarly, GBC and DT will also exhibit statistical insignificance
if one of them is selected.
D. RECALL RATE VS. DECISION BOUNDARY CURVE
The recall rate, in general, depends on the decision boundary
using a certain threshold. To exemplify, the recall rate vs.
decision boundary curve displayed in Figure 9(a), where
VOLUME 9, 2021 10273M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 7. Confusion matrix of the balanced model applied in (a) COVID
test Dataset with ADASYN, (b) original COVID test Dataset only. Figure 7(a)
depicts the percentage of the correct classification in with the first two
diagonal cells generated by the trained network. The numbers of patients
who are correctly classified as a COVID and non-COVID were 3150 and
3233, corresponding to 48.7% and 49.9% in each group’s patients,
respectively. Likewise, the numbers of patients who are incorrectly
classified as a COVID and non-COVID were 24 and 67, with 0.4% and 1.0%
correspondingly among all patients in each group. Similarly, the overall
99.2% were correctly, and 0.8% were incorrectly classified COVID, and
non-COVID were overall, 98.0% and 2.0% correctly and incorrectly
classified accordingly. In the case of prediction, the correct overall
predictions for COVID and non-COVID were 97.9% and 99.3%, respectively.
On the other hand, the incorrect results for COVID and non-COVID were
2.1% and 0.7%. Similarly, we can also interpret Figure 7(b).
0.5 decision boundary threshold (T ) has been used for the
‘‘COVID-19-yes’’ class. The recall rate of QLDA is about
0.98 at default threshold T = 0.5, meaning that about
98% times this optimized classifier can truly classify the
FIGURE 8. Box-plot for (a) COVID Dataset and (b) multi-comparison test.
Note that (b) is a graphical user interface tool by which one can test the
statistical significance of any classifiers. Here we only show the effect
of XGB. The effect of other classifiers can also be interpreted in the same
way.
‘‘COVID-19-yes’’. The XGB and RF provided a moderate performance of around 0.75 at default threshold
T = 0.5 defining the ‘‘COVID-19-yes’’ class. The SVC shows
the third highest performance of around 0.90. In contrast,
the recall rate of NB at this threshold is 0.25, meaning
that only 25% times NB can truly classify the ‘‘COVID19-yes’’ class. A similar scenario is observed for the
LDA classifier.
On the other hand, looking at Figure 9(b), the recall rate of
QLDA is drastically falling to a value of 0.1 at T = 0.5,
revealing that only 10% times QLDA can classify the
‘‘COVID19-no’’ class. The recall rate of XGB, GBC, and
RF is about 0.99 at this threshold whereas the recall rate
of SVC is 0.90. Finally, considering both ‘‘COVID19-yes’’
and ‘‘COVID-19-no’’ classification using recall rate vs.
decision threshold measure, it can be concluded that
SVC, XGB, and, RF provide the satisfactory recall
rate among different optimized classifiers predicting both
classes.
10274 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 9. Recall rate vs. decision boundary curve for (a) COVID positive and (b) COVID negative.
E. BOOTSTRAP ROC WITH ADASYN
To determine whether the optimized model is highly sensitive
to training data or not, bootstrapping is performed on the
XGB model as it is the best performing model. This gives
Nboot XGB having slightly different discriminative abilities.
To show the error, three ROC curves are plotted in Figure 10;
the middle one represents the average ROC where upper
and lower curves represent the 95% confidence interval (CI).
To obtain this bootstrap ROC, Nboot = 100 XGB models are trained and mean AUC of 0.98 with an upper and
lower confidence interval of 0.97 and 0.99, respectively, are
obtained. This indicates that training is not highly sensitive to
the training dataset.
F. FEATURE IMPORTANCE USING SHAP
In a variable importance plot, the most significant variables are sorted in descending order. The top variables
contribute more to the model than the bottom ones
and thus have high predictive power. By way of example, ‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’,
‘‘high_risk_interactions’’, ‘‘wheezes’’ are the most important
features, where ‘‘fever’’ touched the mountain point in this
case [shown in Figure 11]. Simultaneously, ‘‘pulse’’ and
‘‘sore_throat’’ received the least importance in classifying
the COVID-19 contaminated patients.
G. SHAP VALUE ANALYSIS
From the pictorial example of SHAP analysis [Figure 12] for
training data, it can be summarized that the three features,
‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’ and
‘‘loss_of _smell’’ have a massive positive impact is on the
target variable. The ‘‘high’’ comes from the red colour, and
the ‘‘positive’’ impact is shown on the X-axis. Whereas,
we conclude by mentioning that the features ‘‘ctab’’ and
‘‘wheeze’’ are highly negatively correlated with the target
variable. In this way, all the variables can be efficiently
explained. It should be mentioned that the behaviour of the
FIGURE 10. Bootstrap ROC curve of the COVID dataset using XGB
with 95% CI.
XGB model is defined by the SHAP and are not necessarily
causal in the real world. In other word, SHAP values do not
provide the causality; it only describes the model behaviour
and the behaviour of the data used to build the model [55].
As the model does not predict all the COVID patients accurately, it is plausible to get some false positives and false
negatives. However, the SHAP value can able to explain such
results, and the summary plot will be helpful to explain those
results.
H. PERFORMANCE ON THE GRID SEARCH, RANDOM
SEARCH, BAYESIAN OPTIMIZATION AND HARRIS
HAWKS OPTIMIZATION
We propose to use Bayesian optimization techniques in
our framework, and therefore, it is logical to compare
VOLUME 9, 2021 10275M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 5. Comparative search techniques.
FIGURE 11. Feature importance plot using SHAP for XGB.
FIGURE 12. The SHAP variable importance plot of training data using XGB.
the Bayesian optimization algorithm with commonly used
parameter search algorithms. Two popular and widely used
algorithms, namely, grid search and random search, compare
with our proposed techniques. Table 5 presents the comparison of different search algorithms in terms of several
parameters evaluated; the overall time is taken (in sec.) to
complete the program, cross-validation accuracy score, test
score. All the simulations were run on Intel core i9 computer
having 64GB RAM and used the XGB model. It can be seen
that it takes 10473.740 Sec. to complete the simulation using
grid search, whereas random search and proposed Bayesian
optimization take only 162.794 Sec. and 675.389 Sec, respectively. Furthermore, the random search and Bayesian algorithm take 30 parameters each, while the grid search requires
more parameters, which is 218 times than that of others. The
test score using Bayesian optimization is 98.20%, which is
better than grid search, random search.
The pictorial depiction of the comparative search methods has also been given in Figure 13, from where it can
be added that at the initial stage, the accuracy of Random
Search was nearly 97.50%, which was almost stable up to
12 iterations. Then, with a single iteration, it takes a
sharp change in its accuracy, touching closely the score
of 98%, which was followed by an unchanged condition until
30 iterations. In contrast, the score of our proposed Bayesian
Optimization technique commenced before 97%, which was
almost steep up to 2 iterations, touching the accuracy
FIGURE 13. Comparative optimization techniques applied to the XGB
model.
10276 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
above 98%. The most exciting information should be mentioned here that the score of our proposed method remains
unchanged, except for a slight change after 15 iterations.
Before finishing 30 iterations, its accuracy touched the mountain point.
The proposed Bayesian Optimisation Framework has
also been applied to the most recent Harris Hawks optimization algorithm calculated over 200 evolutions with
20 populations on the same train-test settings. It provides
98.39% cross-validation accuracy, whereas the testing accuracy is 98%. The result is very similar to the Bayesian Optimisation framework. However, it takes 6204.80 Sec. which is
9.4 times slower than our proposed framework as it requires
more evaluations and optimization calculations; see Table 5.
To further justify, a statistical significance test between
Bayesian optimization and Harris Hawks optimization algorithm is performed on 10-fold cross-validation using t-test.
After that, the p-value is calculated, and the box-plot is
plotted. A p-value of 0.47 is found, which suggests that
there is no statistically significant difference between these
two optimizations. The box-plot illustrated in Figure 14 also
justifies the same statements.
FIGURE 14. Box-plot of Bayesian optimization and Harris Hawks
optimization.
IV. DISCUSSION AND COMPARISON
In this research, a Bayesian optimization-based machine
learning framework with a class balancing strategy using
the ADASYN algorithm is proposed to identify COVID
patients from their inpatient facility data. Nine state-of-theart classifiers such as LDA, QLDA, NB, KNN, DT, RF,
XGB, GB, and SVC are utilized in this proposed framework to identify COVID patients. Different classification
measures such as accuracy, sensitivity, specificity, Kappa
index, Matthews correlation coefficient are used to show the
efficacy of different classifiers. This study also performed
10-fold cross-validation accuracy to achieve statistical significance using ANOVA, recall rate vs. decision boundary
threshold analysis, ROC, and bootstrap ROC. Finally, SHAP
analysis is performed to interpret the feature importance and
interpret the model. These different classification indicators
describe model performance from another point of view.
The primary intention to use these indicators is to describe
the classification performance from a different perspective.
It can be seen from Table 2 that RF yielded the highest
classification performance in terms of accuracy, kappa index,
and MCC, etc. However, the classification performance of
XGB and GBC is very close to RF. The ANOVA and
multi-comparison tests show that the average accuracy of
RF, XGB, and GBC are very close and are not statistically
significant. However, the 10-fold cross-validation accuracy
of XGB provides the highest value (see Table 4). Moreover, the balanced XGB model offers the highest classification performance when applied to the original test data (see
Table 3). Also, the recall rate vs. decision threshold boundary indicates the superior performance of XGB and SVC
(see Figure 9). This concludes that the balanced and optimized XGB model would be the best choice for detecting
COVID patients using their inpatient facility data. Therefore,
further analyses such as bootstrap ROC and SHAP analysis
and features importance analysis are done on a balanced and
optimized XGB model.
Regarding the ADASYN algorithm, it should be mentioned
that ADASYN adaptively generates synthetic data samples
for the COVID-yes class since it is a minority class to reduce
bias introduced by imbalanced data distribution. ADASYN
moves the classifier’s decision boundary towards harder-tolearn examples, improving the learning performance [28].
Therefore, applying the ADASYN algorithm enhances the
learning process and eventually improves our COVID classification performance; see Table 2 to understand the effect of
ADASYN in detail. Regarding Bayesian optimization (BO),
unlike grid search and random search, it can be mentioned
that BO takes the previous objective function evaluation
into account, and the function goes to the optimal solution.
Therefore, the hyperparameter using BO provides fine-tuning
parameters, which ultimately builds an optimized model and
consequently increases the classification performance. SHAP
is used to determine feature importance and model interpretation; it can be mentioned that SHAP uses a game-theoretic
approach, which has an excellent mathematical background
and current state-of-the-art approach.
Due to the salient features mentioned above, it can be
noted that the proposed framework can not only be applied to
COVID-19 detection but also applied to other classification
problems such as diabetic prediction, asthma prediction, etc.
While describing the significance and strength of this study,
it is also logical to explain the weaknesses of this study. The
database used in this study is a moderately large dataset.
It will be useful to apply the proposed framework on a larger
dataset and validate the proposed approach on a completely
independent dataset before clinical use. Clinical blood sample
data and integration to X-ray and CT-scan will enhance the
detection rate and validity. This is beyond the scope of this
study.
VOLUME 9, 2021 10277M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 6. Description of the clinically operable decision tree algorithm.
FIGURE 15. A decision rule using four key features and their thresholds
in absolute value.
A. DEVELOPMENT OF A CLINICALLY OPERABLE
DECISION TREE
A clinically operable decision tree would benefit clinical staff
as it is straightforward to understand the underlying process. As DT are simple classifiers consisting of sequences of
binary decisions organized hierarchically [56], we have built
a simple tree by using four important features, x1 = cough;
x2 = loss of smell; x3 = high-risk exposure occupation;
x4 = sats; Note that, the continuous value of oxygen saturation feature, i.e., x4 feature is discretized into three different
levels of 1, 2 and 3 to denote severe, moderate and normal
level, respectively. x4 feature value lies between 75 and 90
mm-Hg is treated as severe, 91 and 95 mm-Hg as moderate,
and 96 and 100 mm-Hg as a normal level. Figure 15 represents the corresponding DT, and the description of the tree
algorithm is given in Table 6.
B. DEVELOPMENT OF A DECISION SUPPORT
SYSTEM (DSS)
A DSS could be beneficial to support clinical staff for screening COVID-19 patients from their inpatient facility data.
A DSS is usually a graphical representation of decision,
FIGURE 16. Probabilistic output for the DSS. In the upper figure, the 0 has
represented a subject with COVID negative, whereas 1 represented a
subject with COVID positive. The lower figure represents a probabilistic
outcome of the subject affected by COVID, where the red dotted line
defines the threshold level. When the patient data level exceeds this
threshold level, then the subject will be considered as COVID positive.
Whereas the subject with the probability of less than 0.5, i.e., the
threshold value, will be regarded as COVID negative. In either way, we can
say that this the chance that a person is affected by COVID.
COVID-19, in this case, to visualize the probable state of the
patient. A possible outcome of COVID suspected patient’s
inhouse facility data is presented in Figure 16, in terms of the
posterior probability. A probabilistic result is more intuitive
to the clinical staff and, therefore, used in this DSS. Note
that 100 patients are used from the test database for illustration purposes. The patient is sorted in ascending order so
that patients with ‘‘COVID-no’’ labelled appears first, and
patients with ‘‘COVID-yes’’ appear.
C. COMPARISONS WITH OTHER METHODS/STUDIES
To delineate the superiority of our proposed research,
an illustrative comparison of our work has been accomplished to other COVID studies. From the tabular illustration
[Table 7], it can be mentioned that both Jim et al. [11] and
Ozturk et al. [57] used CNN to obtain the accuracy respectively 92.50% and 98.08%. Furthermore, multiples research
works have been carried out by [7], [63], [64] with the direct
10278 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 7. Comparison of performance with other methods.
implementation of XGB using mostly clinical data, where
the average of the accuracy obtained from [7], [63] was
less than 90%. On top of that, Wu et al. [58] used RF to
get a classification accuracy of approximately 96%, which
outperformed Brinati et al. [59], who utilized both DT and
RF. In addition, the lowest performance was obtained by Sun
et al. [60], who used the SVM classifier for clinical and
Demographic data. Most importantly, although the accuracy
of Wu et al. [58] is slightly higher than that of our proposed
method, the AUC and Specificity of our work far outweigh
the other methodologies mentioned here.
V. CONCLUSION
This paper presents the optimal use of different machine
learning techniques, including state-of-the-art classifiers,
to predict COVID. The proposed approach is aimed to handle
the real-time in-home dataset in detecting the COVID effectively. Thus, the proposed technique provides a user-friendly
and low-cost tool for COVID detection. In designing the
method, the COVID dataset, collected from CH-BH, has
been used to assess the performance using different classification metrics such as accuracy, sensitivity, specificity,
kappa index, etc. The hyper-parameters of different classifiers
have been optimized using Bayesian optimization, and the
ADASYN has been used to balance the dataset. Compared
to the studies presented in this study, it is evidenced that
both the classification accuracy and AUC for our proposed
framework has attained the highest values of 98.50% and
99.40% using XGB, respectively. As the proposed approach
has been applied to a moderately large dataset, it should be
used on a big dataset before clinical trials. However, our
primary intention is to test the feasibility of such settings.
A similar approach can be applied to design other classification problems. Finally, two potential applications of our
proposed technique, namely clinically operable decision tree
and decision support system, would be beneficial for clinical
staff and building an efficient recommender system. It could
easily be integrated into mobile devices which would be very
useful for the end-users.
DATA AVAILABILITY
The raw dataset can be accessed through Github:
https://github.com/mdcollab/covidclinicaldata. The processed data can be obtained from the first author (Md Abdul
Awal; m.awal@ece.ku.ac.bd) of this paper.



NEW_PAPER


Received August 25, 2020, accepted September 20, 2020, date of publication September 22, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025971
Balancing Personal Privacy and Public Safety
During COVID-19: The Case of South Korea
NA YOUNG AHN 1
, JUN EUN PARK2
, DONG HOON LEE 3
, (Member, IEEE),
AND PAUL C. HONG4
1
Institute of Cyber Security and Privacy, Korea University, Seoul 02841, South Korea
2Department of Pediatrics, Korea University College of Medicine, Seoul 02842, South Korea
3
Institute of Cyber Security and Privacy and The Graduate School of Information Security, Korea University, Seoul 02841, South Korea
4
Information, Operations, and Technology Management College of Business and Innovation, The University of Toledo, Toledo, OH 43606, USA
Corresponding authors: Dong Hoon Lee (donghlee@korea.ac.kr) and Paul C. Hong (paul.hong@utoledo.edu)
ABSTRACT There has been vigorous debate on how different countries responded to the COVID-19
pandemic. To secure public safety, South Korea actively used personal information at the risk of personal
privacy whereas France encouraged voluntary cooperation at the risk of public safety. In this article,
after a brief comparison of contextual differences with France, we focus on South Korea’s approaches
to epidemiological investigations. To evaluate the issues pertaining to personal privacy and public health,
we examine the usage patterns of original data, de-identification data, and encrypted data. Our specific
proposal discusses the COVID index, which considers collective infection, outbreak intensity, availability of
medical infrastructure, and the death rate. Finally, we summarize the findings and lessons for future research
and the policy implications.
INDEX TERMS COVID-19, COVID index, de-identification, epidemiological investigation, infectious
diseases, pandemic, personal information, personal privacy, policy, public safety, South Korea.
I. INTRODUCTION
Increasingly, the integration of big data and information and
communications technology (ICT) promises enormous social
value creation. In a pandemic crisis, public safety is a top
priority. Simultaneously, we cannot ignore potential privacy
breaches. The ‘‘old’’ debate over personal privacy and public
security is still relevant. Since personal information is crucial
to curtail the spread of a pandemic, policymakers and officials
can more likely expect ‘‘implicit’’ consent. However, in the
course of pursuing compelling public purpose, privacy rights
may be at risk [1]–[3].
In general, any epidemiological study is subject to an ethics
review to ensure privacy [4], [5]. For a face-to-face investigation, investigators respect confidentiality requirements. However, in view of the increasing social costs associated with the
prevention and treatment of serious infectious diseases, there
is a growing demand to gather accurate personal information
in real time. For example, Gilbert Beebe suggested that in
certain disastrous circumstances, public interest might be a
higher priority than privacy issues [7]. The widespread flu
The associate editor coordinating the review of this manuscript and
approving it for publication was Yu-Chi Chen .
epidemic in 2009 provided additional support for this line of
reasoning. While conducting epidemiological investigations,
researchers did not always obtain an individual’s explicit
consent. In the United States, the Health Insurance Portability
and Accountability Act (HIPAA) established the privacy rules
that set limits on the use and disclosure of any personal health
information [8], though aggregating personal information for
public health purposes is a somewhat different matter [9].
COVID-19 is an extraordinary circumstance that poses
enormous public health risks—potentially affecting millions
of people worldwide [10]–[12]. Nations are at war with the
coronavirus. In this context, what does it mean to balance
personal privacy and public safety? What are the boundaries and acceptable norms? This study considers these questions and examines the actual cases of two countries—South
Korea and France. The subsequent sections of this study proceed as follows. In Section 2, we discuss the characteristics
of the virus that causes COVID-19. We then introduce an
anti-displacement alternative to COVID-19. We further compare the results of the French and Korean governments’ quarantine measures against COVID-19. We apply the STRIDE
Threat Model to perform a risk analysis of the Korean government’s quarantine system. Our specific proposal considers
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 171325N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
collective infection, outbreak intensity, availability of medical infrastructure, and the death rate. Based on our findings,
we present lessons and implications for future epidemiological investigations.
II. COVID-19 RESPONSES
A new type of coronavirus (SARS-CoV-2) was first reported
in Wuhan, China, in December 2019. Since then, this respiratory infection epidemic, designated as COVID-19, spread
throughout China and worldwide. Upon infection, after a
2- to 14-day incubation period, patients experience respiratory symptoms including high fever (about 37.5 degrees) and
cough or dyspnea [13]–[19]. However, it seems that there
are several cases of asymptomatic infections. On January 21,
2020, the Chinese government officially reported 15 confirmed cases of COVID-19 [20]–[23]. The medical staff
involved in the incident became credible evidence of humanto-human transmission [24]. On January 30, 2020, the World
Health Organization (WHO) declared the continual spread
of this infection as an International Public Health Emergency (PHEIC). With an accelerating rate of confirmed
patients worldwide, on March 11, 2020 the WHO declared
the COVID-19 outbreak a pandemic [25].
COVID-19 is a respiratory virus that spreads primarily
through droplets generated when an infected person coughs
or sneezes, or through droplets of saliva or discharge from
the nose. The infected patient’s saliva can be transmitted
directly to another person’s eye or if a person rubs their
eyes with a virus-contaminated hand [24]. The rapid spread
of COVID-19 was expected to overwhelm limited medical
equipment and facilities with the sudden increase in the
explosive number of patients [26]. Consequently, the fight
against COVID-19 requires contact tracing for close contacts
of laboratory-confirmed or probable patients. In some countries, these responses were compulsory, while others implemented a voluntary system. Our study compares the cases
of France and South Korea, with special focus on the South
Korean government’s approaches in seeking the participation
of its citizens.
A. KOREAN GOVERNMENT’s APPROACH
At first, the South Korean government did not respond
appropriately by not knowing the precise nature of the
COVID-19 pandemic. The initial optimism was based on
confidence that Korea’s medical capabilities could handle any
major public health challenges. Additionally, how to assess
asymptomatic patients was determined somewhat later. For
example, a Chinese woman who arrived from Wuhan on
January 20, 2020 was identified as the first confirmed case.
Until then, foreign tourists without fever were free to enter
Korea, and there was not yet any serious effort to track
asymptomatic patients.
However, upon understanding the significance of asymptomatic patients and the nature of droplet infection, the next
task was to identify the pathogens of confirmed patients.
Fig. 1 describes the essential elements of the Disease Health
FIGURE 1. Disease health Integrated Management System for COVID-19.
Integration System (DHIMS), which collects and uses epidemiological survey data. Local governments conduct tests
for epidemiologic investigation. Medical staff at public health
centers and diagnostic screening centers follow-up with the
confirmed patients. Local governments are responsible for
operating screening clinics through large scale drive-through
or walk-through testing sites without harvesting virus
transmission [27].
If a person tests positive, then the health or diagnostic
center immediately uploads the relevant personal information of the patient to the DHIMS. The health or diagnostic
center immediately submits incident reports to the Korean
Centers for Disease Control (KCDC). The local government
health center also conducts an additional epidemiological
investigation. The public safety law requires that confirmed
patients disclose their recent movements and identify all contacted persons. The local government examines a confirmed
patient’s recent usage information from mobile phones and
credit cards and uploads all information about the contacted
persons including their name, address, contact information,
date of birth, gender, disease name, diagnosis date, age,
occupation, place of residence, telephone number, and health
status, to the DHIMS. In this way, a national database of epidemiological investigations maintains all the relevant information of the confirmed patient and all contacts.
A diagnostic test is performed immediately for persons
with symptoms. According to the severity of the COVID-19
symptoms, the individuals are either self-quarantines or hospitalized. Recent contacts who have no symptoms are quarantined for 14 days from the contact date of the confirmed
patient. Self-quarantined individuals are monitored daily at
local government call centers. If the additional diagnostic test
after 14 days shows that the individual is negative and he/she
has no symptoms, then the individual is released.
The Korean government implemented a COVID-19 response system with 3P (Preemptive, Prompt, and Precise)
and 3T (Trace, Test, Treat) plus P (Participate) quarantine
response model [27]. It used innovative ICT systems such as
self-isolation and diagnostic apps, drive-through and walkthrough clinics, and mobile phone location information analysis. The Korean government also counted on voluntary
171326 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
participation by citizens to develop additional app capabilities. For example, using these aggregated epidemiological
survey databases, real time COVID-19 maps and monitoring
apps were developed to benefit society at large.
B. FRENCH GOVERNMENT’s APPROACH
France established Public Health France (PHF) on
January 13, 2020 to monitor and respond to the COVID-19
epidemic [28], [29]. PHF’s Crisis Center monitors epidemiological prevention, mobilizes health protection organizations,
manages the strategic resources of medical facilities, and
offers support services. The PHF conducts daily epidemiological investigations and releases the aggregate details
including the area, gender, and age group of COVID-19
patients [30], [31].
The PHF set up a surveillance system to monitor the epidemiological and clinical aspects of COVID-19 using urban
medicine, measure the severity of the epidemic and its impact
on the medical system, and report the fatality rate. The PHF
took active preventative measures to control the spread of
COVID-19 with the aim of reducing the risk of transmission
by providing warning messages to people in affected areas.
In addition, the precautionary measures aimed to help people
maintain a better quality of life, even in social isolation.
The PHF also supported active health-related services
by operating a remote support system. The PHF allows
healthcare professionals (e.g., doctors, nurses, pharmacists,
physical therapists, midwives, etc.) and health professionals
(managers, supervisors, health facility personnel, and engineers) to be prepared for a request for help from the health
center. The French government implemented quarantine measures since March 16, 2020. The PHF monitors the behavioral responses and mental health practices in response to
these changes and assesses social anxiety levels. Certainly,
the COVID-19 pandemic disrupted the French ways of life
and restricted vital economic and social activities. From the
early days of the outbreak, the PHF’s main challenge has
been how to mobilize citizen participation in the fight against
COVID-19.
C. COMPARISONS OF FRANCE AND SOUTH KOREA
According to WHO data, the first confirmed case in South
Korea was January 20, 2020. In France, the first reported case
appeared on January 24, 2020. However, after little more than
two months, these two countries showed a marked difference
in terms of cumulative number of confirmed cases and total
deaths [25]. As Table 1 (as of June 7, 2020) reports, the cumulative total of confirmed cases in Korea is 11,776 and 153,634
in France. The cumulative deaths are 273 and 29,143 for
Korea and France, respectively.
Korea’s population is 51,269,183, and France’s population
is 65,273,512 as of June 7, 2020 [25], [32]. In France, 20%
of the population is over the age of 65, while it is about 14%
in Korea, indicating that France has many elderly people.
In addition, the number of beds per 1,000 people is 5.98 in
France and 12.27 in Korea. In general, mortality is closely
TABLE 1. Comparison of COVID-19 data for Korea and France.
related to the number of hospital beds and the elderly population [33], [34]. Therefore, when comparing the hospital
bed and proportion of the elderly population, more deaths
should be more likely in Korea than in France. Both countries
encouraged their citizens to join the fight against COVID-19.
Even so, France has relatively more fatalities than Korea.
These differences deserve careful analysis of other preventive
measures. In the next section, we examine the impact of the
epidemiological investigation database and the ICT technology usage in Korea.
III. SECURITY OF THE KOREAN RESPONSE SYSTEM
It is beyond the scope of this study to describe the development of the Korean government’s quarantine system processes and its operational mechanisms fully. For the purpose
of this research, we applied available response guidelines
released by the Korean government and explored other documents about the quarantine system [35], [36].
A. THREAT ANALYSIS USING THE STRIDE THREAT MODEL
We evaluated security by applying the STRIDE threat model
and examined the dynamic investigation data input and output
of the DHIMS [27], [37].
FIGURE 2. Potential data vulnerabilities in the system.
Fig. 2 shows the sequence of on-line and off-line data
collection, DHIMS storage, and third-party access. Potential data vulnerability spots are noted ( ) in the process
linkage sequences. Threats to data integrity occur in several
ways. Despite Korea’s effective response to COVID-19 using
epidemiological survey data, the entire process also contains
potential privacy violations.
Identity Spoofing: The appropriate security level of the
DHIMS system requires identity safeguarding and restricting
access to epidemiological investigation data. After performing the basic authentication operation procedures, the relevant
VOLUME 8, 2020 171327N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
medical personnel, epidemiologists, government agencies,
or civilians (i.e., third parties) are allowed to access the
epidemiological investigation database. Identity spoofing;
that is, misusing stolen identity data, is the most prevalent
security risk attack.
Data Tampering: The on-line/off-line epidemiological
data collection methods involve extensive personal information: name, address, contact information, gender, age, and
phone number of the confirmed patient / all contacted. The
DHIMS does not automatically de-identify such epidemiological survey data. During the data entry process, medical
personnel or epidemiologists may make mistakes or arbitrarily change some of personal information content.
Repudiation: Because a legitimate user has access to the
input and output of epidemiological survey data from the
DHIMS, there must be sufficient correcting and checking
procedures in the processing data operation. For example,
what if the epidemiological investigation results in an offline
state do not always exactly match the epidemiological data
entered in an online state? Therefore, a repudiation option
is necessary to ensure the integrity of the epidemiological
investigation data.
Information Disclosure: The retention period for epidemiological data in DHIMS is permanent or semipermanent. If the DHIMS has solid system security, then we
can assume that all personal information is safe. However,
when a third party requests a particular set of epidemiological investigation data, the DHIMS is supposed to conduct a
de-identification process and offer specific numbers instead
of names [37]. However, in the course of various information disclosures, an individual’s privacy might not always be
well-respected.
Denial of Service/ Elevation of Privilege: What might
be problematic is the fact that these epidemiological investigation data have a legally permanent or semi-permanent
retention period [37]. The DHIMS quality control measures
require an application of relevant parameters (e.g., proper
authorization and examination of usage patterns). Without the
full operation of strict safeguarding measures when issuing
permission or denial of personal information access, serous
privacy risk concerns remain.
Table 2 summarizes the various types of threat and risk
levels according to the DHIMS system access level.
B. PERSONAL PRIVACY vs. PUBLIC SAFETY
The Korean government disclosed the COVID-19 confirmatory movement paths and the addresses of quarantined
buildings and enforced two weeks of self-containment for all
confirmed patients and their contacts. In the early days of the
epidemic, COVID-19 maps tracked the movements of these
individuals, thus raising awareness of many people in affected
areas.
In the digital age, balancing public safety and personal privacy is still enormously challenging [38]–[40]. With the rapid
spread of COVID-19, unidentified aggregate information has
little value. Public safety requires the ‘‘right to know’’ about
TABLE 2. Threat type and threat level.
the status of infection. Individuals may waive their privacy
rights for public safety when it requires informing people
about relevant COVID-19 infection information. The question is, ‘‘For legitimate public safety purposes, how do government authorities rightfully use personal information?’’
C. EXAMPLE OF BIG DATA USE IN THE
COVID-19 PANDEMIC
From the early stage of the outbreak, the Korean government
collected detailed personal information about the confirmed
patients. Using these data (e.g., credit cards, phone number, and address), investigators could specify the paths of
infection, conduct disaster prevention, and implement selfcontainment measures of all contacts. Such active follow-up
methods had a considerable success.
On February 18, 2020, Korea had its 31st confirmed
patient from the Shincheonji church in the Daegu area.
With the sudden increase in confirmed patients among Shincheonji church members, the Korean government changed its
approach and implemented more aggressive follow-up measures [27]. Shincheonji church, as a new religious movement,
employ somewhat controversial elements in their recruitment
of new members and the education of its existing members.
In particular, their regular mass meeting often occurs in an
enormous, enclosed hall. Hundreds of the church’s leaders
attended their international missionary outreach gathering
in Wuhan, China and returned to Korea in January 2020.
In the meantime, the number of confirmed patients increased
explosively—up to 7,513 on March 10, 2020 [41]–[43].
Considering the rapid virus transmission among the church
members, the Korean government took aggressive action.
At the government’s request, the Shincheonji Church provided the social security and phone numbers of its members.
Local governments called the church members in their region,
looked for symptoms, and conducted COVID-19 tests. The
Shincheonji church ledger has more than 200,000 people.
Thus, nearly all the church’s members (about 212,000) were
contacted and examined. The Korean government used this
set of big data to prevent the COVID-19 pandemic. With the
use of this data and follow-up testing, the government effectively contained one of the main sources of the widespread
outbreak.
171328 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
FIGURE 3. Comparison of cumulative deaths in South Korea and
France [44].
Fig. 3 shows a comparison of the cumulative deaths in
Korea and France. The number of deaths before and after
the COVID-19 pandemic, declared on March 11, shows a
sharp difference. As we discussed in the case of Shincheonji
church, Korea’s aggressive and extensive use of personal
information made a significant difference. The question is,
‘‘What is the proper way to use personal information, even
in this pandemic?’’ Here, we consider the value of using
de-identified information.
D. DE-IDENTIFICATION IN EPIDEMIOLOGICAL
INVESTIGATIONS
As a proactive measure to contain and prevent the pandemic, the Korean government used epidemiological data
through ICT. Medical testing equipment expedited massive COVID-19 testing, which was instrumental in reducing
mortality. It is a public safety imperative to use personal information to control and prevent the spread of a pandemic. Managing personal information stored in big data sets requires
appropriate privacy protection measures. Privacy violation is
related to the use of identifiable personal information. Therefore, an effective safeguard of personal privacy requires the
use of non-identifiable personal information. The right type
of technological support is essential for such de-identification
options.
In the United States, the HIPPA set national standards for
the protection of an individual’s medical records and personal
health information. It applies to health plans, health care
information centers, and health care providers that transmit
any health care transactions electronically. This rule requires
appropriate safeguards to protect the privacy of personal
health information, sets limits, and specifies the conditions
for the use and disclosure of such information without patient
consent and approval [9], [45].
However, the Korean government uses identifiable personal information with limited restrictions, potentially leading to serious violations of the privacy of patients and their
contacts. Securing personal information for quarantine measures is appropriate. With respect to personal privacy, it is
important to use the information gathered for the specific
intended purpose only. Using identifiable personal information for any other purpose is a breach of confidence and trust.
Moreover, the legal provision of keeping quarantine investigation data either permanently or semi-permanently is not
reasonable at all. Requiring the de-identification of personal
information and rapid-deployment-relevant technology is an
urgent need [46].
IV. ADAPTIVE EPIDEMIOLOGICAL INVESTIGATIONS
The purpose of conducting epidemiological investigations is
to understand the nature of an epidemic and determine how to
control the spread of infectious diseases for public safety [47].
However, public safety does not justify privacy infringement.
In this section, we discuss the practical steps epidemiological
investigations can take to achieve a balance between privacy
and public health.
A. CLASSICAL TRADE-OFF BETWEEN PERSONAL PRIVACY
AND PUBLIC SAFETY
The HIPAA’s privacy rules propose two approaches to the
de-identification of personal health information: the safe
harbor method and the expert determination method [45].
The safe harbor method deletes 18 personal identification
variables such as name, social security number, contact information, IP address, fingerprints, photographs, and detailed
address. The method of using experts is to process personal
information using non-identifying algorithms.
The release and forget model, the data use agreement (DUA) model, and the enclave model are all useful to
achieve effective control in data storage and usage processes.
The general pre-sale model is to release unidentified personal
information to the public by posting data online. A DUA
establishes sharing rules between research collaborators who
are covered entities under the HIPAA privacy rule. Only
intended recipients can use certain information in a limited
data set. The closed room model maintains a safe analytic
environment that restricts unauthorized access and the export
of personal information in its original form. It is a physical
and technical control method to respond and export [48].
It is often challenging to enhance the scientific utilization
value of data collected with de-identified personal information. An increasing level of de-identification is negatively
related to the quality of the data and the precision of the
research results. Conversely, higher data quality and outcome
precision require lower levels of de-identification. A greater
level of personal identification is related to a higher possibility of privacy infringement [49].
Therefore, individual researchers aiming to achieve more
precise analysis results may prefer to use the original data,
which contains identifiable personal information. On the
other hand, reputable institutions satisfy personal privacy
requirements by ensuring the anonymity of the data.
B. BALANCING PERSONAL PRIVACY AND PUBLIC SAFETY
There are diverse approaches to data de-identification. In general, methods to determine the level of de-identification of
VOLUME 8, 2020 171329N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
personal information are known [48]. The National Institute
of Standards and Technology (NIST) proposes a method
determined by an expert and a safe hopper method for removing multiple identifiers [50], [51]. In recent years, differential
privacy technology that adds noise to personal information
has been attracting attention as a way to increase privacy in
big data analysis [52], [53]. This differential privacy technique is a de-identification method that performs a kind of
pseudonymization process.
With widely available de-identification technologies, it is
difficult to prevent individuals from being re-identified from
de-identification measures. Researchers at the Imperial College London, UK, conducted experiments with published
data from the United States, Turkey, and other countries, and
found certain attributes accurately even by using de-identified
data [54]. Their machine learning model could identify individuals with 99.98% accuracy from anonymized data using
only 15 demographic attributes (age, gender, marital status, etc.). This research team suggests a paradigm shift:
‘‘We need to de-identify, then move on. Anonymity is not
a property of the data set. It depends on how the person
who writes it uses it.’’ In other words, what matters is not
anonymizing, but designing and organizing data to be useful
and meaningful.
So then, what are the alternatives? It is time to move from
the idea of de-identification to the application of appropriate
technologies. The aim is to strike a balance between the public use of data and personal privacy [55], [56]. Technologies
such as secure multi-party computation and homomorphic
encryption are emerging. More innovations are certainly in
progress in the post-COVID-19 world of new big data technologies and ICT applications [57], [58].
The development of these new technologies can increase
our options when dealing with infectious diseases. It is imperative to balance personal privacy and public safety, even in the
context of COVID-19. Personal information with individual
consent may be used for specific research purposes.
C. THE NEED FOR AN INDEX TO BALANCE PERSONAL
PRIVACY AND PUBLIC SAFETY
There has been serious debate over the value priorities of the
epidemiological investigation. Healthcare policymakers are
more likely to lean toward public safety goals. On the other
hand, safeguarding personal privacy is important from the
individual rights perspective. In this context, developing an
effective mechanism for balancing public safety and personal
privacy is important and timely. We present an index measure
for balancing criteria. Our study provides a helpful practical
tool in epidemiological investigations.
D. COVID INDEX FOR EPIDEMIOLOGICAL INVESTIGATION
By applying the concept of DREAD modeling in security
engineering, we propose the COVID index as a method to
balance public health and privacy in epidemiological investigations [35]. This COVID model uses five parameters: collective infection, outbreak intensity, viral tiler, infrastructure
of medical faculties (e.g. number of medical beds per million
people), and death rates (or fatality rate).
TABLE 3. COVID index for intelligent epidemiological investigations.
Table 3 illustrates how adaptive epidemiological investigations may use the COVID index. Here, C represents collective
infection, O represents the outbreak intensity, and V represents the viral propagation power. Here, the value indicates
the minimum concentration at which the virus infects the cell.
I represents the level of medical infrastructure. D represents
the mortality rate of the virus. The COVID index can be
calculated as follows:
COVID index =
C + O + V + I + D
5
. (1)
Values from 0 (low) to 5 (high) are assigned to each item.
The values of each item are summed according to Equation 1,
and the COVID index is determined as the average value
of the results. The sum with be a value from 0 to 25, and
the COVID index will therefore be a value 0, 1, 2, 3, 4,
or 5. A high COVID index suggests a significant risk of the
virus’s propagation power and public health and an urgent
need to investigate the epidemiology. In this case, aggressive
epidemiological investigations should be conducted by collecting original data. Aggressive epidemiological investigations minimize the incidence of additional confirmed patients
from contact and suspected patients [59], [60]. Quarantine
measures can rapidly contain a virus. Thus, deploying the
available medical resources has the maximum prevention
effect.
If the COVID index is greater than or equal to 2, then the
epidemiological investigation should focus on collecting and
using de-identified data. On the other hand, for a COVID
index of either 0 or 1, researchers should collect and use
encrypted data instead.
E. SUGGESTIONS TO STRENGTHEN PRIVACY IN
EPIDEMIOLOGICAL INVESTIGATIONS
The primary purpose of the epidemiological investigation is
to minimize contact with a confirmed patient. Thus, isolating
individuals that test positive for a disease is imperative to
prevent the occurrence and spread of infectious diseases.
Here, we suggest several practical suggestions to enhance
security in the epidemiological investigations.
First, investigators should be required to obtain a personal
consent forms and use personal information within a specific
period. In the early breakout period of COVID-19, personal
information was often collected without a proper personal
consent process. Later, a mandatory requirement to specify
171330 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
the data storage period and usage patterns of personal information was put in place. If proper consent forms are not
obtained, then the personal information collection process
should stop. All personal information stored in the database
should include the entry time and expiration date. The investigation system should automatically delete epidemiological
survey data after the expiration date. Further steps may also be
taken to remove personal information completely from other
databases and thus guarantee personal privacy [61].
Second, we should explore other options to use identifiable
personal information. What if de-identification is not practical for research purposes? Personal information is regarded as
similar to the copyright concept. For the sale of any products
with copyright, a certain amount of money is set aside to
compensate the copyright holder. Similarly, it is plausible
to compensate each individual for the use of their personal
information for specific research purposes.
Third, we should address de-identification technology.
An individual from the medical field or an epidemiologist
may apply de-identification technology when storing personal information. When the required information is collected
through off-line systems and then uploaded to a database,
then the individual under investigation should be notified
to check the accuracy and provide consent. Afterward,
the offline information should be destroyed immediately and
the individual should be notified of the destruction. Epidemiologists should do the same when they apply de-identification
technology to store personal information collected online.
Fourth, researchers should establish conditions for third
party access. Any personal information provided to a third
party should be made available in the form of non-identifying
numbers or symbols. In case a third party need to use
identified personal information, they should require personal
consent.
Fifth, researchers should design an operating system for
personal privacy. Google and Apple recently released a tracking system with privacy features [62], [63]. Other scholars
also introduced systems that encrypt data to ensure privacy in
applications [64], [65]. These options offer additional safeguards for ensuring personal privacy.
Adaptive epidemiological surveys may still contain human
errors in the course of using different types of technologies,
including artificial intelligence (AI)-based epidemiological
investigation systems. Implementing the suggestions above
should aim to improve personal privacy in epidemiological
investigations. In addition, our proposed COVID index can
provide a basis for epidemiological investigations to support
efforts to balance personal privacy and public safety.
F. IMPROVING THE INTEGRITY OF OFFLINE DATA IN
EPIDEMIOLOGICAL INVESTIGATIONS
People issues are too often related to data integrity and
information quality. In epidemiological investigations, offline
information gathering raises questions about the reliability. Incorrect information obtained from interviews with
patients may lead to wrong assessment and evaluation about
quarantine decisions. Therefore, it is important to check the
quality and assure the integrity of offline epidemiological
investigations. Specific security measures we propose are to
strengthen an epidemiological investigation system. It is to
cross-check the accuracy of offline information in real time
using other online information sources (e.g., usage history
of credit cards, bus and subway transportation cards). This
will enhance the integrity of data gathering process. It will
also prevent the rapid spread of infectious diseases through
monitoring of the history of patients contacts and taking
additional preventive measures for all those affected.
V. CONCLUSION
In the COVID-19 context, the Korean government actively
used personal information and achieved fairly successful public safety outcomes. However, that is only part of the whole
story. The extensive use of personal information may also
negatively impact personal privacy. Therefore, practical safeguard measures, including clear communication of the scope
of public disclosure and the de-identification of personal
information are required. This paper examined how to implement personal consent procedures and the appropriate use of
big data. Even in a devastating pandemic like COVID-19,
balancing personal privacy and public safety is still very
important. Future research may explore how to prepare for
other pandemic outbreaks by combining the capabilities of
governmental leadership, technological innovation, big data
use, and societal cooperation. However, such aggressive epidemic control measures involve personal privacy concerns.
Further investigations should consider cultural issues related
to privacy and public safety in different national contexts.
NOTE OF APPRECIATION
Authors of this article wish to express our deepest gratitude to
all the dedicated medical practitioners and numerous patients
worldwide who are at the frontline in the battle against
COVID-19.



NEW_PAPER


Received February 10, 2021, accepted March 7, 2021, date of publication March 10, 2021, date of current version March 23, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3065456
Bias Analysis on Public X-Ray Image Datasets
of Pneumonia and COVID-19 Patients
OMAR DEL TEJO CATALÁ 1
, ISMAEL SALVADOR IGUAL 1
,
FRANCISCO JAVIER PÉREZ-BENITO 1
, DAVID MILLÁN ESCRIVÁ 1
,
VICENT ORTIZ CASTELLÓ 1
, RAFAEL LLOBET 1,2
,
AND JUAN-CARLOS PERÉZ-CORTÉS 1,3
1
Instituto Tecnológico de Informática (ITI), Universitat Politècnica de València, 46022 Valencia, Spain
2Department of Computer Systems and Computation (DSIC), Universitat Politècnica de València, 46022 Valencia, Spain
3Department of Computing Engineering (DISCA), Universitat Politècnica de València, 46022 Valencia, Spain
Corresponding author: Ismael Salvador Igual (issalig@iti.upv.es)
This work was supported by Generalitat Valenciana through the ‘‘Instituto Valenciano de Competitividad Empresarial—IVACE’’ under
Grant IMDEEA/2020/69.
ABSTRACT Chest X-ray images are useful for early COVID-19 diagnosis with the advantage that
X-ray devices are already available in health centers and images are obtained immediately. Some datasets
containing X-ray images with cases (pneumonia or COVID-19) and controls have been made available
to develop machine-learning-based methods to aid in diagnosing the disease. However, these datasets
are mainly composed of different sources coming from pre-COVID-19 datasets and COVID-19 datasets.
Particularly, we have detected a significant bias in some of the released datasets used to train and test
diagnostic systems, which might imply that the results published are optimistic and may overestimate the
actual predictive capacity of the techniques proposed. In this article, we analyze the existing bias in some
commonly used datasets and propose a series of preliminary steps to carry out before the classic machine
learning pipeline in order to detect possible biases, to avoid them if possible and to report results that are
more representative of the actual predictive power of the methods under analysis.
INDEX TERMS
Deep learning, COVID-19, convolutional neural networks, chest X-ray, bias, segmentation, saliency map.
I. INTRODUCTION
Chest X-ray (CXR) radiography is the most widely accepted
imaging modality for detecting pneumonia and it is becoming crucial for tracking the clinical evolution of COVID-19
patients [1]. The COVID-19 disease is caused by Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2)
and has become a global pandemic in a few months. Early
diagnosis is a key factor due to the stealthy contagious nature
of the virus and a lack of vaccines or effective treatments
and, thus, it helps to prevent further spreading and to control
it under the existing healthcare facilities. The small size of
the acquisition devices, their ease of operation and their low
cost make them more widely available than the Computer
Tomography (CT) equipment, despite image quality and the
diagnostic performance of CT are superior.
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
As a response to the COVID-19 outbreak, the scientific
community has rapidly reacted and a lot of works using CXR
images for COVID-19 detection have been published. The
majority of them make use of well-known CNN architectures such as VGG [2], ResNet [3]–[5], SqueezeNet [3], [6],
DenseNet [7] and also combine them with decision trees [8]
and Support Vector Machines (SVM) [9]. Given the difficulty
of obtaining COVID-19 samples, GAN networks have been
used [10], [11] in order to enhance the performance. Moreover, other approaches [12], [13] based on multi-resolution
methods report results that are comparable to those obtained
by CNNs.
Machine learning models need large amounts of data
which, in this case, are difficult to acquire, being the existing
collections a mix of already well-known datasets and new
COVID-19 image datasets. This heterogeneous mixture of
observations provides more variety and usually reduces epistemic uncertainty. However, if these datasets, for instance, are
42370 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 1. Workflow of the different experiments. From left to right: Network activations, Image features evaluation and
background expansion and lung exclusion.
not equally balanced (label-wise), they may induce a certain
amount of dataset bias to the training phase. This happens
when the images can be easily discriminated by features not
relevant to the task, i.e. if the dataset inadvertently contains
some distinctive features which are not related to the disease
and are not shared among the source datasets. For instance,
let’s assume an extreme case. Two image datasets are formed
by two different classes, that is, dataset A made of class A
samples and dataset B of class B samples. Let’s assume in
most dataset A samples there is a white rectangle on the top
right corner, and the true class features are not as trivial.
Classifiers will focus on the easiest feature to discriminate
between classes and not the true class features. Therefore,
this leads to poor generalization; given a new dataset C
full of class A, samples with no white rectangle will be
misclassified.
We have detected significant biases in some of the
most commonly used datasets intended for pneumonia and
COVID-19 detection and we suspect that the accuracy
reported in some studies might be due in part to them, and thus
not directly related to the image features that could characterize the disease. These biases could arise, for example, when
using some specific devices to acquire images of patients with
a low probability of suffering the disease (mainly controls),
and different ones for those patients with a high probability of
suffering it (mainly cases). This could happen, for example,
when most of the patients are screened in certain health services and highly suspicious patients are derived to a different
area or, even worse, when, aiming to increase the number
of controls or cases, a dataset is expanded with samples
coming from significantly different origins and labeled with
unbalanced class identifiers. In these cases, a CNN trained
to discriminate between cases and controls could learn to
differentiate images from different origins rather than finding
features actually related to the disease.
Therefore, to effectively assess the performance of the
classifier, there must exist a previous study of the dataset bias,
so that the results can be validated. Thus, we present several
studies to assess the validity of the results. The following
datasets will be used to perform the experiments: BIMCV
Padchest, CheXpert, RSNA and a COVID-19 image data
collection that we will refer to as COVIDcxr, which will be
further described in Section II-A.
The main contributions of this work are:
• To propose a bias analysis methodology to assert the
validity of the results achieved on a dataset.
• To study the possible existence of bias in three broadly
used pneumonia classification datasets.
• To study the effect of mixing several datasets.
This work is structured as follows: Section I outlines the
problem of bias in CXR datasets. After that, the datasets
and networks used, along with the proposed methodology are
described in Section II. The workflow related to this section
can be seen in Figure 1. Section III shows the results achieved
using this article’s methodology over the proposed datasets
and Section IV gives an analysis of the results. Finally, conclusions are presented in Section VI.
II. METHODS
A. DATASETS
Several public datasets have been used in this article:
• PADCHEST1
[14] is a CXR dataset that includes
more than 160K images from 67625 patients that were
reported by radiologists at Hospital de San Juan (Spain)
1http://bimcv.cipf.es/bimcv-projects/padchest/
VOLUME 9, 2021 42371O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
from 2009 to 2017. The reports are labeled with
174 different radiographic findings, 19 differential diagnoses and 104 anatomic locations. 27% of the reports
were manually annotated by trained physicians and the
remaining set was labeled using a supervised method
based on a Recurrent Neural Network with attention
mechanisms. Generated labels were validated, achieving
a 0.93 Micro-F1 score using an independent test set.
For the experiments, only Posterior-Anterior images are
considered. Therefore, there are 9110 images in the
remaining dataset: 6790 control and 2320 pneumonia
images.
• RSNA pneumonia dataset2
is made up of images from
the National Institutes of Health (NIH) and labeled by
the Radiological Society of North America along with
the Society for Thoracic Radiology and MD.ai. The goal
of this dataset was to develop an AI classifier capable of
distinguishing between pneumonia and control images,
so it was released in a Kaggle competition in 2018.
It consists of 26684 images from which 20672 are control and 6012 are pneumonia images.
• CheXpert dataset3
[15] is provided by Stanford
University and contains 224316 chest radiographs
of 65240 patients with labels of 14 sub-categories. The
exams were performed at Stanford Hospital between
October 2002 and July 2017. Structured labels for the
images were created by an automated rule-based labeler,
which the researchers developed to extract observations
from free-text radiology reports. From the 224316 chest
radiographs, this article only takes the ones related to
pneumonia and control cases. Therefore, 5870 images
are remaining in the dataset: 4878 control and 992 pneumonia images.
• COVID-19 image data collection (COVIDcxr)4
[16] is
a project to collect X-ray and CT images that present
COVID-19, SARS, MERS and ARDS from online
sources. These sources are varied: scientific publications, websites, etc. As of June 2020, COVIDcxr has
around 424 COVID-19 images and is one of the largest
COVID-19 datasets publicly available to the best of our
knowledge.
B. MOTIVATION
The motivation for this study comes from analyzing the
results of a neural network trained to classify between
radiographic images of patients with pneumonia and healthy
control patients in order to determine the validity of the
classification. An interesting first validation can be done by
visualizing the network’s activation heatmaps. When we performed these checks against networks trained with pneumonia datasets, we observed many suspicious patterns, as these
heatmaps often highlighted areas of the image which did not
2https://www.kaggle.com/c/rsna-pneumonia-detection-challenge
3https://www.healthimaging.com/topics/artificial-intelligence/stanfordresearchers-release-chest-x-ray-dataset-train-ai
4https://github.com/ieee8023/covid-chestxray-dataset
contain lung tissue (see Figure 2). This made us suspect that
the networks were learning to classify, achieving large values
of AUC ROC, using features unrelated to the task. Thus,
the datasets might be biased.
FIGURE 2. Lung heatmaps for BIMCV’s dataset.
Grad-CAM [17] allows us to visualize the gradient of the
label in the final convolutional layer to produce a heatmap
depicting regions of the image that are relevant for the prediction. Blue pixels and red pixels correspond to low and
high values of the gradient at the final convolutional layer,
respectively.
As observed in Figure 2, there are highly activated regions
in areas without lung presence when the expected activation
should be inside the lung. It is not known how many pixels
inside the lungs should show an activation, as no detection
mask is available. However, we can assume that the activation
map in a control patient should not exceed a given threshold,
whilst a positive case’s map should show widespread activations within the lungs. Nonetheless, the activated area outside
the lungs should be minimal in all cases. For this reason,
a measure to inform about the distribution of the activated
pixels could be useful.
Given a heatmap image I = {pij} ∈ Matn,m(R), where
n is the number of rows, m the number of columns, and
pij represents the pixel value at row i and column j. Let A
be a region of interest and B its complement. Let t be the
activation map threshold, and let R and W be the number of
pixels with an activation value higher than t that are in A and
B respectively.
We can calculate the percentage of pixels with an activation
value over a threshold that fall outside an expected region as
the quotient between W and W + R (see Figure 3 and the
equations below, where p ∈ {pij} = I).
Considering activated pixels in region W as false positives (FP) and activated pixels in region R as true positives
(TP), the above quotient corresponds to the False Discovery
42372 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 3. Activation regions diagram.
Rate (FDR), which is the complement of the Positive Predictive Value (PPV).
R = TP = |(p > t) ∩ A|
W = FP = |(p > t) ∩ B|
FDR =
FP
FP + TP
FDR = 1 − PPV
For instance, in this task, any activated pixel that falls
outside the lungs is marked as wrong (W), as no information
should be found there. The lower this value, the better. This
score is designed to measure the validity of the trained CNN
classifier based on its activation maps and allows the selection
of different operation points depending on the threshold t to
be applied to the heatmaps. In this work, t is set to 90% of the
maximum heatmap value.
Table 1 shows the computed FDR for the activation maps
under three different datasets. It is worth noting that some
image findings are usually located on the border of the lungs,
so if the highlighted area is near the border, some pixels
might easily fall outside the region (A) and be considered as
wrong (W). On the grounds of the information provided by
the FDR, further experiments would be required to measure
the extent to which this phenomenon affects the datasets.
TABLE 1. False discovery rate of activation maps for three different
datasets.
Additionally, some suspicious patterns appeared when
visualizing the grayscale histograms of the images.
Ideally, gray levels of images from different sources should
be equally distributed, but in practice, this may not happen
and give rise to inaccurate conclusions. The histograms
of the images may be considered as Probability Density
Functions (PDFs) and may serve to measure the variability
among gray-level distributions using a methodology based
on information geometry [18]. This methodology has been
successfully applied to characterize EHR (Electronic Health
Record) data [19], [20], to assess the variability among
patients with different headache pain intensity [21], or to
detect pixel distribution differences among images acquired
from different mammographs [22].
Given a set of PDFs, this approach is based on the computation of the distance between each pair of PDFs using
the Jensen-Shannon distance. The simplex where each point
represents a PDF and the distance between two points is
the Jensen-Shannon distance between the two PDFs they
represent is known as a statistical manifold, which in turn
is a Riemannian manifold. For visualization purposes, this
simplex may be embedded in a real Euclidean space by using
Multidimensional Scaling [23] and, finally, projected into two
dimensions using a dimension reduction algorithm such as
Principal Component Analysis.
This methodology was applied three times to a random
balanced sample of 2000 individuals (1000 pneumonia cases
and 1000 controls) of each dataset mentioned, which will
be described in section II-A. Firstly, it was applied to the
histograms of the complete images and, after a segmentation step, which will be described in detail in section II-D,
the variability analysis was applied only to the histograms
of the backgrounds, and then to the histograms of the lungs
(see Figure 4). The variability of the three datasets is shown
in Figure 5.
In the center row of Figure 5, which depicts the distributions of the backgrounds of the different datasets, we can see
that the first two columns show distinct clusters composed
predominantly of cases or controls that allow a certain degree
of discrimination without taking into account the lung tissue.
In fact, the last row, which represents lung area, shows fewer
differences between the cases and control patient histograms.
In the last column, corresponding to CheXpert’s dataset, these
differences are not evident.
This could imply that, for some datasets, as BIMCV and
RSNA, a Machine Learning algorithm can classify pneumonia and control cases using features outside the lungs.
C. NETWORK
In this article, Convolutional Neural Networks (CNNs) are
used to classify the CXR images. These Machine Learning models have been widely employed in the last years
for image classification, particularly in the field of medical
imaging. The CNN topology used is VGG16 [24], which
is broadly reported as a good classifier for chest image
analysis [25]–[27]. In this scenario, a common practice with
this type of networks is to trim the last layers (usually
dense layers) and add a lighter classifier, which in this
VOLUME 9, 2021 42373O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 4. Example of case and control patient histograms. The first row shows the histogram of the whole image for an example of a case and a
control patient, the second row shows the histogram of the background (the image with the lung area subtracted) and, the last one shows the
histogram of the lungs.
case is a Global Average Pooling followed by a Multilayer
Perceptron, which projects the pooled features of VGG’s
last convolution to 64 dimensions before performing the
classification.
Transfer learning technique is a common practice within
Deep Learning models. It is proven that pretrained networks, in particular their first layers, are generic and
can be transferred to new domains without requiring
special training. In fact, it also facilitates training for
domains with a scarce amount of training samples. Therefore, the VGG16 network used is pretrained with Imagenet dataset, and the last 2 convolutional layers, along
with the classification layers, are unfrozen for domain
training.
It is noteworthy that the network structure is, up to a
point, not critical for the conclusions drawn in this article,
as it is not trying to present advancement in the state-of-theart classification for the datasets used. The focus is rather
on comparing the results obtained for images coming from
different datasets, and whether those results suggest the presence of classification biases within the data. Nonetheless,
it must at least achieve an acceptable accuracy in order to
ensure the extracted features are good enough and close to
the ones extracted in other articles.
D. SEGMENTATION
By segmenting the lungs, it is possible to remove parts of
the image that do not contain relevant information and that
can be a source of noise or bias, such as the presence of text
annotations that can identify a machine or a hospital, or the
appearance of images coming from specific medical devices
that have been used in more cases than control patients or vice
versa.
Lung segmentation in CXR images has been successfully
tackled with different approaches during the last years [28].
For this work, a U-Net network has been trained on the
Montgomery dataset [29]. Moreover, we have manually
labeled a total of 1115 images coming from BIMCV’s
42374 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 5. Image histogram variability. The first row represents the variability of the histograms of the complete images, the second row the variability of
the background histograms (the images with the lung area subtracted), and the third row the histograms of the lungs. The first column represents a
sample of BIMCV’s dataset, the second column a sample of RSNA’s, and the last, a sample of CheXpert’s.
Padchest dataset to increase the number of training images.
Figure 6 shows the segmentation results. This network
achieves 0.974 DICE and 0.934 IoU scores over the Montgomery test partition, where DICE and IoU are defined as
follows, being A and B the predicted segmentation mask and
the true segmentation mask.
DICE =
2 | A ∩ B |
| A | + | B |
IoU =
A ∩ B
A ∪ B
VOLUME 9, 2021 42375O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
E. BIAS ANALYSIS
This work proposes a methodology to measure the degree of
bias in a dataset. The focus is on the classification of pneumonia or COVID against control samples, but the methods
can be generalized to other classification tasks where prior
knowledge of the region of interest is available.
As stated before, areas that should not contain information about the problem can be possibly used to discriminate
between classes, for example, text annotations or image features related to the medical devices employed. In order to
solve this problem, we make use of a segmentation algorithm
to extract the relevant regions which in this case are the lungs
(see Figure 6). These regions will be referred to as masks.
The rest of the image will be considered as background
(see B in Figure 3).
FIGURE 6. Lung segmentation (left) and after post-process (right).
To check the previous hypothesis presented in II-B,
two experiments were carried out by training a model
with different image areas according to the following
ideas:
• We want to study how the background affects the results.
Starting from an image that contains only the lungs
(the background is erased), the visible region is progressively expanded to include more background by
means of sequential dilation operations over the mask
(see Figure 7a). An unbiased dataset should not increase
the classification accuracy along this process.
• We want to analyze how the lack of lung area affects
the results; this time starting from the whole image and
progressively removing the lungs (see Figure 7b). The
classification accuracy over an unbiased dataset should
progressively drop from its maximum value (whole
image) to 0.5 AUC ROC.
Thus, adjusting the expansion or exclusion of the lung region
will allow us to trace the variation of the accuracy metric.
We used images scaled to 256 × 256 pixels. For background
expansion, lung segmentation masks were dilated 0, 10, 30,
50, 80, 120 and 140 pixels and for lung exclusion, masks were
eroded 0, 10, 20, 30, 40 and 100 pixels (from right to left
in Figure 7).
Figure 7a shows the lung segmented area in blue and
the background expansion in green. Also, Figure 7b shows
the lung exclusion area in yellow. Additionally, a detailed
workflow for this experiment is shown in Figure 8
F. COMBINATION ANALYSIS
Combining datasets can be useful to enlarge the sample size,
increase the variability explained by the data, and reduce the
epistemic uncertainty of the classifiers. This latter is related
to the problem-domain knowledge of the model, being it the
uncertainty or lack of knowledge bound to the limited amount
of data. However, if the combination and the balance among
the classes are not carefully controlled, a classifier may learn
to discriminate between features of the different datasets.
To check this hypothesis, we mixed RSNA and CheXpert
datasets to achieve a balanced combination by adding positive
pneumonia observations from the RSNA dataset into CheXpert. The latter is a highly unbalanced dataset (83% of negative and 27% of positive observations after our pre-process
and segmentation validity filters), so it could be considered
a good idea to add positive samples from another dataset.
Needless to say, if the images from RSNA have distinct
features that allow the classifier to tell them apart from
CheXpert, for example including a large proportion of images
from a particular equipment brand or model, the system will
learn to classify the images from that equipment as positive,
regardless of any image content that could be related to the
disease.
Additionally, we simulated the combination of
COVID-19 and control datasets and evaluated their bias
with the proposed method. In particular, the datasets combined are positive COVID-19 cases from COVIDcxr with
CheXpert’s negative control samples. COVIDcxr is built with
datasets from different origins, hence this experiment illustrates the likely problematic effects of heterogeneous data
combinations.
Based on our methodology that probes the discrimination
induced outside the lungs, the expectations about the results
of the experiment, if there is bias in the dataset, are: (1) the
background expansion could increase the accuracy and
(2) the accuracy when occluding the lungs should differ
significantly from the 0.5 AUC ROC. Did the results follow
these predictions, the hypothesis would be confirmed.
III. RESULTS
A. BACKGROUND EXPANSION AND LUNG EXCLUSION
STUDY
In the previous section, we proposed to examine the performance of classification experiments varying the addition of
background and the reduction of the lung area. The expected
results of the first test for a non-biased dataset, where the
background area is added to the initial lung-only images,
is that the classification rate stays constant (or almost constant, due to possible imprecise segmentation and other random perturbations), as the disease information is already
present from the beginning.
In the second scenario, the accuracy should potentially
drop from the value achieved when the network sees the
complete image to a value close to 0.5 AUC ROC when the
lungs are completely removed. This drop is not necessarily
42376 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 7. Background expansion and lung exclusion. (a) The original contour area is shown in blue and the expanded area contour in green (b) The
contour of the removed area is shown in yellow.
FIGURE 8. Bias analysis’s workflow.
linear, but will be shown in the graphs as a straight red line,
as can be seen in the right part of Figure 9, to offer a simplified
graphical representation of the expected behavior. In the left
part of the figure, the green line represents the classification
rate obtained using only the lung area.
This analysis has been performed in the three datasets:
• The first one (see Figure 9a), BIMCV, clearly shows
a significant bias within the data, as the classification
rate steadily increases with the background expansion.
The second graph shows that removing the lung area is
not associated with a significant decrease in accuracy,
as it should, and even with the complete exclusion of the
lungs the classifier achieves almost 0.88 AUC ROC.
• The second one (see Figure 9b), RSNA, displays a
slightly lower but still consistent bias within the data
in both graphs. However, the RSNA dataset was harder
to segment than the other ones and, thus, part of the
variability shown could arise from poorly segmented
images. Nonetheless, a 0.79 AUC ROC is achieved with
the lungs completely occluded, which is far from the
expected 0.5 AUC ROC.
• The third one (see Figure 9c), CheXpert, conveys interesting results. The left graph’s trend is the one expected
for an unbiased dataset, as it doesn’t vary along with
the background expansion. Nevertheless, the precision
achieved when the lung is completely occluded is
around 0.74 AUC ROC. This implies that the bias is not
located specifically in the background, but it must lie in
the whole image.
B. COMBINATION STUDY
As mentioned before, the combination study seeks to evaluate
how the combination of datasets might provoke the creation
of biased data and how the methodology proposed can detect
these weaknesses in the final data collection.
The experiments of Section III-A have been reproduced
using the combined dataset. Figure 10(a) shows the effect
of varying background expansion and lung exclusion when
the combination is designed to balance CheXpert with RSNA
cases (4878 control and 992 positive pneumonia images from
CheXpert plus 3886 positive images from RSNA, giving a
balanced dataset with 50% observations from each class).
The last experiment explored a combination of 4878 images
of control patients from CheXpert and the whole set
of 424 COVID-19 images from COVIDcxr. This dataset
combination is typical of the recent crisis scenario, where few
images from the new disease are available, they are obtained
from different locations, under uncontrolled conditions, with
different equipment and acquisition protocols, etc. This is the
worst-case scenario and the results are in accordance with it,
as can be seen in Figure 10(b).
The results for these experiments show, in a similar fashion
to Chexpert’s base case, that the bias is ubiquitous in the
VOLUME 9, 2021 42377O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 9. Accuracy as a function of the background expansion and lung reduction. The green dotted lines
mark the correct behavior of a non-biased dataset when more and more background is included, and the
red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from the
analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line indicating the
standard deviation.
image. Despite increasing the amount of background inside
the images doesn’t affect the accuracy, the effect of the lung
occlusion is not remarkable within the results.
IV. DISCUSSION
Deep learning has been receiving a lot of attention
as a very powerful methodology for analyzing medical
images [30]. The ability of Convolutional Neural Networks (CNN) to obtain excellent results even when it is used
as a blackbox, as opposed to the classical design of ad-hoc
algorithms, has attracted many researchers.
Some works using CNNs for COVID-19 detection on
cxr images report high accuracies for a variety of network
architectures. In particular, studies using VGG16 report [9]
89.8% accuracy for a dataset built of 180 COVID-19 and
200 control samples, 90% accuracy is obtained [27] for a
dataset composed of 202 COVID-19 images, 300 of pneumonia and 300 negative and 93.48% accuracy [31] is achieved
using a dataset that contains 224 COVID-19 images, 700 of
pneumonia and 504 negative. The fact that VGG16 achieves
good results for detecting pulmonary diseases strengthens
the hypothesis that the features extracted by the network
are relevant to the task and therefore, as detected from our
experiments, related to some sort of bias within the images.
One of the drawbacks of CNNs is that they often need
large amounts of data to learn and, while generic CXR
databases are available, public existing COVID-19 datasets
are composed of a few images that were collected by
volunteers [16]. As a consequence, these datasets show
unbalanced labels and a mix of different data sources that
42378 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 10. Addition of positive samples from RSNA and COVIDcxr to CheXpert’s dataset. The green dotted
lines mark the correct behavior of a non-biased dataset when more and more background is included, and
the red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from
the analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line
indicating the standard deviation.
makes getting a robust model and reliable performance
measures difficult. In this regard, some articles report the
problem of small and unbalanced datasets for COVID-19
detection [4], [32], and propose solutions to mitigate the
problem.
Bias analysis has been tackled by other authors. For
instance, in [33] the authors proposed that train and test
partitions should come from different datasets (related to the
same task), as the classifier is trying to achieve maximum
performance over a certain task and not over a dataset. This
may also assert the true generalization capacity of the classifier. On the other hand, [34] sought to minimize the effects
of different biased datasets by way of converting different
dataset observations to prototypes, greatly reducing possible
intra-dataset specific features.
Recently, [35] addresses this issue for COVID-19 detection
and reports that the problem of mixing different datasets may
lead the network to learn background information. Our study
performs a similar approach to the one presented in thisarticle, i.e. both study possible biases within the lungs. [35]
occludes the lungs with rectangular fixed-size black boxes
and measures the accuracy achieved. However, the proposed
methodology extends the concept proposed to more precise
masks and progressive inclusion and exclusion of information
to the learning process. This allows the ability to detect
where the bias approximately is and enables more precise bias
estimation.
Furthermore, [36] studies bias within the nCov2019 dataset
using information about patients (symptoms, comorbidities,
age, and sex). This dataset collects clinical data from different sources rather than images. They found significant bias
related to the origin of the data and exposed several issues
related to multisource variability.
This article is focused on detecting some biases within
widely used CXR datasets to glimpse the degree to which
these biases affect the results and proposes a bias detection
methodology to assert the validity of results. This methodology makes use of techniques such as heatmap visualization,
histogram analysis and selective image occlusion which are
combined to evaluate which parts of the images are being
used as discriminative features for a classification task. In this
work, this methodology has been applied in two case scenarios, one for the existence of bias on individual pneumonia
datasets and another to detect the existence of bias in a mix
of datasets.
V. LIMITATIONS OF THE STUDY
Regarding possible limitations, there could be a problem with
the methodology proposed, since the segmentation masks
used for expansion and reduction may be biased themselves.
The segmentation process might be more prone to fail in
images with pneumonia since the borders of the lungs are
more diffuse, whereas this could not happen in images of
control patients. This could pose a significant difference
VOLUME 9, 2021 42379O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 11. Lung occlusion with fixed-size rectangular boxes.
between cases and controls masks, and therefore, we might
be introducing a new bias that would imply a problem with
the proposed methodology.
However, to rule this out, we designed an experiment where
the occlusion masks were substituted by rectangles the size
of the lungs. This experiment is similar to the one presented
in [35], but here we ensure that the lungs are completely
removed using the segmentation mask shape whereas in the
aforementioned work they just place a fixed size black rectangle in the central area leaving some lung area uncovered.
Some examples from our method can be seen in Figure 11.
The results achieved for BIMCV’s dataset can be seen
in Figure 12, where the differences found are not significant,
suggesting that the shape of the lung masks is not influencing
the bias detection algorithm proposed.
Furthermore, to increase the confidence in our conclusions,
we pre-processed all the images by means of CLAHE histogram normalization to assert how this pre-process affected
the results. As can be seen in Figure 13, there is no difference
in the results achieved between the normalized and plain
images.
Talking about strengths, the results of the experiments
described in Section III-B demonstrated that the classification
rate does not improve when the background area is included
in the images, which means that either there is no bias
specifically on the background or the most significant bias
is already within the lungs. However, when the lung area
is progressively removed from the image we find in both
experiments that the accuracy does not decrease, suggesting
FIGURE 12. Comparison between fine-grain and squared masks for BIMCV’s dataset.
42380 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 13. Comparison between normalized and plain BIMCV’s dataset.
that the system is classifying the images according to some
elements present in the whole image, not only inside the
lungs. That result confirms the hypothesis that powerful systems like Convolutional Networks can find subtle features
in the images and give optimistic classification results if no
measures are taken to avoid biases in the data.
To summarize, further research should be conducted to
reduce the impact of the intrinsic bias for the datasets whose
images are collected from several sources. Recent literature
has demonstrated the emergence of methodologies useful
to reduce the impact of such a bias. Image preprocessing methods [22] or deep learning architectures designed
to deal with biased datasets [37] may be a good starting
point.
VI. CONCLUSION
In this work, a novel methodology to assess the existence of
bias in CXR image datasets is presented. Techniques such
as activation heatmap visualization, histogram analysis and
selective image occlusion are combined to evaluate which
part of the images are being used as discriminative features
for a classification task. In this case, the regions of interest
were the lungs. The datasets used show different levels of
bias, these comprising datasets that try to make information quickly available in an urgent scenario like the current
COVID-19 crisis. Some examples are BIMCV’s collection or
the combination of datasets created for this purpose, which
are the ones with more problems. The results are confirmed
with the other methodologies used, such as the FDR of the
activation map or the histogram analysis.
The study of the effects of combining datasets from different sources is especially interesting because it shows that, if it
is not strictly controlled, important biases can be induced in
the final dataset. A typical solution for the lack of samples
of a given class is to compile different datasets into one that
collects all the categories to study, as the recent COVID-19
datasets. In particular, the widely used COVIDcxr dataset,
built from different sources, might in fact have included
significant biases that inadvertently affected the results published. This kind of heterogeneous dataset often mix observations coming from very diverse equipment, acquisition protocols and processing software. In that context, features found
by Deep Convolutional Networks in the images, including the
background areas, are enough to get a good classification rate,
whilst the actual performance of the classifier for the clinical
task attempted can be much lower.
ACKNOWLEDGMENTS
The authors would like to thanks of gratitude to BIMCV
and the other teams that compiled and made available the
datasets used in this work. The experiments were conducted employing Instituto Tecnológico de Informática (ITI)
High-Performance Computing platform, which is funded
by IVACE and AVI, and implemented within ITI Data
Space, being these experiments a TECH4CV’s project use
case.
VOLUME 9, 2021 42381O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets



NEW_PAPER



BIG DATA MINING AND ANALYTICS
ISSN 2096-0654 01107 pp65-75
Volume 4, Number 2, June 2021
DOl: 10.26599/BDMA.2020.9020013
Analysis and Predictions of Spread, Recovery, and Death Caused by
COVID-19 in India
Rajani Kumari, Sandeep Kumar*, Ramesh Chandra Paonia, Vijander Singh, Linesh Raja,
Vaibhav Bhatnagar, and Pankaj Agarwal
Abstract: The novel coronavirus outbreak was first reported in late December 2019 and more than 7 million people
were infected with this disease and over 0.40 million worldwide lost their lives. The first case was diagnosed on
30 January 2020 in India and the figure crossed 0.24 million as of 6 June 2020. This paper presents a detailed
study of recently developed forecasting models and predicts the number of confirmed, recovered, and death cases
in India caused by COVID-19. The correlation coefficients and multiple linear regression applied for prediction and
autocorrelation and autoregression have been used to improve the accuracy. The predicted number of cases shows
a good agreement with 0.9992 R-squared score to the actual values. The finding suggests that lockdown and social
distancing are two important factors that can help to suppress the increasing spread rate of COVID-19.
Key words: COVID-19; regression; correlation; machine learning; prediction
1 Introduction
The coronavirus disease spreads through getting in touch
with an infected person, touching a thing or object that
has the virus on its surface and then touching their
mouth, eyes, ears, or nose. The first case of COVID19 was detected in the last week of January 2020 in India
and only 3 cases were diagnosed in next month. As of
6 June 2020, the total number of confirmed cases in
India was 247857 with 119293 recovered cases and
6954 deaths. There is a need for the current situation
• Rajani Kumari is with Department of Information Technology
and Computer Application, JECRC University, Jaipur,
Rajasthan 303905, India. E-mail: rajanikpoonia@gmail.com.
• Sandeep Kumar is with CHRIST (Deemed to be University),
Bangalore, Karnataka 560029, India. E-mail: sandpoonia@
gmail.com.
• Ramesh Chandra Poonia and Pankaj Agarwal are with Amity
University Rajasthan, Jaipur, Rajasthan 303002, India. E-mail:
rameshcpoonia@gmail.com; mr.pankajagarwal@gmail.com.
• Vijander Singh, Linesh Raja, and Vaibhav Bhatnagar
are with Manipal University Jaipur, Rajasthan 303007,
India. E-mail: vijan2005@gmail.com;lineshraja@gmail.com;
vaibhav.bhatnagarI5@gmail.com.
*To whom correspondence should be addressed.
Manuscript received: 2020-05-07; revised: 2020-06-14;
accepted: 2020-07-28
to predict possible infected and death cases by using a
computational model to arrange the necessary resources.
The virus ofCOVID-19 shows great resemblance with
the Severe Acute Respiratory Syndrome (SARS) and
Middle East Respiratory Syndrome (MERS) coronavirus
as investigated by pathologists[l]. It is the seventh
member of the coronavirus family that can spread
among humans and easily transmit human-to-human
through droplets of coughs or sneezing by an infected
person[l]. Major symptoms of COVID-19 are fever,
cough, shortness of breath, and some patients show
symptoms of diarrhea. The major problem in the case of
this disease is that its symptoms generally appear after 2
to 14 days if an individual gets infected. This period is
known as the incubation period and the mean incubation
period is approximately 5 days[2]. An infected person
may infect the number of healthy persons during the
incubation period. These patients are asymptomatic and
major challenge is to identify them. The rate at which
one infected person transmits this disease into others
is termed as transmission rate (Ro)[l]. Recent studies
by leading research organizations estimated that Ro is
between 1.5 and 3.5[3-5]. This rate of transmission is very
high in comparison to SARS (2.0) and common flu (1.3),
and thus it is very dangerous. In the early stage, the Case
© The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.orgllicenseslby/4.0f).66
Fatality Rate (CFR) for coronavirus was estimated at
2%[1]. While the fatality rate for SARS and MERS was
approximately 10% and 30%, respectivelyW Highest
CFR was reported in France (19%), followed by Belgium
(16.23%), Italy (14.4%), and UK (14.2%)[6]. Almost 5%
of the total infected persons lost their lives around the
world, while in India CFR was near to 2.8%. The actual
CFR can only be computed based on the identification
of the correct number of infected individuals. The major
contributions of this research are as follows:
• This paper performs a descriptive analysis of the
COVID-19 outbreak in different states of India.
• We propose a model for predicting the number of
confirmed, recovered, and death cases due to COVID-19.
• The proposed model deploys multiple linear
regression to analyze the existing data.
• This paper also employs the autoregression to
predict the cases.
The organization of this paper is as follows: Section 2
discusses some recent studies carried out by researchers,
medical practitioners, and scientists in the field of
infectious disease. In Section 3 the detailed analysis
is carried out from the considered dataset of COVID-19
for India. Section 4 introduces the proposed prediction
model to estimate the count of infection, recovery, and
death due to COVID-19. Section 5 concludes this study.
2 Recent Study on COVID-19
Many researchers involved in the study of novel
coronavirus after the outbreak at Wuhan, China in late
December 2019 and developed various types of models
for prediction of its spread, transmission, and death
caused by it. Some studies and researches are related to
the development of medicine and diagnostic tool for this
pandemic. Few of these recent studies discussed here.
Zhong et al.[7] developed a mathematical model for
the timely prediction of the coronavirus outbreak in
China. Harnzah et al.[8] developed an online platform
to provide real-time information related to COVID-19
and a statistical analysis of data. Susceptible-ExposedInfectious-Recovered (SEIR) predictive modeling was
used for forecasting on daily basis. They developed
their micro-services to fetch data from different
sources. Morawska and Cao[9] discussed how COVID-19
spreads especially through the air.
Li et al.[10] investigated the genetic evolution of the
virus that is responsible for COVID-19. This study
identified that novel coronavirus has a genetic similarity
with coronavirus derived from rhinolophus sinicus,
Big Data Mining and Analytics, June 2021, 4(2): 65-75
paradoxurus hermaphroditus, paguma larvata, aselliscus
stoliczkanus, and civet, while homology analysis shows
that it has close resemblance with bat coronavirus.
Ma et al.[ll] analyzed the effect of humidity and
changes in temperature on COVID-19 patients, but
the study was limited to Wuhan city only. This study
established a correlation with variation in temperature
and humidity on daily death due to the virus. Singh
et al.[12] studied and compared SARS, MERS, and
COVID-19 viruses based on transmission cycle, etiology,
genetics, hosts, diagnosis, reproductive rates, laboratory
diagnosis, clinical features, and radiological features. Pal
et al.[13] illustrated the classification of ribonucleic acid
group of viruses and origin of severe acute respiratory
syndrome coronavirus along with virion structure and
genetic characteristics of COVID-19. Dutheil et al.[14]
investigated the role of COVID-19 for decreasing air
pollution as most of the industries are shut down and
traffic is also significantly low.
Vellingiri et al.[15] discussed the cause of infection,
symptoms, and the structure of the virus in detail
and compared it with common flu, SARS, and MERS
at various parameters. They also discussed ongoing
treatment to the infected people and suggested some
Indian plants for medical use. Henry and Lippi[16]
suggested that Extracorporeal Membrane Oxygenation
(ECMO) is one of the options for survival therapy to
COVID-19 patients. Some limitations of ECMO were
also discussed here. Lai et al.[17] also discussed major
symptoms and ongoing methods of cure for COVID-19.
They raised some unresolved issues, like the presence
of SARS-CoV-2 in patient stool and the efficiency of
disinfection agents used for sanitization.
Ghosal et al.[18] developed a model to predict week
wise death in India due to COVID-19. They used
linear regression and multiple regression for prediction
and deployed autoregression to enhance the prediction
capability of the proposed model. The projected model
is based on data analysis of 15 highly infected countries.
Liang[19] compared the spread characteristics of novel
coronavirus with characteristics of SARS and MERS.
A new mathematical model was proposed to identify
the symptoms of coronavirus diseases. Nicola et al.[20]
suggested that veterinary medicine may be helpful in the
cure of COVID-19.
Lee et al.[21] discussed the importance of Computed
Tomography (CT) images in the diagnosis of COVID-19
infected individuals. As technology growing, there are
many applications and tools being produced that utilizeRajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 67
various algorithms. In many fields, computer-assisted
tools are being designed and employed successfully. The
efficient use of such computer-aided systems in medicine
is no exception. Medical images are very useful for
the doctor, and their detailing can have a decisive
influence on the correctness of the diagnosis. One
of the branches of the healthcare system that tightly
works with images is the radiology. There have
been generated several datasets containing CT scans,
Magnetic Resonance Imaging (MRI), etc., to detect
novel coronavirus pneumonia diseases. Pan et al.[22]
illustrated changes in the lung of COVID-19 patients
during the recovery process with the help of CT images.
Singh et al.[23] classified COVID-19 patients based on
their chest CT images. For this classification they
implemented a convolutional neural network based
on differential evolution algorithm. Jaiswal et al.[24]
deployed DenseNet20l for classification. The proposed
approaches achieved a higher rate of accuracy and
precision.
Singh et al.[25] analyzed time series data and predicted
the registered, deceased, and death numbers per reported
case (mortality rate) based on COVID-19's world health
data for the world population. This study concluded that
COVID-19's regular mortality is positively correlated
with the number of confirmed cases. It may also be
dependent upon the population's dietary routine and
robustness of the immune system. This study suggested
that an emergency can awaken before the proper vaccine
is invented. Some critical issues were measured by
several researchers, considering individual countries,
provinces, and derived some conclusions. Bhatnagar
et al.[26] presented a detailed analysis of the COVID-19
pandemic with the help of a boxplot and Q plot.
Ivanov et al.[27] analyzed and predicted the effect of
the ongoing pandemic on global supply chains. They
also performed a simulation-based analysis in the case
of supply chains and the impact of COVID-19 on
supply chains along with associated risks. Hou et
al.[28] performed SEIR model analysis to examine the
effectiveness of quarantine especially for Wuhan city
and developed a new variant of the SEIR model. They
concluded that quarantine and isolation are two powerful
and unique tools to reduce the risk of infection. Roosa et
al.[29] developed a system for forecasting the COVID-19
in real-time in China for a specific time period. Tuli
et al.[30] employed the latest technologies, like machine
learning and cloud computing, for predicting the growth
rate of COVID-19 pandemic with the help of the Weibull
model.
Xu et al.[31] explained the pathological characteristics
of COVID-19 and compared them with SARS and
MERS. These pathological features are highly similar
to SARS and MERS. This study provided some
recommendations to physicians so that they can timely
plan a therapeutic strategy for the patient. Kucharski
et al.[32] developed a mathematical model and analyzed
four datasets. This study revealed that the transmission
rate is between 1.6 to 2.6. Here they classified patients
into four different classes: susceptible, exposed (but not
yet infectious), infectious, and removed (i.e., isolated,
recovered, or otherwise no longer infectious). Yuvaraj
et al.[33] used a deep neural network for the analysis of
interactions of protein-ligand for SARS-CoV-2 against
selective drugs. Some studies focused on psychological
health of farmers engaged in the business of poultry[34].
Researchers are also working on test procedures and
trying to reduce testing time. In this sequence, Assad et
alPS] suggested that sample pooling is the best option to
reduce the testing time that leads to reduce fatality but
with a limitation of 10% positive cases. If positive cases
are very low, binary elimination algorithms are the better
option.
These studies revealed that symptoms of COVID19 are similar to SARS and MERS. COVID-19 is
more infectious but has a low fatality rate. The virus'
root cause is still unclear, and virologists are actively
working to establish its antidote. However, physicians
are continuously trying to cure patients by using antiviral
therapy, antibiotic treatment, systematic corticosteroids,
etc. Table I summarises a few of the recently developed
prediction and forecasting models. Most of the models
are based on the SEIR model and its extended
version, like symptomatic infectious, asymptomatic
infectious, quarantined, hospitalized, recovered, dead
model (SEIDIuQHRD)[36-38]. Machine learning and
deep learning models are also used for prediction and
forecasting[39-41] .
3 Analysis of COVID-19 Data
Analysis of the COVID-19 dataset for coronavirus
disease is performed on the basis of reported cases
(confirmed, recovered, and death) in India. We have
collected data from 29 February 2020 to 6 June 2020
(hereafter it is termed as WeekI to WeeklS) of some
states in India that are worst hit by this virus. The
dataset is taken from www.kaggle.com[54] and shown in
Table 2. Attributes which are considered in this dataset68 Big Data Mining and Analytics, June 2021, 4(2): 65-75
Table 1 Comparative study of recent prediction and forecasting models for COVID-19.
Author(s) Activity performed Methodology used Strength Drawback
Ghosal et al.[18]
Singh et aU23]
Prediction Linear regression analysis Statistical analysis results prove its Results are over-estimated and
reliability. significance of predictor is very low.
Prediction Gaussian mixture model Predicted values with 95% Predicted end dates are not true.
confidence intervals
Chakraborty Forecasts and risk
and Ghosh[49] assessment
Tiwari et aU50] Prediction
Maheshwari Forecasting
et al.[51]
Bhattacharjee Prediction
et aU52]
Sree[53] Prediction
Results are not consistent throughout the
study area.
Tested for 15 days only
Accuracy and reliability of this model
depend on the assumption of parameter
values and initial population size.
Accuracy and reliability of this model
depend on the assumption of parameter
values.
Data considered from 2 March 2020 to
2 April 2020 only.
Achieved accuracy (78.8%) is
significantly low.
Predicted number of infected persons
only
Results may be improved by deep
learning.
Considered only weather conditions that
less significant
Data were taken till 27 March 2020 only.
Proposed model used data till 3 April
2020 only
Achieved accuracy (93.695%, 86.96%,
87.94%, and 90.91 % for confirmed,
recovered, death, and death rate,
respectively) is significantly low.
Study is restricted till 24 April 2020.
Used different models for different states
Only 10 days data used for testing
purpose
Considered small size data (till 24 March
2020)
The error rate is very high.
Model is highly reliable
R statistical package used for
forecasting for the next 76 days
Predicted results with higher accuracy
Predicted peak time and end time
of the pandemic, this model also
analyzed the effect of lockdown.
Considered the impact of temperature
and humidity
Maximum-likelihood and bootstrap
strategy are used to analyze the Ro
and re-sampling, respectively.
Deep LSTM, convolutional LSTM,
and bi-directional LSTM are deployed
for accurate prediction.
Fbprophet model deployed for
forecasting in various countries
Deployed multilayered perceptron,
linear regression, and vector
autoregression for better results
Performed prediction for one month
Predicted the effect of social
distancing for 30 days and lockdown
also analyzed
Analyzed data of the USA and India
Cases load rate based on cumulative
confirmed cases and the recovery rate
are used for prediction.
Hybrid non-linear cellular automata
deployed for prediction
Considered six components: Susceptible
(S), Asymptomatic (A), Recovered (R),
Infected (I), Isolated Infected (Iq), and
Quarantined Susceptible (Sq)
Developed a reliable model using trustregion-reflective algorithm
Machine learning
LSTM and curve-fitting
Cellular automata classifier
Daily temperature and relative
humidity-weighted against cases
Mathematical model
New mathematical model
proposed
SEIRmodel
Analyzed reproduction number and
sensitivity analysis to decide the
preventive measure
Hybrid of wavelet-based A risk assessment performed using Forecasts for ten days only
forecasting and ARIMA regression tree
model
Generalized additive model.
Sen's slope, Man-Kendall
test, and Verhulst (logistic)
population model
Gene expression programming
Predictive error minimizationbased approach
Mathematical model developed
for predication
Logistic model and machine
learning technique
Machine learning
Deep learning
ARIMAmodel
SARIIqSq model
Developed a new model
(SEIDIuQHRD)
Prediction
Prediction
Prediction
Prediction and
analysis
Forecasting
Forecasting
Prediction and analysis
of meteorological
factors
Evaluation and
prediction
Prediction
Predicted risk based on
weather conditions
Prediction
Modeling and
forecasting
Forecasting
Kanagarathinam
and Sekar[38]
Nabi[37]
Mandai et al.[48]
Sarkar et al.[36]
Arora et al.[39]
Rafiq et al.[42]
Sahoo and
Sapra[43]
Salgotra
et aU45]
Tomar and
Gupta[46]
Gupta et aU47]
Wang et al.[40]
Goswami
et aU44]
Sujath et al.[41]
are mainly week wise confirmed cases in concerning
states. After collecting the required data, they are refined
and analyzed.
Tables 3 and 4 illustrate the mathematical description
of considered dataset and correlation among those data,
respectively. In Table 3, the notations: Count, Mean,Rajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 69
Table 2 Dataset from WeekI to WeekI5 including confirmed cases in different states of India. CH: Chandigarh, KR: Karnataka,
MP: Madhya Pradesh, MH: Maharashtra, and TL: Telengana.
Week
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Kerala
3
8
22
52
182
306
364
396
453
499
505
587
794
1208
1807
Gujarat
2
7
13
18
58
122
308
1272
2848
4948
7404
9931
13 268
15953
18584
CH
1
2
3
5
8
18
18
21
37
49
59
66
172
289
301
Delhi
1
4
7
29
49
503
903
1707
2501
4068
6261
8895
12319
17 415
25004
KR
1
3
6
26
76
144
214
371
482
611
750
1056
1743
2728
4329
Ladakh
1
2
3
12
13
14
15
18
19
32
42
43
44
74
90
MP
1
2
3
4
30
165
443
1355
1974
2838
3433
4595
6170
7672
8762
MH
1
2
32
67
186
490
1574
3323
7029
11823
19101
29100
44582
62357
77793
TL
1
1
3
22
66
269
504
791
988
1062
1143
1454
1761
2378
3147
Table 3 Mathematical description of datasets.
Week
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Count
23
23
23
23
22
18
9
9
9
9
9
9
9
9
9
Mean
2.13
4.22
13.74
38.04
104.5
254.44
482.56
1028.22
1814.56
2881.11
4299.78
6191.89
8983.67
12230.44
15535.22
Std
2.88
4.75
17.29
43.83
126.74
239.93
490.04
1049.76
2220.68
3806.50
6188.59
9382.13
14291.02
19916.79
24897.31
Min
1
1
1
3
6
14
15
18
19
32
42
43
44
74
90
25%
1
1
3
10
22.5
75.5
214
371
453
499
505
587
794
1208
1807
50%
1
2
7
26
57.5
171
364
791
988
1062
1143
1454
1761
2728
4329
75%
1.5
4.5
21
50.5
163
401.25
504
1355
2501
4068
6261
8895
12319
15953
18584
Max
14
18
80
190
485
911
1574
3323
7029
11823
19101
29100
44582
62357
77793
Std, Min, Max, 25%, 50%, and 75% are used to
denote the number of non-null values, mean of values,
the standard deviation of the values, minimum value,
maximum value, first quartile, second quartile, and
third quartile, respectively. These same notations also
used in Table 5 for the statistical description of the
considered dataset. The objective of this analysis is
to find the correlation between WeekI to WeekI5 for
all confirmed cases in different states. Through this
analysis, it is observed that there is a strong correlation
between the complete datasets. Table 4 represents the
correlation analysis which determines the relationship
among WeekI to WeekI5 data. According to descriptive
analysis concerning spread rate of coronavirus disease
in different states, it is observed that in the first four to
five weeks the spread rate of this virus is very less in
India, but after that spread rate is very high in some of
the states in India due to social gathering by a single
source (refer to Table 3). It is observed from Figs. I and
2 that till Wee~ the spread rate of confirmed cases is
very low and Week5 onwards spread rate is very high.
Figure 1 illustrates the confirmed cases in considered
states and shows that exponential growth in confirmed
cases occurs after the fourth week. Similarly, Figs. 2
and 3 also illustrate an exponential growth pattern for
confirmed cases in considered states and it indicates that
in the near future situation it will be very tough if it is
not controlled.70 Big Data Mining and Analytics, June 2021, 4(2): 65-75
Table 4 Correlation analysis of determining relationship between datasets.
Week Week
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
1 1.00
2 0.91 1.00
3 0.45 0.40 1.00
4 0.37 0.30 0.92 1.00
5 0.53 0.40 0.92 0.95 1.00
6 0.06 0.11 0.60 0.75 0.64 1.00
7 -0.15 -0.11 0.70 0.74 0.62 0.89 1.00
8 -0.11 0.13 -0.07 0.00 -0.19 0.45 0.28 1.00
9 -0.16 0.09 -0.15 -0.06 -0.25 0.43 0.23 0.98 1.00
10 -0.16 0.10 -0.18 -0.10 -0.28 0.39 0.19 0.97 1.00 1.00
11 -0.15 0.12 -0.18 -0.10 -0.28 0.39 0.18 0.96 0.99 1.00 1.00
12 -0.14 0.13 -0.17 -0.09 -0.27 0.41 0.20 0.95 0.99 1.00 1.00 1.00
13 -0.14 0.14 -0.17 -0.07 -0.25 0.43 0.21 0.95 0.99 0.99 1.00 1.00 1.00
14 -0.12 0.16 -0.15 -0.05 -0.24 0.45 0.22 0.94 0.98 0.98 0.99 1.00 1.00 1.00
15 -0.09 0.20 -0.13 -0.05 -0.22 0.45 0.22 0.95 0.98 0.98 0.99 0.99 1.00 1.00 1.00
Table 5 Statistical description of datasets.
Dataset Count Mean Std Min 25% 50% 75% Max
Confirmed cases 70.00 69595.39 70086.76 1024.00 12599.00 41102.00 110639.75 246622.00
Recovered cases 70.00 27765.33 34180.32 95.00 1516.00 11297.00 44643.75 118695.00
Death cases 70.00 2087.83 1981.72 27.00 415.75 1357.00 3401.00 6946.00
Fig. 1 Confirmed cases of COVID-19 in India.
Weelc1 Week2 Week3 Week4 Weeks Week6 Week 7
Week
Prediction using the proposed model is performed for
data from 20 March 2020 to 6 June 2020. This date
range is different from the date range considered for
analysis, because initially the number of cases is very
low and the use of that data may affect the accuracy
of the model, data after 20 March 2020 are considered
when the number of COVID-19 patients are significantly
higher. Data were collected in the CSV file (from
www.kaggle.com[54]) and imported in Jupyter notebook
through anaconda navigator and analyzed with Python
4 Proposed Model
Predictions
3.7.6 software. Attributes that were considered in this
dataset are mainly confirmed, recovered, and death
cases. Figure 3 shows the graphical representation
of the dataset. It is assumed that the coronavirusinfected persons are available in India and they come
into contact with other healthy persons. Since it is an
infectious disease, it is going to spread into others also.
Consequently, the number of cases is growing rapidly.
During the development of the model, the collected
data were analyzed by using functions in Python
Software. For understanding the dataset properly, a
statistical description was performed on the complete
dataset. The description of statistical data is shown in
Table 5.
The proposed model is summarised in Fig. 4. It
is important to discover and compute the degree of
variables in the dataset and this information is helpful
for better preparation of dataset to meet the expectations
of machine learning algorithms. A recovery strategy and
correlation analysis are performed on data using Python
Software. It reveals a statistical summary of confirmed,
recovered, and death cases and also finds a strong
relationship among current data. The consequential
correlation analysis is shown in Table 6.
Multiple regression analysis is used for predicting
for COVID-19
- Kerala
- GUjarat I
- Chandigarh / - Delhi / - Karnataka
- Ladakh
- Madhya Pradesh / - Maharashtra
Telengana //
~" .....-:
~ r7/
.............: I~ ~
1400
~ 1200
~1000
'E 800
8
b 600
:;;
~ 400
z
1600
o
200Rajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 71
80000 o
70000
o ~ 60000
~
'"
u
] 50000
E
g40000
u
'0
Qj 30000 .c
E
~ 20000
10000
o -e- -e- -e0
0
0
i 0
I I 0
• ...g",. I 0
-• .....Q- ~
Week, Weeks Week6
-
Week7 Weeks Weekg Week10 Week 11 Week12 Week13 Week14
Week
Fig. 2 Boxplot for confirmed cases of COVID-19 in India.
Parameter Value
Table 7 Summary of output for multiple linear regression
analysis.
death cases with the help of confirmed and recovered
cases. This regression technique has more than one
variables to predict the output. It is helpful in predicting
a target variable using more than one independent
variables. For predictive analysis, the multiple linear
regression techniques are used to explain the relationship
between two independent variables (confirmed and
recovered cases) and one dependent variable (death
cases). Here the dataset is divided into training and
test datasets as 70% for training and 30% for testing.
This model has a very strong predictive capacity after
training with the dataset and found Root Mean Square
Error (RMSE) as 3085.4305 and R2 score as 0.9992.
The summary of output for multiple linear regression
analysis is shown in Table 7.
Decision tree learning techniques are used to
continuously split training and test data according to
a certain parameter. It is a widely accepted supervised
learning approach that split our dataset based on
conditions. It is equally useful for regression and
classification. This approach assigns the most feasible
class for each record for classification. At the time of
testing with a different set of input values, it is observed
that predicted output is very close to actual values.
During the analysis of the complete dataset, it is
20 30 40 50 60 70
Number of days
o 10
Find cofficienl and
predicted values
50 OOOH----,..".,I----+--+-~~-----1;;;"."_____t--H
250 OOO~.::;::c=on:;::firm==e':=d=ca=:=se=:=s t===t==+===t====t==;R • Recovered cases
200 OOO~·,:::D::ea~th..::ca;::se::.s_-t----t---.~----t-----t------tFind slope,
intercept,
RMSE,and
A2 Sl.LJre
150000H--I----+--.AA---+--+-I'+--H
100000H--I--------"Ir--+---+--Jl'-------+--:IIIII"'---H
Fig. 3 Confirmed, recovered, and death cases in India.
Fig. 4 Proposed model for predictions of confirmed,
recovered, and death cases of COVID-19 in India.
Table 6 Correlation analysis of determining relationship
between datasets.
Confirmed cases Recovered cases Death cases
Confirmed cases
Recovered cases
Death cases
1
0.99373420
0.99813925
1
0.98584439
Slope
Intercept
RMSE
R2 score
[0.0418 -0.0280]
-43.5073
3085.4305
0.9992Lag
-O.sOf---+---+------1f---+----+--+---1
-0.751--+---+------11--+----+--+---1
72
[1] World Healthy Organization, Statement on the second
meeting of the international health regulations (2005)
emergency committee regarding the outbreak of novel
coronavirus (2019-nCoV), https://www.who.int/news/item/
30-01-2020-statement-on-the-second-meeting-of-theinternational-health-regulations-(2005 )-emergencycommittee-regarding-the-outbreak-of-novel-coronavirus-
(2019-ncov), 2019.
[2] M. Xie and Q. Chen, Insight into 2019 novel coronavirusBig Data Mining and Analytics, June 2021, 4(2): 65-75
Table 8 Prediction for the next 30 days (7 June 2020 to 6
July 2020).
Predicted Predicted Predicted
Date confirmed recovered death
cases cases cases
07-Jun-20 256972 132398 7230
08-Jun-20 268021 146535 7529
09-Jun-20 279935 154647 7834
IO-Jun-20 292 393 162747 8156
ll-Jun-20 304886 169880 8500
12-Jun-20 318185 175762 8851
13-Jun-20 331964 180 150 9215
14-Jun-20 346329 185 645 9589
15-Jun-20 361 364 193564 9971
16-Jun-20 377 129 210 844 10 373
17-Jun-20 393235 236021 10 789
18-Jun-20 410 083 256198 11223
19-Jun-20 427679 271631 11 676
20-Jun-20 445982 285667 12142
21-Jun-20 465005 295537 12626
22-Jun-20 484898 300267 13 128
23-Jun-20 505477 303 552 13 648
24-Jun-20 526898 311 531 14191
25-Jun-20 549246 332608 14753
26-Jun-20 572 521 370832 15337
27-Jun-20 596690 412622 15943
28-Jun-20 621 891 447115 16571
29-Jun-20 648083 476246 17223
30-Jun-20 675324 497 141 17899
01-Jul-20 703 696 504343 18602
02-Jul-20 733247 501616 19331
03-Jul-20 763961 501854 20088
04-Jul-20 795938 521520 20873
05-Jul-20 829215 572 506 21688
06-Jul-20 863836 645885 22534
in resource management, like health services, and timely
action may be taken with prior preparation to reduce the
loss of human life.
The proposed model may be extended to predict
the end of this pandemic in a particular region. Total
causality and total economic losses may be predicted
with the help of this model.
References
I
1--
,
Confi~med cas~s ,
_ Recovered cases I
I
- Death cases I
--- Predicted confirmed cases
--- Predicted recovered cases / --- Predicted death cases / ,-
/ /
V ./
, ~,--" V V- --
1.00~
0.7sl-----'...-,,+---+------1f---+----+--+---1
0.50 ~ _
0.25 I I~I
o I -- -0.2si-"""'~-F-~"""~""""'ii-"""'~+~"""~~-F-~""'i
100000
150000
o
200000
250000
300000
Fig. 5 Autocorrelation plot.
50000
-1.00 '----------,1""0------=2.':-0-----='3':-0-----"40=---'"'50-----,-6""0-------='70
observed that the model can use regression against
itself and also able to use the autocorrelation plot to
check the randonmess within the data. Figure 5 shows
the autocorrelation plot. Now create an autoregression
model that uses observation from the previous steps as
input. The time-series model is used to predict the values
at the next time step. Results prove that the forecasted
range of time series is accurate. Now fit the model using
the existing dataset and find the lag and coefficients.
Based on the lag value, a separate analysis is performed
for confirmed, recovered, and death cases. It is observed
from Table 8 that the testing of existing data is very close
to the actual dataset and predicted values are also very
relevant to the existing dataset.
Fig. 6 Actual and predicted: confirmed, recovered, and
death cases in India.
o w m ~ ~ ~ ~ ro Number of days
5 Conclusion and Future Scope
This study discussed the spread of COVID-19 in
different states of India and proposed a model for
predicting the number of confirmed, recovered,
and death cases. Multiple linear regression and
autoregression were used to predict the possible number
of cases in the future. The predicted confirmed cases of
India for the next 30 days are recorded in Table 8. The
predicted values and actual values are together in good
agreement (see Fig. 6). This prediction may be helpfulRajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 73
An updated intrim review and lessons from SARS-CoY and
MERS-CoY, International Journal ofInfectious Diseases



NEW_PAPER


Received May 6, 2020, accepted May 8, 2020, date of publication May 11, 2020, date of current version May 28, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2993967
INVITED PAPER
Quantifying COVID-19 Content in the Online
Health Opinion War Using Machine Learning
RICHARD F. SEAR 1
, NICOLÁS VELÁSQUEZ 2,3, RHYS LEAHY 2,4
,
NICHOLAS JOHNSON RESTREPO 2,4, SARA EL OUD 5
, NICHOLAS GABRIEL5
,
YONATAN LUPU 6
, AND NEIL F. JOHNSON 2,5
1Department of Computer Science, George Washington University, Washington, DC 20052, USA
2
Institute for Data, Democracy, and Politics, George Washington University, Washington, DC 20052, USA
3Elliott School of International Affairs, George Washington University, Washington, DC 20052, USA
4ClustrX LLC, Washington, DC 20007, USA
5Department of Physics, George Washington University, Washington, DC 20052, USA
6Department of Political Science, George Washington University, Washington, DC 20052, USA
Corresponding author: Neil F. Johnson (neiljohnson@gwu.edu)
ABSTRACT A huge amount of potentially dangerous COVID-19 misinformation is appearing online. Here
we use machine learning to quantify COVID-19 content among online opponents of establishment health
guidance, in particular vaccinations (‘‘anti-vax’’). We find that the anti-vax community is developing a
less focused debate around COVID-19 than its counterpart, the pro-vaccination (‘‘pro-vax’’) community.
However, the anti-vax community exhibits a broader range of ‘‘flavors’’ of COVID-19 topics, and hence can
appeal to a broader cross-section of individuals seeking COVID-19 guidance online, e.g. individuals wary
of a mandatory fast-tracked COVID-19 vaccine or those seeking alternative remedies. Hence the anti-vax
community looks better positioned to attract fresh support going forward than the pro-vax community. This
is concerning since a widespread lack of adoption of a COVID-19 vaccine will mean the world falls short of
providing herd immunity, leaving countries open to future COVID-19 resurgences. We provide a mechanistic
model that interprets these results and could help in assessing the likely efficacy of intervention strategies.
Our approach is scalable and hence tackles the urgent problem facing social media platforms of having to
analyze huge volumes of online health misinformation and disinformation.
INDEX TERMS COVID-19, machine learning, topic modeling, mechanistic model, social computing.
I. INTRODUCTION
Scientific experts agree that defeating COVID-19 will depend
on developing a vaccine. However, this assumes that a sufficiently large proportion of people would receive a vaccine
so that herd immunity is achieved. Because vaccines tend to
be less effective in older people, this will require younger
generations to have very high COVID-19 vaccination rates
in order to guarantee herd immunity [1]. Yet there is already
significant opposition to existing vaccinations, e.g. against
measles, with some parents already refusing to vaccinate
their children. Such vaccine opposition increased the number
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
of cases in the 2019 measles outbreak in the U.S. and
beyond [2]. Any future COVID-19 vaccine will likely face
similar opposition [3], [4]. Mandatory COVID-19 vaccinations for schoolchildren could trigger a global public health
conflict. A better understanding of such opposition ahead of
a COVID-19 vaccine is therefore critical for scientists, public
health practitioners, and governments.
Online social media platforms, and in particular the builtin communities that platforms like Facebook (FB) feature,
have become popular fora for vaccine opponents (anti-vax)
to congregate and share health (mis)information. Such misinformation can endanger public health and individual safety
[1], [4]. Likewise, vaccine supporters (pro-vax) also congregate in such online communities to discuss and advocate for
91886 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
professional public health guidance. Well before COVID-19,
there was already an intense online conflict featuring antivax communities and pro-vax communities. Within anti-vax
communities, the narratives typically draw on and generate
misinformation about establishment medical guidance and
distrust of the government, pharmaceutical industry, and new
technologies such as 5G communications [1], [4], [5]. Adding
fuel to this fire, the January 2020 birth of the COVID-19
‘‘infodemic’’ has led to a plethora of misinformation in
social media surrounding COVID-19 that directly threatens
lives [6]. For example, harmful ‘‘cures’’ are being proposed
such as drinking fish tank additives, bleach, or cow urine,
along with coordinated threats against public health officials
like Dr. Anthony Fauci, director of the U.S. National Institute of Allergic and Infectious Diseases [7]. Moreover, false
rumors have been circulating that individuals with dark skin
are immune to COVID-19. These may have contributed to
more relaxed social distancing among some minorities and
hence their over-representation as victims. In Chicago and
Louisiana as of early April 2020, ∼70% of the fatalities were
African Americans even though this demographic only makes
up ∼30% of the population [8], [9]. In addition, the world
has witnessed an alarming rise in COVID-19 weaponization
against the Asian community [10]–[12]. It is also clear that
such misinformation is not a fringe phenomenon, and can
instead be very widely held as true within the general population. Indeed, a recent Pew study [13] found that ∼30%
of Americans believe the COVID-19 virus was likely created
in a laboratory, despite statements from infectious disease
experts to the contrary.
Unfortunately, the sheer volume of new online content and
the speed with which it spreads, means that social media
companies are struggling to contain such health misinformation [14], [15]. Making matters worse, people around the
world are spending more time on social media due to social
distancing imposed during the COVID-19 pandemic. This
increases the likelihood that they become exposed to such
misinformation, and as a result they may put themselves and
their contacts at risk with dangerous COVID-19 remedies,
cures and falsehoods.
The present study is motivated by both these needs: (1) the
need for a deeper understanding of this intersection between
online vaccination opposition and the online conversation
surrounding COVID-19; and (2) the need for an automated
approach since the sheer volume of new online material every
day makes manual analysis a non-viable option going forward. We pursue an automated, machine learning approach
that avoids the scalability limitations of manual content analysis. While the present paper is just the first step in a challenging longer-term goal, the automated approach that we
present allows the following questions to be addressed: How
did COVID-19 change the online conversation within antivaccination and pro-vaccination communities over the two
month period in early 2020 when the disease became a global
threat; and what do the topical changes that we observe in the
anti-vax and pro-vax online communities’ narratives, imply
about their relative abilities to attract new supporters going
forward?
Unlike many existing works, this study does not use Twitter
data [16], [17] since it is known that Twitter is more of a
broadcast medium for individual shout-outs, whereas discussions and narratives tend to be nurtured in in-built online
community spaces that are a specific feature of platforms
like Facebook (e.g., fan page) [18]. Twitter does not have
such in-built community spaces. In the present methodology,
generalized from [19] and [20], data is collected from these
online communities, specifically Facebook Pages that support either anti-vaccination or pro-vaccination views. This
information is publicly available and does not require any
individual details, thereby avoiding any privacy concerns –
just as understanding the content of a conversation among
a crowd of people in an open, real-world public space does
not require knowledge of any personal details about the individuals within that crowd. Details of our approach are given
in Sec. II and the Appendix. A third difference between this
study and previous ones is that the machine learning findings
here are interpreted in terms of a mechanistic model (Sec. IV)
that captures the general trend for the coherence in the online
conversations over time. Though much work still needs to be
done, this study therefore provides a first step toward a fully
automated but interpretable understanding of the growing
public health debate concerning vaccines and COVID-19.
II. DATA AND MACHINE LEARNING ANALYSIS
The terms ‘Facebook Page’ and ‘cluster’ are used interchangeably here since each Facebook Page is a cluster of
people. Facebook Pages, also known as fan pages or public
pages, are accounts that represent organizations, causes, communities, or public figures. According to Facebook’s policies,
‘‘Content posted to a Page is public and can be viewed by
everyone who can see the Page’’ [see 21, Sec. 5]. A Facebook
Page is different from a Facebook personal account. Personal
accounts represent private individuals, and their posts and
interactions are considered more private and targeted to their
immediate contacts. This paper does not analyze data from
personal accounts. Our methodology follows [19] and [20] by
analyzing the public content of Facebook Pages for both antivaccination (‘‘anti-vax’’) and pro-vaccination (‘‘pro-vax’’)
communities. The publicly available content of these online
communities is obtained using a snowball approach, starting
with a seed of manually identified pages discussing either
vaccines, public policies about vaccination, or the pro-vs-anti
vaccination debate. Then their connections to other fan pages
are indexed. At each step, new clusters are evaluated through
a combination of human coding and computer-assisted filters.
To classify a cluster as being (1) anti-vax or pro-vax and
(2) including COVID-19 content or not, we reviewed its
posts and the Page’s ‘‘about’’ section. Pro-vax and anti-vax
classifications required that either (a) at least 2 of the most
recent 25 posts dealt with the pro-vax or anti-vax debate,
or (b) the page’s title or ‘‘about’’ section described it as
pro-vax or anti-vax. At least two researchers classified each
VOLUME 8, 2020 91887R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
cluster independently. If they disagreed on their suggested
classification, a third researcher reviewed the posts and then
all three reviewers discussed these cases. Agreement was
reached in each case. This also enabled us to distinguish
between content that is intended to be serious versus merely
satirical. The self-weeding tendency within Facebook Pages
tends to reduce material from bots and fake profiles. We kept
the present study focused on English, though this can be
easily generalized using our same procedure. Beyond that,
our study was global and not limited to a particular region.
The content of these clusters was then bundled together
separately for the anti-vax community and the pro-vax community, and the two resulting sets of content were analyzed
using machine learning. Specifically, we used an unsupervised machine learning technique called Latent Dirichlet
Allocation (LDA) [22] to analyze the emergence and evolution of topics around COVID-19. The LDA method models
documents as distributions of topics and topics as distributions of words. During its training process, these distributions
are adjusted to fit the dataset. The LDA method is described
correctly in Wikipedia as [23] ‘‘[quote] .. a generative statistical model that allows sets of observations to be explained by
unobserved groups that explain why some parts of the data
are similar. For example, if observations are words collected
into documents, it posits that each document is a mixture
of a small number of topics and that each word’s presence
is attributable to one of the document’s topics. LDA is an
example of a topic model and belongs to the machine learning toolbox and in wider sense to the artificial intelligence
toolbox.’’
The coherence score provides a quantitative method for
measuring the alignment of the words within an identified
topic (see [22]). It is generated from a separate algorithm
which is run over a trained LDA model. The overall coherence
score of a single model is the arithmetic mean of its pertopic coherences. There are many different coherence metrics
to evaluate per-topic coherence. We use CV which is based
on a sliding window, one-set segmentation of the top words
and an indirect confirmation measure that uses normalized
point-wise mutual information and the cosine similarity. It
comprises collections of probability measures on how often
top words in topics co-occur with each other in examples
of the topics. We refer to [22] for a full explanation and
discussion of CV.
Machine learning automation can, in principle, help
address the significant issues facing social media platforms
by mechanically picking out material that requires attention from the huge haystack of online content. While this
could help to better curtail online misinformation, one might
rightly ask about its accuracy and reliability as compared to
human analysts. This has been recently addressed in [24]. We
use the same coherence metric (CV) as these authors. They
addressed the problem that topic models had previously given
no guarantee on the interpretability of their output. Specifically, they produced several benchmark datasets with human
judgements of the interpretability of topics and they found
results that outperformed existing measures with respect to
correlation to human ratings. They achieved this by evaluating 237,912 coherence measures on 6 different benchmarks
for topic coherence, making this the biggest study of topic
coherences at that time. Separately, we have done our own
comparison for the general area of online hate and have found
comparable consistency.
In summary, our machine learning approach identifies topics in the online narratives with high coherence, meaning the
word groupings identified are strongly related according to
the coherence scoring approach discussed earlier. Our human
inspection of the word distribution making up each grouping
showed that they do indeed correspond to reasonably distinct
conversation topics. Details and examples are given in the
Appendix.
III. RESULTS
The main focus here is in the endogenous development of
COVID-19 conversation at the beginning of the global pandemic and prior to the first officially reported U.S. COVID-19
death on February 29, 2020 [25]. Hence we collected Facebook public post data for the period 1/17/2020-2/28/2020
inclusive. To assess the change over time, this period was
divided into time intervals. Since having more time intervals
would mean smaller amounts of data within each and hence
more fluctuations, and since we are just interested in the
change over time, two intervals were chosen of equal duration, T1 and T2. The first time-interval 1/17/2020-2/7/2020
(T1) contains 774 total pro-vax posts and replies, and 3630
total anti-vax posts and replies. The second time-interval
2/7/2020-2/28/2020 (T2) contains 673 total pro-vax posts and
replies, and 3200 total anti-vax posts and replies. Hence our
two equal time windows contains similar amounts of data. We
checked that our results are relatively robust to other choices
of time interval. Interestingly, T1 roughly corresponds to
the time when COVID-19 was largely seen as a problem
in Asia, while T2 roughly corresponds to the time during
which it became a serious problem in Europe. For further
reassurance that our data was representative of the COVID-19
conversation during these intervals, we also checked that the
data split is similar to that for mentions of COVID-19 in
article counts from worldwide anglophone newspapers and
worldwide Google trends.
The LDA models were trained over posts in the following
distinct groups: anti-vaccination posts in T1, anti-vaccination
posts in T2, pro-vaccination posts in T1, and pro-vaccination
posts in T2. For each of these sets, 10 separate LDA models
were trained with the number of topics parameter ranging
from 3-20, for a total of 180 models in each of the four groups.
Fuller details are given in the Appendix. The CV coherence
algorithm was then run over each of these models and the
coherence scores were averaged for each number of topics.
These averaged scores are plotted in Figures 1B and 1C.
Figure 1A shows the result of the same procedure applied to
all posts in our dataset, and to all anti-vaccination posts, and
to all pro-vaccination posts.
91888 VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
FIGURE 1. Coherence scores CV
for (A) anti-vax (dashed line), pro-vax
content (dotted line), and anti-vax combined with pro-vax (dashed-dotted
line), calculated over the entire time period of study (T1 + T2
). (B) Anti-vax
content for the separate time periods T1
(blue line) and T2
(orange line).
The number of topics for which the coherence score CV
is a maximum is
indicated, i.e. the optimal number of topics. The optimal number of topics
for anti-vax moves from 15 to 10 from T1
to T2
. (C) Pro-vax content for the
separate time periods T1
(blue line) and T2
(orange line). The optimal
number of topics for pro-vax moves from 19 to 5 from T1
to T2
.
The coherence score CV for the entire period of study (i.e.
T1 + T2) in Fig. 1A, is consistently larger across the number
of topics for pro-vax than for anti-vax, suggesting that the
pro-vax community overall has a more focused discussion
around COVID-19 than the anti-vax. This is consistent with
the pro-vax community featuring a more monolithic discussion around public health – namely, it is focused on advising
people to follow professional medical guidance.
The bad news for the pro-vax community from this higher
overall coherence, is that it is less well positioned to engage
with the wide variety of more blurry, and often more extreme,
COVID-19 narratives that are now circulating online. This
represents a significant potential disadvantage for the pro-vax
community in that it may therefore be less able to attract the
attention of the many different types of users who are now
entering this online space in search of a particular nuanced
‘flavor’ of COVID-19 narrative that appeals to them. These
users could consequently be pulled toward the anti-vax cause.
Figures 1B and 1C indicate the change over time by comparing the curves of the coherence score across number of
topics, for time periods T1 and then T2. The curve moves
up from T1 to T2 for the pro-vax community (Fig. 1C) and
the optimal number of topics shows a dramatic decrease
from 19 to 5. This is consistent with the notion that the provax community is working toward a common COVID-19
interpretation and narrative with fewer ‘flavors’ of discussion
and interpretation than the anti-vax community. Again, while
this may sound like a strength, it suggests that the pro-vax
community overall is actually becoming less appealing over
time to the many different types of new users who are in
search of their own COVID-19 narrative ‘flavor’. By contrast,
the curves for the anti-vax community from T1 to T2 (Fig. 1B)
show a far smaller reduction in the optimal number of topics
(15 to 10) and the curves move down, in the opposite direction to the pro-vax. Hence the anti-vax compensates a small
increase in focus (reduction in the optimal number of topics)
with an overall reduction in coherence, i.e. these 10 topics
for T2 are effectively more blurry than the original 15 for T1,
and hence the overall anti-vax community is becoming more
accommodating to the diverse population of new additions
coming into the online health space over time.
Figure 2 shows a visualization with more detail about the
information structure of the individual topics, and how far
these topics are from one another in terms of informational
distance. The plot is obtained using the pyLDAvis package
[26] which provides a global view of the topics and how
they differ from each other, while at the same time allowing
for a deeper inspection of the terms most highly associated
with each individual topic. This provides a novel method for
implying the relevance of a term to a topic. The study in [26]
showed that ranking terms purely by their probability under a
topic, by contrast, is suboptimal for topic interpretation. We
refer to [26] for full details of LDAvis.
The change in the pro-vax community from time period
T1 (Fig. 2C) to T2 (Fig. 2D) is such that the optimal number
of topics decreases (i.e., the number of circles decreases
from 19 to 5 following Fig. 1C) and the topics evolve to
become located mostly in the same portion of the space (i.e.,
toward the right-hand side of Fig. 2D). Following Fig. 1B,
the change in the anti-vax community from time period T1
(Fig. 2A) to T2 (Fig. 2B) is such that the optimal number
of topics starts off slightly smaller than the pro-vax, but
although it also decreases over time (i.e., the number of
circles decreases) there are more topics (i.e., more circles
VOLUME 8, 2020 91889R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
FIGURE 2. Visualization of the informational structure of the individual
topics, and how they relate to each other. This plot is obtained using
pyLDAvis. The circles in each plot are the topics from Fig. 1 for which the
average coherence score is highest, i.e. the optimal number of topics.
Their size indicates the marginal topic distribution as discussed in detail
in [26], while the two axes are principal components in the distribution
analysis.
in Fig. 2B) than for the pro-vax in time period T2 (Fig. 2D).
Also, the topics seem more spread out across the space in
Fig. 2B as compared to Fig. 2D. These observations are
consistent with our earlier interpretations that the pro-vax
community is more focused (equivalently, narrower) than the
anti-vax community in terms of COVID-19 narratives, and
that the pro-vax community is evolving toward a common
COVID-19 interpretation and narrative with a lower diversity
on offer than the anti-vax community.
IV. TOWARD A MECHANISTIC MODEL INTERPRETATION
We created a mechanistic model that further supports these
empirical findings and provides a microscopic interpretation
of the machine learning output. Specifically, we generated a
computer simulation of an ecology of online components of
the overall community content, each of which is characterized
by a vector x = (x1, x2, . . . ) in which each component xi
signifies the strength of a given factor surrounding the online
health debate, e.g. government control. The exact nature of
these components does not need to be specified, i.e. whether
they are words or short phrases. It just matters that there is
a diverse ecology of such building blocks. This mechanistic
model setup, while seemingly very simplistic, does indeed
reflect the empirical observations and literature surrounding
the themes of online discussions of vaccination opposition, as
listed and studied in detail by Kata in [1]. We then carry out a
simulation whereby these components are selected randomly
to build up content. Components cluster together (or their
clusters cluster together, if they are already in a cluster) if their
FIGURE 3. Output from our mechanistic model in which clusters form if
the component x-values are sufficiently similar (i.e., homophily in
panel A) or different (i.e., heterophily in panel B).
x values are sufficiently similar (i.e. homophily in Fig. 3A) or
different (i.e. heterophily in Fig. 3B). To illustrate the output
of our model, Fig. 3 shows a one-dimensional version. We
checked that a two-dimensional version gives similar results,
though it is visually more complicated because of having the
time component along the third dimension. Most importantly,
it produces plots that are visually similar to those in Fig. 2.
As can be seen from Fig. 3, the case of homophily (which
is akin to building a more monolithic topic discussion with
few flavors, like the pro-vax community) has a convergence
that is quicker, as observed in Figs. 1 and 2 for the pro-vax
community. By contrast, the case of heterophily (which is
akin to building diverse topic discussions with many flavors,
like the anti-vax community) is slower to gel, which is consistent with the anti-vax community in Figs. 1 and 2. The red
dotted horizontal line in Figs. 3A and 3B gives an indication
of the stage in the simulation that is broadly consistent with
Figs. 2D and 2B for the pro-vax and anti-vax communities
respectively.
The delay in the gelation time observed in Fig. 3B for
heterophily (anti-vax) as compared to homophily (pro-vax)
in Fig. 3A, can be derived analytically using mathematical
analysis from statistical physics (see [27] for full details).
In particular, we have been able to show that the time at
which gelation emerges depends inversely on the average
probability that two randomly picked components join the
same cluster, which is smaller for heterophily than homophily
and hence the gelation time is later for heterophily than
homophily – exactly as observed in Fig. 3. Similarly, it can
be shown mathematically that the gelation sizes (akin to the
sizes of the circles in Fig. 2) will be smaller for heterophily
than homophily, as also observed in Fig 3.
Again, instead of this being good news for the pro-vax
community, the simulation of this mechanistic model shows
that the case of homophily (pro-vax) is less able to absorb an
influx in new users with a range of x values, as compared to
the case of heterophily (anti-vax). This is consistent with the
idea stated earlier, that the anti-vax community appears more
engaging to new users (e.g. parents with children of schoolage who are wary of school vaccine requirements, or who fear
government control) and hence the anti-vax will be more able
to gain new supporters in the long run than the pro-vax.
91890 VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
V. LIMITATIONS OF THE STUDY
There are of course many limitations of this study. There
are other social media platforms, apart from Facebook, that
should be explored – but Facebook is the largest. Similar
behaviors should arise in any platform where communities
can form. It will also be interesting, for example, to compare
our findings to other studies focused on Twitter, where messaging is more in the form of short, individual statements [17].
There is also the question of influence of external agents or
entities [16]. However, these social media communities tend
to police themselves for bot-like or troll behavior. Further
analysis is required of the details of the content. This will
require going beyond just text and perhaps beyond LDA,
since memes and images are also shared. Also, the generative
model output needs to be compared in detail to the timeevolution of topics. Further research is also required to formulate the results across all platforms into detailed, actionable
consequences for policy makers. These limitations will be
addressed in future work.
VI. CONCLUSION
These findings suggest that the online anti-vax community is
developing a more diverse and hence more broadly accommodating discussion around COVID-19 than the pro-vax community. As a result, the pro-vax community runs the risk of
making itself less engaging to the heterogeneous ecology of
potential new users who join the online COVID-19 discussion, and who may arrive online with a broad set of concerns,
questions, and possibly preconceived notions, misinformation and even falsehoods.
The analysis in this paper also provides a first step toward
eventually either replacing, or at least supplementing, the
non-scalable efforts of human moderators tasked with identifying online misinformation. In addition, the mechanistic
model (Fig. 3) could be used for what-if scenario testing of
how quickly coherence develops and what the impact would
be of breaking up the coherence around certain topics, e.g.
by counter-messaging against individuals ingesting bleach or
the even newer ‘COVID Organics’ that are circulating as a
cure in Madagscar, Africa and beyond. This can be achieved
by using the empirical analysis in Fig. 2 – repeated over
multiple consecutive time intervals – to identify the growth
of topics around new words which may be gaining popularity as a home cure (e.g. ‘‘bleach’’). Then Facebook, for
example, could post ads that specifically target these specific
new words and topics, rather than blanket vanilla messaging
promoting establishment medical science narratives.
Overall, this approach shows that a machine-learning algorithm, the LDA algorithm, identifies plausible topics within
collections of posts from online communities surrounding
the vaccine and COVID-19 debate. In addition to being
able to handle large quantities of data, its results emerge
quickly using statistical grouping techniques, instead of having to rely on potentially biased, slow and costly human
labeling.
APPENDIX
As mentioned in the main text, the methodology starts with a
seed of manually identified Facebook Pages discussing either
vaccines, public policies about vaccination, or the pro-vs-anti
vaccination debate. Then their connections to other fan pages
are indexed. At each step, new findings are vetted through a
combination of human coding and computer assisted filters.
This snowball process is continued, noting that new links can
often lead back to members already in the list and hence some
form of closure can in principle be achieved. This process
leads to a set containing many hundreds of pages for both the
anti-vax and pro-vax communities. Before training the LDA
models, several steps are employed to clean the content of
these pages in a similar way to other LDA analyses in the
literature:
Step 1: Mentions of URL shorteners are removed, such
as ‘‘bit.ly’’ since these are fragments output by Facebook’s
CrowdTangle API.
Step 2: Many of the posts link to external websites. The fact
that these specific websites were mentioned could itself be an
interesting component of the COVID-19 conversation. Hence
instead of removing them completely, the pieces ‘‘.gov’’,
‘‘.com’’, and ‘‘.org’’ were replaced with ‘‘__gov’’, ‘‘__com’’,
and ‘‘__org’’, respectively. This operation effectively concatenates domains into a form that will not be filtered out by
the later preprocessing steps.
Step 3: The posts are then run through Gensim’s simple_preprocess function, which tokenizes the post on spaces
and removes tokens that are only 1 or 2 characters long. This
step also removes numeric and punctuation characters.
Step 4: Tokens that are in Gensim’s list of stopwords, are
removed. For example, ‘‘the’’ is not a good indication of a
topic.
Step 5: Tokens are lemmatized using the WordNetLemmatizer from the Natural Language Toolkit NLTK, which
converts all words to singular form and/or present tense.
Step 6: Tokens are stemmed using the SnowballStemmer
from NLTK, which removes affixes on words.
Step 7: Any remaining fragments of URLs (other than
domain) that are left over after stemming, such as ‘‘http’’ and
‘‘www’’, are removed.
Steps 5 and 6 help ensure that words are compared fairly
during the training process, and that if a particular word
is a strong indicator of a topic, its signal is not lost just
because it is used in many different forms. These steps rely
on words existing in NLTK’s pretrained vocabulary. Any
word not in this vocabulary is left unchanged. After this
preprocessing, we then train the LDA models on the cleaned
data. Specifically, 10 separate LDA models were trained with
the ‘‘number of topics’’ parameter ranging from 3-20, for a
total of 180 models in each of the two time intervals T1 and
T2. The CV coherence algorithm was then run over each of
these models and the coherence scores were then averaged
for each number of topics. To produce the results, multiple
trials were run for each number of topics to ensure that the
VOLUME 8, 2020 91891R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
coherence for a particular number of topics is representative
of what LDA models tend to find (and by extension a better
fit for the data) and is not the result of unaccounted noise
swaying the model to overfit in one way or another. These
trials are independent because the random number generator
for each LDA model was initialized with a different seed,
ensuring that statistical inferences were not be repeated. The
GitHub link is: https://github.com/searri/social-clusteringresearch/wiki/Coronavirus-Vax.
The following illustrates the topic output, focusing on antivax in time interval T2 in Fig. 2B. In this, 9 of the 10 topics
had the word ‘coronavirus’ among the 5 highest weighted
words in the topic; 4 were focused around ‘coronavirus’ and
‘vaccine’ co-occuring together. Others had ‘vitamin’, ‘fear’
and ‘ddt’ in relation to alternative treatments, and ‘weapon’
related to conspiracy theories of COVID-19’s origin. Within
one of the topics, which is focused around alternative health
explanations and cures with words like ‘vitamin’ etc., illustrative posts include the following from Feb 8, 2020 in one
of the ‘Coalition for Vaccine Choice’ pages, with spelling
mistakes left as is: ‘‘The story of this FAKE ‘‘epidemic’’
with the ‘‘corona virus’’ from China is a cover-up story for
the grim reality of the health problems due to 5G technology
exposure coroborated with a lot of other factors: vaccination,
poor alimentation in vitamins, bad water, air pollution, lack of
sleep, etc.... scientists have shown that low level microwave
EMF exposure can result in VGCC activation and elevated
intracellular calcium’’. Meanwhile, for a topic focused on
conspiracy theories with words such as ‘weapon’ and ‘fear’,
an example phrase from a posting is ‘‘..keeping the world
under the thumb of tyrants! You are soldiers, and that means
that you are expendable by your trained nature. You are
being micro-managed by people that give not one caring
thought of you, five thousand miles away, that know little
of the true nature of the battle’’. This illustrates the type of
detailed analyses that we carried out to check our automated
approach, and which underlie our claim that the groupings do
correspond to reasonably distinct conversation topics.
ACKNOWLEDGMENT
CrowdTangle data are made available to the Institute for Data,
Democracy, and Politics.



NEW_PAPER


SPECIAL SECTION ON EMERGING DEEP LEARNING THEORIES AND
METHODS FOR BIOMEDICAL ENGINEERING
Received May 26, 2020, accepted June 25, 2020, date of publication June 29, 2020, date of current version July 8, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3005510
Weakly Supervised Deep Learning for
COVID-19 Infection Detection and
Classification From CT Images
SHAOPING HU1
, YUAN GAO 2,3, (Member, IEEE), ZHANGMING NIU3,4, YINGHUI JIANG4,5
,
LAO LI4,5, XIANGLU XIAO3,5, MINHAO WANG4,5, EVANDRO FEI FANG6
, WADE MENPES-SMITH3
,
JUN XIA7
, HUI YE8
, AND GUANG YANG 9,10, (Member, IEEE)
1Radiology Department, Hospital of Wuhan Red Cross Society, Wuhan 430015, China
2
Institute of Biomedical Engineering, University of Oxford, Oxford OX3 7DQ, U.K.
3Aladdin Healthcare Technologies Ltd., London EC1Y 0UH, U.K.
4Hangzhou Ocean’s Smart Boya Company, Ltd., Hangzhou 310016, China
5Mind Rank Ltd., Admiralty, Hong Kong
6Department of Clinical Molecular Biology, University of Oslo, 0315 Oslo, Norway
7Radiology Department, Shenzhen Second People’s Hospital, Shenzhen 518035, China
8PET-CT Center, Hunan Cancer Hospital, Changsha 410013, China
9NHLI, Imperial College London, London SW3 6LY, U.K.
10Royal Brompton Hospital, London SW3 6NP, U.K.
Corresponding authors: Hui Ye (yuxin75831@163.com) and Guang Yang (g.yang@imperial.ac.uk)
This work was supported in part by the European Research Council Innovative Medicines Initiative on Development of Therapeutics and
Diagnostics Combatting Coronavirus Infections Award ’DRAGON: rapiD and secuRe AI imaging based diaGnosis, stratification,
fOllow-up, and preparedness for coronavirus paNdemics’ under Grant H2020-JTI-IMI2 101005122, and in part by IIAT Hangzhou.
ABSTRACT An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded in Wuhan,
China since late December 2019, which subsequently became pandemic around the world. Although
COVID-19 is an acutely treated disease, it can also be fatal with a risk of fatality of 4.03% in China
and the highest of 13.04% in Algeria and 12.67% Italy (as of 8th April 2020). The onset of serious
illness may result in death as a consequence of substantial alveolar damage and progressive respiratory
failure. Although laboratory testing, e.g., using reverse transcription polymerase chain reaction (RT-PCR),
is the golden standard for clinical diagnosis, the tests may produce false negatives. Moreover, under the
pandemic situation, shortage of RT-PCR testing resources may also delay the following clinical decision
and treatment. Under such circumstances, chest CT imaging has become a valuable tool for both diagnosis
and prognosis of COVID-19 patients. In this study, we propose a weakly supervised deep learning strategy
for detecting and classifying COVID-19 infection from CT images. The proposed method can minimise the
requirements of manual labelling of CT images but still be able to obtain accurate infection detection and
distinguish COVID-19 from non-COVID-19 cases. Based on the promising results obtained qualitatively and
quantitatively, we can envisage a wide deployment of our developed technique in large-scale clinical studies.
INDEX TERMS COVID-19, deep learning, weakly supervision, CT images, classification, convolutional
neural network.
I. INTRODUCTION
Coronavirus disease 2019 (COVID-19) has been widespread
worldwide since December 2019 [1], [2]. It is highly contagious, and severe cases can lead to acute respiratory distress
or multiple organ failure [3]. On 11 March 2020, the WHO
has made the assessment that COVID-19 can be characterised
as a pandemic. As of 8th April 2020, in total, 1,391,890 cases
The associate editor coordinating the review of this manuscript and
approving it for publication was Shuihua Wang .
of COVID-19 have been recorded, and the death toll has
reached 81,478 with a rapid increase of cases in Europe and
North America.
The disease can be confirmed by using the reversetranscription polymerase chain reaction (RT-PCR) test [4].
While being the gold standard for diagnosis, confirming
COVID-19 patients using RT-PCR is time-consuming, and
both high false-negative rates and low sensitivities may put
hurdles for the presumptive patients to be identified and
treated early [3], [5], [6].
VOLUME 8, 2020 
 2020 IEEE. This article is free to access and download, along with rights for full text and data mining, re-use and analysis 118869S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
As a non-invasive imaging technique, computed tomography (CT) can detect those characteristics, e.g., bilateral
patchy shadows or ground glass opacity (GGO), manifested
in the COVID-19 infected lung [7], [8]. Hence CT may serve
as an important tool for COVID-19 patients to be screened
and diagnosed early. Despite its advantages, CT may share
some common imagery characteristics between COVID-19
and other types of pneumonia, making the automated distinction difficult.
Recently, deep learning based artificial intelligence (AI)
technology has demonstrated tremendous success in the field
of medical data analysis due to its capacity of extracting rich
features from multimodal clinical datasets [9]. Previously,
deep learning was developed for diagnosing and distinguishing bacterial and viral pneumonia from thoracic imaging
data [10]. In addition, attempts have been made to detect various chest CT imaging features [11]. In the current COVID-19
pandemic, deep learning based methods have been developed efficiently for the chest CT data analysis and classification [2], [3], [12]. Besides, deep learning algorithms have
been proposed for COVID-19 monitoring [13], screening [14]
and prediction of the hospital stay [15]. A full list of current
AI applications for COVID-19 related research can be found
elsewhere [16]. In this study, we will focus on the chest CT
image based localisation for the infected areas and disease
classification and diagnosis for the COVID-19 patients.
Although initial studies have demonstrated promising
results by using chest CT for the diagnosis of COVID-19 and
detection of the infected regions, most existing methods are
based on commonly used supervised learning scheme. This
requires a considerable amount of work on manual labelling
of the data; however, at such an outbreak situation clinicians
have very limited time to perform the tedious manual drawing, which may fail the implementation of such supervised
deep learning methods. In this study, we propose a weakly
supervised deep learning framework to detect COVID-19
infected regions fully automatically using chest CT data
acquired from multiple centres and multiple scanners. Based
on the detection results, we can also achieve the diagnosis
for the COVID-19 patients. In addition, we also test the
hypothesis that based on the CT radiological features, we can
classify COVID-19 cases from community acquired pneumonia (CAP) and non-pneumonia (NP) scans using the deep
neural networks we developed.
II. MATERIALS AND METHODS
A. PATIENTS AND DATA
This retrospective study was approved by the institutional
review board of the participating hospitals in accordance with
local ethics procedures. Further consent was waived with
approval. This study included 150 3D volumetric chest CT
exams of COVID-19, CAP and NP patients, respectively.
In total, 450 patient scans acquired from two participating
hospitals between September 2016 and March 2020 were
included for further analysis.
TABLE 1. Summary of the patient demographic statistics.
All the COVID-19 patients were confirmed as positive by
the RTPCR testing that were scanned from December 2019
to March 2020. According to the diagnosis and treatment
program of COVID-19 (Trial version sixth) issued by the
National Health Commission in China [17], the clinical classification of COVID-19 patients can be categorised as mild,
moderate, severe, and critical. All our COVID-19 patients
were at severe or critical stage and all the CT scans had been
performed within 3 days of hospitalisation.
CAP and other NP (no lung disease, lung nodules,
chronic inflammation, chronic obstructive pulmonary disease) patients were randomly chosen from the participating
hospitals between September 2016 and January 2020. The
inclusion criteria of CAP patients are in accordance with the
guidelines on the management of community-acquired pneumonia in adults published by the Infectious Diseases Society
of America/American Thoracic Society [18]. CAP diagnosis
is focused on the existence of identified clinical characteristics (e.g., cough, fever, sputum development, and pleuritic
chest pain) and is accompanied by pulmonary examination,
typically by chest X-ray and in our case using CT. In the regular examination of patients that are suspected to have CAP,
a chest radiograph is needed to determine the diagnosis and
to better distinguish CAP from other specific causes of cough
and fever, such as acute bronchitis. Although various CT
manifestations might be observed due to different pathogens,
all our CAP patients were laboratory confirmed bacterial culture positive cases or negative cases, e.g., with mycoplasma
and viral pneumonia. Our assumption is that the proposed
weakly supervised deep learning method can sense subtle
discrepancies in CT images acquired for CAP and COVID-19
patients. NP patients were diagnosed with no lung disease
or lung disease, e.g., lung nodules, chronic inflammation,
chronic obstructive pulmonary disease and others. It is of note
that the criterion for normal CT in the context is that the CT
examinations have shown no obvious lesions in both lungs.
Demographic statistics of the patients are as reported
in Table 1. One-way ANOVA (ANalysis Of VAriance) were
conducted on gender and age distribution over the three
patient groups and the p-values obtained suggest that there
were no significant differences found among three groups in
terms of gender and age distribution (p>0.05).
COVID-19 patients were admitted from two hospitals in China, including 138 patients from Hospital of
Wuhan Red Cross Society (WHRCH) and 12 patients
from Shenzhen Second Hospital (SZSH). Both CAP
and NP patients were recruited from SZSH. COVID-19
118870 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
TABLE 2. Imaging parameters of the CT systems used for COVID-19, CAP and NP patients.
patients were obtained from either Siemens SIEMENS
SOMATOM go.Now16 (WHRCH) or GE Revolution 256
(SZSH) CT systems. For the SIEMENS SOMATOM
go.Now16 CT system, the scanning parameters were as
follows: tube voltage = 130 kVp, automatic tube current modulation = 50 mAs, pitch = 1.5 mm, matrix =
512×512, slice thickness = 0.7 mm, field of view = 350 mm
× 350 mm, and reconstructed slice thickness = 1 mm. For
the GE Revolution 256 CT system, the scanning parameters
were set as tube voltage = 120 kVp, automatic tube current modulation = 150 mAs, pitch = 1.375 mm, matrix =
512 × 512, slice thickness = 0.625 mm, field of
view = 400 mm × 400 mm, and reconstructed slice thickness = 2 mm. All the CAP and NP patients were scanned
using SIEMENS SOMATOM Emotion CT system with the
main imaging parameters of tube voltage = 110 kVp, automatic tube current modulation = 70 mAs, pitch = 1.2 mm,
matrix = 512 × 512, slice thickness = 1.2mm, field of
view = 260 mm × 260 mm, and reconstructed slice thickness = 1.5 mm. Details are shown in Table 2.
B. DATASET FOR LUNG SEGMENTATION
In order to achieve a highly accurate lung segmentation that
can facilitate the following infection detection and classification, we utilised an open dataset (TCIA dataset) [19]
for training a deep neural network for the lung delineation. The data can be accessed from the Cancer Imaging
Archive (TCIA) Public Access.1
In total, 60 3D CT lung
scans were retrieved with manual delineations of the lung
anatomy. These open datasets were made publicly accessible
from the scans obtained by three different institutions: MD
Anderson Cancer Centre, Memorial Sloan-Kettering Cancer
Centre, and the MAASTRO clinic, with 20 cases from each
institution. All the data were scanned with matrix = 512 ×
512, the field of view = 500 mm×500 mm, and reconstructed
slice thickness varies at either 1 mm, 2.5 mm or 3 mm.
C. PRE- AND POST-PROCESSING FOR
LUNG SEGMENTATION
Data pre-processing steps were performed to standardise
data acquired from multiple centres and multiple scanners.
1http://doi.org/10.7937/K9/TCIA.2017.3r3fvz08
Instead of normalising input slices into a pre-defined
Hounsfield unit (HU) window, we designed a more flexible
scheme based on previously proposed image enhancement
methods [20], [21]. Rather than clipping based on HU windows, we proposed to use a fixed-sized sliding window WQ,S
(where Q denotes the size of the window and S denotes
the step length of the sliding procedure) to find the range
where covers most of the pixel values. This can reduce the
bias of data acquired from different centres and different
scanners. Loosely inspired by [22], we proposed a multi-view
U-Net [23] based segmentation network for lung segmentation. Our multi-view U-Net based segmentation network
consisted of a multi-window voting post-processing procedure and a sequential information attention module in order
to utilise the information from each view of the 3D volume
and reinforce the integrity of the 3D lung structure of the
delineation results. Our lung segmentation model was trained,
cross-validated and tested on the TCIA dataset with manual
ground truth. The trained lung segmentation model was then
used for inferencing the delineation of the lung anatomy of
the COVID-19, CAP and NP patients included in this study.
D. DETECTION AND CLASSIFICATION NETWORK
Inspired by the VGG architecture [24], we adopted the configuration that increased CNN depth using small convolution filters stacked with non-linearity injected in between,
as depicted in Figure 1. All convolution layers consisted of 3
× 3 kernels, batch normalisation and Rectified Linear Units.
The proposed CNN was fully convolutional consisting of five
convolutional blocks, i.e., Conv1, Conv2, Conv3, Conv4 and
Conv5 in the backbone architecture. The full architecture,
using shorthand notation, is 2 × C(32, 3, 1) − MP − 2 ×
C(64, 3, 1)−MP−3×C(128, 3, 1)−MP−3×C(256, 3, 1)−
MP − 3 × C(256, 3, 1) − MP, where C(d, f ,s) indicates a
convolution layer with d filters of spatial size f × f , applied
to the input with stride s. MP represents non-overlapping
max-pooling operation with a kernel size of 2 × 2.
E. MULTI-SCALE LEARNING
From the previous findings using CT [25]–[27], it is known
that infections of COVID-19 share the similar and common
radiographic features as CAP, such as GGO and airspace
VOLUME 8, 2020 118871S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 1. Network architecture of our proposed weakly supervised multi-scale learning framework for COVID-19/NP/CAP classification and lesions
detection.
consolidation. They frequently distribute bilaterally, peripherally in lower zone predominant, and the infectious areas
can vary significantly in size depending on the condition of
the patients. For example, in mild cases the lesions appear
to be small, but in severe cases they appear scattered and
spread around over a large area. Therefore, we proposed a
multi-scale learning scheme to cope with variations of the
size and location of the lesions. To implement this, we fed
the intermediate CNN representations, i.e., feature maps,
at Conv3, Conv4 and Conv5, respectively into the weakly
supervised classification layers, in which 1 × 1 convolution
was applied to mapping the feature maps down to the class
score maps (i.e., class activation maps). We then applied
a spatial aggregation with a Global Max Pooling (GMP)
operation to obtain categorical scores. The scores vectors at
Conv3, Conv4 and Conv5 level were aggregated by sum to
make a final prediction with a Softmax function. We then
trained the proposed model end-to-end by minimising the
following objective function
L = −
1
N
X
N
i=1
wi
fi(Sc(xi) − logX
K
k=1
e
Sk (xi)
), (1)
where there are N training images xi and K training classes.
Sk is the kth component in the score vector ∈ <K , and c
is the true class of xi
. As we encountered an imbalanced
classification, we added a class-balanced weighting factor
wi
to the cross-entropy loss, which was set by inverse class
frequency, i.e., wi =
1
freq(c)
. While this emphasised the
importance of a rare class during training, it showed no
difference between easy and hard examples. For instance,
in mild COVID-19 slices, infectious or diseased regions are
often very small and not prominent. Thus, they are prone to be
misclassified as NP examples. To address this, we introduced
another modulating factor, i.e., to down-weight easy examples and therefore focused the training on hard examples [28]
fi = (1−Pc)
γ
, where Pc is the true class posterior probability
of xi
. Intuitively, the modulating factor can reduce the loss
contribution from easy examples. This in turn increases the
importance of correcting misclassified examples. When an
example was misclassified and Pc was small, the factor f was
near 1 and the loss was unaffected. As Pc → 1, the factor
went to 0 and the loss for well-classified examples was downweighted. The parameter γ is a positive integer which can
smoothly adjust the rate at which easy examples are downweighted. As γ is increased the modulating effect of the factor
f is likely to be increased.
F. WEAKLY SUPERVISED LESIONS LOCALISATION
After determining the class score maps and the image category in a forward pass through the network, the discriminative
patterns corresponding to that category can then be localised
118872 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 2. Examples of saliency maps for COVID-19 lesions localisation: (a) shows an example input image, (b) shows the saliency map obtained at
Conv3, (c) shows the saliency map obtained at Conv4, (d) shows the saliency map obtained at Conv5, (e) shows the overlay of the joint saliency map
(pixel-wise multiplication of the Conv3, Conv4 and Conv5 saliency maps) with the input image, and (f) shows the resulting bounding boxes.
in the image. A coarse localisation could already be achieved
by directly relating each of the neurons in the class score maps
to its receptive field in the original image. However, it is also
possible to obtain pixel-wise maps containing information
about the location of class-specific target structures at the
resolution of the original input images. This can be achieved
by calculating how much each pixel influences the activation
of the neurons in the target score map. Such maps can be used
to obtain a much more accurate localisation, like the examples
shown in Figure 2.
In the following, we will show how categorical-specific
saliency maps can be obtained through the integrated gradients. Besides, we will also show how to post-process the
saliency maps from which we can extract bounding boxes
around the detected lesions.
1) CATEGORY-SPECIFIC SALIENCY
Generally, suppose we have a flattened input image denoted
as x = (x1, . . . , xn) ∈ <n
(number of pixels = n), categoryspecific saliency map can be obtained by calculating the
gradient of the predicted class score S(x) at the input x:
g =
∂S(x)
∂x = (g1, . . . , gn) ∈ <n
, where gi represents the contribution of individual pixel xi
to the prediction. In addition,
the gradient can be estimated by back-propagating the final
prediction score through each layer of the network. There
are many state-of-the-art back-propagation approaches,
including Guided-Backpropagation [29], DeepLift [30] and
Layer-wise Relevance Propagation (LRP) [31]. However,
Guided-Backpropagation method may break gradient sensitivity because it back-propagates through a ReLU node only
if the ReLU is turned on at the input. In particular, the lack
of sensitivity causes gradients to focus on irrelevant features
and results in undesired saliency localisation. DeepLift and
LRP methods tackle the sensitivity issue by computing discrete gradients instead of instantaneous gradients at the input.
However, they fail to satisfy the implementation invariance
because the chain rule does not hold for discrete gradients
in general. In doing so, the back-propagated gradients are
potentially sensitive to unimportant features of the models.
To deal with these limitations, we employ a feature attribution
method named ‘‘Integrated Gradients’’ [32] that assigns an
importance score φi(S(x), x) (similar to pixel-wise gradients)
to the ith pixel representing how much the pixel value adds or
subtracts from the network output. A large positive score indicates that pixel strongly increases the prediction score S(x),
while an importance score closes to zero indicates that pixel
does not influence S(x). To compute the importance score,
it needs to introduce a baseline input representing ‘‘absence’’
of the feature input, denoted as x
0 = (x
0
1
, . . . , x
0
n
) ∈ <n
, which
in our study, was a null image (filled with zeros) with the same
shape as input image x. We considered the straight-line path,
i.e., point-to-point from the baseline x
0
to the input x, and
computed the gradients at all points along the path. Integrated
gradients can be defined as
φi(S(x), x, x
0
)= (xi − x
0
i
)×
Z 1
α=0
∂S(x
0 + α(x − x
0
))
∂xi
dα, (2)
where α ∈ [0, 1]. Intuitively, integrated gradients can obtain
importance scores by accumulating gradients on images interpolated between the baseline value and the current input.
The integral in Eq. 2 can be efficiently approximated via a
summation of the gradients as:
φi(S(x), x, x
0
)≈(xi − x
0
i
)×
Xm
n=1
∂S(x
0 +
n
m × (x − x
0
))
∂xi
×
1
m
,
(3)
where m is the number of steps in the Riemann approximation
of the integral. We compute the approximation in a loop over
the set of inputs, i.e., for n = 1, . . . , m. The integrated
gradients are computed at different feature levels, in our
experiments, which are Conv3, Conv4 and Conv5 respectively, as shown in Figure 2(b), Figure 2(c) and Figure 2(d).
Then, a joint saliency can be obtained, as depicted
in Figure 2(e), by pixel-wise multiplication between the
multi-scale integrated gradients.
2) BOUNDING BOX EXTRACTION
Next, we post-processed the joint saliency map from which
a bounding box can be extracted. Firstly, we took the absolute value of the joint saliency map and blurred it with a
5 × 5 Gaussian kernel. Then, we thresholded the blurred
saliency map using the Isodata thresholding method [33]
that it iteratively decided a threshold segmenting the image
VOLUME 8, 2020 118873S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 3. Dice scores of the lung segmentation using different pre-processing and post-processing methods on the TCIA dataset. Left Panel: without any
pre-processing; Middle Panel: normalising using a pre-defined Hounsfield unit (HU) window; Right Panel: normalising using the proposed fixed-sized
sliding window. W/O P: without multi-view learning based post-processing; W P: with multi-view learning based post-processing.
into foreground and background, where the threshold was
midway between the mean intensities of sampled foreground
and background pixels. In doing so, we obtained a binary
mask on which we applied morphological operations (dilation followed by erosion) to close the small holes in the
foreground. Finally, we took the connected components with
areas above a certain threshold and fit the minimum rectangular bounding boxes around them. An example is shown
in Figure 2(f).
G. IMPLEMENTATION DETAILS
1) EXPERIMENTS SETUP
We trained the proposed model for both a three-way classification (i.e., K = 3 for NP, CAP and COVID-19) and three
binary classification tasks (K = 2), i.e., NP vs. COVID-19,
NP vs. CAP and CAP vs. COVID19, respectively. In the
three-way classification settings, we first trained individual
classifiers at different convolution blocks. In our experiment,
we chose Conv3, Conv4 and Conv5, respectively. Then,
we trained a joint classifier on the aggregated prediction
scores (as described in the ‘‘Multi-Scale Learning’’ Section).
All the classifiers were trained with the loss in Eq. 1. Finally,
we conducted a 5-fold cross-validation on all tasks that in
each category, we split the datasets into training, validation and test set. This can ensure that no samples (images)
originating from validation and test patients were used for
training. In each fold, we held out 20% of all samples
for validation and test, and the remaining were used for
training.
2) TRAINING CONFIGURATIONS
We implemented the proposed model (as depicted
in Figure 1) using Tensorflow 1.14.0. All models were trained
from scratch on four Nividia GeForce GTX 1080 Ti GPUs
with an Adam optimiser (learning rate: 10−4
, β1 = 0.5,
β2 = 0.9 and  = 10−8
). We set γ to 1 in the focal
modulator f and the total number of training iterations was set
to 20,000. Early stopping was enabled to terminate training
automatically when validation loss stopped decreasing for
1,000 iterations. We run validation once every 500 iterations
of training, a checkpoint was saved automatically if the current validation accuracy exceeded the previous best validation
accuracy. Once the training was terminated, we generated
a frozen graph on the latest checkpoint and saved it in.pb
format. For testing, we simply loaded the frozen graphs
and retrieved the required nodes. Empirically, we found
that 20 to 30 steps were good enough to approximate the
integral when computing the integrated gradients; thus, we fix
m = 25 in Eq. 3.
3) DATA AUGMENTATION
We applied several random on-the-fly data augmentation
strategies during training, including (1) cropping square
patches at the centre of the input frames with a scaling factor
randomly chosen between 0.7 to 1, and resized the crops to
the size of 224 × 224 (input resolution); (2) rotation with an
angle randomly selected within θ = −25o
to 25o
; (3) Random
horizontal reflection, i.e., flipped the images in the left-right
direction with a probability p = 0.5; and (4) adjust contrast
118874 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 4. Results of the multi-scale COVID-19 class activation mapping.
by randomly darkening or brightening with a factor ranging
between 0.5 and 1.5.
H. EVALUATION METRICS
Using positive results of the RTPCR testing as the ground
truth labelling for the COVID-19 group and diagnosis results
of CAP and NP patients, accuracy, precision, sensitivity and
specificity [34], [35] of our classification framework were
calculated. We also carried out the area under the receiver
operating characteristic curve (AUC) analysis for the quantification of our classification performance. For the lung segmentation, we used Dice score [36] to evaluate the accuracy.
III. EXPERIMENTS AND RESULTS
A. LUNG SEGMENTATION
In order to evaluate the lung segmentation network, we randomly split the 60 TCIA data with ground truth into
40 training, 10 validation and 10 independent testing datasets.
Ablation study results of different pre-processing and postprocessing methods using Dice scores are shown in Figure 3.
B. INFECTION DETECTION
1) CLASS ACTIVATION MAPPING
As a result of multi-scale learning, Figure 4 illustrates
some examples of COVID-19 class activation maps (CAMs)
obtained at the different feature levels, i.e., Conv3, Conv4
and Conv5. The CAMs depict the spatial distribution of classification probability on which the hot areas indicate where
infected areas are. The hotter the areas, the more likely they
are infected. Of note from the multi-scale CAMs, our proposed model learns to capture the distributions of lesions with
different scale: for instance, the large patchy-like lesions,
such as crazy paving sign and consolidation; and also small
nodule-like lesions, such as ground-glass opacities (GGO)
and bronchovascular thickening. Although the CAMs can
indicate where the diseased regions are, they are still too
coarse to localise and estimate the extent of lesions precisely.
The saliency maps shown in Figure 5, on the other hand,
can provide pixel-level information that delineates the exact
extent of the lesions, and therefore can deduce a precise
localisation of the lesions. Notably from the saliency maps,
VOLUME 8, 2020 118875S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 5. Multi-scale detection of COVID-19 lesions with varied size. Green box: small lesions. Yellow box: mix of small and large patchy or strip like
lesions. Red box: large lesions.
the mid-level layer, i.e., Conv3 can learn to detect small
lesions (GGO most frequently), especially those distributed
peripherally and subpleurally. However, Conv3 is not able to
capture larger patchy-like lesions, and this may be because of
the limited receptive field at the mid-layer. On the contrary,
the higher-level layers, e.g., Conv4 and Conv5, having sufficiently large receptive filed to detect the diffuse and patchylike lesions, such as crazy paving sign and consolidation,
which are often distributed centrally and peribronchially.
However, Conv4 and Conv5 tend to overestimate the extent
of small lesions. The multi-scale features complement each
other and result in more precise localisation and estimation of the lesions extent, as shown from the joint saliency
maps.
2) CATEGORICAL-SPECIFIC SALIENCY
Figure 6 shows the examples of categorical-specific joint
saliency computed by integrated gradients. It shows the original inputs on the left and the overlaid saliency on the right.
CAMs showed in Figure 4 only depict the spatial distribution
of infection. However, it can not be used for precise localisation of the lesions. The saliency maps, on the other hand,
can provide pixel-level information that delineates the exact
extent of the lesions so providing a precise localisation of the
lesions.
The saliency maps can also be useful for diagnosis that the
percentage of infection to lung areas can be estimated automatically. These saliency maps highlight the pixels that contribute to increasing categorical-specific scores: the brighter
the pixels, the more significant the contribution. Intuitively,
one can also interpret this as the brighter the pixels are,
the more critical features to the network to make the decision
(prediction). It is of note that in Figure 4 and Figure 6, there
is not only an inter-class contrast variation (due to the data
are collected from multi-institutions) but also an intra-class
contrast variation, especially in COVID-19 group. In our
experiments, we found that histogram matching can suppress lesions, especially on COVID-19 images; for instance,
GGO disappears or become less apparent. Besides, this
leads to inferior performance of detection. Therefore, instead
of directly applying histogram matching, we applied random on-the-fly contrast adjustment for data augmentation at
training time. This turns out to be very effective, as demonstrated in Figure 6, our proposed model learns to be invariant
to image contrast, and precisely capture the lesions.
In particular, in Figure 8, we randomly selected typical
example images to illustrate the variations of the image contrast in COVID-19 cases and compared the saliency maps
obtained from models trained with and without contrast
augmentation (CA vs. NCA). We found that without contrast augmentation, the saliency maps tend to be noisy and
poor in localisation, as mis-detection can be observed often
in the cases such as either only partial instances of infection being captured or the regions without infection being
captured. Whereas, with contrast augmentation, the learned
models generate more discriminative saliency maps and
localisation of infected areas is robust and more accurate
against the contrast variation. As can be seen (enclosed by
green box), our model with contrast augmentation is capable
of capturing all the diseased regions and highlighting their
extent precisely, regardless single or multiple instances of
infection.
118876 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 6. Results of the categorical-specific joint saliency.
In addition, from the COVID-19 and CAP saliency,
we found that the CAP lesions are generally smaller and
more constrained locally compare to COVID-19 cases that
often have multiple infected regions and lesions are massive and scattered. It should also be noted that COVID-19
and CAP lesions do share similar radiographic features,
such as GGO and air space consolidation. Besides, GGOs
appear frequently in subpleural regions as well in CAP cases.
Interestingly, from the saliency map for the NP cases,
we found the network takes the pulmonary arteries as
the salient feature. Finally, Figure 7 shows the bounding boxes extracted from COVID-19 and CAP saliency
maps (corresponding to the examples in Figure 6).
We found the results agree with our primary findings that
CAP cases have less infected areas and often there is
single-instance of infection, in contrast, COVID-19 cases
often have more infected areas (multi-instances of infection),
and the COVID-19 lesions vary a lot in terms of extent.
Overall, CAP infection areas are smaller compare to those of
COVID-19.
C. CLASSIFICATION PERFORMANCE
Performance of our proposed model for each specific task
was evaluated with 5-fold cross-validation, and the results on
the test set are reported and summarised in Table 3. We use
five evaluation metrics, which are accuracy (ACC), precision
(PRC), sensitivity (SEN), specificity (SPE) and the area under
the ROC curve (AUC). We report the mean of 5-fold crossvalidation results in each metric with the 95% confidence
interval. We also compared our proposed method with a
VOLUME 8, 2020 118877S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 7. Bounding boxes extracted from saliency for COVID-19 and CAP examples. (Corresponding to the examples in Figure 6).
FIGURE 8. Effect of applying random contrast augmentation (in data augmentation). Contrast adjustment leads to better saliency quality (less noisy) and
more precise and contrast-invariant detection of infected areas. Cyan arrows: false positives of the saliency maps; Pink arrows: false negatives of the
saliency maps; NCA: No Contrast Adjustment; CA: with Contrast Adjustment.
reimplementation of the Navigator-Teacher-Scrutinizer
Network (NTS-NET) [37].
As described earlier in the experimental settings, basically
we have two groups of tasks: three-way classification tasks
(indicated by ∗
) and binary classification tasks (indicated
by o
), and two learning configurations: single-scale learning (indicated by †
) that assigns an auxiliary classifier to
a specific feature level, and multi-scale learning (indicated
by ‡
) that aggregates the multi-level prediction scores then
trained with a joint classifier. All the binary tasks listed were
trained with the multi-scale learning. In terms of three-way
classification, we found the multi-scale learning with joint
classifier achieves superior overall performance than any of
the single-scale learning tasks. It is of note that among the
single-scale learning tasks, classification with Conv4 and
Conv5 features achieve very similar performance in every
metric, which is significantly better than classification with
mid-level, i.e., Conv3 features. One possible explanation is
the mid-level features are not sufficiently semantic compare
to higher-level features, i.e., Conv4 and Conv5. As we know,
118878 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
TABLE 3. The overall classification performance comparison between different tasks on the test set. Values in brackets are 95% confidence intervals.
AUC: area under the receiver operating characteristic curve, COVID-19: coronovirus disease 2019, CAP: Community Acquired Pneumonia, NP:
Non-Pneumonia. ∗
: three-way classification tasks (i.e., NP/CAP/COVID-19). o
: binary classification tasks. †: single-scale learning. ‡: multi-scale learning.
NCA: No Contrast Adjustment (data augmentation).
TABLE 4. The performance (breakdown into each individual class) of three-way classification on the test set. Values in brackets are 95% confidence
intervals. AUC: area under the receiver operating characteristic curve, COVID-19: coronovirus disease 2019, CAP: Community Acquired Pneumonia, NP:
non-pneumonia. ∗
: no random contrast adjustment. †: with random contrast adjustment.
high-level CNN representations are semantically strong but
poorly at preserving spatial details, whereas mid-lower level
CNN representations preserve well the local features but lack
of semantic information.
Furthermore, it is of note that, overall, binary classification
tasks achieve significantly better performance than three-way
classification, especially in the tasks, such as NP/COVID-19
and NP/CAP. It can be seen our proposed model is reasonably
good at distinguishing COVID-19 cases from NP cases as
suggested by the results, showing that it achieves a mean ACC
of 96.2%, PRC of 97.3%, SEN of 94.5%, SPE of 95.3% and
AUC of 0.970, respectively. One can explain this is because
binary classification is less complicated, and there is also
less uncertainty than three-way classification. This may also
because COVID-19 and CAP image features are intrinsically
discriminative compare to the NP cases. For instance, as the
COVID-19 cases demonstrated earlier, there is often a combination of various diseased patterns and large areas of infection
on the scans.
Last but not least, we found that the performance of
COVID-19/CAP classification is the least superior among
all the binary classification tasks. One possible reason is
COVID-19 shares the similar radiographic features with
CAP, such as GGO and airspace consolidation and the network capacity may not be enough to learn disease-specific
representations. Nevertheless, the results obtained using
our proposed method outperformed the ones obtained by
the NTS-NET.
We also break down the overall performance, i.e., the
joint classifier into classes, and the classification metrics are
reported for each class, as shown in Table 4 and Figure. 9. We
found that the models learned without contrast augmentation
are biased that the classification performance for COVID-19
is significantly better than the other two classes. This may
because models learn to discriminate the classes based on
image style (contrast) rather than the content (normal or
disease patterns) and the COVID-19 class in our data has
the most discriminative contrast style (high variability in
brightness) among all three classes. In comparison, learning
with contrast augmentation results in superior overall classification performance (Table 3) and no class bias (Table 4). In
addition, the ‘‘COVID-19’’ and the ‘‘NP’’ classes achieve the
comparable performance in each metric and the ‘‘NP’’ class
has higher sensitivity (91.3%) than the COVID-19 (87.6%)
and CAP (83.0%). Besides, we found, overall, the ‘‘COVID’’
remains the best performed and the most discriminative class
with a mean AUC of 0.923, compared to the ‘‘CAP’’ (0.864)
and the ‘‘NP’’ (0.901). It can also be noted that the overall
results for the class ‘‘CAP’’ are moderately lower than those
of the ‘‘NP’’ and ‘‘COVID-19’’. This could be correlated
VOLUME 8, 2020 118879S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 9. Receiver operating characteristic (ROC) of individual categories for three-way classification (5-fold cross-validated). (a) NP with AUC
of 0.90±0.03 (mean±standard deviation); (b) CAP with AUC of 0.86±0.03 (c) COVID-19 with AUC of 0.92±0.02. The green region indicates the
95%CI. COVID-19: coronavirus disease 2019, CAP: Community Acquired Pneumonia, NP: Non-Pneumonia, CI: Confidence Interval.
with our finding in the COVID-19/CAP classification that
because of similar appearance, the ‘‘CAP’’ class is likely to be
misclassified as the ‘‘COVID-19’’ sometimes. Also, another
possible reason is that the network could have learned and
be distracted by the few ‘‘NP noises’’, and there might be a
fractional number of non-infected slices in between the CAP
training samples. This is because we sampled all the available
slices from each subject, and there might be a few slices
having no infections.
IV. DISCUSSIONS
In this work, we have presented a novel weakly supervised
deep learning framework that is capable of learning to detect
and localise lesions on COVID-19 and CAP CT scans from
image-level label only. Different from other works, we leverage the representation learning on multiple feature levels and
have explained what features can be learned at each level.
For instance, the high-level representation, i.e., Conv5 captures the patch-like lesions that generally have a large extent.
However, it tends to discard small local lesions. This is well
complemented by the mid-level representations (Figure 4),
i.e., Conv4 and Conv5, from which the lesions detected also
correspond to our clinical findings that the infections usually
located in the peripheral lung (95%), mainly in the inferior
lobe of the lungs (65%), especially in the posterior segment
(51%). We speculate that it is mainly because there are more
well-developed bronchioles, alveoli, rich blood flows and
immune cells such as lymphatic cells in the periphery. These
immune cells played a vital role in the inflammation caused
by the virus. We have also demonstrated that combing multiscale saliency maps, generated by integrated gradients, is the
key to achieve a precise localisation of multi-instance lesions.
Furthermore, from a clinical perspective, the joint saliency
is useful that it provides a reasonable estimation of the
118880 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
percentage of infected lung areas, which is a crucial factor
that clinicians take account for evaluating the severity of a
COVID-19 patient. Besides, the classification performance
of the proposed network has been studied extensively that
we have not only conducted three-way classification but also
binary classification by combining any two of the classes.
We found one limitation of the proposed network is that
it is not discriminative enough when it comes to separate the
CAP from COVID-19. We suspect this is due to the limited
capacity of the backbone CNN that a straightforward way of
boosting CNN capacity is to increase the number of feature
channels at each level. Another attempt in the future would
be employing more advanced backbone architecture, such as
Resnet and Inception. Another limitation in this work is that
we have trained the networks on individual slices (images)
that we use all available samples for each subject. However,
for the CAP or COVID-19 subjects, there might be fractional
non-infection slices in between which could introduce noises
in training, which have been confirmed by scrutinisation by
our clinicians. In the future, we can address the limitation
by attention-based multiple instances learning that instead
of training on individual slices, we put the patient-specific
slices into a bag and train on bags. The network will learn
to assign weights to individual slices in a COVDI-19 or CAP
positive bag and automatically sample those high weighted
slices for infection detection. Further supervision via labelled
non-infection slices may also boost the performance of our
proposed model, but at a cost of time-consuming manual
labelling procedure.
V. CONCLUSION
In this study, we designed a weakly supervised deep learning framework for fast and fully-automated detection and
classification of COVID-19 infection using retrospectively
extracted CT images from multi-scanners and multi-centres.
Our framework can distinguish COVID-19 cases accurately
from CAP and NP patients. It can also pinpoint the exact position of the lesions or inflammations caused by the COVID19, and therefore can also potentially provide advice on
patient severity in order to guide the following triage and
treatment. Experimental findings have indicated that the proposed model achieves high accuracy, precision and AUC
for the classification, as well as promising qualitative visualisation for the lesion detections. Based on these findings
we can envisage a large-scale deployment of the developed
framework.
ACKNOWLEDGMENT
(Shaoping Hu, Yuan Gao, and Zhangming Niu contributed
equally to this work.)


NEW_PAPER


Received June 14, 2020, accepted July 10, 2020, date of publication July 20, 2020, date of current version July 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3010287
Can AI Help in Screening Viral and COVID-19
Pneumonia?
MUHAMMAD E. H. CHOWDHURY 1
, (Member, IEEE), TAWSIFUR RAHMAN 3
,
AMITH KHANDAKAR 1
, (Senior Member, IEEE), RASHID MAZHAR2
,
MUHAMMAD ABDUL KADIR 3
, ZAID BIN MAHBUB4
, KHANDAKAR REAJUL ISLAM5
,
MUHAMMAD SALMAN KHAN 6,8, (Member, IEEE),
ATIF IQBAL 1
, (Senior Member, IEEE), NASSER AL EMADI1
,
MAMUN BIN IBNE REAZ 7
, (Senior Member, IEEE),
AND MOHAMMAD TARIQUL ISLAM 7
, (Senior Member, IEEE)
1Department of Electrical Engineering, Qatar University, Doha, Qatar
2Thoracic Surgery, Hamad General Hospital, Doha, Qatar
3Department of Biomedical Physics and Technology, University of Dhaka, Dhaka 1000, Bangladesh
4Department of Mathematics and Physics, North South University, Dhaka 1229, Bangladesh
5Department of Orthodontics, Bangabandhu Sheikh Mujib Medical University, Dhaka 1000, Bangladesh
6Department of Electrical Engineering (JC), University of Engineering and Technology, Peshawar 25120, Pakistan
7Department of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi 43600, Malaysia
8Artificial Intelligence in Healthcare, Intelligent Information Processing Laboratory, National Center for Artificial Intelligence, University of Engineering and
Technology, Peshawar 48550, Pakistan
Corresponding author: Muhammad E. H. Chowdhury (mchowdhury@qu.edu.qa)
This work was supported by the Qatar National Research Fund, a member of Qatar Foundation, Doha, Qatar, under Grant
NPRP12S-0227-190164. The statements made herein are solely the responsibility of the authors.
ABSTRACT Coronavirus disease (COVID-19) is a pandemic disease, which has already caused
thousands of causalities and infected several millions of people worldwide. Any technological tool
enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the
healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the
Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires
specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative
in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI)
in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to
propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray
images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public
database was created by the authors combining several public databases and also by collecting images from
recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and
1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation
to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks
were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral
and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision,
sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%,
97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly
improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic
where disease burden and need for preventive measures are at odds with available resources.
INDEX TERMS Artificial intelligence, COVID-19 pneumonia, machine learning, transfer learning, viral
pneumonia, computer-aided diagnostic tool.
The associate editor coordinating the review of this manuscript and
approving it for publication was Xin Zhang .
I. INTRODUCTION
Coronavirus disease (COVID-19) is an extremely contagious
disease and it has been declared as a pandemic by the World
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 132665M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
Health Organization (WHO) on 11th March 2020 considering the extent of its spread throughout the world [1].
The pandemic declaration also stressed the deep concerns
of the alarming rate of spread and severity of COVID-19.
It is the first recorded pandemic caused by any coronavirus.
It is defined as a global health crisis of its time, which has
spread all over the world. Governments of different countries
have imposed border restrictions, flight restrictions, social
distancing, and increasing awareness of hygiene. However,
the virus is still spreading at very rapid rate. While most of
the people infected with the COVID-19 experienced mild
to moderate respiratory illness, some developed a deadly
pneumonia. There are assumptions that elderly people with
underlying medical problems like cardiovascular disease,
diabetes, chronic respiratory disease, renal or hepatic diseases
and cancer are more likely to develop serious illness [2].
Until now, no specific vaccine or treatment for COVID-19
has been invented. However, there are many ongoing clinical
trials evaluating potential treatments. More than 7.5 million
infected cases were found in more than 200 countries until
11th June 2020, among which around 421 thousand deaths,
3.8 million recovery, 3.2 million mild cases and 54 thousand
critical cases were reported [3], [4].
In order to combat with the spreading of COVID-19,
effective screening and immediate medical response for the
infected patients is a crying need. Reverse Transcription
Polymerase chain reaction (RT-PCR) is the most used clinical
screening method for the COVID-19 patients, which uses
respiratory specimens for testing [5]. RT-PCR is used as a
reference method for the detection of COVID-19 patients,
however, the technique is manual, complicated, laborious
and time-consuming with a positivity rate of only 63% [5].
Moreover, there is a significant shortage of its supply,
which leads to delay in the disease prevention efforts [6].
Many countries are facing difficulties with incorrect number
of COVID-19 positive cases because of not only due to
the lack of test kits but also due to the delay in the
test results [7]. These delays can lead to infected patients
interacting with the healthy patients and infecting them in
the process. It is reported that the RT-PCR kit costs about
USD 120-130 and also requires a specialized biosafety lab
to house the PCR machine, each of which may cost USD
15,000 to USD 90,000 [8]. Such an expensive screening
tool with delayed test results is leading to spread of the
disease, making the scenario worst. This is not an issue
for the low-income countries only but certain developed
countries are also struggling to tackle with this [9]. The
other diagnosis methods of the COVID-19 include clinical
symptoms analysis, epidemiological history and positive
radiographic images (computed tomography (CT) /Chest
radiograph (CXR)) as well as positive pathogenic testing.
The clinical characteristics of severe COVID-19 infection is
that of bronchopneumonia causing fever, cough, dyspnea, and
respiratory failure with acute respiratory distress syndrome
(ARDS) [10]–[13]. Readily available radiological imaging
is an important diagnostic tool for COVID-19. The majority
of COVID-19 cases have similar features on radiographic
images including bilateral, multi-focal, ground-glass opacities with a peripheral or posterior distribution, mainly in the
lower lobes, in the early stage and pulmonary consolidation
in the late stage [13]–[19]. Although typical CXR images
may help early screening of suspected cases, the images of
various viral pneumonias are similar and they overlap with
other infectious and inflammatory lung diseases. Therefore,
it is difficult for radiologists to distinguish COVID-19 from
other viral pneumonias. The symptoms of COVID-19 being
similar to that of viral pneumonia can sometimes lead to
wrong diagnosis in the current situation while hospitals are
overloaded and working round the clock. Such an incorrect
diagnosis can lead to a non-COVID viral Pneumonia being
falsely labelled as highly suspicious of having COVID-19 and
thus delaying in treatment with consequent costs, effort and
risk of exposure to positive COVID-19 patients.
Currently many biomedical health problems and complications (e.g. brain tumor detection, breast cancer detection, etc.) are using Artificial Intelligence (AI) based
solutions [20]–[25]. Deep learning techniques can reveal
image features, which are not apparent in the original
images. Specifically, Convolutional Neural Network (CNN)
has been proven extremely beneficial in feature extraction
and learning and therefore, widely adopted by the research
community [26]. CNN was used to enhance image quality
in low-light images from a high-speed video endoscopy [27]
and was also applied to identify the nature of pulmonary
nodules via CT images, the diagnosis of pediatric pneumonia
via chest X-ray images, automated labelling of polyps
during colonoscopic videos, cystoscopic image analysis
from videos [28]–[31]. Deep learning techniques on chest
X-Rays are getting popularity with the availability of the
deep CNNs and the promising results it has shown in
different applications. Moreover, there is an abundance
of data available for training different machine-learning
models. Transfer learning technique has significantly eased
the process by allowing quickly retrain a very deep CNN
network with a comparatively low number of images.
Concept of transfer learning in deep learning framework
was used by Vikash et al [32] for the detection of
pneumonia using pre-trained ImageNet models [33] and
their ensembles. A customized VGG16 model was used
by Xianghong et al. [34] for lung regions identification and
different types of pneumonia classification. Wang et al [35]
used a large hospital-scale dataset for classification and
localization of common thoracic diseases and Ronneburger
et al [36] used image augmentation on a small set of images
to train deep CNN for image segmentation problem to achieve
better performance. Rajpurkar et al [37] reported a 121-
layer CNN (CheXNet) on chest X-rays to detect 14 different
pathologies, including pneumonia using an ensemble of
different networks. A pre-trained DenseNet-121 and feature
extraction techniques were used in the accurate identification
of 14 thoracic diseases in [38]. Sundaram et al. [39] used
AlexNet and GoogLeNet with image augmentation to obtain
132666 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
an Area Under the Curve (AUC) of 0.95 in pneumonia
detection.
Recently, several groups have reported deep machine
learning techniques using X-ray images for detecting
COVID-19 pneumonia [40]–[56]. However, most of these
groups used rather a small dataset containing only a few
COVID-19 samples. This makes it difficult to generalize
their results reported in these articles and cannot guarantee that the reported performance will retain when these
models will be tested on a larger dataset. Ioannis et al. [39]
reported transfer learning approach for classifying dataset
of 1427 X-ray images containing 224 COVID-19, 700 Bacterial Pneumonia and 504 Normal X-ray images with
accuracy, sensitivity, and specificity of 96.78%, 98.66%,
and 96.46% respectively. Different pre-trained models were
compared however, the reported results were based on a small
dataset. Ashfar et al. [43] proposed a Capsule Networks,
called COVID-CAPS rather than a conventional CNN to deal
with a smaller dataset. COVID-CAPS was reported to achieve
an accuracy of 95.7%, sensitivity of 90%, and specificity
of 95.8%. Abbas et al. [44] have worked on a very small
database of 105 COVID-19, 80 Normal and 11 SARS X-ray
images to detect COVID-19 X-ray images using modified
pre-trained CNN model (DeTraC-Decompose, Transfer and
Compose) to project the high-dimension feature space into
a lower one. This would help to produce more homogenous
classes, lessen the memory requirements and achieved
accuracy, sensitivity and specificity of 95.12%, 97.91% and
91.87% respectively. Wang and Wong in [40] introduced a
deep CNN, called COVID-Net for the detection of COVID-19
cases from around 14k chest X-ray images, however
the achieved accuracy was 83.5%. Ucar et al. [47] has
fine-tuned SqueezeNet pre-trained network with Bayesian
optimization to classify COVID-19 images, which showed
promising result on a small dataset. This approach should
be evaluated on a large COVID and non-COVID dataset.
Khan et al. [51] applied transfer learning approach on
310 normal, 330 bacterial pneumonia, 327 viral pneumonia
and 284 COVID-19 pneumonia images. However, different
machine learning algorithms were not evaluated in this study
and the experimental protocol was not clear in this work.
In summary, several recent works were reported on transfer
learning approach for the detection of COVID-19 X-ray
images from a small dataset with promising results however
these needed to be verified on a large dataset. Some group
have modified or fine-tuned the pre-trained networks to
achieve better performance while some groups use capsule
networks. A rigorous experiment on a large database of
COVID and non-COVID classes are very few and missing
in case of transfer learning approach. The authors in this
paper have prepared a large database of X-ray images
of 1579 normal, 1485 viral pneumonia and 423 COVID-19
positive pneumonia and made this publicly available so that
other researchers can get benefit from it. Moreover, eight
different pre-trained deep learning networks were trained,
validated and tested for two different classification schemes.
One classification model was trained to classify COVID-19
and normal X-ray images while other was trained to classify
normal, viral pneumonia and COVID-19 pneumonia images.
Both of the experiments were evaluated with and without
image augmentation technique to study the effect of image
augmentation in this particular problem.
II. METHODOLOGY
Deep convolutional neural networks typically perform better
with a larger dataset than a smaller one. Transfer learning
can be used in the training of deep CNNs where the dataset
is not large. The concept of transfer learning uses the
trained model from large dataset such as ImageNet [57] and
modify the Softmax and classification layer of the pre-trained
networks. The pre-trained weights are then used for faster
training of the network for an application with comparatively
smaller dataset. This removes the requirement of having
large dataset and also reduces the long training period as is
required by the deep learning algorithm when developed from
scratch [58], [59].
Although there are a large number of COVID-19 patients
infected worldwide, the number of chest X-ray images
publicly available online are small and scattered. Therefore,
in this work, authors have reported a comparatively large
dataset of COVID-19 positive chest X-ray images while
normal and viral pneumonia images are readily available
publicly and used for this study. A Kaggle database was
created by the authors to make the database publicly available
to the researchers worldwide and the trained models were
made available so that others can get benefit of this study [60].
A. DATABASE DESCRIPTION
In this study, posterior-to-anterior (AP)/anterior-to-posterior
(PA) image of chest X-ray was used as this view of radiography is widely used by radiologist in clinical diagnosis.
Six different sub-databases were used to create one database.
Among these databases, COVID-19 database was developed by the authors from collected and publicly available
databases, while normal and viral pneumonia databases were
created from publicly available Kaggle databases. In the
following section, authors have summarized how this dataset
is created.
COVID-19 sub-database, comprising of 423 AP/PA
images, was created from the following four major data
sources.
• Italian Society of Medical and Interventional
Radiology (SIRM) COVID-19 DATABASE :
SIRM COVID-19 database [61] reports 384 COVID-19
positive radiographic images (CXR and CT) with varying
resolution. Out of 384 radiographic images, 94 images are
chest X-ray images and 290 images are lung CT images.
This database is updated in a random manner and until 10th
May 2020, there were 71 confirmed COVID-19 cases were
reported in this database.
• Novel Corona Virus 2019 Dataset :
VOLUME 8, 2020 132667M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
Joseph Paul Cohen and Paul Morrison and Lan Dao
have created a public database in GitHub [62] by collecting 319 radiographic images of COVID-19, Middle
East respiratory syndrome (MERS), Severe acute respiratory syndrome (SARS) and ARDS from the published
articles and online resources. In this database, they have
collected 250 COVID-19 positive chest X-ray images and
25 COVID-19 positive lung CT images with varying image
resolutions. However, in this study, authors have considered
134 COVID-19 positive chest X-ray images, which are
different from the images of the database that the authors
created from different articles.
• COVID-19 positive chest x-ray images from different
articles:
GitHub database has encouraged the authors to look into
the literature and interestingly more than 1200 articles were
published in less than two-months of period. Authors have
observed that the GitHub database has not collected most
of the X-ray and CT images rather a small number of
images were in that database. Moreover, the images in SIRM
and GitHub database are in random size depending on the
X-ray machine resolution and the articles from which it was
taken. Therefore, authors have carried out a tedious task of
collecting and indexing the X-ray and CT images from all the
recently publicly available articles and online sources. These
articles and the radiographic images were then compared with
the GitHub database to avoid duplication. Authors managed
to collect 60 COVID-19 positive chest X-ray images from
43 recently published articles [60], which were not listed
in the GitHub database and 32 positive chest x-ray images
from Radiopaedia [63], which were not listed in the GitHub
database.
• COVID-19 Chest imaging at thread reader:
A physician has shared 103 images for 50 different cases
with varying resolution from his hospital in Spain to the
Chest imaging at thread reader [64]. Images from RSNAPneumonia-Detection-Challenge database along with the
Chest X-ray Images database from Kaggle were used
to create the normal and viral pneumonia sub-databases
of 1579 and 1485 X-ray images respectively.
• RSNA-Pneumonia-Detection-Challenge
In 2018, Radiology Society of North America (RSNA)
organized an artificial intelligence (AI) challenge to detect
pneumonia from the chest X-ray images. In this database,
normal chest X-ray with no lung infection and non-COVID
pneumonia images were available [65].
• Chest X-Ray Images (pneumonia):
Kaggle chest X-ray database is a very popular database,
which has 5247 chest X-ray images of normal, viral and
bacterial pneumonia with resolution varying from 400p to
2000p [66]. Out of 5247 chest X-ray images, 3906 images are
from different subjects affected by pneumonia (2561 images
for bacterial pneumonia and 1345 images for viral pneumonia) and 1341 images are from normal subjects. Chest X-ray
images for normal and viral pneumonia were used from this
FIGURE 1. Sample X-ray image from the dataset: COVID-19 X-ray image
(A), normal X-ray image (B), and viral pneumonia X-ray image (C).
database to create the new database. Figure 1 shows sample
images from the database for normal, COVID-19 pneumonia,
and viral pneumonia chest X-ray images.
B. CNN MODEL SELECTION
Eight different pre-trained CNN models were trained, validated and tested in this study. The experimental evaluation of
MobileNetv2, SqueezeNet [67], ResNet18 [68], ResNet101
and DenseNet201 were performed utilizing MATLAB 2020a
running on a computer with Intel
i7-core @3.6GHz processor and 16GB RAM, with an 8-GB NVIDIA GeForce
GTX 1080 graphics processing unit (GPU) card on 64-bit
Windows 10 operating system. On the other hand, CheXNet,
Inceptionv3 and VGG19 were implemented using PyTorch
library with Python on Intel
R Xeon
R CPU E5-2697 v4 @
2,30GHz and 64 GB RAM, with a 16 GB NVIDIA GeForce
GTX 1080 GPU. Three comparatively shallow networks
(MobileNetv2, SqueezeNet and ResNet18) and five deep
networks (Inceptionv3, ResNet101, CheXNet, VGG19 and
DenseNet201) were evaluated in this study to investigate
whether shallow or deep networks are suitable for this
application. Two different variants of ResNet were used
to compare specifically the impact of shallow and deep
networks with similar structure. Performance difference due
to initially trained on different image classes other than
X-ray images were compared with CheXNet, which is a
121-layer DenseNet variant and the only network pre-trained
on X-ray images. Several researchers showed the reliability of
using this network for COVID-19 classification. Therefore, it
was important to investigate whether CheXNet outperforms
other deep networks or not. Eight pre-trained CNN models
were trained using stochastic Gradient Descent (SGD)
with momentum optimizer with learning rate, α = 10−3
,
momentum update, β = 0.9 and mini-batch size of 16 images
with 20 Back Propagation epochs. Fivefold cross-validation
result was averaged to produce the final receiver operating
characteristic (ROC) curve, confusion matrix, and evaluation
matrices.
Two different experiments were carried out in this study:
i) Two-class image classification using models trained
without and with images augmentation, and ii) Three-class
image classification using models trained without and
with image augmentation. Figure 2 illustrates the overall
system diagram with the three-class image classification
problem.
132668 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 2. Block diagram of the overall system.
TABLE 1. Number of images per class and per fold before and after data augmentation.
C. PREPROCESSING
Chest X-ray images were only resized before applying as
input to the networks. Input requirements for different CNNs
are different. For SqueezeNet, the images were resized
to 227 × 227 pixels whereas for mobilenetv2, ResNet18,
ResNet101, VGG19 and DenseNet201, the images were
resized to 224 × 224 pixels; and for Inceptionv3 the images
were resized to 299×299 pixels. All images were normalized
according to the pre-trained model standards.
In the study1, image augmentation technique was not
applied to the training data. Since COVID-19 positive chest
X-ray images were 423, same number of X-ray images
were randomly selected from normal (out of 1579) and viral
pneumonia (out of 1485) images to match with COVID-19
images to balance the database. In study2, entire database
(i.e., 423 COVID-19, 1579 normal and 1485 viral pneumonia
images) was used. Both the experiments were evaluated using
a stratified 5-fold cross-validation (CV) scheme with a ratio
of 80% for training and 20% for the test (unseen folds) splits,
where 10% of training data is used as a validation set to avoid
overfitting. However, in study2, COVID-19 images are much
smaller in number than that in the other two image classes.
Moreover, overall image number in any class was not several
thousand. Therefore, Image augmentation techniques were
applied to viral pneumonia, normal and COVID-19 X-ray
images for training to create a balanced training set. However,
COVID-19 images were augmented six times while normal
and viral pneumonia images were augmented once only.
FIGURE 3. Original chest X-ray image (A), Image after rotation by
15 degree clockwise (B), Image after rotation by 15 degree counter
clockwise (C), Image after 5% horizontal translation (D), after 5% vertical
translation (E), and after 5% horizontal and vertical translation (F).
D. IMAGE AUGMENTATION
In this study, two different image augmentation techniques (rotation, and translation) were utilized to generate COVID-19 training images, as shown in Figure 3.
The rotation operation used for image augmentation was done
by rotating the images in the clockwise and counter clockwise
direction with an angle of 5, 10 and 15 degrees. Image
translation was done by translating image horizontally and
vertically by −5% to 5%. However, only image translation
was applied to the viral and normal X-ray training images.
Table 1 summarizes the number of images per class used
for training, validation, and testing at each fold. Study1 was
carried out with COVID-19 and normal images while
study2 was carried out with COVID-19, normal and viral
pneumonia images.
E. INVESTIGATION OF THE DEEP LAYER FEATURES
The deep layers features of the image were investigated by
comparing the activated areas of the convolutional layers with
VOLUME 8, 2020 132669M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 4. Activation map for sample network models of (i) first
convolutional layer, (ii) strongest activation channel of first convolutional
layer, (iii) deep layer images set, and (iv) corresponding strongest
activation channel for the deep convolutional layer for a specific X-ray
image input.
the matching regions in the original images. The activation
map can take different range of values and was therefore
normalized between 0 and 1. The strongest activation
channels from the COVID-19, normal and viral pneumonia
X-ray images were identified and compared with the original
images. It was noticed that the strongest channel activates on
edges with positive activation on light left/dark right edges,
and negative activation on dark left/light right edges.
Convolutional neural networks learn to detect features
like color and edges in their first convolutional layer.
In deeper convolutional layers, the network learns to detect
features that are more complicated. Later layers build
up their features by combining features of earlier layers.
Figure 4 shows the activation map in early convolutional
layers, deep convolutional layer and their corresponding
strongest activation channel for each of the models. It might
be difficult to distinguish COVID-19 and viral pneumonia
from the original images as reported by different research
groups. However, the deep layer features explain better the
reason of a deep learning network’s failure or success in a
particular decision. It provides a visual explanation of the
prediction of CNN and it highlights the regions of the images
which are contributing more in classification. This technique
will be used in the result and discussion section to illustrate
how this activation mapping is a distinguishing feature
of COVID-19 X-ray images from the other two class of
images.
F. PERFORMANCE EVALUATION MATRIX
In order to evaluate the performance of different deep
learning algorithms for classifying the X-ray images in
case of two different classification schemes. The trained
algorithms were validated using 5-fold cross-validation.
The performance of different networks was evaluated using
five performances metrics such as- accuracy, sensitivity or
recall, specificity, precision (PPV), and F1 score. Per-class
values were computed over the overall confusion matrix that
accumulates all test fold results of the 5-fold cross-validation.
Accuracyclass_i =
TPclass_i+TNclass_i
TPclass_i+TNclass_i+FPclass_i+FNclass_i
(1)
Precisionclass_i =
TPclass_i
TPclass_i + FPclass_i
(2)
Sensitivityclassi =
TPclassi
TPclassi + FNclassi
(3)
F1_scoreclassi = 2
Precisionclassi × Sensitivityclassi
Precisionclassi + Sensitivityclassi
(4)
Specificityclass_i =
TNclass_i
TNclass_i + FPclass_i
(5)
where classi = COVID-19, and Normal for two class
problem; COVID-19, Normal and Viral Pneumonia for three
class problem.
III. RESULTS AND DISCUSSION
Two different schemes were studied in this study. Classification of COVID-19 and Normal images using eight
different pre-trained CNN models while training was done
with and without image augmentation. COVID-19, normal
and viral pneumonia images were classified using same eight
pre-trained models and training was carried out with and
without image augmentation.
A. EXPERIMENTAL RESULTS-TWO CLASS PROBLEM
The comparative performance for different CNNs for twoclass classification problem with and without augmentation
is shown in Table 2 and comparative AUC curves are
shown in Figure 5.It is apparent from Table 2 that all the
evaluated pre-trained models perform very well in classifying
COVID-19 and normal images in two-class problem. The
weighted average performance matrix for eight different
networks are very similar whereas small gain can be observed
when training was done using image augmentation. Among
the networks trained with 338 X-ray images for two-class
problem, ResNet18 and CheXNet are equally performing
for classifying images while CheXNet and DenseNet201 are
performing better than others in case of training with augmented images, although the difference is marginal. CheXNet
is producing the highest accuracy of 99.4% and 99.7% for
two-class classification without and with image augmentation
respectively. Interestingly, CheXNet is performing well in
both the cases, with and without augmentation and this can
be explained from the fact that CheXNet is the only network
which is pre-trained on a large.
X-ray image database and the network supposed to
perform better for X-ray image classification without the
requirement of training again on a larger dataset. However,
in this classification problem as the COVID-19 images are
significantly different from normal images all the tested
networks are performing well. This is apparent from the ROC
curves of Figure 5 as well. In both the cases (without and
with augmentation) for two-class problem, ROC curves are
showing comparable performance from all the networks.
132670 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 5. Comparison of the ROC curve for normal, and COVID-19 Pneumonia classification using CNN based models without (A) and with
(B) image augmentation.
TABLE 2. Weighted average performance metrics for different deep learning networks for two-class classification problem with and without image
augmentation.
B. EXPERIMENTAL RESULTS-THREE CLASS PROBLEM
Table 3 summarizes the performance matrix for different
pre-trained CNN algorithms tested for the two different
classification schemes without and with image augmentation.
It can be noticed that all the pre-trained networks (shallow
or deep) are showing very similar performance apart from
CheXNet in case of training without image augmentation.
If the pre-trained networks are trained on a small image
dataset as reported by the most of the research groups in
the literature, the performance difference is very marginal
and overall performance is reduced for three-class problem
in comparison to two-class problem. This is expected as
networks are now confused between COVID-19 and viral
pneumonia. However, CheXNet is still performing well while
trained on a small dataset as CheXNet was originally trained
one a very large X-ray image dataset. On the other hand,
while the image augmentation was applied to the training
image set, all the pre-trained networks are now performing
based on their capability to distinguish the three-class
images. Typically, the deeper the network the better is the
performance in distinguishing the image classes.
However, it is important to note that Resnet18 and
ResNet101 do not support this statement rather ResNet18
being a much shallow network than ResNet101, ResNet18 is
still outperforming ResNet101.
Interestingly, CheXNet which is a 121-layer variant of
DenseNet trained on X-ray images, is not outperforming a
deeper variant of DenseNet with 201-layers. Therefore, it can
be summarized that even though CheXNet was trained originally on X-ray images but training an even deeper network
with a larger image set can give better chance of training from
the new image sets on which the training is done, i.e., deep
network can learn better and perform better if the training
is carried out on a larger dataset. DenseNet201 outperforms
VOLUME 8, 2020 132671M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
TABLE 3. Weighted average performance metrics for different deep learning networks for three-class classification problem with and without image
augmentation.
other models in three-class classification scheme in terms of
different performance indices when the image augmentation
was employed and the performance matrix was significantly
improved with image augmentation. It is obvious from
Figure 6 that DenseNet201with image augmentation can
significantly increase overall network performance.
Figure 7 shows the confusion matrix for DenseNet201 for
two-class and three-class problems with image augmentation.
It is clear from Figure 7(A) that only three COVID-19 images
out of 423 images were miss-classified to normal (false
negative) and only three images out of 1579 images were
miss-classified to COVID-19 (false positive). This reflects
that this deep learning technique is extremely robust in
distinguishing COVID-19 images from normal X-ray images.
In the three-class problem, only one COVID-19 image
was miss-classified to normal, which is one of the three
images miss-classified by the two-class classifier. Two other
COVID-19 images were miss-classified as viral pneumonia
images. None of normal images were miss-classified to
COVID-19 by the three-class classifier although several
normal images were miss-classified to viral pneumonia.
COVID-19 image miss-classified to normal has bad consequences than miss-classified to other disease category (i.e.,
viral pneumonia). Similarly, normal images miss-classified
to viral pneumonia has less severe consequence than to be
miss-classified to COVID-19 pneumonia. Only four viral
pneumonia images were miss-classified to COVID-19 out
of 1485 images while 33 images miss-classified to normal.
It can be noted that network is not confusing between
COVID-19, and other two image classes rather network is
more confused between viral pneumonia and normal images.
However, the high precision and F1 score show that the
network is still performing excellent in classifying most of the
images reliably. This is very important, as the computer-aided
system (CAD) should not classify any COVID-19 patients to
normal or vice versa; however, it is important to see the reason
of the classifier being failed for three COVID-19 patients’
X-ray images and miss-classified them to normal.
The difference between normal and COVID-19 X-ray
images can be observed in the deep convolutional layer of
pre-trained CNN model. It is notable from Figure 8 that the
14th layer of the DenseNet201 can detect features that can
distinguish normal, COVID-19 and Viral Pneumonia images.
This shows the reason of the success of the network in
detecting COVID-19 X-ray images and distinguishing it from
normal and viral pneumonia images, which several groups
of researchers reported earlier are not reliably possible by
plain X-ray images [69]–[72]. It is really difficult for the
practicing radiologist to find abnormality in the early stage of
COVID-19. However, with the help of artificial intelligence,
the X-ray images can be used to identify the deep layer
features which are not visible to the human eyes [73]. The
deep layers enhance the distinctive features of COVID-19,
viral pneumonia and normal patients’ X-ray images, thereby
enhancing the chance of identifying the abnormality in the
lungs of the patients.
Figure 9 shows the three images of COVID-19
miss-classified to normal. Image 01-03 are miss-classified
by two-class classifier and Image-03 is miss-classified by
three-class classifier. The main reason behind the missing
of these COVID-19 images is a less opacity in the left
and right upper lobe and suprahilar on posterior-to-anterior
132672 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 6. Comparison of the ROC curve for normal, COVID-19 and viral pneumonia classification using CNN based models without (A) and
with (B) image augmentation.
FIGURE 7. Confusion matrix for classification of (A) Normal and COVID-19, and (B) Normal, COVID-19 and viral pneumonia using DenseNet201.
FIGURE 8. Images of 23rd channel of first convolutional layer (i), 14th
convolutional layer (ii) and 29th convolutional layer images (iii) from
DenseNet201 for different subject groups: Normal, COVID-19, and viral
pneumonia. Red arrows in COVID-19 image shows the regions of light
focus edge, a distinctive feature in COVID-19 patients’ X-ray images which
are not present in viral pneumonia and normal patients.
x-ray images, which is very similar to normal X-ray images
(see Figure 8). The algorithm fails if no evident light focus
edge feature is appeared in the deep layer and this type of
FIGURE 9. Three COVID-19 X-ray images which are miss-classified to
normal images by two- and three-class classifier. Note: Image 01-03 are
miss-classified by two-class classifier and Image-03 is miss-classified by
three-class classifier.
COVID-19 cases have to be confirmed by other techniques.
These three images were evaluated by three practicing
radiologists to identify what is their evaluations for these
three images. First and third images were identified as no
sign or very little sign of COVID-19 by the radiologists while
image-02 was identified as very mild stage of lung infections.
It can be summarized that the proposed technique can classify
most of the COVID-19 X-ray images very reliably.
VOLUME 8, 2020 132673M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
IV. CONCLUSION
This work presents deep CNN based transfer learning
approach for automatic detection of COVID-19 pneumonia.
Eight different popular and previously reported efficient CNN
based deep learning algorithms were trained, validated and
tested for classifying normal and pneumonia patients using
chest X-ray images. It was observed that DenseNet201 outperforms other different deep CNN networks while image
augmentation was used for training the CNN models.
CheXNet which is a variant of DenseNet was outperforming
other networks while image augmentation was not used.
This is obvious as the CheXNet was pre-trained on a large
X-ray database and it is showing better performance on this
study while trained on a small non-augmented image dataset.
However, a deeper version of DenseNet, when trained on a
large augmented dataset, Dense201 outperforms CheXNet.
This clearly reveals the fact that the performance reported
on smaller database in the literature should be evaluated on a
large dataset otherwise, the findings of these studies cannot be
generalized for real applications. In this work, authors have
reported the findings from a large database along with the
image augmentation to train shallow and deep networks and
it was observed that deep networks perform better than the
shallow networks particularly in classifying normal and viral
images as most of the networks can identify COVID-19 with
very high sensitivity. The classification accuracy, precision,
sensitivity, and specificity of normal and COVID-19 images,
and normal, COVID-19 and viral pneumonia were (99.7%,
99.7%, 99.7% and 99.55%), and (97.9%, 97.95%, 97.9%,
and 98.8%) respectively. COVID-19 has already become
a threat to the world’s healthcare system and economy
and thousands of people have already died. Deaths were
initiated by respiratory failure, which leads to the failure
of other organs. Since a large number of patients attending
out-door or emergency, doctor’s time is limited and computeraided-diagnosis can save lives by early screening and propercare. Moreover, there is a large degree of variability in the
input images from the X-ray machines due to the variations of
expertise of the radiologist. Artificial intelligence exhibits an
excellent performance in classifying COVID-19 pneumonia
provided that the network is effectively trained from a large
dataset. We believe that this computer aided diagnostic tool
can significantly improve the speed and accuracy in the
screening of COVID-19 positive cases. The method would be
highly useful in this pandemic where disease burden and need
for preventive measures are at odds with available resources.
AUTHORS CONTRIBUTION
Muhammad E. H. Chowdhury: Conceptualization, Writing -
Review & Editing, Supervision, and Project administration.
Tawsifur Rahman: Data Curation, Methodology, Software,
Validation, Formal analysis, Writing - Review & Editing.
Amith Khandakar: Data Curation, Investigation, Resources,
Writing - Original Draft, Writing - Review & Editing. Rashid
Mazhar: Writing - Original Draft, Writing - Review & Editing. Muhammad Abdul Kadir: Methodology, Visualization,
Editing. Zaid Bin Mahbub: Methodology, Visualization.
Khandakar R. Islam: Data Curation, Writing - Original Draft.
Muhammad Salman Khan: Visualization, Writing - Original
Draft. Atif Iqbal: Writing - Review & Editing, Nasser
Al-Emadi: Writing - Review & Editing, Supervision, Mamun
Bin Ibne Reaz: Writing - Review & Editing, Supervision,
Conceptualization. M. T. Islam: Writing - Review & Editing,
Supervision.
ACKNOWLEDGMENTS
This work was made possible by NPRP12S-0227-190164
from the Qatar National Research Fund, a member of Qatar
Foundation, Doha, Qatar. The statements made herein are
solely the responsibility of the authors. The publication of this
article was funded by the Qatar National Library. The authors
would like to thank Italian Society of Medical Radiology and
Interventional for sharing the X-ray images of COVID-19
patients publicly and would like to thank J. P. Cohen for
taking the initiative to gather images from articles and online
resources. Last but not the least, authors would like to
acknowledge the Chest X-Ray Images (pneumonia) database
and RSNA Pneumonia Detection Challenge in Kaggle which
helped significantly to make this work possible. Otherwise,
normal and viral pneumonia images were not accessible to
the team.
CONFLICTS OF INTEREST
The authors declare no conflict of interest.



NEW_PAPER


Received April 27, 2021, accepted May 22, 2021, date of publication June 3, 2021, date of current version June 18, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3085682
COVID-Scraper: An Open-Source Toolset for
Automatically Scraping and Processing Global
Multi-Scale Spatiotemporal COVID-19 Records
HAI LAN 1
, DEXUAN SHA 1,2, ANUSHA SRIRENGANATHAN MALARVIZHI1,2, YI LIU 3
,
YUN LI1,2, NADINE MEISTER4
, QIAN LIU 1,2, ZIFU WANG1,2, JINGCHAO YANG1,2
,
AND CHAOWEI PHIL YANG 1,2, (Member, IEEE)
1NSF Spatiotemporal Innovation Center, George Mason University, Fairfax, VA 22030, USA
2Department of Geography and Geoinformation Science, George Mason University, Fairfax, VA 22030, USA
3Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN 46556, USA
4Department of Physics, Harvard University, Cambridge, MA 02138, USA
Corresponding author: Chaowei Phil Yang (cyang3@gmu.edu)
This work was supported by the National Science Foundation under Award 2027521 and Award 1841520.
ABSTRACT In 2019, COVID-19 quickly spread across the world, infecting billions of people and disrupting
the normal lives of citizens in every country. Governments, organizations, and research institutions all over
the world are dedicating vast resources to research effective strategies to fight this rapidly propagating
virus. With virus testing, most countries publish the number of confirmed cases, dead cases, recovered
cases, and locations routinely through various channels and forms. This important data source has enabled
researchers worldwide to perform different COVID-19 scientific studies, such as modeling this virus’s
spreading patterns, developing prevention strategies, and studying the impact of COVID-19 on other aspects
of society. However, one major challenge is that there is no standardized, updated, and high-quality data
product that covers COVID-19 cases data internationally. This is because different countries may publish
their data in unique channels, formats, and time intervals, which hinders researchers from fetching necessary
COVID-19 datasets effectively, especially for fine-scale studies. Although existing solutions such as John’s
Hopkins COVID-19 Dashboard and 1point3acres COVID-19 tracker are widely used, it is difficult for users
to access their original dataset and customize those data to meet specific requirements in categories, data
structure, and data source selection. To address this challenge, we developed a toolset using cloud-based web
scraping to extract, refine, unify, and store COVID-19 cases data at multiple scales for all available countries
around the world automatically. The toolset then publishes the data for public access in an effective manner,
which could offer users a real time COVID-19 dynamic dataset with a global view. Two case studies are
presented about how to utilize the datasets. This toolset can also be easily extended to fulfill other purposes
with its open-source nature.
INDEX TERMS Web scraper, COVID-19, spatiotemporal data, multiple scale.
I. INTRODUCTION
The worldwide COVID-19 pandemic has infected billions
of people in the past year [1]. This global crisis triggered
lockdowns in most countries around the world for months in
hopes to slow the spread of this novel virus and save lives [2].
Inevitably, the normal lives of citizens have been heavily disturbed and impacted. Scientists all over the world are studying
this pandemic to analyze the spreading dynamics, design
The associate editor coordinating the review of this manuscript and
approving it for publication was Ahmed Farouk .
effective control policies, predict the next possible outbreak
centers, develop vaccines, and optimize vaccination strategies. COVID-19 virus samples, statistics of positive cases,
existing policies, and environmental factors have become
important data for COVID-19 related research [3]. Another
example is spatiotemporal COVID-19 records, which most
countries have gradually published through virus testing
since early 2020. Collecting, organizing, and distributing
spatiotemporal COVID-19 records provide avenues and data
sources to support COVID-19 studies in different fields
such as public health, economics, and environmental science.
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 84783H. Lan et al.: COVID-Scraper: Open-Source Toolset
Governments and organizations of each country recognize the
need for public records. For example, most of the COVID-19
cases data comes from international agencies (i.e. the World
Health Organization (WHO) and the Global Health Council
(GHC)), or individual national organizations (i.e. the Centers
for Disease Control and Prevention (CDC) and the National
Health Commission of the People’s Republic of China).
These organizations have subcommittees that collect and
produce datasets published to the public [4]. However, for
researchers, one difficulty in obtaining these datasets is that
information is published in various sources, formats, types,
scales, channels, and time intervals by different countries.
This makes it time-consuming to acquire the latest fused
structured data for each country routinely, thus hindering the
response progress to fight COVID-19. To address this problem, we developed the COVID-Scraper, a toolset for automatically aggregating the multiple sources of spatiotemporal
COVID-19 dataset from different scales into one spatiotemporal framework with tailored data structures that benefit
related studies.
For some actors, like large institutions, this task has
been undertaken since the COVID-19 outbreak. John’s Hopkins is a prime example that provides a daily updated
COVID-19 Dashboard by pulling data from eight different
non-governmental sources, including the WHO, the CDC,
the European Centre for Disease Prevention and Control
(ECDC), and numerous countries’ data repositories and
organizes the data into one dataset for public sharing [5].
However, the process of data collecting, organizing, and
structuring for their ‘‘COVID-19 Dashboard by the Center
for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU)’’ is not transparent, which leads to
another challenge that some users cannot use it as a tool
to acquire datasets from preferred data sources with customized data structures and setup user-defined acquisition
frequency. Another widely known system is the 1Point3Acres
COVID-19 dashboard, which has gained over 2.8 billion
visits [6]. Similar to the COVID-19 Dashboard by JHU, users
cannot customize the data sources for countries. Another
issue is for a display dashboard, the raw data is difficult
to access by the public (even it claims the data could be
distributed with permission). Hence, it is impossible for users
to define the granularity of data, filter the content of data
and select the categories of data for customized scholar
research. In other words, existing solutions are not flexible enough for users, especially those which have specific
requirements to obtain targeted datasets.
We developed the COVID-Scraper as an open-sourced
COVID-19 scraping toolset by adopting the technology of
web crawlers to collect, filter, organize, pre-process, and
store multi-scale spatiotemporal COVID-19 records for each
nation over the world to generate a comprehensive data product in a single run. It is highly flexible and allows users
to customize the data sources, data structures, filter criteria,
database setup, and visualization formats with only minor
adjustments. Once those parameters are set up, this toolset
can be easily deployed on any cloud platform to fetch required
COVID-19 spatiotemporal datasets automatically. In addition, the COVID-Scraper is easy to use and process data
effectively. For example, it can finish acquiring the available
COVID-19 datasets from all countries over the world within
about six minutes. Furthermore, the COVID-Scraper works
exceptionally well for countries that do not provide good,
well-structured data from their official reports about their
current situation of COVID-19 other than portable document
format (PDF), or pictures in their reports. It can also be used
as a powerful toolset for building historical spatiotemporal
COVID-19 data records for some countries that only provide
the latest COVID-19 data reports.
In this paper, the different types of spatiotemporal
COVID-19 data sources from different countries consumed
by the COVID-Scraper are discussed in section III. Then the
components, mechanism, and implementation of this toolset
are detailed in section IV and include: 1) a workflow of
how the COVID-Scraper functions, 2) how it is designed to
cater to different types of data sources, and 3) the processing
of automation configurations. Section V details two case
studies of how the scraper functioned and produced data for
countries especially those that did not have well-documented
information for easy access. Performance tests are conducted
to demonstrate the overall performance of a single complete scraping process and processing time for different data
types. We also introduce two cases that utilized the final
data product generated by the COVID-Scraper to monitor
the medical resource deficiency dynamics and the impact of
social distancing measures on COVID-19 cases and mortality.
The paper is concluded with discussions of the implications
of the scraper and the future directions of the COVID-Scraper.
The major contributions of this work are:
1) an open-sourced COVID-19 scraping toolset with
web crawlers to collect, filter, organize, pre-process, and
store multi-scale spatiotemporal COVID-19 records for each
nation over the world.
2) a list of data scraping scripts to accommodate
COVID-19 spatiotemporal data scraping tasks for various
types of source data published by various countries.
3) a workflow that could automatically drive this scraping toolset and generate a comprehensive data product in a
single run
4) an up-to-date multi-scale COVID-19 records data product is provided in GitHub repository and a cloud-based
database for the public.
5) an operational dashboard is maintained to visualize the
data product for quick query and access.
II. LITERATURE REVIEW
Web scraping is a data mining technology that is commonly
used for extracting unstructured data from different online
sources and restructuring and converting acquired data into
a structured form that can be further stored and analyzed in
a database [7]. The benefit of a well-designed web scraper
is that it automatically sifts through targeted data sources
84784 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
and form valuable information into a comprehensive dataset.
There are different forms of web scraping including copy and
pasting, text grabbing, HTML parsing, and others [7]. A benefit of web scraping is that it simulates human interaction
with a web page and can obtain attribute data from the web
page itself [8]–[10]. This is beneficial because it brings in
pertinent information that is relevant to the topic assigned
to look for and not scraping for erroneous information. For
example, Weng and his colleagues applied web scraper techniques to collect large-scale datasets of horticultural products information to predict the trend of price fluctuation
with Auto Regressive Integrated Moving Average (ARIMA)
and integrated recurrent neural network (RNN) model [11].
Pawar and colleagues implemented a web scraper to search
medicinal plants and relevant diseases in the India Ayurvedic
system [12].
Web scraping is widely used by epidemiological research
and public health studies. By scraping and analyzing
text-based data from the Internet, researchers can successfully detect diseases and food hazards, as well as predict
potential pandemics. For example, Pollett and colleagues
used a web scraper as a tool to scrape unstructured Internet newswire data to timely detect outbreaks and epidemics
from vector-borne diseases [13]. Walid and his team scraped
worldwide Twitter data for 2 years [14]. By applying sentiment analysis and natural language processing on Walid’s
data, they built a model to detect and predict cancer. In addition to diseases detection, web scraping has been adopted in
food hazards detection and dissemination. By scraping the
events related to food hazards from news and social media,
Ihm and colleagues built a system to prevent and control
food hazards in Korea [15]. In addition, Majumder et al.
utilized web scraped data collected by HealthMap coupled
with Google Trend time series data to calculate the R0 and
predict the outbreak level of Zika virus in 2015 [16]. Beyond
scraping text-based data from Internet resources, images have
been scraped as a valuable dataset to support public health
research. For example, Li et al. scraped illicit drug dealerrelated photos and posts from Instagram. With 3 different
deep learning models applied, they detected 1129 drug dealers successfully [17].
This same technique can be applied to COVID-19 related
data collection. Chen et al. adopted a web crawler to collect
emotion and experience data of online education platforms
for users to assess the satisfaction and quality of online education under the pandemic [18]. La et al. scanned and collected
official media news related to COVID-19 in Vietnam to evaluate the response from policymaking, social media, and science journalism regarding the outbreak [19]. Xu et al scraped
Weibo posts from Wuhan, China at the early stage of the
COVID-19 outbreak to analyze public reaction, knowledge,
and attitude [20]. Their findings potentially support future
policy making and possible future outbreak responses.
However, it is worthwhile to point out that an expressed
concern in the field of web scraping due to the fact that
scrapers can obtain personal information and publish it to an
open database [21]–[23]. This becomes even more sensitive
when medical records are retrieved by the scraper. In our
study, the COVID-19 web scraper is aimed at collecting fine
scale spatiotemporal COVID-19 records for countries that are
releasing numerical data globally and aggregating them into
a central database without directly working with the personal
medical records.
III. DATA TYPES AND AVAILABILITY FOR THE
COVID-SCRAPER
The COVID-Scraper was developed to automatically and
routinely collect spatiotemporal COVID-19 records released
by countries all over the world. However, there are varying
degrees to which these records are available from different countries (Figure 1). Some countries such as the U.S.
and China provide trustable, comprehensive, fully processed,
ready to use datasets through official portals. These datasets
are usually in Comma-Separated Values (CSV) tabular or
JavaScript Object Notation (JSON) structured format that
stored in a standalone file or cloud shared documents such as
Google Spreadsheet [24]. Some other countries like Turkey
and Chile also provide information on COVID-19, but it is
not well organized. For example, the data may be published
on a dynamic website inside a PDF file or embedded in an
image-based file. In these contexts, the datasets cannot be
read and parsed by text-based processing algorithms directly
and automatically. Hence, advanced technologies should be
developed and integrated to mine the expected dataset, extract
required information from those unstructured data sources,
and convert them into user-defined data structures for storage
and sharing. Currently, the COVID-Scraper scans and scrapes
all countries with available data sources daily (Figure 1).
It will skip those countries without any available data source.
Countries listed in Table 1 are the major focus of
the COVID-Scraper, which provides COVID-19 records in
unstructured and not well-organized formats (Table 1). Our
toolset checks the data sources to confirm availability before
every run and reports exceptions if the data source is no longer
valid or the data type/format has been changed.
From a computing perspective, data types of COVID-19
records published by different countries are in structured or
unstructured formats. CSV is one of the most commonly used
formats for structured data. However, other formats are also
adopted by official sources for releasing tabular cases data.
For example, cases data from Brazil [32] are in the Microsoft
Excel format (.xlsx), which will be required to be converted
into CSV before further processing. JSON is another format
for structured data, typically provided as standalone JSON
files or via API by the data sources. In addition to structured data formats, unstructured data formats include original
HTML, PDF, or images (jpg, png, bmp, etc.).
The COVID-Scraper is developed to accommodate various types of COVID-19 case datasets in structured or
unstructured formats. In our study, open-sourced packages
and browser rendering tools [83] have been applied to
support scraping, parsing, and analyzing data in different
VOLUME 9, 2021 84785H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 1. Global scale data availability and the COVID-Scraper coverage.
FIGURE 2. Overall workflow.
formats. Once required spatiotemporal COVID-19 records
are extracted from the data sources, the COVID-Scraper will
filter, organize, and store the data into a single database
under the same data framework. In section VI, the COVIDScraper’s automation methodologies, structures, and detailed
implementation will be discussed for each type of data from
different countries.
IV. METHOD
The overall workflow of the COVID-Scraper toolset contains
seven steps (Figure 2):
1. Detecting the official, trust-worthy websites for
COVID-19 spatiotemporal records data from each individual
country. Choose a preferred data source for each target
country.
2. Scanning all the targeted data sources and analyzing
what type of data should be collected and extracted.
3. Adjusting template crawler unit to accommodate specific needs of each unique data source. Testing it and verifying that only the expected data are collected from the target
data source.
4. Assembling all crawlers into a toolset and hosting
it on a platform for automation. In our operational version, GitHub actions have been adopted for this purpose.
By utilizing GitHub actions, a workflow was developed
and configured, including managing scraping tasks, handling
84786 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
TABLE 1. Major countries and DATA sources scraped by the COVID-Scraper.
VOLUME 9, 2021 84787H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 3. Methodology flow of COVID-Scraper.
exceptions, and processing frequency to automatically run the
COVID-Scraper on demand.
5. Fetching collected results from the configured temporary data store paths. Merging and matching those data based
on unique geographical IDs. Unifying data structure based on
user settings.
6. Verifying data quality and pushing them into a database
as a data product.
7. Visualizing generated data product and publishing it as a
web service for sharing, interactively viewing, and querying.
From the perspective of algorithm implementation, HTTP
requests will be sent at the initialization stage of the
COVID-Scraper to all selected data sources (Figure 3).
By parsing the acquired dataset in different formats via
open-source packages, the spatiotemporal COVID-19 records
from each country can be extracted. After all required datasets
are collected, parsed, matched, and merged automatically,
the whole dataset will be pushed into the database as a final
data product.
To successfully accommodate various types of data
sources, our toolset is designed to handle both structured
datasets and unstructured datasets with only minor parameters adjustments.
A. STRUCTURED DATA SCRAPING
It is straightforward to handle most structured datasets
because they are usually stored in wide or long formats.
Long format tables contain columns corresponding to date,
location, and numbers of confirmed/death/recovered cases.
Since the long format is consistent with that of the daily report
used in our database, the data are expeditiously processed
by identifying the columns and matching the location names
with ISO3, Hierarchical Administrative Subdivision Code
(HASC), or local geographical IDs. Conversely, wide-format
tables usually include multiple columns corresponding to
different locations or dates, which must be converted to a long
format before processing.
CSV, Microsoft Excel, and JSON are three major structured data types from COVID-19 cases data sources. If the
records are provided in CSV format, they can be directly
downloaded and sent for further processing. However, if these
datasets are in Microsoft Excel or JSON, they have to be
converted into CSV first before entering the next processing
stage. Microsoft Excel format can be easily converted to
CSV using the pandas package in Python. The JSON dataset,
which is typically provided as standalone JSON files or via
API by the sources, will require identifying the keys corresponding to date, locations, and case numbers from the JSON
objects to convert them into tabular data format.
Occasionally, although the data is in a structured format,
the link to the data file cannot be directly obtained. For example, one needs to click a button to download the data file from
Brazil’s dashboard, where the link is not hardcoded in the
source code but dynamically generated. For such cases, techniques to handle dynamic web pages will be adopted to obtain
the download URL and acquire the expected dataset. The
detailed implementation for handling dynamic web pages
will be elaborated in the following section.
B. UNSTRUCTURED DATA SCRAPING
Although structured data formats such as CSV and JSON
are preferred, such data sources are not always available.
Sometimes data must be scraped from web pages in addition
to provided data links or APIs. Web pages can be developed
in static and dynamic mode depends on the frameworks of
websites, technology selection, and security concerns. In our
toolset, both static and dynamic web pages can be scraped
automatically.
1) STATIC WEB PAGES SCRAPING
Static web pages are web pages with fixed content. When
HTML data is loaded on the client’s web browser, it directly
displays the same contents that are stored on the web server
side. For static pages, an HTTP request is performed to
retrieve HTML data from the web page. However, how to get
required data out from web pages content effectively should
be carefully considered. A challenge here is it will be very
time consuming to design a parser and acquire valuable data
when it encounters multiple layer nested web data structure
in some web pages. Hence, it is recommended to apply an
optimized approach to design parsers. Subsequently, various
tools can be used to harvest the data from HTML content.
For example, in our toolset, python packages ‘‘requests’’ and
‘‘BeautifulSoup’’ are used. The get() method in the requests
84788 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
package is used to send a GET request to the selected data
source. After that, ‘‘BeautifulSoup’’ [84] is adopted to parse
HTML, filter relevant HTML elements, and extract information from those elements. BeautifulSoup provides an object
that represents web documents as a nested data structure.
By searching and filtering required tags from this object,
users can parse required information in straightforward ways,
which saves significant amounts of time. Hence, the desired
tag in the HTML page could be extracted using the select
method in the BeautifulSoup package. Afterwards, the relevant information is stored as CSV files with proper settings.
2) DYNAMIC WEB PAGES SCRAPING
Unlike static web pages with fixed data structure and web
contents, some data on web pages are dynamically loaded
with JavaScript and therefore they are not accessible in the
requested HTML of the target web page. This results in
a problem that by simply sending an HTTP request, web
content cannot be fetched as expected. One way to scrape
data from dynamic pages is to apply reverse engineering
(i.e., identifying and manually analyzing JavaScript codes
responsible for retrieving data). If relevant APIs can be identified, data could then be directly fetched through the APIs.
For instance, ArcGIS is a commonly used technology to
create many online COVID-19 dashboards. COVID-19 data
published by those channels are normally hosted through
ArcGIS’s feature server and can be queried through APIs.
Those APIs share the same format, and once relevant information such as catalog instance ID and service name are
pinpointed by inspecting the web page’s network activity,
the corresponding ArcGIS query APIs can be obtained.
In general, reverse engineering based on monitoring network
activity can be used to find various other APIs.
However, this technique does not work smoothly sometimes especially when the relevant webpage code is minified
and/or generated using a higher-level framework such as
React.js, which makes the codes less readable. In those cases,
HTML and Javascript codes need to be manually inspected
to reverse engineer relevant information. To conquer this
problem, headless browser rendering tools are adopted in
our toolset to generate static HTML content for dynamic
web pages. In the COVID-Scraper, Selenium web drivers are
exploited to obtain rendered HTML content from dynamic
pages. Selenium is a python package which is used to launch
web driver from a remote machine. The driver.get method
from selenium package is utilized to navigate to the selected
data source. The drivers (such as ChromeDriver, FirefoxDriver) send direct commands to the corresponding web
browser and retrieve the response. Occasionally, user input
such as clicking on buttons and selecting relevant options
from dropdown menus is necessary to obtain correct information, which is nicely supported by Selenium. To better
integrate with the GitHub Actions workflows as mentioned
before, remote web drivers are utilized by creating Selenium servers through Docker containers. Docker containers
connecting to web services are natively supported by GitHub
Actions, making the workflows much smoother. The generated HTML content can then be scraped as static web pages
by using the methods described in section IV part B(1). The
desired HTML tag in the page source is located by using the
find element by id and find element by css selector methods
in the selenium package.
3) PDF DATA PROCESSING
In addition, it is common that some official COVID-19 daily
reports are distributed as PDF documents by governments,
which typically contains tables of case records. A challenge
is to parse data directly from online PDF documents. After
getting the required PDF documents back to a local server,
extracting text-based information from the PDF file is also
necessary.
In order to retrieve data from the PDF documents, two steps
are applied in the COVID-Scraper.
1. The COVID-Scraper first gets links of the daily situation
reports. Usually, there is an official web page containing
links to all the reports. In such a case, the technique
used for scraping from static web pages can be used to
acquire the links. On occasion, documents of different
dates share the same file name except for the date string.
Thus, we can easily substitute the target date into the file
name to obtain the link for the corresponding date.
2. After retrieving the links for PDF documents, several
tools could be utilized to scrape data from the documents. Here we use tabula-py, a Python wrapper for
tabula-java, which is a PDF table extraction engine.
Normally, the relevant table contents are located at the
same locations inside the PDF documents for different
dates. Thus, coordinates of the areas containing those
tables can be specified in tabula-py to obtain better
results. The extracted data are then converted into CSV
files for further processing. However, extra care needs
to be taken to check the format and verify the data
since sometimes the extraction output format may not
be consistent.
4) IMAGE DATA PROCESSING
Another common format for distributing covid case records
is as a picture, usually for easy understanding and easy share
through social media. However, this will be a challenge for
automatic web scrapers to get data directly. For this kind
of data, we also use the python BeautifulSoup package to
scrape those pictures with the specific ID or group name to
fit users’ needs from static or dynamic websites. First, a GET
request will be sent to the data source using get() method
in the requests package. Then, the response of the request
will be parsed by BeautifulSoup. Lastly, select method is
applied to extract all image URLs from the data source to
setup download tasks. After collecting pictures every day,
our volunteers will manually record all the picture data to
a CSV file.
Regardless of the format, typically data can be accessed via
directly HTTP request or by reverse engineering. However,
VOLUME 9, 2021 84789H. Lan et al.: COVID-Scraper: Open-Source Toolset
occasionally the data may be distributed in a platform that
requires authenticated requests. For instance, the Philippines’
daily data are released on Google Drive. To access the data,
client credentials need to be created for connecting to the
Google Drive API before access to those specific resources.
In addition, source websites may have additional protection built to avoid DDOS attacks, which can also break
the scrapers. For instance, the Croatia official COVID-19
website [37] utilizes the Cloudflare DDOS protection, and
therefore requesting the source JSON file directly or via
Selenium from a script will be denied. We use FlareSolverr
to bypass the protection, which starts a proxy server and
opens the requested URL via Chrome browser, and sends the
requested file back after the Cloudflare challenge is solved.
C. DATA COLLECTION AUTOMATION
Once all crawler units are tuned properly, they can be
assembled and processed automatically. Automation of the
COVID-Scraper can be implemented in many different
ways such as a simple script hosted on a server, automation toolkits, or workflows supported by cloud platforms.
In our operational version, GitHub actions are applied to
set up automated scraping processes in the COVID-Scraper.
By hosting our toolset on GitHub actions and using the
workflow files (.yml,.yaml) with a customized virtual environment, the COVID-Scraper can be built, deployed, and
performed under manual control or operation by scheduled
time and period (Figure 4).
FIGURE 4. YML workflow to collect data automatically and routinely.
The event-driven GitHub Action uses YAML file to define
the parameters including 1) the event that triggers the workflow (parameter on is set to push event), 2) when to run
the workflow (parameter schedule, which is set to run daily
at 5:00 pm UTC in current operation), 3) the list of all the
jobs that run in the workflow (parameter job, which is used
to group together runs-on and steps parameters), 4) specify
the configuration environment (parameters runs-on is set to
Ubuntu Linux Runner in our case), 5) a group of all steps
that needs to be run in the workflow (parameters steps is
set to run the python environment in the runner and run
the list of country-wise crawler scripts), and 6) the jobs to
execute the command on the runner (parameter run is set to
GitHub configuration settings to push the latest data). The
steps parameter can be expanded to nest additional crawler
scripts which in turn increases the total crawling time.
However, to ensure high quality dataset can be collected
and saved locally before pushing them into a database, preconfiguration and post-processing will be performed to solve
three possible issues:
• inconsistent location names in data sources
• inconsistent spatial scale
• temporal data gap
Those issues are nearly inevitable in practical operations.
The mismatches of inconsistent names of administrative divisions, regions, or locations need to be fixed before collecting
data. For instance, the Bogra District in Bangladesh officially
changed its English spelling to Bogura District in 2018, but
data scraped from Bangladesh’s COVID-19 dashboard [85]
contains both spellings. Ignoring this issue may result in
missing data or inaccurate cases count for some regions in
those countries.
The inconsistent spatial scale and temporal data gap problem can be handled by post-processing. The truth is daily
cases data for some countries may be reported for administrative divisions, health boards, or other statistical regions.
In other words, after obtaining those datasets, the region
names in those data are needed to match with HASC or
local geographical IDs at consistent scales. For example,
sometimes the data is reported at admin 2 (county/city) level
while the required data scale is admin 1 (province/state)
level [3], [86]. In such cases, a mapping table will be created to convert the admin 2 level dataset to admin 1 level.
In the meantime, the cases records based on the admin 2
level will be aggregated and matched based on admin 1
regions. In addition, data may be missing for certain dates
in some cases. For example, Denmark does not report daily
cases on weekends. To make sure that the output reports
are in consistent format, missing data are filled using data
of the closest previous date when data are available. After
the global dataset has been cleaned and formatted following
each scraping, the cases dataset is exported as a CSV file.
For each region, the corresponding record includes region
name, country name, ISO3, HASC or local ID, and numbers
of confirmed cases, deaths cases, and recovered cases when
available. However, a data quality verification and validation
will be done before pushing them into the database for effective inquires.
D. DATA QUALITY CONTROL
Because the various data formats from the datasets collected
globally, dealing with the instability of raw data quality is a
84790 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 5. An operational dashboard of global COVID-19 records.
challenge for automatically processed crawlers. For example,
the structure of content from many sources is updated frequently which usually results in unexpected scraping errors.
Therefore, detecting errors and anomalies is essential for this
toolset. In addition, to quickly respond to errors during the
toolset running, it is important to validate the collected data
after the scraping process to make sure all datasets are correct
and accurate. Three dimensions of data quality were evaluated in the automatic detection script, including data integrity;
consistency; and validity. The completion check of continuous time-series data availability is required by data integrity.
For consistency, the scraped data should be consistent with
the sources. And several numeric rules were made for data
validity evaluation. For example, 1) the accumulated viral
case value should be unabated by time change; 2) the summarized cases value of a certain region should change among
continuous time step; 3) a surge increase of new cases will be
identified as abnormal growth; and 4) the accumulated case
value of confirmed cases should be much larger than cases
of death/recovered. To implement data quality evaluation in
this toolset, validation scripts were developed as a component of the COVID-Scraper to compare each record from
scraped data sources with corresponding data in validation
data sources automatically. This process will be started after
the crawling process. A data quality report will be produced
to help verify if there is any inconstancies or mistakes in
the collected dataset. For instance, the data of Nigeria is
scraped from a public dataset [62] that provides admin1 level
records. In the meantime, another dataset provided by Nigeria
Centre for Disease Control is applied as a validation data
source to ensure the accuracy of scraped dataset. By daily
comparison of each pair of records in both datasets with the
COVID-Scraper validation process, all mismatching and data
gaps can be found before data finalization. The crawler for
this specific country may need to be adjusted or the scraped
data source may be replaced if any problems were detected
during validation.
The current validation approach can accurately support
data that has been formatted as CSV tabular format. However,
for datasets extracted from PDF types, even if text recognition tool is applied, the recognition accuracy cannot be fully
guaranteed. In those cases, a group of volunteers is helping
manually check all the image type data daily, to make sure
the data that has been published is in a high-quality standard.
E. FINAL DATA PRODUCT GENERATED BY DATA SCRAPER
TOOLSET
Once all scraped datasets pass the daily data quality check
process, they will be converted into a standard table format
joint with a basemap which serves as the spatial supplement
attribute. The datasets are organized by region areas scaling
from country level globally to admin 1 level of each country.
Underneath each region area, daily reports, and time-series
summary tables of confirmed, death, and recovered cases
are produced and presented. After that, the COVID-19 data
collection is pushed and shared via the GitHub repository [87]
as the final data product with daily updates. In addition,
the obtained data is also being loaded into a pre-designed
relational database for backup and public representation purposes. An operational dashboard [88] has been developed
and published online to represent and share the real-time
global scale COVID-19 records in a visual manner with five
minutes updating intervals by using the dataset from the
database (Figure 5).
VOLUME 9, 2021 84791H. Lan et al.: COVID-Scraper: Open-Source Toolset
V. EXPERIMENTS AND DISCUSSION
To verify if the COVID-Scraper can work as designed to
scrape COVID-19 dataset from different countries with various data formats, two study cases are selected in this section
to represent the capability of our toolset to collect both structured data and unstructured dataset from static and dynamic
web-based sources. Furthermore, performance is tested to
check if the COVID-Scraper can be applied to scrape global
datasets in a reasonable time thus support near real-time
updating of the data product. After that, two study cases using
the data product are introduced.
A. COLLECTING FROM CHILE OFFCIAL COVID-19 WEBSITE
The COVID-19 dashboard of Chile [36] is an example of a
static website (Figure 6). This website updates daily with the
newest information about COVID-19 in Chile, all of which is
shown as a table on the webpage.
FIGURE 6. An operational dashboard of global COVID-19 records.
To accommodate static websites, the key task is to parse
the web elements and get required data from nested web
structures. Three steps were applied:
1. Utilize the BeautifulSoup package in python to find the
required data which are in the table or in <tr> or <td>
html elements.
2. Apply pandas package to extract the required information from each parsed web element.
3. Concatenate all the data to a single CSV file as a
result.
Once this file is created, it will be saved as a temporary
result file and passed to a folder which is named by the time
of the crawling process started. This experiment demonstrates
successful functionality of COVID-Scraper, namely locating and scraping the datasets published by static websites.
Scraped data has been stored in both database and the GitHub
repository after the scraping process finished.
B. COLLECTING FROM PAKISTAN COVID-19 DASHBOARD
Pakistan’s COVID-19 dashboard [65] is an example of
dynamic web page (Figure 7). In this website, daily cases data
from seven top-level regions in Pakistan are displayed in a
table located at bottom left of this dashboard page. However,
the table is generated dynamically using Google Data Studio,
hence the data cannot be scraped directly from the page’s
HTML source code.
FIGURE 7. Pakistan COVID-19 Dashboard.
To solve this problem, four steps are needed before scraping data.
1. Analyze the network activity. The direct link of the
dashboard in Google Data Studio (https://datastudio
.google.com/embed/reporting/1PLVi5amcc_R5Gh928g
TE8-8r8-fLXJQF/page/R24IB) should be detected by
using browser tools such as Google Chrome’s developer
tools.
2. Render the dashboard using Selenium web driver, which
connects to and retrieves data from a web browser as
discussed in section IV part B.
3. Start a standalone Selenium service on port 4444 to
listen to incoming requests by adopting Github Actions’
service container capability.
4. Connect to the web driver at http://localhost:4444/
wd/hub once the service in step 3 is established.
Until now, the web page is rendered and returned from the
Selenium web driver. HTML elements in the rendered HTML
document can be located using various methods provided by
the web driver. By using those methods, such as identifying
elements by CSS selectors, cell elements in the table that
contain region names and cases data can then be identified.
Each day, daily cases data is scraped and saved in a new file
in CSV format. Data update time can also be extracted from
rendered HTML as highlighted in Figure 7, as the temporal information. This experiment shows that COVID-Scraper
can successfully scrape data from dynamic website. Different from static websites, web drive technologies have been
adopted here to make sure targeted data can be recognized,
accessed, and scraped.
C. PERFORMANCE TEST
To test if the COVID-Scraper can process the scraping
tasks in a reasonable time for supporting COVID-19 related
research, comprehensive performance tests are conducted.
84792 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
For the overall performance of the automatic scraping all
available countries over the world, the average time spent
for the whole GitHub action job is around six minutes fiftyfive seconds by averaging 15 times tests (Figure 8). For
each test, the processing time varies, mainly because the
internet speed is unstable. When COVID-Scraper is starting,
the process of setup job, setup Python, commit, and push
result takes around 3 to 10 seconds to finish, which is quick.
The major time-consuming steps are processing checkout
repositories, installing Python dependencies, and generating
new data, which are heavily impacted by the Internet speed
during the processes. In addition, we noticed that after the
source websites add more content or change the layout of
their websites, the time spent crawling this website takes
longer, or in the worst case, stops working. Once the scraper
detects those abnormal statuses, a notification will be alarmed
automatically to operators that support them to take action in
real time. We continue to maintain and support this project
in the long run to make sure it is working normally and
effectively.
FIGURE 8. Overall performance of the COVID-Scraper.
To understand the detailed performance of the COVIDScraper to get data from different countries, 10 countries have
been selected including Austria, Chile, Jamaica, Panama,
Bosnia, Hungary, Sri Lanka, Turkey, Slovenia, and Switzerland. Every two of those countries share the same data type,
hence the five types of data scraping performance could
be tested. Every country was run 15 times and the average
time is calculated to reduce randomness. Austria and Chile
publish data in table format. The average processing time
is 2.0 and 2.9 seconds, respectively. Though they are in the
same format, the reason for the difference in processing time
is primarily due to the difference in size of crawling data.
For Austria, the data size is 1. 1 KB whereas for Chile
the data size is 1.46 KB. This may be the reason it takes
more time to process Chile’s data in comparison to Austria’s
data. In addition, the downloading speed during processing
time also contributes to the difference. The Jamaica’s and
Panama’s data are in JSON and show an average time of
2.4 and 0.6 seconds, respectively. Similar to Austria and
Chile, the JSON file size of those two countries is the major
reason for the time difference. The file size of Jamaica and
Panama are 584 KB and 245 KB, respectively. Bosnia and
Hungary publish data in image format and take an average
time of 2.8 and 4 seconds. The file size of Hungary is greater
than Bosnia which contributes to more processing time for
Hungary. The data source of Sri Lanka and Turkey are in
PDF format. The difference in processing time between those
two countries is primarily due to two reasons. First, for Sri
Lanka, the crawling script directly scrapes the data from the
current data PDF file. But for Turkey, the script first crawls
the HTML page to retrieve the latest PDF file link which
then scraps the desired data from the PDF, which takes more
time to process. Second, the required data of Sri Lanka is on
the first page of the published PDF file whereas for Turkey,
the desired data is on the third page during our performance
testing which results in need of crawling more pages than
Sri Lanka. The Slovenia and Switzerland data source are in
XLSX format with a file size of 47.7 and 35 KB, respectively.
The processing time for Slovenia is more than Switzerland
because the file size is larger. Hence, the downloading time
increases, causing an increase of processing time. To sum
up, the processing time for countries mainly depends on the
complexity of published website or data files, size of the data
sources and, Internet speed.
FIGURE 9. Performance tests on single countries with different data
types.
D. USE CASES WITH SCRAPED DATA PRODUCT
The data generated by the COVID-Scraper has been used to
support much scientific research within the academic community. Two studies are introduced here by applying the
data generated by COVID-Scraper as one of the major data
sources.
1) MEDICAL RESOURCE DEFICIENCY DYNAMICS
Since late March 2021, over 61 million of the U.S. population has been tested for a positive result for COVID-19.
Whether medical resources were enough to handle the worst
scenario amid the crisis is discussed and evaluated for public
good. Three elements including ventilators, ICU beds, and
critical medical care staff were reported as the fundamental
VOLUME 9, 2021 84793H. Lan et al.: COVID-Scraper: Open-Source Toolset
medical resources to support critically ill patients. In this
study, authors have created a medical resource deficiency
index (MRDI) by using the COVID-Scraper data product and
related COVID-19 medical data to measure the reality of
the medical burden by using the crawled confirmed, death,
recovered, and hospitalized viral cases at the county level
in U.S [89].
MRDI is defined as the division of daily active cases and
medical resources at the county scale, while the daily active
cases refer to the difference of accumulated number of confirmed (positive tested) patients with accumulated number
of deaths. And the medical resources were calculated by the
number of licensed beds multiplied by the total number of
critical care staff, specifically for COVID-19 response. The
higher the value of MRDI, the medical source for a certain
area is pressed harder. The accumulated viral case numbers
of positive confirmed and deaths were extracted from USA
Facts and cross-validated with sources from John Hopkins
University. Hospital licensed bed number and critical medical care staff with comprehensive specialty were accessed
from Definitive Healthcare consulting services and National
Provider Identifier Registry (NPI) database respectively. All
data collected in this study was converted into county scale
with a unique identifier of county code by Census standard.
To monitor and share the dynamic heterogeneity information of medical resource distribution, a medical resource
deficiency dashboard is created based on the ArcGIS dashboard for analyzing and visualizing the generated results
(Figure 10). A bubble map in the center of the dashboard
represents the spatial distribution MDRI, where the area of
circle refers to the index value. Two lists of counties are
displayed on the right to show the statistics rank of MRDI and
Infection Risk/Rate, which is interactively generated based
on the selected extend of the map. An indicator and two
pie charts (fraction of hospital bed types and medical care
staff) are applied to display for each county on the left of the
dashboard. To track the temporal pattern of the index, a line
chart is built in the bottom to demonstrate the time-series
analysis result for the selected area(s).
FIGURE 10. Use scraped data product to monitor medical resource
deficiency dynamics of COVID-19.
2) THE IMPACT OF SOCIAL DISTANCING MEASURES ON
COVID-19 CASES AND MORTALITY
Another study was on the impact of control policies by using
the COVID-Scraper data and corresponding policies dataset.
In this study, authors analyzed a series of social distancing
policies including school closure, workplace closure, cancellation of public events, public information campaigns, cancel
public transport, internal movement restriction, and travel
control that have been implemented to combat the worldwide pandemic. Previous studies have found social distancing
policies are effective in mitigating COVID-19 [90], [91],
however, these policies have negative impacts on economic
development and normal life [92]. Limited understanding of
the effectiveness of each individual policy has posed grand
challenges on the reopening process in which the stringency
of social distancing is reduced to balance health and development. A study investigating the effectiveness of seven major
social distancing policies in the US on COVID-19 case and
mortality growth rate [93] was conducted using the case data
collected and policy data shared by the oxford policy tracker
project [94]. To estimate the temporal dynamic impact of
policies on the COVID-19 cases, policy data was transformed
to 0-1 variables, which represent the policy’s implementation
periods including one week, two weeks, three weeks, one
month, two months, and more than two months. The scraped
daily cumulative case data were converted to daily case
growth rate, which is the difference between the logarithms
of cumulative case numbers in two successive days. These six
implementation indicators were regressed to case growth rate
using panel regression analysis. Panel regression is widely
used to analyze two-dimensional panel data which typically
cross sectional (e.g., states, countries) and longitudinal (e.g.,
year, month) dimensions [95]. Specifically, a fixed effects
panel regression model was adopted in our study, it could
model unobserved heterogeneity through state-specific fixed
effects [96]. In addition, the growth rate was multiplied by
100 in the regression, thus the regression coefficient of policy
could be interpreted as percentage point changes of growth
rate (Figure 11).
FIGURE 11. Use scraped data product to support COVID-19 policy
analysis.
The study demonstrated that the stay-at-home orders,
workplace closures, and public information campaigns can
drastically decrease the confirmed case growth rate. Stay-athome orders and workplace closure decrease case growth rate
through changes in mobility while public information campaign impact confirmed case growth rate through channels
other than mobility. In addition, regarding death case growth
rate, stay-at-home orders and international travel controls
had limited mitigation effect. The relation between policies
84794 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
and case growth rates learned by the study could provide
policymakers a better understanding of the effectiveness of
each policy to support decision-making.
VI. CONCLUSION
The COVID-19 outbreak has impacted billions of people over
the world. Governments, organizations, and research institutions are conducting rapid research on COVID-19 related
problems that aim to bring people of every country back to
normalcy. Detailed spatiotemporal COVID-19 records data
is proved to be important evidence to support COVID-19
related research. However, how to collect, aggregate, store
and share the data published by each country in the world to
the community effectively is a challenge. To solve this problem, the COVID-Scraper was developed as an open-sourced
toolset that can automatically scan, extract, collect, filter,
refine, unify and store the public spatiotemporal COVID-19
records of fifty-eight countries around the world, which
provide available COVID-19 data sources [97]. With minor
code adjustments, this toolset can accommodate various types
of data published by each country in various data formats,
scales, channels, and publish frequencies. More importantly,
for the countries that do not provide access to historical
COVID-19 data, it can automatically build historical data collections to support research repeatedly on a certain frequency.
The COVID-Scraper processes in a high effective manner by
collecting data from countries over the world within a single
run in about six minutes. After post-processing and data
cleaning, the fetched data is unified and saved into a database
for sharing. With daily data quality checking and data product
production, a global COVID-19 data Github repository has
been maintained since March 2020. In addition, a visualization component is developed in the COVID-Scraper to
publish the data product as a web service for public view and
access.
The COVID-Scraper utilized the web scraping technologies that are used in data science and GIS-related fields.
By integrating open-source packages and tools for data
extracting, network simulation, file, image parsing, and workflow automation, the COVID-Scraper is a highly flexible and
automatic toolset that can process tasks unsupervised under
users’ settings. With the nature of open source, users can
easily customize the data sources, the data structure of the
output data product, execution logic, processing frequency,
and exception handling. In addition, users can modify the
source code to extend it for collecting datasets for other
purposes to support wider studies and tasks such as emergency response and natural disaster detection for saving
lives.
Currently, a limitation is that the data quality control and
validation cannot be fully automated because the accuracy
of parsing and text extracting cannot be always guaranteed
by using current packages. Hence, users need to intervene
in the data quality control process for PDF and image type
data to make sure the data product is of high quality. With the
rapid development of text parsing from images, we will keep
updating this component to minimize the human intervention
in the automation process.

