COVIDGR Dataset and COVID-SDNet
Methodology for Predicting COVID-19
Based on Chest X-Ray Images
S. Tabik , A. Gómez-Ríos, J. L. Martín-Rodríguez, I. Sevillano-García, M. Rey-Area, D. Charte,
E. Guirado, J. L. Suárez, J. Luengo, M. A. Valero-González, P. García-Villanova,
E. Olmedo-Sánchez, and F. Herrera
Abstract—Currently, Coronavirus disease (COVID-19),
one of the most infectious diseases in the 21st century, is diagnosed using RT-PCR testing, CT scans and/or
Chest X-Ray (CXR) images. CT (Computed Tomography)
scanners and RT-PCR testing are not available in most
medical centers and hence in many cases CXR images
become the most time/cost effective tool for assisting clinicians in making decisions. Deep learning neural networks
have a great potential for building COVID-19 triage systems
and detecting COVID-19 patients, especially patients with
low severity. Unfortunately, current databases do not allow
building such systems as they are highly heterogeneous
and biased towards severe cases. This article is threefold: (i) we demystify the high sensitivities achieved by
most recent COVID-19 classification models, (ii) under a
close collaboration with Hospital Universitario Clínico San
Cecilio, Granada, Spain, we built COVIDGR-1.0, a homogeneous and balanced database that includes all levels
Manuscript received September 25, 2020; revised October 27, 2020;
accepted November 3, 2020. Date of publication November 10, 2020;
date of current version December 4, 2020. This work was supported by
the project DeepSCOP-Ayudas Fundación BBVA a Equipos de Investigación Científica en Big Data 2018, COVID19_RX-Ayudas Fundación
BBVA a Equipos de Investigación Científica SARS-CoV-2 y COVID-19
2020, and the Spanish Ministry of Science and Technology under the
project TIN2017-89517-P. S. Tabik was supported by the Ramon y Cajal
Programme (RYC-2015-18136). A. Gómez-Ríos was supported by the
FPU Programme FPU16/04765. D. Charte was supported by the FPU
Programme FPU17/04069. J. Suárez was supported by the FPU Programme FPU18/05989. E.G was supported by the European Research
Council (ERC Grant agreement 647038 [BIODESERT]). This project
is approved by the Provincial Research Ethics Committee of Granada.
(Corresponding author: Siham Tabik.)
S. Tabik, A. Gómez-Ríos, I. Sevillano-García, D. Charte, J. L. Suárez,
J. Luengo, and F. Herrera are with Andalusian Research Institute in
Data Science, and Computational Intelligence, University of Granada,
18071 Granada, Spain (e-mail: siham@ugr.es; anabelgrios@decsai.
ugr.es; isega24ivan@gmail.com; fdavidcl@ugr.es; jlsuarezdiaz@ugr.es;
julianlm@decsai.ugr.es; herrera@decsai.ugr.es).
J. L. Martín-Rodríguez, M. A. Valero-González, P. García-Villanova,
and E. Olmedo-Sánchez are with Hospital Universitario Clínico
San Cecilio de Granada, 36310 Spain (e-mail: joseluismartin.rx@
hotmail.com; valerogonzalez@yahoo.es; pgvillanova@gmail.com;
euolm@yahoo.es).
M. Rey-Area is with atlanTTic Research Center for Telecommunication Technologies, University of Vigo, Galicia, Spain (e-mail:
mreyarea@gmail.com).
E. Guirado is with the Multidisciplinary Institute for Environment
Studies Ramón Margalef, University of Alicante, 03690, Spain (e-mail:
geesecillo@gmail.com).
Digital Object Identifier 10.1109/JBHI.2020.3037127
of severity, from normal with Positive RT-PCR, Mild, Moderate to Severe. COVIDGR-1.0 contains 426 positive and
426 negative PA (PosteroAnterior) CXR views and (iii) we
propose COVID Smart Data based Network (COVID-SDNet)
methodology for improving the generalization capacity of
COVID-classification models. Our approach reaches good
and stable results with an accuracy of 97.72% ± 0.95%,
86.90% ± 3.20%, 61.80% ± 5.49% in severe, moderate and
mild COVID-19 severity levels. Our approach could help in
the early detection of COVID-19. COVIDGR-1.0 along with
the severity level labels are available to the scientific community through this link https://dasci.es/es/transferencia/
open-data/covidgr/.
Index Terms—COVID-19, convolutional neural networks,
smart data.
I. INTRODUCTION
I
N THE last months, the world has been witnessing how
COVID-19 pandemic is increasingly infecting a large mass
of people very fast everywhere in the world. The trends are
not clear yet but some research confirm that this problem may
persist until 2024 [1]. Besides, prevalence studies conducted in
several countries reveal that a tiny proportion of the population
have developed antibodies after exposure to the virus, e.g., 5%
in Spain.1 This means that frequently a large number of patients
will need to be assessed in small time intervals by few number
of clinicians and with very few resources.
In general, COVID-19 diagnosis is carried out using at least
one of these three tests.  Computed Tomography (CT) scans-based assessment: it
consists in analyzing 3D radiographic images from different angles. The needed equipment for this assessment
is not available in most hospitals and it takes more than
15 minutes per patient in addition to the time required for
CT decontamination.2
 Reverse Transcription Polymerase Chain Reaction (RTPCR) test: it detects the viral RNA from sputum or
1[Online]. Available: https://english.elpais.com/society/2020-05-14/
antibody-study-shows-just-5-of-spaniards-have-contracted-the-coronavirus.
html 2[Online]. Available: //www.acr.org/Advocacy-and-Economics/ACRPosition-Statements/Recommendations-for-Chest-Radiography-and-CT-forSuspected-COVID19-Infection
© IEEE 2020. This article is free to access and download, along with rights for full text and data mining, re-use and analysis.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3596 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 1. The stratification of radiological severity of COVID-19. Examples of how RALE index is calculated.
nasopharyngeal swab [2]. It requires specific material and
equipment, which are not easily accessible and it takes at
least 12 hours, which is not desirable as positive COVID19 patients should be identified and tracked as soon as possible. Some studies found that RT-PCR results from several
tests at different points from the same patients were variable during the course of the illness producing a high falsenegative rate [3]. The authors suggested that RT-PCR test
should be combined with other clinical tests such as CT.
 Chest X-Ray (CXR): The required equipment for this
assessment are less cumbersome and can be lightweight
and transportable. In general, this type of resources is more
available than the required for RT-PCR and CT-scan tests.
In addition, CXR test takes about 15 seconds per patient
[2], which makes CXR one of the most time/cost effective
assessment tools.
Few recent studies provide estimates on expert radiologists
sensitivity in the diagnosis of COVID-19 based on CT scans,
RT-PCR and CXR. A study on a set of 51 patients with chest
CT and RT-PCR essay performed within 3 days, reported a
sensitivity in CT of 98% compared with RT-PCR sensitivity
of 71% [4]. A different study on 64 patients (26 men, mean age
56 ± 19 years) reported a sensitivity of 69% for CXR compared
with 91% for initial RT-PCR [2]. According to an analysis of 636
ambulatory patients [5], most patients presenting to urgent care
centers with confirmed coronavirus disease 2019 have normal or
mildly abnormal findings on CXR. Only 58.3% of these patients
are correctly diagnosed by the expert eye.
In a recent study [2], authors proposed simplifying the quantification of the level of severity by adapting a previously defined
Radiographic Assessment of Lung Edema (RALE) score [6] to
COVID-19. This new score is calculated by assigning a value
between 0-4 to each lung depending on the extent of visual
features such as, consolidation and ground glass opacities, in the
four parts of each lung as depicted in Fig. 1. Based on this score,
experts can identify the level of severity of the infection among
four severity stages, Normal 0, Mild 1-2, Moderate 3-5 and
Severe 6-8. In practice, a patient classified by expert radiologist
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3597
as Normal can have positive RT-PCR. We refer to these cases as
Normal-PCR+. Expert annotation adopted in this work is based
in this score.
Automated image analysis via Deep learning (DL) models
have a great potential to optimize the role of CXR images
for a fast diagnosis of COVID-19. A robust and accurate DL
model could serve as a triage method and as a support for
medical decision making. An increasing number of recent works
claim achieving impressive sensitivities > 95%, far higher than
expert radiologists. These high sensitivities are due to the bias
in the most used COVID-19 dataset, COVID-19 Image Data
Collection [7]. This dataset includes a very small number of
COVID-19 positive cases, coming from highly heterogeneous
sources (at least 15 countries) and most cases are severe patients,
an issue that drastically reduces its clinical value. To populate
Non-COVID and Healthy classes, AI researchers are using
CXR images from diverse pulmonary disease repositories. The
obtained models will have no clinical value as well since they
will be unable to detect patients with low and moderate severity,
which are the target of a clinical triage system. In view of this
situation, there is still a huge need for higher quality datasets built
under the same clinical protocol and under a close collaboration
with expert radiologists.
Multiple studies have proven that higher quality data ensures
higher quality models. The concept of Smart Data refers to
the process of converting raw data into higher quality data
with higher concentration of useful information [8]. Smart data
includes all pre-processing methods that improve value and
veracity of data. Examples of these methods include noise
elimination, data-augmentation [9] and data transformation [10]
among other techniques.
In this work, we designed a high clinical quality dataset,
named COVIDGR-1.0 that includes four levels of severity,
Normal-PCR+, Mild, Moderate and Severe. We identified these
four severity levels from a recent COVID-19 radiological study
[2]. We also propose COVID Smart Data based Network
(COVID-SDNet) methodology. It combines segmentation, dataaugmentation and data transformations together with an appropriate Convolutional Neural Network (CNN) for inference.
The contributions of this paper can be summarized as follows:
 We analyze reliability, potential and limitations of the most
used COVID-19 CXR datasets and models.
 From a data perspective, we provide the first public dataset,
called COVIDGR-1.0, that quantifies COVID-19 in terms
of severity levels, normal, mild, moderate and severe,
with the aim of building triage systems with high clinical
value.
 From a pre-processing perspective, we combined several
methods. To eliminate irrelevant information from the
input CXR images, we used a new pre-processing method
called segmentation-based cropping. To increase discrimination capacity of the classification model, we used a
class-inherent transformation method inspired by GANs.
 From a post-processing perspective, we proposed a new
inference process that fuses the predictions of the four
transformed classes obtained by the class-inherent transformation method to calculate the final prediction.
 From a global perspective, we designed a novel methodology, named COVID-SDNet, with a high generalization capacity for COVID-19 classification based on CXR
images. COVID-SDNet combines segmentation, datatransformation, data-augmentation, and a suitable CNN
model together with an inference approach to get the final
prediction.
Experiments demonstrate that our approach reaches good and
stable results especially in moderate and severe levels, with
97.72% ± 0.95% and 86.90% ± 3.20% respectively. Lower accuracies were obtained in mild and normal-PCR+ severity levels
with 61.80% ± 5.49% and 28.42% ± 2.58%, respectively.
This article is organized as follows: A review of the most used
datasets and COVID-19 classification approaches is provided in
Section II. Section III describes how COVIDGR-1.0 is built and
organized. Our approach is presented in Section IV. Experiments, comparisons and results are provided in Section V. The
inspection of the model’s decision using heatmaps is provided
in Section VI and the conclusions are pointed out in Section VII.
II. RELATED WORKS
The last months have known an increasing number of works
exploring the potential of deep learning models for automating
COVID-19 diagnosis based on CXR images. The results are
promising but still too much work needs to be done at the level
of data and models design. Given the potential bias in this type
of problems, several studies include explication methods to their
models. This section analyzes the advantages and limitations of
current datasets an models for building automatic COVID-19
diagnosis systems with and without decision explication.
A. Datasets
There does not exist yet a high quality collection of CXR
images for building COVID-19 diagnosis systems of high clinical value. Currently, the main source for COVID-19 class is
COVID-19 Image Data Collection [7]. It contains 76 positive and
26 negative PA views. These images were obtained from highly
heterogeneous equipment from all around the world. Another
example of COVID-19 dataset is Figure-1-COVID-19 Chest
X-ray Dataset Initiative [11]. To build Non-COVID classes, most
studies are using CXR from one or multiple public pulmonary
disease data-sets. Examples of these repositories are:  RSNA Pneumonia CXR challenge dataset on Kaggle [12].
 ChestX-ray8 dataset [13].
 MIMIC-CXR dataset [14].
 PadChest dataset [15].
For instance, COVIDx 1.0 [16] was built by combining three
public datasets: (i) COVID-19 Image Data Collection [7], (ii)
Figure-1-COVID-19 Chest X-ray Dataset Initiative [11] and (iii)
RSNA Pneumonia Detection Challenge dataset [12]. COVIDx
2.0 was built by re-organizing COVIDx 1.0 into three classes,
Normal (healthy), Pneumonia and COVID-19, using 201 CXR
images for COVID class, including PA(PosteroAnterior) and
AP(AnteroPosterior) views (seeTable I). Notice that for a correct
learning front view (PA) and back view (AP) cannot be mixed
in the same class.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3598 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE I
A BRIEF DESCRIPTION OF COVIDX DATASET [7] (ONLY PA VIEWS ARE
COUNTED)
Although the value of these datasets is unquestionable as they
are being useful for carrying out first studies and reformulations,
they do not guarantee useful triage systems for the next reasons.
It is not clear what annotation protocol has been followed
for constructing the positive class in COVID-19 Image Data
Collection. The included data is highly heterogeneous and hence
DL-models can rely on other aspects than COVID visual features
to differentiate between the involved classes. This dataset does
not provide a representative spectrum of COVID-19 severity
levels, most positive cases are of severe patients [17]. In addition,
an interesting critical analysis of these datasets has shown that
CNN models obtain similar results with and without eliminating
most of the lungs in the input X-Ray images [18], which confirms
again that there is a huge need of COVID-19 datasets with high
clinical value.
Our claim is that the design of a high quality dataset must
be done under a close collaboration between expert radiologists
and AI experts. The annotations must follow the same protocol
and representative numbers of all levels of severity, especially
Mild and Moderate levels, must be included.
B. DL Classification Models
Existing related works are not directly comparable as they
consider different combinations of public data-sets and different
experimental setup. A brief summary of these works is provided
in Table II.
The most related studies to ours as they proposed different
models to the typical ones are [16] and [19]. In [16], the authors
designed a deep network, called COVIDNet. They affirmed
that COVIDNet reaches an overall accuracy of 92.6%, with
97.0% sensitivity in Normal class, 90.0% in Non-COVID-19
and 87.1% in COVID-19. The authors of a smaller network,
called COVID-CAPS [19], also claim that their model achieved
an accuracy of 98.7%, sensitivity of 90%, and specificity of
95.8%. These results look too impressive when compared to
expert radiologist sensitivity, 69%. This can be explained by the
fact that the used dataset is biased to severe COVID cases [17].
In addition, the performed experiments in both cited works are
not statistically reliable as they were evaluated on one single
partition. The stability of these models, in terms of standard
deviation, has not been reported.
C. DL Classification Models With Explanation
Approaches
Several interesting explanations were proposed to help inspect the predictions of DL-models [21], [22] although all their
classification models were trained and validated on variations
of COVIDx. The authors in [21] first use an ensemble of two
CNN networks to predict the class of the input image, as Normal,
Pneumonia or COVID. Then highlight class-discriminating regions in the input CXR image using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation
(LRP). In [22], the authors proposed explaining the decision of
the classification model to radiologists using different saliency
map types together with uncertainty estimations (i.e., how certain is the model in the prediction).
III. COVIDGR-1.0: DATA ACQUISITION,
ANNOTATION AND ORGANIZATION
Instead of starting with an extremely large and noisy dataset,
one can build a small and smart dataset then augment it in a way
it increases the performance of the model. This approach has
proven effective in multiple studies. This is particularly true in
the medical field, where access to data is heavily protected due
to privacy concerns and costly expert annotation.
Under a close collaboration with four highly trained radiologists from Hospital Universitario Clínico San Cecilio, Granada,
Spain, we first established a protocol on how CXR images are
selected and annotated to be included in the dataset. A CXR
image is annotated as COVID-19 positive if both RT-PCR test
and expert radiologist confirm that decision within less than 24
hours. CXR with positive PCR that were annotated by expert
radiologists as Normal are labeled as Normal-PCR+. The involved radiologists annotated the level of severity of positive
cases based on RALE score as: Normal-PCR+, Mild, Moderate
and Severe.
COVIDGR-1.0 is organized into two classes, positive and
negative. It contains 852 images distributed into 426 positive and
426 negative cases, more details are provided in Table III. All
the images were obtained from the same equipment and under
the same X-ray regime. Only PosteriorAnterior (PA) view is
considered. COVIDGR-1.0 along with the severity level labels
are available to the scientific community through this link:
https://dasci.es/es/transferencia/open-data/covidgr/.
IV. COVID-SDNET METHODOLOGY
In this section, we describe COVID-SDNet methodology in
detail, covering pre-processing to produce smart data, including
segmentation and data transformation for increasing discrimination between positive and negative classes, combined with a
deep CNN for classification.
One of the pieces of COVID-SDNet is the CNN-based classifier. We have selected Resnet-50 initialized with ImageNet
weights for a transfer learning approach. To adapt this CNN to
our problem, we have removed the last layer of the net and added
a 512 neurons layer with ReLU activation and a two or four
neurons layer (according to the considered number of classes)
with softmax activation.
Let X be the set of n images and K the total number of classes.
Each image xi ∈ X has a true label yi with i = 1, 2,...,n.
The softmax function computes the probability that an image
belongs to class k with k = 1,...,K. Let w = (w1,...,wK)
be the output of the last fully connected layer before the softmax activation is applied. Then, this function is defined as:
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3599
TABLE II
SUMMARY OF RELATED WORKS THAT ANALYZE VARIATIONS OF COVIDX WITH CNN
TABLE III
A BRIEF SUMMARY OF COVIDGR-1.0 DATASET. ALL SAMPLES IN COVIDGR 1.0 ARE SEGMENTED CXR IMAGES CONSIDERING ONLY PA VIEW
softmax : RK → [0, 1]K,
softmax(w)j = exp(wj )
K
k=1 exp(wk) .
Let yi be the class prediction of the network for the image xi,
then yi = argmax(softmax(w)), where w is the output vector
of the last layer before softmax is applied for the input xi.
All the layers of the network were fine-tuned. We used a batch
size of 16 and SGD as optimizer.
The main stages of COVID-SDNet are three, two associated
to pre-processing for producing quality data (smart data stages)
and the learning and inference process. A flowchart of COVIDSDNet is depicted in Fig. 2.
1) Segmentation-Based Cropping: Unnecessary Information
Elimination: Different CXR equipment brands include different
extra information about the patient in the sides and contour of
CXR images. The position and size of the patient may also imply
the inclusion of more parts of the body, e.g., arms, neck, stomach.
As this information may alter the learning of the classification
model, first, we segment the lungs using the U-Net segmentation
model provided in [24], pre-trained on Tuberculosis Chest X-ray
Image datasets [25] and RSNA Pneumonia CXR challenge
dataset [12]. Then, we calculate the smallest rectangle that
delimits the left and right segmented-lungs. Finally, to avoid
eliminating useful information, we add 2.5% of pixels to the left,
right, up and down sides of the rectangle. The resulting rectangle
is cropped. An illustration with example of this pre-processing
is shown in Fig. 3.
2) Class-Inherent Transformations Network: To increase the
discrimination capacity of the classification model, we used,
FuCiTNet [10], a Class-inherent transformations (CiT) Network
inspired by GANs (Generative Adversarial Networks). This
transformation method is actually an array of two generators
GP and GN, where P refers to the positive class and N refers to
the negative class. GP learns the inherent-class transformations
of the positive class P and GN learns the inherent-class transformations of the negative class N. In other words, GP learns the
transformations that bring an input image from its own k domain,
with k ∈ {P, N}, to the P class domain. Similarly, GN learns
the transformations that bring the input image from its k space,
with k ∈ {P, N}, to the N class space. The classification loss is
introduced in the generators to drive the learning of each specific
k-class transformations. That is, each generator is optimized
based on the following loss function:
Lgenk = lMSE + 0.006 · lPerceptual + λ · lCE(y == k) (1)
Where lMSE is a pixel-wise Mean Square Error, lPerceptual is
a perception Mean Square Error and lCE is the classifier loss.
The weighted factor λ indicates how much the generator must
change its outcome to suit the classifier. More details about these
transformation networks can be found in [10].
The architecture of the generators consists of 5 identical residual blocks. Each block has two convolutional layers with 3 × 3
kernels and 64 feature maps followed by batch-normalization
layers and Parametric ReLU as activation function. The last
residual block is followed by a final convolutional layer which
reduces the output image channels to 3 to match the input’s
dimensions. The classifier is a ResNet-18 which consists of an
initial convolutional layer with 7 × 7 kernels and 64 feature
maps followed by a 3 × 3 max pool layer. Then, 4 blocks of
two convolutional layers with 3 × 3 kernels with 64, 128, 256
and 512 feature maps respectively followed by a 7 × 7 average
pooling and one fully connected layer which outputs a vector of
N elements. ReLU is used as activation function.
Once the generators learn the corresponding transformations,
the dataset is processed using GP and GN. Two pair of images (x+
i , x−
i ) will be obtained from each input image xi, i =
1,...,n, where x+
i and x−
i are respectively the positively and
negatively transformed images of xi. Note that, once the entire
dataset is processed, we have four classes (P+,P−, N+, N−)
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3600 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 2. Flowchart of the proposed COVID-SDNet methodology.
instead the original P and N classes. Let yi be the class of xi,
yi ∈ {P, N}. If yi = P, GP and GN will produce the positive
transformation x+
i with y+
i = P+ and the negative transformation x−
i with y−
i = P−, respectively. If yi = N, GP and GN
will produce the positive transformation x+
i with y+
i = N+ and
the negative transformation x−
i with y−
i = N−, respectively.
Fig. 4 illustrates with example the transformations applied by
GN andGP. Notice that these transformations are not meant to be
interpretable by the human eye but rather help the classification
model better distinguish between the different classes.
3) Learning and Inference Based on the Fusion of CNN
Twins: The CNN classification model described above in
this section (Resnet-50) is trained to predict the new four
classes: P+,P−, N+, N−. The output of the network (after softmax is applied) for each transformed image associated to the original one is a vector θ = (θP+, θP−, θN+, θN−),
where θj is the probability of the transformed image to
belong to class j ∈ {P+,P−, N+, N−}. Herein, we propose an inference process to fuse the output of the two
transformed images x+
i and x−
i to predict the label of the
original image xi. In this way, for each pair (x+
i , x−
i ),
the prediction of the original image yi will be either P
or N. Let y
+
i = argmax θ = argmax (θP+, θP−, θN+, θN−)
and y
−
i = argmax ψ = argmax (ψP+, ψP−, ψN+, ψN−) be the
ResNet-50 predictions for x+
i and x−
i respectively. Then:
1) If y
+
i = N+ and y
−
i = N−, then yi = N.
2) If y
+
i = P+ and y
−
i = P−, then yi = P.
3) If none of the above applies, then
yi =
⎧
⎨
⎩
N if max(θNj , ψNj ) > max(θPj , ψPj ),
j ∈ {+, −}
P otherwise .
Experimentally, we used a batch size of 16 and SGD as
optimizer.
V. EXPERIMENTS AND RESULTS
In this section we (1) provide all the information about
the used experimental setup, (2) evaluate two state-of-the-art
COVID classification models and FuCiTNet alone [10] on our
dataset then, analyze (3) the impact of data pre-processing and
(4) Normal-PCR+ severity level on our approach.
A. Experimental Setup
Due to the high variations between different executions, we
performed 5 different 5 fold cross validations in all the experiments. Each experiment uses 80% of COVIDGR-1.0 for
training and the remaining 20% for testing. To choose when
to stop the training process, we used a random 10% of each
training set for validation. In each experiment, a proper set of
data-augmentation techniques is carefully selected. All results,
in terms of sensitivity, specificity, precision, F1 and accuracy, are
presented using the average values and the standard deviation of
the 25 executions. The used metrics are calculated as follows:
recall(positive class) = sensitivity = TP
actual positives
recall(negative class) = specificity = TN
actual negatives
precision(positive class) = TP
predicted positives
precision(negative class) = TN
predicted negatives
accuracy = TP+TN
total predictions
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3601
Fig. 3. The segmentation-based cropping pre-processing applied to the input X-ray image.
Fig. 4. Class-inherent transformations applied to a negative sample. a) Original negative sample; b) Negative transformation; c) Positive
transformation.
F1 = 2 ·
precision · recall
precision + recall
TP and TN refers respectively to the number of true positives
and true negatives.
B. Analysis of COVIDNet and COVID-CAPS
We compare our approach with the two most related approaches to ours, COVIDNet [16] and COVID-CAPS [19].  COVIDNet: Currently, the authors of this network provide
three versions, namely A, B and C, available at [26]. A has
the largest number of trainable parameters, followed by B
and C. We performed two evaluations of each network
in such a way that the results will be comparable to
ours.
 First, we tested COVIDNet-A, COVIDNet-B and
COVIDNet-C, pre-trained on COVIDx, directly on our
dataset by considering only two classes: Normal (negative), and COVID-19 (positive). The whole dataset
(426 positive images and 426 negative images) is evaluated.We report inTable IV recall and precision results
for Normal and COVID-19 classes.
 Second, we retrained COVIDNet on our dataset. It is
important to note that as only a checkpoint of each
model is available, we could not remove the last layer
of these networks, which has three neurons. We used
5 different 5 fold cross validations. In order to be
able to retrain COVIDNet models, we had to add a
third Pneumonia class into our dataset. We randomly
selected 426 images from the Pneumonia class in
COVIDx dataset. We used the same hyper-parameters
as the ones indicated in their training script, that is, 10
epochs, a batch size of 8 and a learning rate of 0.0002.
We changed covid_weight to 1 and covid_percent to
0.33 since we had the same number of images in all
the classes. Similarly, we report in Table IV recall and
precision of our two classes, Normal and COVID-19,
and omit recall and precision of Pneumonia class. The
accuracy reported in the same table only takes into
account the images from our two classes. As with our
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3602 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
TABLE IV
COVIDNET AND COVID-CAPS RESULTS ON OUR DATASET
TABLE V
RESULTS OF COVID-19 PREDICTION USING RETRAINED COVIDNET-CXR A, RETRAINED COVID-CAPS, RESNET-50 WITH AND WITHOUT SEGMENTATION,
FUCITNET AND COVID-SDNET. ALL FOUR LEVELS OF SEVERITY IN THE POSITIVE CLASS ARE TAKEN INTO ACCOUNT
models, we report here the mean and standard deviation
of all metrics.
Although we analyzed all three A, B and C variations of
COVIDNet, for simplicity we only report the results of the
best one.
COVID-CAPS: This is a capsule network-based model
proposed in [19]. Its architecture is notably smaller than
COVIDNet, which implies a dramatically lower number
of trainable parameters. Since the authors also provide a
checkpoint with weights trained in the COVIDx dataset,
we were able to follow a similar procedure than with
COVIDNet:
 First, we tested the pretrained weights using COVIDx
on COVIDGR-1.0 dataset. COVID-CAPS is designed
to predict two classes, so we reused the same architecture with the new dataset and compute the evaluation
metrics shown in Table IV.  Second, COVID-CAPS architecture was retrained over
the COVIDGR-1.0 dataset. This process finetunes the
weights to improve class separation. The retraining
process is performed using the same setup and hyperparameters reported by the authors. Adam optimizer is
used across 100 epochs with a batch size of 16. Class
weights were omitted as with COVIDNet, since this
dataset contains balanced classes in training as well as
in test. Evaluation metrics are computed for five sets
of 5-fold cross-validation test subsets and summarized
in Table IV.
The results from Table IV show that COVIDNet and COVIDCAPS trained on COVIDx overestimate COVID-19 class in our
dataset, i.e., most images are classified as positive, resulting in
very high sensitivities but at the cost of low positive predictive
value. However, when COVIDNet and COVID-CAPS are retrained on COVIDGR-1.0 they achieve slightly better overall
accuracy and a higher balance between sensitivity and specificity, although they seem to acquire a bias favoring the negative
class. In general, none of these models perform adequately for
the detection of the disease from CXR images in our dataset.
C. Results and Analysis of COVID Prediction
The results of the baseline COVID classification model considering all the levels of severity, with and without segmentation,
FuCiTNet [10], and COVID-SDNet are shown in Table V.
In general, COVID-SDNet achieves better and more stable
results than the rest of approaches. In particular, COVID-SDNet
achieved the highest balance between specificity and sensitivity
with 76.94 ± 2.82 F1 in the negative class and 75.71 ± 3.35
F1 in the positive class. Most importantly, COVID-SDNet
achieved the best sensitivity 72.59 ± 6.77 and accuracy with
76.18 ± 2.70. FuCiTNet provides in general good but lower
and less stable results than COVID-SDNet. When comparing
the results of the baseline classification model with and without
segmentation, we can observe that the use of segmentation improves substantially the sensitivity, which is the most important
criteria for a triage system. This can be explained by the fact
that segmentation allows the model to focus on most important
parts of the CXR image.
C. Analysis Per Severity Level
To determine which levels are the hardest to distinguish by
the best approach, we have analyzed the accuracy per severity level (S), with accuracy(S) = Correct predictions(S)
Total number(S) , where
S ∈ {Normal-PCR+, Mild, Moderate, Severe}. The results are
shown in Table VI.
As it can be seen from these results, COVID-SDNet correctly
distinguish Moderate and Severe levels with an accuracy of
86.90% and 97.72%, respectively. This is due to the fact that
Moderate and Severe CRX images contain more important
visual features than Mild and Normal-PCR+ which ease the
classification task. Normal-PCR+ and Mild cases are much more
difficult to identify as they contain few or none visual features.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3603
TABLE VI
RESULTS OF COVID-SDNET PER SEVERITY LEVEL
TABLE VII
RESULTS OF THE BASELINE CLASSIFICATION MODEL WITH SEGMENTATION, COVID-SDNET, RETRAINED COVIDNET-CXR-A AND RETRAINED
COVID-CAPS. ONLY THREE LEVELS OF SEVERITY ARE CONSIDERED, MILD, MODERATE AND SEVERE
TABLE VIII
RESULTS OF COVID-SDNET BY SEVERITY LEVEL WITHOUT CONSIDERING
NORMAL-PCR+
These results are coherent with the clinical studies provided in
[5] and [2] which report that expert sensitivity is very low in
Normal-PCR+ and Mild infection levels. Recall that the expert
eye does not see any visual signs in Normal-PCR+ although
the PCR is positive. Those cases are actually considered as
asymptomatic patients.
D. Analysis of the Impact of Normal-PCR+
To analyze the impact of Normal-PCR+ class on COVID-19
classification, we trained and evaluated the baseline model,
FuciTNet, COVID-SDNet classification stage, COVIDNetCXR-A and COVID-CAPS, on COVIDGR-1.0 by eliminating
Normal-PCR+. The results are summarized in Table VII.
Overall, all the approaches systematically provide better results when eliminating Normal-PCR+ from the training and test
processes, including COVIDNet-CXR-A and COVID-CAPS.
In particular, COVID-SDNet still represents the best and most
stable approach.
E. Analysis Per Severity Level
A further analysis of the accuracy at the level of each severity
degree (see Table VIII) demonstrates that eliminating NormalPCR+ decreases the accuracy in Mild and Moderate severity
levels by 15.8% and 1.52% respectively.
These results show that although Normal-PCR+ is the hardest
level to predict, its presence improves the accuracy of lower
severity levels, especially Mild level.
VI. INSPECTION OF MODEL’S DECISION
Automatic DL diagnosis systems alone are not mature yet to
replace expert radiologists. To help clinician making decisions,
these tools must be interpretable so that clinicians can decide
whether to trust the model or not [27]. We inspect what led
our model make a decision by showing the regions of the input
image that triggered that decision along with its counterfactual
explanation by showing the parts that explain the opposite class.
We adapted Grad-CAM method [28] to explain the decision of
the negative and positive class.
Figs. 5, 6, and 7 show (a) the original CXR image, (b) visual
explanation by means of a heat-map that highlights the regions/pixels which led the model to output the actual prediction
and (c) its counterfactual explanation using a heat-map that
highlights the regions/pixels which had the highest impact on
predicting the opposite class. Higher intensity in the heat-map
indicates higher importance of the corresponding pixel in the
decision. The larger higher intensity areas in the heat-map
determine the final class. However, Fig. 8(b) represents first the
counterfactual explanation and Fig. 8(c) represents the explanation of the actual decision.
As expected, negative and positive interpretations are complementary, i.e, areas which triggered the correct decision are
opposite, in most cases, to the areas that triggered the decision towards negative. In CXR images with different severity levels, the heat-maps correctly point out opaque regions
due to different levels of infiltrates, consolidations and also to
osteoarthritis.
In particular, in Fig. 5(b), the red areas in the right lung points
out a region with infiltrates and also osteoarthritis in the spine
region. Fig. 6(b) correctly shows moderate infiltrates in the right
lower and lower-middle lung fields in addition to a dilation of
ascending aorta and aortic arch (red color in the center). Fig. 5(c)
shows normal upper-middle fields of both lungs (less important
on the left due to aortic dilation). Fig. 7(b) indicates an important
bilateral pulmonary involvement with consolidations.
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
3604 IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS, VOL. 24, NO. 12, DECEMBER 2020
Fig. 5. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 6. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 7. Heatmap showing the parts of the input image that triggered the positive prediction (b) and counterfactual explanation (c).
Fig. 8. Heatmap that explains the parts of the input image that triggered the counterfactual explanation (b) and the negative actual prediction (c).
Authorized licensed use limited to: UNIVERSITY OF HERTFORDSHIRE. Downloaded on July 16,2021 at 08:01:03 UTC from IEEE Xplore. Restrictions apply.
TABIK et al.: COVIDGR DATASET AND COVID-SDNET METHODOLOGY FOR PREDICTING COVID-19 BASED ON CHEST X-RAY IMAGES 3605
As it can be observed in Fig. 8(c), the explanation of the
negative class correctly highlights a symmetric bilateral pattern
that occupies a larger lung volume especially in regions with
high density. In fact, a very similar pattern is shown in the
counterfactual explanation of the positive class in Fig. 5(c), 6(c)
and 7(c).




NEW_PAPER




BIG DATA MINING AND ANALYTICS
ISSN 2096-0654 06/07 pp116–123
Volume 4, Number 2, June 2021
DOI: 10.26599/BDMA.2020.9020016

C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Prediction of COVID-19 Confirmed, Death, and Cured Cases in
India Using Random Forest Model
Vishan Kumar Gupta
, Avdhesh Gupta, Dinesh Kumar, and Anjali Sardana
Abstract: A novel coronavirus (SARS-CoV-2) is an unusual viral pneumonia in patients, first found in late December
2019, latter it declared a pandemic by World Health Organizations because of its fatal effects on public health. In this
present, cases of COVID-19 pandemic are exponentially increasing day by day in the whole world. Here, we are
detecting the COVID-19 cases, i.e., confirmed, death, and cured cases in India only. We are performing this analysis
based on the cases occurring in different states of India in chronological dates. Our dataset contains multiple classes
so we are performing multi-class classification. On this dataset, first, we performed data cleansing and feature
selection, then performed forecasting of all classes using random forest, linear model, support vector machine,
decision tree, and neural network, where random forest model outperformed the others, therefore, the random
forest is used for prediction and analysis of all the results. The K-fold cross-validation is performed to measure the
consistency of the model.
Key words: coronavirus; COVID-19; respiratory tract; multi-class classification; random forest
1 Introduction
The virus of coronaviruses (CoV) is a special kind
of virus that itself is a disease and it enhances the
existing disease in humans body which makes it a
very dangerous virus. This virus results in wheezing,
hard to breathe, bad digestive system, and liverwort,
effects badly human nervous system (center), and also
harms animals like cows, horses, and pigs that are kept,
raised, and used by people and different wild animals. In
 Vishan Kumar Gupta is with Department of Computer
Science and Engineering (CSE), Graphic Era Deemed
to be University, Dehradun 248002, India. E-mail:
vishangupta@gmail.com.
 Avdhesh Gupta and Anjali Sardana are with Department
of CSE, IMS Engineering College, Ghaziabad 201009,
India. E-mail: avdhesh.gupta@imsec.ac.in; anju.sardana@
gmail.com.
 Dinesh Kumar is with Department of CSE, KIET
Group of Institutions, Ghaziabad 201206, India. E-mail:
dineshvashist@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-17; revised: 2020-08-10;
accepted: 2020-08-21
2002–2003 the epidemic of Severe Acute Respiratory
Syndrome (SARS) and in 2012 the burst of the Middle
East Respiratory Syndrome (MERS) have illustrated the
probability of transferrable newly arrived COVID-19 in
human to human and animal to human and vice versa,
though there are very fewer cases of this kind, they
do exists. In late December 2019, the effect of secret
pneumonia in the whole world is a noticeable topic of
study[1]
.
In India, the first case of coronavirus disease 2019
(COVID-19) was announced on 30th January 2020. This
virus extends to the whole of India (in their different
districts) till April 2020 end. In India, the total cases
announced were 5734 in which 472 were recovered and
166 people were dead till 9th April 2020. In India, the
total cases announced were 236 184 in which 113 233
were recovered and 6649 people were dead till 6th June
2020. After this date, fresh cases are still coming into
light daily which is around 10 000. In India, the infection
rate of COVID-19 is lesser than that in some other
countries till date. The website worldometers[2] gives
us all these details in a precise manner. Figure 1 is
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 117
Fig. 1 Structure of coronavirus.
showing the structure of COVID-19, this structure looks
like a crown. The different parts of this virus are also
introduced in this diagram[3]
.
The objectives of this surveillance are the following:
(1) Monitor trends in COVID-19 disease at national
levels.
(2) Rapidly detect new cases in countries where
the virus has started to circulate and monitor cases in
countries where the virus is not circulating.
(3) Provide epidemiological information to conduct
risk assessments at the national and state level.
(4) Provide epidemiological information to guide
preparedness and response measures.
1.1 Transmission
In China, COVID-19 first case was reported in Huanan
Seafood Wholesale Market, Wuhan. The main reason
which was supposed for the spread of this virus is
the transmission from animal-to-human. Even so, the
upcoming COVID-19 cases were not related to the
subjection method. Hence the conclusion is that virus
transmission is from humans to humans, and people with
viruses indicative are the main recurrent reason for the
spread of COVID-19. Before the symptoms progress,
the transmission probability of COVID-19 appears to be
very rare, even though, this virus transmission can not
be prohibited. Besides these, the advice for every person
is that the people who are symptomless or asymptomatic
could pass on the virus and social distancing is the only
way to be secure from this virus[4]
.
Including rhinovirus and flu, additional wheezing
bacterium, it is believed that the droplets of sneeze
and cough of a person are the main reason for virus
imparting. In closed places, aerosol transmission is also
possible in case of long exposure to deep-mouthed
aerosol concentrations. In China, the result of data
analysis of SARS-CoV-2 spread is that the close contact
of two people is the demanded condition for the spread
of the virus. The virus extension is mainly restricted to a
person’s family members, other nearly contacted people
and healthcare experts[4]
.
1.2 Treatment and prevention
Currently, there is no isolated particular antiviral
treatment for COVID-19 virus and their treatments are
reassuring. The effects of recombination of IFN with
ribavirin are very less against the infection of COVID-19.
After the SARS and MERS pandemic, several valuable
efforts have been provided for the development of new
antivirals targeting the CoV proteases, polymerases, and
entry proteins, nevertheless, none of them has been
proven to be worthwhile in clinical trials, nevertheless, of
them has been proven to be worthwhile in clinical trials.
The patient who can already be recovered from COVID19 can donate their plasma and antibodies, because it has
been proved beneficial in the treatment of COVID-19[1]
.
As well, diverse vaccine schemes, like the use of
disabling viruses, live attenuated viruses, a vaccine based
on viral vector, subunit injection, recombinant proteins,
and DNA vaccines, have been evolved, but they are
tested only in the animals so far.
Till now there is not any effective injection or therapy
available for COVID-19, but only the finest measures
are to control the source of infection, early diagnosis,
reporting, isolation, supportive treatments, and on-time
producing outbreak details to keep away from inessential
anxiety. For every person, a fine exclusive hygiene,
wearing a shaped or suitable mask, ventilation, and
keeping away from massed areas will assist to block
COVID-19 virus or its inflammation[1]
.
The guidance and directions issued by the World
Health Organization (WHO) and other corporations are
as follows:
 Keep away from adjacent correspondence with
people suffering from serious CoV inflammation.
 Clean your hands regularly, mainly when you come
in close contact with CoV-infected people and the place
where they live.
 Keep away from unsafe connections with wild and
farm animals.
 Persons having symptoms of critical air shaft
inflammation should maintain a distance from other
peoples, enfold wheeze or sneezes with a throwaway
paper napkin or material, and clean their hands from
time to time.
 Specifically, in the department of a medical
emergency, proper arrangement of strict hygiene
measures are required for the prevention and control
of infections.
 Individuals that are immunocompromised should
118 Big Data Mining and Analytics, June 2021, 4(2): 116–123
avoid public gatherings.
This paper proposes machine learning schemes based
on a data-driven approach. This approach gives a
prediction about the number of infected people with
COVID-19 in the upcoming days using the available
data. This paper proposes a model, which can easily
forecast the count of fresh COVID-19 cases, so that the
management can make a preparation to handle these
cases.
Figure 2 shows the general diagram of the prediction
model, where the various features are taken, and their
multiple cases (classes) are predicted through random
forest prediction model.
This paper is organized as follows. Section 2
explains methodology and materials for the prediction
of COVID-19, where we present dataset and its features,
feature selection, and all the classes. The procedure
of the prediction model is clarified in Section 3. The
description of various machine learning models used
in this work and their performance metric is presented
in Section 4. Sections 5 present the result analysis,
comparison of reported and estimated cases. At long
last, the conclusion is exhibited in Section 6.
2 Methodology and Material
2.1 Dataset and its features
Coronaviruses are a large family of viruses that
may cause illness in animals or humans. In humans,
several coronaviruses are known to cause respiratory
infections ranging from the common cold to more severe
diseases, such as MERS and SARS. The most recently
discovered coronavirus causes coronavirus disease in
2019 (COVID-19)[5]
.
The number of new cases is increasing day by day
around the world. This dataset has information from the
Confirmed, death, and cured cases
Confirmed Indian National
Dataset features
Observation date, time,
and State/Union Territory
Prediction model
Confirmed Foreign National
State
Time
Observation date
Fig. 2 Prediction method.
states and union territories of India daily. The effect of
preventing measures, like social distancing, face mask,
and the lockdown, has also been considered.
The dataset consists of features of COVID-19
data which are taken from https://www.kaggle.com/
sudalairajkumar/covid19-in-india/ and also from the
Ministry of Health & Family Welfare. The dataset
consists only of 2342 samples of COVID-19 cases in
India from 30 January 2020 to 26 May 2020. Table 1
shows the attributes/features used in this study and
glimpse of dataset is presented in Table 2.
2.2 Feature selection
During the process of model building, feature selection
is used to select most relevant features out of all the
features. It reduces the complexity of the prediction
model. Here, we performed feature selection using
random forest importance algorithm in R programming
language[6]. The classification model features are
calculated using the above algorithm, whose input
parameters are all the features of dataset of COVID-19
cases in India.
So, we got three features, which were used for
the building of multi-class classification model using
a random forest importance algorithm. These are
“Obervation date”, “Time”, and “State/Union Territory”
out of five, only two features have been discarded,
that are “Confirmed Indian National” and “Confirmed
Foreign National”. These features are discarded, because
they impact only at the beginning of COVID-19
infection, when patients were coming from abroad, later
Table 1 Feature for the prediction of COVID-19 cases in
India.
Name Description
Observation date It is the date on which how many
COVID-19 positive cases have
occurred.
Time It is the time of that particular date
at which how mang COVID-19
positive cases have occurred.
State/Union Territory It is the name of the state/union
territory of India where COVID-19
cases were found.
Confirmed Indian National It is the total number of confirmed
COVID-19 cases found in India
itself at the starting of SARS-CoV-2
in India.
Confirmed Foreign National It is the total number of confirmed
COVID-19 cases found in India,
which came from any foreign
countries at the beginning of SARSCoV-2 cases in India.
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 119
Table 2 Dataset on SARS-CoV-2 in India.
Date Time State/Union
Territory
“Confirmed Indian
National” case
“Confirmed Foreign
National” case
Cured
case
Death
case
Confirmed case
30-01-2020 6:00 PM Kerala 1 0 0 0 1
04-03-2020 6:00 PM Rajasthan 1 14 0 0 15
07-03-2020 6:00 PM Telengana 1 0 0 0 1
07-03-2020 6:00 PM Tamil Nadu 1 0 0 0 1
08-03-2020 6:00 PM Ladakh 2 0 0 0 2
08-03-2020 6:00 PM Telengana 1 0 0 0 1
10-03-2020 6:00 PM Jammu and Kashmir 1 0 0 0 1
11-03-2020 7:00 PM Maharashtra 2 0 0 0 2
11-03-2020 7:00 PM Delhi 5 0 0 0 5
29-03-2020 7:30 PM Andhra Pradesh – – 1 0 19
10-04-2020 5:00 PM Maharashtra – – 125 97 1364
29-04-2020 5:00 PM Gujarat – – 434 181 3774
01-05-2020 5:00 PM Madhya Pradesh – – 482 137 2719
26-05-2020 8:00 PM West Bengal – – 1414 278 3816
CoV cases are arisen only based on internal infection
due to COVID-19’s communicable property. Therefore,
the values of these fields are not considered.
2.3 Target classes used in prediction dataset
Our dataset contains three target classes, which have
multiple discrete instances. These target classes are the
following:
(1) Confirmed cases: Number of confirmed cases at
any particular date. It may be increased or decreased
according to next date, time, and location-specific to the
Indian states only.
(2) Death cases: Number of death cases at any
particular date. It may be increased or decreased
according to next date, time, and location-specific to
the Indian states only.
(3) Cured cases: Number of cured cases at any
particular date. It may be increased or decreased
according to the next date, time, and location-specific to
the Indian states only.
3 Procedure of Prediction Model
We are developing a machine learning-based
methodology, which has the following four steps.
This methodology is also depicted in Fig. 3.
Step 1: Building multi-class classification model
using the training-testing concept. The dataset of
COVID-19 features of date-wise, time-wise, and statewise were taken from Kaggle and then trained and tested
at 70% and 30%, respectively.
Step 2: Feature selection. Before going to the model
formation, we selected only important features for the
reduction of the complexity of the model. For the same,
1. Data collection from Kaggle
2. Data cleansing
3. Feature selection
4. Model building
5. Result analysis
Fig. 3 Methodology of work.
we applied the random forest importance algorithm.
Section 2.2 describes it in detail. The formulas for the
prediction model in the confirmed, death, and cured
cases are the following:
Confirmed f .Observation Date C TimeC
State/Union Territory/ (1)
Death f .Observation Date C TimeC
State/Union Territory) (2)
Cured f .Observation Date C TimeC
State/Union Territory/ (3)
Step 3: Training the dataset using the multi-class
classification. The dataset is then modeled using random
forest, Support Vector Machine (SVM), decision tree,
multinomial logistic regression, and neural network at
70% training dataset.
Step 4: Testing the dataset using the multi-class
120 Big Data Mining and Analytics, June 2021, 4(2): 116–123
classification: 30% data are tested using these all five
models, the results from all the five models are collected
and found that the random forest model outperformed the
other models for the prediction of confirmed, death, and
cured cases, individually. Therefore, we have considered
the random forest model for the prediction of this multiclass classification model.
4 Machine Learning Models Used in This
Study and Their Performance Metrics
These are the following models used for the prediction of
the cases of COVID-19 using multi-class classification:
(1) Decision tree (rpart): To build decision trees, we
used rpart() method of R programming language[7, 8]
.
(2) Random forest (randomForest): It is an
ensemble tree-based learning algorithm. The random
forest classifier is a set of decision trees from a randomly
selected subset of the training set. It aggregates the votes
from different decision trees to decide the final class of
the test object. We used randomForest() method of R
programming language for this algorithm[9, 10]
.
(3) Multinomial logistic regression (multinome):
In statistics, multinomial logistic regression is a
classification method that generalizes logistic regression
to multi-class problems, i.e., with more than two possible
discrete outcomes. We used multinome() method of
nnet package of R programming language for this
algorithm[11]
.
(4) Neural networks (nnet): Neural networks are
used just for classification as well as for regression.
We are using here feed-forward neural networks with a
single hidden layer, possibly with skip-layer connections.
We used nnet() method of R programming language for
this algorithm[7, 11]
.
(5) Support vector machine (svm): SVM can be
used for classification or regression. It represents the
input features as vectors, which are projected onto
higher-dimensional space. An optimal hyperplane is
then constructed for separating the different instances of
confirmed, death, or cured cases. We have used svm()
method of e1071 package of R programming language
for this algorithm[7, 12]
.
4.1 Performance tuning of the prediction models
Table 3 shows the popular prediction models, which are
used in our study, and the packages used by these models
are open source libraries in R programming language,
licensed under GNU GPL. All packages are used here
having some appropriate method for model formation,
Table 3 Machine learning models and their tuning
parameters.
Model Method Required
package
Tuning
parameter
Random forest randomForest randomForest mtry=2,
ntree=500
SVM svm e1071 kernal=radial,
degree=3
Decision tree rpart rpart usesurrogate=0
Neural
network nnet nnet size=10
Multinomial
logistic
regression
multinome nnet maxit=1000
which are tuned for better results[13]
.
4.2 Accuracy
The accuracy is computed as the percentage deviation
of the predicted target concerning the actual target
with some acceptable error. It is the main performance
evaluation parameter of any machine learning
model[7, 14]
.
Accuracy D
100
n
Xn
iD1
qi
;
qi D
(
1; if abs.pi  ai/ 6 2I
0; otherwise
(4)
where pi
is a predicted target, ai
is an actual target, and
qi
is an arbitrary variable, which contains the absolute
difference of predicted target value and actual target
value.
5 Result Analysis and Comparison of
Reported and Estimated Cases
The number of the total sample for training and testing is
2342 according to different date, time, and states, which
are taken from the website of Kaggle. This is the dataset
of multi-class classification to foresee confirmed, death,
and recovered/cured cases calculated through various
decision models, like decision tree, multinomial logistic
regression, neural network, SVM, and random forest.
The distribution of data in the training and testing
experiments has been set to 70% and 30%, respectively,
for all the methods used. Comparative performance of
all the methods in the prediction of confirmed, death, and
cured cases on accuracy has been highlighted. Accuracy
is computed as the percent deviation of the predicted
target concerning the actual target. The accuracy has
been calculated using Eq. (4), and Table 4 lists the
accuracy of all the models. The results show tha
Vishan Kumar Gupta et al.: Prediction of COVID-19 Confirmed, Death, and Cured Cases in India Using : : : 121
Table 4 Multi-class classification accuracy calculated by
various machine learning models. (%)
Model name Confirmed cases Death cases Cured cases
Random forest 83.54 72.79 81.27
Decision tree 77.69 69.11 79.62
Multinomial logistic
regression 67.69 66.52 71.96
Neural network 70.28 63.18 69.16
SVM 71.35 70.12 68.27
the random forest method outperforms other machine
learning models. Random forest is an ensemble model
that uses bagging for sampling, therefore, we found
its overwhelming performance in comparison to other
models.
In the prediction of confirmed, death, and cured cases
on the testing dataset, random forest has the highest
accuracy of 83.54%, 72.79%, and 81.27% on confirmed,
death, and cured cases, respectively.
Figures 4, 5, and 6 show the histogram for the
comparison of accuracy of confirmed, death, and cured
cases, respectively, using the random forest model as
well as some other models. These results show that
the random forest model has outperformed the other
machine learning models.
Fig. 4 Performance comparison of random forest model
with other models in confirmed cases prediction.
Fig. 5 Performance comparison of random forest model
with other models in death cases prediction.
Fig. 6 Performance comparison of random forest model
with other models in cured cases prediction.
5.1 K-fold cross-validation
The K-fold cross-validation technique shows the robust
performance for the accuracy of any machine learning
model[7]. Here, we have used 7-fold cross-validation for
the prediction of confirmed, death, and cured cases. In
this case, at a time six data frames are used for training
and one data frame is used for testing. Table 5 describes
the accuracy of random forest model for the different
folds of dataset, and Fig. 7 shows the accuracy of the
random forest model in the form of a line graph for the
prediction of all the target classes, which depicts the
consistent performances of random forest model[15]
.
5.2 Comparison of total reported and estimated
confirmed, death, and cured cases
For this data-driven estimations, the data has been taken
from 30 January 2020 to 26 May 2020 from different
states of India. The comparison has also been made
for the daily reported positive confirmed cases with
estimated cases (by data-driven model) for some dates
and states. Tables 6, 7, and 8 are showing the comparison
made by us for the confirmed, death, and cured cases,
respectively.
6 Conclusion
We tend to explore five machine learning models with
three important features for estimating the confirmed,
Table 5 Accuracy provided by 7-fold cross-validation.
(%)
Fold Confirmed cases Death cases Cured cases
1 83.29 72.97 82.52
2 84.98 70.81 81.63
3 81.71 72.35 79.92
4 84.83 72.67 81.17
5 82.65 72.19 81.06
6 84.72 72.88 80.22
7 81.40 70.63 82.44
122 Big Data Mining and Analytics, June 2021, 4(2): 116–123
(a) Confirmed cases
(b) Death cases
(c) Cured cases
Fig. 7 Results of K-fold cross-validation.
Table 6 Comparison of total reported and estimated
confirmed cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 1596 1520 4:76
09-05-2020 Bihar 297 305 2.62
21-05-2020 Maharashtra 10 318 10 386 0.60
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 5897 5912 0.25
Table 7 Comparison of total reported and estimated death
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 97 88 9:27
09-05-2020 Bihar 5 5 0
21-05-2020 Maharashtra 1390 1376 1:01
22-05-2020 Gujarat 773 740 4:26
23-05-2020 Delhi 208 256 2.30
death, and cured cases of COVID-19 in the various states
of India. The qualitative measures are the confirmed,
death, and cured cases. Here, machine learning methods
do not embody any additional information from different
models or different templet structures. All the models
are evaluated on accuracy. Through the intensive
experiments, it is found that the random forest method
Table 8 Comparison of total reported and estimated cured
cases.
Date State Official data Estimation Error (%)
08-05-2020 Rajasthan 3427 3514 2:53
09-05-2020 Bihar 571 601 5.25
21-05-2020 Maharashtra 39 297 38 920 0.90
22-05-2020 Gujarat 5488 5403 1:50
23-05-2020 Delhi 12 319 12 356 0.30
outperforms other machine learning methods, therefore,
we considered it as a final prediction model for the
prediction of our various cases. The K-fold crossvalidation is used to measure the consistency of random
forest model, which provided nearly linear performance
to the prediction of all these cases.
Acknowledgment
We are very much thankful to the Indian Ministry of
Health and Family Welfare (MoHFW) for making the data
available to the general public. Thanks to covid19india.org
for providing the individual states level details to the
general public. We are also thankful for Kaggle and the
worldometer website, which provide huge data in datewise to perform data analytics.




NEW_PAPER


Predictive Modeling of Covid-19 Data in the
US: Adaptive Phase-Space Approach
Vasilis Z. Marmarelis , Fellow, IEEE
Abstract—There are currently intensified efforts by the
scientific community world-wide to analyze the dynamics
of the Covid-19 pandemic in order to predict key epidemiological effects and assist the proper planning for its
clinical management, as well as guide sociopolitical
decision-making regarding proper mitigation measures.
Most efforts follow variants of the established SIR
methodological framework that divides a population into
“Susceptible”, “Infectious” and “Recovered/Removed”
fractions and defines their dynamic inter-relationships with
first-order differential equations. Goal: This paper proposes
a novel approach based on data-guided detection and
concatenation of infection waves – each of them described
by a Riccati equation with adaptively estimated parameters.
Methods: This approach was applied to Covid-19 daily
time-series data of US confirmed cases, resulting in
the decomposition of the epidemic time-course into five
“Riccati modules” representing major infection waves to
date (June 18th). Results: Four waves have passed the
time-point of peak infection rate, with the fifth expected
to peak on July 20th. The obtained parameter estimates
indicate gradual reduction of infectivity rate, although the
latest wave is expected to be the largest. Conclusions:
This analysis suggests that, if no new waves of infection
emerge, the Covid-19 epidemic will be controlled in the
US (<5000 new daily cases) by September 26th, and
the maximum of confirmed cases will reach 4,160,000.
Importantly, this approach can be used to detect (via
rigorous statistical methods) the emergence of possible
new waves of infections in the future. Analysis of data from
individual states or countries may quantify the distinct
effects of different mitigation measures.
Index Terms—Adaptive modeling of Covid-19 time-series
data, epidemiological predictive modeling, riccati-based
phase-space modeling, statistical detection of Covid-19 infection waves.
Impact Statement—Analysis of US Covid-19 data yielded
five RMs representing the dynamics of five infection waves.
The further application of this approach could allow interregional comparison of the obtained RM-decompositions.
Manuscript received May 29, 2020; revised June 22, 2020; accepted
July 1, 2020. Date of publication July 9, 2020; date of current version July
24, 2020. This work was supported by NIH under Grant R01-AG058162
awarded to the Biomedical Modeling & Simulations Center at the University of Southern California.
The author is with the Department of Biomedical Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail:
vzm@usc.edu).
Digital Object Identifier 10.1109/OJEMB.2020.3008313
I. INTRODUCTION
MANY efforts have been made recently to analyze the
time-course of the Covid-19 pandemic daily data in
various countries or regions and to predict key aspects of its eventual growth in order to assist the proper planning for healthcare
resources and related socioeconomic decision-making. Among
them, dominant role is played by the SIR class of compartmental
epidemiological models, introduced about a century ago by
Kermack and McKendrick [1], and its many variants over
the years [2]–[5] that generally utilize compartments of
“Susceptible”, “Infectious” and “Removed” fractions of the
population, which are interconnected with dynamic relationships described by nonlinear ordinary differential equations. Another commonly used approach employs linear Auto-Regressive
Integrated Moving-Average (ARIMA) models that have been
popular in econometrics [6]. From the policy-planning point of
view, practical importance is attained by predictive modeling
methods that can provide reliable estimates of key parameters
of the unfolding infectious process at each point in time on an
adaptive basis, as well as offer useful insights into the dynamic
structure of the infectious process. For example, such adaptive
methods can offer useful predictions of the maximum number of
total infections and an upper bound of the daily confirmed new
cases for the purpose of planning the proper clinical management
of the epidemic. Furthermore, the obtained model should be
interpretable in terms of the dynamic characteristics of the epidemic process (e.g. infectivity rate etc.) in order to assist policy
planning and operational implementation. From these observations arise two key aspects of a desirable modeling approach:
1) Suitable model form: The employed model form must
capture the essential dynamic characteristics of the epidemic process at each time-point in a manner that is
scientifically interpretable and operationally useful.
2) Robust estimation and adaptive modeling:Robust estimation of the model parameters at each time-point must be
feasible using tested statistical methods in a manner that
can detect possible changes in the underlying modeling
assumptions over time and offer the means for model
adaptation.
If these two key aspects can be secured, then it would be
possible to predict the maximum spread of anticipated infections
and the maximum rate of infections (as well as their respective
timing) in order to assist rational decision-making.
This paper presents one such approach that employs an
adaptive modeling/estimation strategy based on the use of
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 207
208 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
concatenated Riccati-type modules (each described by a
parabolic phase-space representation) and suitable adaptive statistical estimation methods. The potential utility of this approach
is initially demonstrated with the adaptive analysis of daily data
of reported Covid-19 confirmed cases in the US up to the present
time (June 18, 2020).
The extensive literature on the subject of epidemiological
modeling is not reviewed here in the interest of space, but
some basic comparisons of the proposed approach with the
most widely-used SIR class of models will be discussed. Some
representative recent modeling applications to Covid-19 data
that may be of interest to the readers include: a simulation study
of the SEIR model (a variant of the SIR model that includes a
compartment for “Exposed” individuals) for Covid-19 in Northern Italy [7], a model that seeks to estimate the transmission risk
of the epidemic [8], and a model for the spread of the epidemic
in China [9]. There are many Covid-related modeling studies
that have been posted as “preprints under review”, thus more
citations will soon be available.
II. MATERIALS AND METHODS
The key modeling element of the proposed approach is the
“Riccati module” (RM) that is defined by the Riccati Equation
(1) with constant coefficients A and B (defining a quadratic relation between the rate of change and the number of infectionsX(t)
at each time) [10]. The additive stochastic term R(t) represents
all unknown random influences (unknown external factors and
errors/noise) affecting the reported time-series data [11]–[15]:
dX(t)/dt = AX(t) − BX2(t) + R(t) (1)
This equation captures the essential self-limiting aspect of an
infectious process (due to the gradually acquired “herd immunity” and countervailing factors) in a relatively simple manner
by considering the “effective rate” (which relates the derivative
to the function) being reduced linearly with rising X(t) as: [A –
BX(t)], instead of being a constant as in the conventional rate
processes of the form: dX(t)/dt = AX(t).
Thus, the parameter A is the initial “infectivity rate constant”
that is dominant in the initial exponential-like growth of the
infection and quantifies the degree of contagiousness of an
infectious agent along with the level of contagious interactions
in a given “infection pool” (IP). On the other hand, the parameter
B depends on the size of susceptible population in the IP and
also quantifies the degree to which the aforementioned acquired
“herd immunity” and countervailing factors (both natural and
socially or administratively imposed by the infected community) constrain the initial rapid growth of the infection and
eventually achieve its control. This process is described by a
sigmoidal curve defined by Equation (2), which is the general
solution of the Riccati Equation (1) (in the absence of random
perturbations R(t)), where the maximum number Xmax of total
infections anticipated by the Riccati model (i.e. the plateau of
the sigmoidal curve) is given by the ratio of the two parameters
Xmax = (A/B):
X (t) = Xmax/ [1 + K exp (−At)] (2)
where K = [(Xmax/Xin) − 1], with Xin being the initial value
of X(t) at the start of the respective RM single-pool infection.
The two parameters, A and B, of each RM attain useful interpretations that offer insights into the dynamic characteristics of the
infectious process, which is generally decomposed into a cascade of RMs estimated via the proposed adaptive methodology
and representing the ongoing “recruitment” of distinct/major
IPs. This model-derived knowledge may assist the effective
management of an epidemic describable by a model composed
of such concatenated (latent) RMs.
It is clearly desirable to obtain reliable “running” estimates of
these parameters from time-series data (e.g. daily Covid-19 data)
at any given point in time. The Riccati-equation model has been
shown previously to represent self-limiting infectious processes
that are confined within single isolated “infection pools” (IPs)
[11]–[15]. The challenge in the study of the Covid-19 epidemic
is that, due to its highly contagious nature, there are multiple
communicating IPs that are recruited during the course of the
epidemic and contribute to the reported data at the respective national, international or multi-community level. This presents us
with the daunting task of separating the superimposed sigmoidal
time-courses of multiple RMs corresponding to the various IPs
(without the benefit of separate data from individual IPs). To
perform this task, we propose a methodology that utilizes an
adaptive estimation procedure to detect (via a “running” statistical Hypothesis test) and separate the concatenated parabolic
phase-space representations of the RMs that are present in the
data up to a given time-point.
The phase-space representation of a dynamic process X(t)
pertains to the relation between X(t) and its derivative over time
(in the absence of random perturbations). The Riccati Equation
(1) indicates that this relation is parabolic. For discrete-time data
(i.e. Covid-19 confirmed cases) up to time-step n, a cascade of
parabolic phase-plots can be fitted to the available phase-space
data, and estimates of all the parameters A and B at each timestep n can be obtained. These parameter estimates can be used to
predict the multi-sigmoidal time-course of the infectious process
according to a superposition of cascaded sigmoidal curves,
each described by Equation (2) with its distinct parameters.
This estimation task begins with the statistical detection and
estimation of the first RM that is described by the discretized
Riccati-model:
ΔX (n) /ΔT = AX (n) − BX2 (n) + R (n) (3)
where: ΔX(n) = [X(n) − X(n − 1)], and ΔT denotes the fixed
time-step (1 day in this case). Following adaptive estimation
of the first RM (see below), we perform statistical Hypothesis
testing (using a properly constructed F-statistic) at each timestep to detect the possible emergence of another RM and, if
such is detected, then estimate the distinct parameters of the two
RMs and separate the contributions to the total reported cases
(see below). This procedure is repeated at each time-step n until
all daily data have been analyzed to obtain adaptive estimates
of the distinct RM parameters A and B that correspond to all
detected RMs.
Regarding the robust estimation of the parameters A and
B, initial analysis indicated that the standard deviation of the
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 209
residual valuesR(n) depends roughly linearly onX(n). This nonstationary residual variance implies that least-squares fitting of
the model of Equation (3) would yield unreliable parameter
estimates. However, reliable estimates of A and B may be
obtained via least-squares regression of the “Normalized Rate of
Change”: ΔX(n)/X(n), (equivalent to the logarithmic derivative)
upon X(n) according to the equation:
ΔX (n) /X (n) = A − BX (n) + R (n) /X (n) (4)
when ΔT in Equation (4) is set to 1 (one day). Since the residual
term: R(n)/X(n), is expected to have (approximately) stationary
standard deviation, reliable parameter estimates can be obtained
at each time-step n. Furthermore, the “slope parameter” B in
Equation (4) can be evaluated for statistical significance at
each time-step n (by testing the Null Hypothesis that the slope
parameter is not significantly different from zero at a specified
confidence level) to assess whether Equation (4) remains an
appropriate representation of the data. When this Null Hypothesis gets rejected at some time-step n, then adaptive parameter
estimates can begin to be used for adaptive prediction of the
sigmoidal course of the infection accounted by the respective
RM.
This adaptive estimation procedure can be repeated at each
time-point n, until the linear relationship expressed by Equation
(4) ceases to represent the time-evolution of the data – an event
identified adaptively by examining the statistical significance
of the reduction in Residual Variance (using Hypothesis testing
with an F-statistic) of the regression of the “Normalized Rate
of Change” values: [ΔX(n)/X(n)] upon the linear relationship
of Equation (4) versus a second-degree polynomial expression
that would indicate the emergence of a new RM. Note that a
second-degree polynomial expression like the one in Equation
(5) (starting with a positive value at X = 0, since A must be
positive) may not have a zero-crossing in the phase-plot of the
“Normalized Rate of Change”, but this is not necessary because
it simply quantifies the divergence from the Null Hypothesis
(as an Alternative Hypothesis) and does not seek to represent
the dynamic characterisitcs of the infectious process. Thus,
we construct an adaptive statistical test using the Alternative
Hypothesis that the Normalized Rate of Change follows the
quadratic model of Equation (5):
ΔX (n) /X (n) = A − BX (n)
− CX2 (n) + R (n) /X (n) (5)
to be tested at each time-point against the Null Hypothesis of
the linear model of Equation (4). For this statistical Hypothesis
testing, we use the following F-statistic (with 1 and (N-3) degrees
of freedom) that represents the normalized reduction in Residual
Variance between the linear and the quadratic expressions (4)
and (5):
F1,N−3 = (N − 3) Q1/(Q2 (6)
where Q1and Q2denote the computed Residual Variances for
the linear and the quadratic expression, respectively, and N is
the number of data-points used in the regression.
TABLE I
ESTIMATED PARAMETERS OF THE RM MODEL COMPONENTS
The computed F1,N−3 is compared at each time-point to the
proper critical value Fcrit (for a significance level of 95%).
When F1,N−3 > Fcrit, the Null Hypothesis is rejected (at 95%
confidence level) and a new RM is deemed to be emerging
and included in the model by separating its contributions (and
parameters) from those of all other previous RMs. The contributions of all concatenated RM model components are included
in the total model prediction. The application of this approach is
demonstrated in the following section using daily reported data
of Covid-19 confirmed cases in the US from March 11 until June
18 (the completion date of this manuscript), while the epidemic
is still ongoing.
III. RESULTS
We analyzed the publicly reported data of daily new Covid-19
confirmed cases in the US (database curated by Johns Hopkins
University) and the cumulative number of confirmed cases since
March 11th 2020 (the day the cumulative cases first exceeded
1000 in the US) until June 18th 2020 (the completion date of this
manuscript), a period that covers a total of 100 days. Application
of the aforementioned methodology identified five latent Riccati
modules (RM) with distinct parameters A and B that are given
in Table I, along with the parameters K of Equation (2) and the
respective predictions of the maximum number of anticipated
cumulative cases due to each RM model component. Some other
key parameters of the five component RMs (e.g. the size and
timing of the peak infection rate for each RM) are also reported
in Table I. The timing of the peak infection rate (PIR) for each
RM is given by the expression:
T PIR = ln (K) /A (7)
and the corresponding PIR is determined by A and B as:
PIR = A2/ (4B) (8)
Equation (8) indicates the strong dependence of PIR on
A. Since the PIR value is critical for planning the clinical
management of the pandemic (lest the finite resources of the
healthcare system be temporarily overwhelmed). Equation (8)
underlines the importance of minimizing (i.e. controlling) A for
a given IP size Xmax = A/B. All these parameter estimates are
given in Table I for the five RMs, along with the time of their
earliest detection T det by the proposed algorithm. The units of
these parameter values are the following: A (days−1), B (days−1
210 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
Fig. 1. Cumulative confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and total concatenated-RM
model prediction (red), along with the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
cases−1), K (unitless), Xmax (cases), PIR (cases/day), T PIR
and T det (days since March 11th 2020).
The declining values of the estimated parametersAfor the five
RMs indicate that there is gradual reduction of the infectivity
rate, which may be partially due to the effect of the imposed
social-distancing and other mitigation measures (see Discussion). These parameter values are updated on a daily basis but
were shown to be rather stable away from the days of introduction of new RMs. The estimated parameters B for the five
RMs depend inversely on the size of the susceptible and exposed
population in the respective “infection pool” in combination
with the effect of mitigation measures (see Discussion). This
is consistent with the model-predicted maximum numbers of
confirmed cases for the five RMs. The total maximum number
of cumulative confirmed cases that is predicted by these five
RM components of the model is: 4,160,000 (substantially higher
than the current cumulative total of 2,191,100 cases). Of course,
this prediction is contingent upon the assumption that no new
infection waves will occur and be detected by the algorithm in
the future. In connection with this assumption, we note that the
F-statistic is rising recently and is approaching the critical value
that may trigger the detection of a new emergent infection wave.
Fig. 1 shows the cumulative number of confirmed cases in the
US since March 11th 2020 along with the total model prediction
and the predictions of the five RM components. The depicted
RM-decomposition of the time-course of the cumulative number
of confirmed cases offers useful insight into the time-course of
the epidemic unfolding over five major IPs (defined as the source
of statistically significant RMs) in the US between March 11th
and the present time (June 18th). Consistent with the estimates
shown in Table I, Fig. 1 indicates that the last RM model
component is expected to make the largest contribution to the
total number of confirmed cases, relative to the previous four
RMs (see Discussion).
The analysis of the daily new confirmed cases offers an
informative RM-decomposition that is shown in Fig. 2, along
with the actual time-series data and the total model prediction.
This result demonstrates the ability of the proposed approach to
Fig. 2. New daily confirmed cases in the US from March 11th to
present time of June 18th (blue with circles) and the total concatenatedRM model prediction (red), along with the predictions of the five RM
components (green-dashed, blue-dotted, purple-dot-dashed, browndotted, and black-dashed).
model multi-modal patterns of dynamic changes in the infectious
process due to merging of distinct infection pools – unlike
the unimodal patterns of the widely used SIR models. This
also allows the timely detection of emerging distinct waves of
infection (see Discussion).
The number of daily new confirmed cases due to each RM is
given by the expression:
ΔX (n) = A2K exp (−An) /{B[1 + K exp (−An)]2}
(9)
that exhibits a single peak at the PIR time-point T PIR (see
Equations (7) and (8)), which corresponds to the inflection point
of the respective sigmoidal curve and is half-way to the level
of the sigmoidal plateau (i.e. foretells the maximum value of
cumulative cases to be reached by each RM).
It is evident in Fig. 2 that the first four RMs have passed their
PIR time-points (see Table I). The last RM is expected to reach
its PIR time-point on Day 132 (i.e. on July 20th). This RM-based
model predicts that, unless a new IP is recruited in the near future,
the Covid-19 infection in the US will dip below 5,000 new daily
confirmed cases on Day 194 (i.e. on September 20th), as marked
with an arrow in Fig. 3 that shows the simulated prediction of
the five RM model components over the next 100 days (until
September 26th). It is evident in Fig. 3 that the infection wave
of the last RM is expected to be larger than the combined total
of the other four RMs (see Discussion).
The forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days
(provided that no new infection wave emerges) is shown in Fig. 4
and illustrates the dominant contribution of the last infection
wave that has not yet reached its inflection point (T PIR) that is
expected in 32 days (i.e. on July 20th).
A cyclical ripple is evident in the actual data of daily confirmed cases in Fig. 3 that is not accounted by the RM-based
model. It is probably due to time-varying influences related to the
weekly cycle of social life. The RM-based model is not expected
to account for such time-varying influences, although the use
of the fundamental Riccati Equation (1) can be extended in
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 211
Fig. 3. Forward prediction of the RM-based model for the new daily
confirmed cases in the US over the next 100 days (to September 26th)
made on June 18th (red line), along with the actual time-series data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
Fig. 4. Forward prediction of the RM-based model for the cumulative confirmed cases in the US over the next 100 days (to September 26th) made on June 18th (red line), along with the actual data
to date (blue with circles) and the predictions of the five RM components (green-dashed, blue-dotted, purple-dot-dashed, brown-dotted,
and black-dashed).
future work to time-varying coefficientsAin order to account for
these weekly variations. To examine the dominant frequencies
of these variations, Fig. 5 shows the frequency spectrum of the
residuals of the RM model prediction for the daily confirmed
cases that clearly depicts a 7-day spectral peak (located at
0.143 cycles/day).
Finally, since some take the view that simple curve-fitting
of the cumulative cases data to a sigmoidal expression may
be adequate, we examine whether a direct least-squares fitting
of the sigmoidal expression of Equation (2) to the time-series
data of cumulative confirmed cases may be able to yield a
reasonable approximation of the time-course of the data. The
result is shown in Fig. 6 and demonstrates the inferiority of
simple curve-fitting, both in terms of approximation accuracy
(by comparing with the RM-model approximation in Fig. 1)
and in terms of misleading parameter estimates: low infectivity
rate estimate of Asig = 0.065 and low prediction of maximum
number of confirmed cases: 2,120,000.
Fig. 5. The frequency spectrum of the residuals of the RM model
prediction for the new daily confirmed cases in the US that depicts a
7-day spectral peak at 143 millicycles/day.
Fig. 6. Direct least-squares fit (red line) of the cumulative cases of
confirmed Covid-19 patients in the US from March 11th to June 18th
(blue line with circles). The results are inferior to their counterparts from
the proposed RM-based modeling methodology that are shown in Fig. 1.
Fig. 7. Direct least-squares fit (red line) of the daily cases of confirmed
Covid-19 patients in the US from March 11th to June 18th (blue line with
circles). The results are inferior to their counterparts from the proposed
RM-based modeling methodology that are shown in Fig. 2.
For the data of daily confirmed cases, the direct least-squares
approximation is shown in Fig. 7 and demonstrates the inferiority of curve-fitting in terms of approximation accuracy (by
comparing with the RM-model approximation in Fig. 2) and the
fundamental inability of direct sigmoidal fitting to approximate
212 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, JULY 2020
multi-modal phase-plots that can detect the emergence of new
major infection waves.
IV. DISCUSSION & CONCLUSION
A novel adaptive methodology for predictive modeling of the
time-course of daily and cumulative confirmed cases of Covid19 has been presented and its application to the reported data
for the US has been demonstrated. This methodology achieves
the decomposition of the time-course of the Covid-19 data in
terms of concatenated “Riccati Modules” (RM) and provides
potentially useful predictions as well as valuable insights into
the dynamic characteristics of the infectious process.
Specifically, the advocated approach detects the presence of
multiple overlapping “infection waves” that correspond to major
“infection pools” (IP) described by distinct and concatenated
RMs that are defined by the fundamental Riccati Equation (1) –
each with distinct parameters A and B that quantify the critical
dynamic aspects of the infectious time-course in the respective IP. The parameter A is the “infectivity rate constant” that
determines the initial exponential-like growth of the infection
and depends on the degree of contagiousness and the level of
contagious interactions in a given IP. In this sense, it is akin
to the “reproduction rate” of the conventional SIR models. The
parameter B depends on the size of the susceptible and exposed
population in each IP and also quantifies the degree to which
the gradually acquired “herd immunity” and mitigating factors/measures constrain the initial rapid growth of the infection
and eventually achieve its control according to the sigmoidal
time-course defined by Equation (2) reaching at its plateau the
maximum number of infections: Xmax = (A/B).
To achieve this RM-decomposition of the time-series data,
the proposed approach employs regression analysis in phasespace and statistical Hypothesis testing using an F-statistic (see
Methods) to detect the emergence of new infection waves at
a specified level of statistical significance. Running (adaptive)
estimates of the RM parameters are obtained at each time-point.
They were found to be rather stable away from the points where
new RMs are introduced into the model.
Analysis of Covid-19 daily data in the US from March 11th
to June 18th (when this manuscript was completed) yielded five
RMs that are concatenated as shown in Figs. 1 and 2. They
are deemed to represent the distinct dynamics of five infection
waves in major IPs that have the characteristics defined by
their respective parameters given in Table I. The small initial
RM-1 (possibly corresponding to the initial infection in the
Seattle area) is followed by the larger RM-2 and RM-3 (possibly corresponding to the rapid urban surge in New York City
and subsequently in other US urban centers and the Northeast,
respectively). The broader epidemic spread across smaller towns
and rural areas in the US, under local mitigation measures, may
correspond to RM-4 (slower growth and moderate size). The
emergence of the last and largest infection wave (described
by RM-5) was detected by the proposed algorithm on Day
60 (May 9th) and appears to coincide with the relaxation of
some mitigation measures across the US. The total number
of infections anticipated by the model is 4,160,000 (about
TABLE II
UNITS FOR MAGNETIC PROPERTIES
Vertical lines are optional in tables. Statements that serve as captions for the entire table do
not need footnote letters.
aGaussian units are the same as cg emu for magnetostatics; Mx = maxwell, G = gauss,
Oe = oersted; Wb = weber, V = volt, s = second, T = tesla, m = meter, A = ampere, J
= joule, kg = kilogram, H = henry.
double the current cumulative number), provided that there
will be no new RM added to the model because of Covid-19
spreading into a new IP or caused by significant change in the
current mitigation measures. Under the same key assumptions,
the current model predicts that the number of new confirmed
cases in the US will drop below 5,000 by September 20th (see
Fig. 3).
The results shown in Table I and Fig. 2 indicate an early
rapid reduction of the parameter A in successive RMs, which
plays a key role in determining the critical “stressor” of the
healthcare system, the Peak Infection Rate: PIR = A2/(4B),
provided that the parameter B is not drastically reduced. The last
RM anticipates its PIR to occur in 32 days (July 20th) without
exceeding the previous peaks of RM-1 and RM-2. It is worth
noting that the time between detection of a new infection wave
and its PIR increases with decreasing A.
Analysis of the daily confirmed cases shows the individual
contributions of the five RM components (see Fig. 2) and
demonstrates the versatility of the proposed approach to detect in
a statistically rigorous manner new emerging waves of infection
and be applicable to cases where the pattern of daily changes
is not unimodal. This constitutes an important advantage of
the proposed approach over the widely used SIR models and
other unimodal approaches. Another difference of the proposed
approach from the popular SIR model is that it does not take into
account the number of recovered cases and does not require full
immunity of the latter. To further explore this comparison, the
three equations of the classic SIR model can be combined in a
single nonlinear differential equation that takes the second-order
MARMARELIS: PREDICTIVE MODELING OF COVID-19 DATA IN THE US: ADAPTIVE PHASE-SPACE APPROACH 213
form:
d2Q/dt2 + k dQ/dt = s0b exp [−b Q (t)] (10)
where Q(t) is the integral from 0 to t of the infected fraction of
the population, k is the recovery rate, b is the infection rate and
s0is the initial size of the susceptible population. Equation (10)
indicates that the estimation of the unknown parameter b must
rely on iterative methods (which are far less robust and reliable
than regression utilized by the proposed approach) and that this
differential equation has only one stable equilibrium point when
Q(t)tends to infinity (a less flexible notion than the multiple finite
stable equilibrium points of the concatenated Riccati Equations
that are achieved by each RM when each reaches its individual
plateau for the respective Xmax = A/B). These comparisons
must be explored further in the future.
Regarding the cyclical variations that are evident in the timeseries data of daily confirmed cases, but not accounted by the
RM-based model (see Fig. 3), it is noted that the fundamental
Riccati Equation (1) can be extended in future work to timevarying coefficients that may account for the observed 7-day
cycle revealed in the spectrum of the residuals of the model
prediction (see Fig. 5). The 7-day cycle peaks at the end of each
week and may be due to increased social interactions during the
previous weekend (noting the average Covid incubation period
of 5 days).
It must be emphasized that the RM-based predictive modeling
is distinct from simple curve-fitting methods. This was demonstrated above by contrasting with the results of direct sigmoidal
least-squares fitting (see Figs. 6 and 7) and showing that the latter
may lead to serious mis-estimation of the key parameters of the
infectious process (e.g. much smaller infectivity rate estimate
and smaller predicted maximum number of confirmed cases) –
in addition to misconceptions regarding the dynamic structure
of the process (i.e. unimodal versus multi-modal phase-space
representation).
An interesting question arises with respect to the effect of
changing testing rates upon the obtained parameter estimates.
If the “true” incidence is Y(t), then the “apparent” incidence
due to a time-varying “testing rate function” f(t) is: X(t) =
f(t)Y(t). It can be shown that the “true” parameters A∗ and B∗
(corresponding to the unknown Y(t) values) are related to the
“apparent” parameter estimates A and B (obtained from the
available X(t) data) according to the expressions: A = A∗ +
f’(t)/f(t), and B = B∗/ f(t), where f’(t) = df(t)/dt. Since f(t)
ought to be positive and ≤1 for all times, then B is always an
overestimation of B∗, and A overestimates A∗ only when the
testing rate is increasing (f’(t) >0). For a constant testing rate,
A = A∗. For the estimated maximum number of cases, we have
the relation: Xmax = Y max [f(t) + f(t) / A∗].
This work (like others on Covid-19 predictive modeling) is
published under unique and unprecedented circumstances of an
ongoing pandemic, which render its validation open to the future
data that are publicly reported. The predictions made in this
paper will hold only if no new wave of infections occurs.
The proposed approach can be applied in the near future to
additional Covid-19 data from other countries or from various regions of the US in order to compare the obtained RMdecompositions (revealing the dynamic structure of infection
waves in these infectious processes) and the associated parameter estimates A and B of each RM. The distinct RMdecompositions for various countries/regions and the respective
parameter estimates may reveal valuable correlations with the
mitigation policies followed in each case to examine their effectiveness within each specific socio-cultural context in order
to guide future decision making by examining how much the
respective policies or socio-cultural conditions influence the estimated parameters A and B – and consequently Xmax = A/B
or PIR = A2/(4B).



NEW_PAPER


Diagnosis of COVID-19 from Chest X-Ray Images Using
Wavelets-Based Depthwise Convolution Network
Krishna Kant Singh and Akansha Singh
Abstract: Coronavirus disease 2019 also known as COVID-19 has become a pandemic. The disease is caused
by a beta coronavirus called Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). The severity of
the disease can be understood by the massive number of deaths and affected patients globally. If the diagnosis
is fast-paced, the disease can be controlled in a better manner. Laboratory tests are available for diagnosis, but
they are bounded by available testing kits and time. The use of radiological examinations that comprise Computed
Tomography (CT) can be used for the diagnosis of the disease. Specifically, chest X-Ray images can be analysed to
identify the presence of COVID-19 in a patient. In this paper, an automated method for the diagnosis of COVID-19
from the chest X-Ray images is proposed. The method presents an improved depthwise convolution neural network
for analysing the chest X-Ray images. Wavelet decomposition is applied to integrate multiresolution analysis in the
network. The frequency sub-bands obtained from the input images are fed in the network for identifying the disease.
The network is designed to predict the class of the input image as normal, viral pneumonia, and COVID-19. The
predicted output from the model is combined with Grad-CAM visualization for diagnosis. A comparative study with
the existing methods is also performed. The metrics like accuracy, sensitivity, and F1-measure are calculated for
performance evaluation. The performance of the proposed method is better than the existing methodologies and
thus can be used for the effective diagnosis of the disease.
Key words: coronavirus; COVID-19; deep learning; convolution neural network; X-Ray images
1 Introduction
A pandemic is an outbreak of a disease globally
affecting many populations. The world has witnessed
many pandemics in the 20th century. Flu viruses
are the major cause of pandemics. These viruses
show changing behaviour with the changing seasons
and thus their behaviour needs to be predicted for
 Krishna Kant Singh is with Department of ECE, KIET Group
of Institutions, Delhi-NCR, Ghaziabad 201206, India. E-mail:
krishnaiitr2011@gmail.com.
 Akansha Singh is with Department of CSE, ASET, Amity
University Uttar Pradesh, Noida 201310, India. E-mail:
akanshasing@gmail.com.
* To whom correspondence should be addressed.
Manuscript received: 2020-06-05; revised: 2020-07-19;
accepted: 2020-07-28
prevention. Health professionals generally make the
correct predictions about most viruses. But some
viruses have exceptional behaviour and are difficult to
predict. Such viruses cause pandemics as humans do
not have the immunity to resist to such virus.
The latest coronavirus disease known as COVID-19
has appeared and spread extremely fast. Since its
discovery in December 2019 in Wuhan, China,
the disease has already spread over 199 countries
and territories. The Severe Acute Respiratory
Syndrome Coronavirus 2 (SARS-CoV-2) causes
COVID-19[1]. The virus is a Ribonucleic Acid (RNA)
virus from the Coronavirus family, most viruses from
this family cause common cold. The more severe
variety of coronaviruses is Severe Acute Respiratory
Syndrome Coronavirus (SARS-CoV) and Middle East
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 85
Respiratory Syndrome Coronavirus (MERS-CoV).
COVID-19 causes respiratory ailments ranging from
common cold to serious diseases like pneumonia. The
number of cases worldwide has reached 5 817 385
causing the deaths of 362 705 individuals as on May
30, 2020 as per the situation report published by
World Health Organization (WHO)[2]. The accurate
information about the emergence of COVID-19 is
still unknown. But the initial cases have established
links with the Huanan (Southern China) Seafood
Wholesale Market[3, 4]. The disease is contagious, and
the virus gets spread amongst humans via respiratory
droplets, physical contact, and also through fecal-oral
transmission[5]. Numerous cases of pneumonia of
unknown cause were reported in Wuhan, China in
December 2019. The cases showed similar clinical
characteristics with viral pneumonia[6]. The patients
suffering from COVID-19 infection are observed to
have serious pneumonia with abnormal observations
on chest Computed Tomography (CT) examination[7]
.
The unavailability of medicine for this disease requires
efficient diagnosis methods for controlling the disease.
Common cold to pneumonia is caused by a group
of viruses known as CoV. These diseases include
respiratory, enteric, renal, and neurological diseases.
These viruses are grouped into four genres namely
alpha-CoV, beta-CoV, gamma-CoV, and delta-CoV[8]
.
Figure 1 gives an overview of the disease.
The virus affects individuals from all age groups and
genders. A research study reveals that two groups of
people are specifically affected by this disease. The first
Fig. 1 Overview of COVID-19.
group of individuals are those who are above 60 years
old. The second group is of those individuals who
have some underlying medical condition like diabetes,
cardiovascular disease, and hypertension. The common
symptoms of COVID-19 include fever, dry cough, and
respiratory problems like shortness of breath, muscular
soreness, and fatigue. In some cases, diarrhoea and
vomiting are also reported. The severity of the disease
ranges from mild flu to pneumonia causing respiratory
ailments. The advance stage of the disease even
causes organ failures and Acute Respiratory Distress
Syndrome (ARDS) leading to the deaths of the patients.
The fast-paced human to human transmission of the
disease is a matter of great concern for the regulatory
authorities globally. The control of COVID-19 largely
depends on the diagnosis at the right time. The available
methods for diagnosis comprise of laboratory tests
like Reverse-Transcription Polymerase Chain Reaction
(RT-PCR), real-time RT-PCR (rRT-PCR), and Reverse
Transcription Loop-mediated isothermal Amplification
(RT-LAMP) test[9, 10]. The laboratory tests have some
limitations. Firstly, the test requires testing kits which
have limited availability in the supply chain. Secondly,
the test is time consuming due to the laboratory
processes involved. The X-Ray facilities are easily
accessible in all parts of the world and the results are
also produced at a fast pace. Therefore, the chest XRay images may be utilized for detecting the presence
of COVID-19. The development of an automated
method based on chest X-Ray images for support in
clinical decision making will be significant for the
disease control. According to WHO, the disease can
be controlled by stopping the chain of transmission.
Officials have reported that testing and isolation are the
two key actions that are useful in breaking the chain
of transmission. Therefore, the accurate diagnosis is
significant in controlling COVID-19.
The detection of COVID-19 can be done at an earlier
stage with chest images as compared to the PCR testing.
The chest X-Ray images can be analyzed by using
artificial intelligence techniques[11]
.
Numerous techniques for diagnosis of COVID-19
using machine learning techniques on radiological
images are available in the literature. A transfer learning
model for diagnosis of coronavirus from chest X-Ray
images is presented in Ref. [12]. Another method with
improved accuracy presented a segmentation-based
approach. The method classified the input images as
86 Big Data Mining and Analytics, June 2021, 4(2): 84–93
normal, viral pneumonia, and COVID-19[13]. A deep
learning-based model is applied on CT images for
detection of COVID-19. Some researchers have also
developed public datasets comprising of chest X-Ray
images of COVID-19 patients[14, 15]. A method named
COVID-Net is developed and applied on these public
datasets for diagnosis of COVID-19[14]. The use of deep
learning for diagnosis from the chest X-Ray images
provides good results. Deep learning models are being
widely used for medical image processing. In Ref. [16],
the detection of pneumonia is done using convolution
neural networks. In this paper, an automated method
for the diagnosis of COVID-19 from a deep network
is proposed. The proposed network utilizes the feature
generated by multiresolution analysis. The combination
of wavelet transforms along with the deep network
brings multiple advantages. The wavelet decomposition
is fed into the network. The network used is not the
traditional Convolutional Neural Network (CNN). A
depthwise separable network is utilized in this work.
2 Background
In this section, the wavelet technique and depthwise
convolution neural network are discussed.
2.1 Wavelet
Wavelet theory is a transform-based image processing
technique that makes use of Wavelet transforms.
Wavelets are derived from small waves of changing
frequency and limited duration[17]. These are useful
as they provide both temporal as well as frequency
information for images.
The 2D scaling functions, including '.x; y/,

H .x; y/,
V
.x; y/, and
D.x; y/, are required for
two-dimensional multiresolution analysis. All these
scaling functions are obtained by multiplying the onedimensional functions. The product of these produces
four two-dimensional separable scaling function and
separable “directionally sensitive” wavelets:
'.x; y/ D '.x/'.y/ (1)

H .x; y/ D .x/'.y/ (2)

V
.x; y/ D '.x/ .y/ (3)

D.x; y/ D .x/ .y/ (4)
These functions record the variance in horizontal,
vertical, and diagonal directions. The separabilty in
Eqs. (1)–(4) is the major cause of the directional
sensitivity. The computational complexity of the 2D
transform remains the same. The scaled and translated
basis functions are defined as
'j;m;n.x; y/ D 2
j=2'.2j
x  m; 2j y  n/ (5)

i
j;m;n.x; y/ D2
j=2
i
.2j
x  m; 2j y  n/;
i D fH; V; Dg (6)
The discrete wavelet transform of an image f .x; y/
of size M  N is
W' .jo; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/ 'jo;m;n.x; y/
(7)
W i
 .j; m; n/D
1
p
MN
M
X1
xD0
N
X1
yD0
f .x; y/
i
j;m;n.x; y/;
i D fH; V; Dg (8)
where jo is an arbitrary starting scale and the
W' .jo; m; n/ coefficients define an approximation of
f .x; y/ at scale jo. W i

.j; m; n/ coefficients add
horizontal, vertical, and diagonal details for scales
greater than jo. Generally, jo D 0 is selected and N D
M D 2
j
so that j D 0; 1; 2; : : : ; j  1, and m D n D
0; 1; 2; : : : ; 2j  1.
Given W' and W i

of Eqs. (7) and (8), f .x; y/
is obtained by performing inverse discrete wavelet
transform:
f .x; y/D
1
p
MN
X
m
X
n
W'.jo; m; n/'jo;m;n.x; y/C
1
p
MN
X
iDH;V;D
X1
jDjo
X
m
X
n
W i
 .j; m; n/ i
j;m;n.x; y/
(9)
2.2 Depthwise separable convolution neural
network
The standard convolution layer of a neural network
has large number of parameters. This leads to
over fitting of the network. Depthwise convolution
and depthwise separable convolution layers overcome
this problem. These convolution layers reduce the
computational cost as well as the number of parameters.
The depthwise convolution layers can reduce the
computational cost and the parameter space. The
reduction in parameters in no way reduces the efficiency
of the network. The standard convolution is divided into
depthwise and pointwise convolution[18]. The depthwise
convolution is responsible for applying convolution on
every input. The output of depthwise convolution is
merged using pointwise convolution. The l-th layer of
the network having a 3D input tensor x
l
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 87
x
l 2 I
HlW lDl
where H; W; and D represent the
height, weight, and depth of the input vector. The
convolution layer output .yi
lC1j
lC1;d / represents the
point at location .i; j / in d-th channel and l C 1 layer.
This can be computed using
yi
lC1j
lC1;d D
X
D
dD0
fd
X
H
iD0
X
W
jD0
fi:j  x
l
i
lC1j
lC1;d
(10)
where fd is a pointwise filter of size 1  1.
The depthwise separable convolution performs the
operation in two steps. In the first step, a depthwise
convolution is applied on the input. Thereafter, the
pointwise convolution is applied on the output of
the depthwise convolution. The spatial correlations
are obtained from depthwise convolution and the
channel wise correlations are obtained from pointwise
convolution. The combination of these two forms the
feature map.
3 Proposed Method
The proposed method is based on depthwise separable
convolution network and spectral pooling using wavelet
transforms. The network is formulated by combining
multiresolution analysis with deep learning. The
traditional CNN layers suffer from over fitting and high
computational cost due to large number of parameters
generated at each layer. Powerful properties of the
Discrete Wavelet Transform (DWT), spectral domain,
spectral pooling, and spectral parameterization of
convolutional layers are utilized as a means to improve
CNNs by improving training convergence, allowing
flexible pooling dimensions, and retaining or improving
competitive classification accuracies.
The filters in the network learn from the spectral
domain instead of the spatial domain. The low
frequency spectrum of the input contains most of
the details and the high frequency spectrum contains
noise information. This non-uniformity of spectrum
power enables the removal of high frequencies do
minimal damage of input information. Spectral pooling
truncates the spectral representation of an image–kernel
product. Simply put, spectral pooling is simple lowpass filter. This technique is desirable because it can
be combined with the convolution theorem to achieve
fast training results. The convolution theorem states
that convolution can be used considerably by being
performed in the spectral domain as element-wise
multiplication. The details of the proposed network are
discussed in the following section. Given an image x,
it can be divided into four subbands xLL; xLH; xHL;
and xHH using the Discrete Wavelet transform with
convolution filters fLL; fLH; fHL; and fHH. These filters
have fixed parameters and a stride of 2. The stride of
two provides the down sampling of the result obtained
from convolution. These four sub-bands are fed into
the depthwise separable network for further processing.
The flow chart of the proposed method is shown in
Fig. 2.
The proposed method comprises of the following
steps:
(1) Input image: The COVID-19 dataset comprises
of the chest X-Ray images. These images are used for
the detection. The images are of different sizes, thus
they are resized to 3  224  224 .
(2) Image normalization: The input images are
normalized prior to any further processing. Normalized
images are enhanced images with no errors due to
lightening conditions.
(3) Image decomposition with wavelet: This step is
one of the most significant steps that convert the spatial
domain input to frequency domain. The input images
are decomposed into four sub-bands. Haar Wavelet
transform is used to decompose the image into sub
bands. The dataset is augmented and split into training
and testing set.
(4) Convolution layers: This step comprises of three
standard convolution blocks. The input is convolved in
these three blocks.
(5) Spectral pooling and batch normalization:
Next layer is the pooling layer which combines the
features from the output of the different layers. In
this paper, average pooling is performed in which the
convolution is followed by down sampling.
(6) Output layer: The next layer is the fully
connected layer. The softmax optimizer is applied in the
last layer to predict the output.
(7) Grad-CAM output visualization: The
prediction output obtained from the network needs
to be visualized for building trust on the network for
making diagnosis decision. The Grad-CAM utilizes the
gradient information from the last layer of the network
to visually represent the class activation map.
(8) Diagnosis decision: Finally, any given input
chest X-Ray image is classified into one of three classes,
i.e., normal, COVID-19, or viral pneumonia.
The details of the network architecture are discussed
in the following sections.
88 Big Data Mining and Analytics, June 2021, 4(2): 84–93
Fig. 2 Proposed methodology.
3.1 Network architecture
The input layer of the network is fed with chest X-Ray
images. The network comprises of eighteen convolution
layers. The network comprises of a mix of regular and
depthwise convolution layers. The batch size is fixed
to eight. There are six regular and twelve depthwise
layers. Multiresolution analysis is integrated into the
network after the first convolution block. Between the
convolution layers, max pooling layers are added. The
batch normalization layers are used to solve the local
minima problem by mapping the activations to the mean
of zero and unit variance. It also makes the convergence
for the network fast[19]. The over fitting problem is
solved by using a dropout of 0.2[20]. The specifications
of the network layers are given in Table 1.
3.1.1 Convolution layer
Given an input vector with n components X D fx1;
x2; x3; : : : ; xng 2 R
n
, the output vector Y D fy1;
Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 89
Table 1 Model summary.
Layer type Output shape Number of parameters Kernel size Dropout Number of filters
Input .224; 224; 3/ 0  0
Wavelet Lambda .112; 112; 12/ 0 3  3 0 4
Separable Conv 2dx2 (ReLU) .14; 14; 256/ 3436 3  3 0 32
Batch normalization .14; 14; 256/ 1024  0
Maxpooling 2d .7; 7; 256/ 0  0
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 68 096 3  3 0 64
Batch normalization .7; 7; 256/ 68 096  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 1024 3  3 0 128
Batch normalization .7; 7; 256/ 512  0
Maxpooling 2d .7; 7; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .7; 7; 256/ 102 272 3  3 0 256
Batch normalization .7; 7; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 256/ 133 888 3  3 0 256
Batch normalization .3; 3; 256/ 1024  0
Maxpooling 2d .3; 3; 256/ 0  0.2
Separable Conv 2dx2 (ReLU) .3; 3; 512/ 267 264 3  3 0 512
Batch normalization .3; 3; 512/ 2048  0
Maxpooling 2d .1; 1; 512/ 0  0.2
FC1 (ReLU) (512) 262 656 0.7 512
FC2 (ReLU) (128) 65 664 0.5 128
FC3 (ReLU) (64) 8256 0.3 64
FC4 (ReLU) (32) 2080 0.2 32
FC5 (ReLU) (3) 99 0 3
y2; y3; : : : ; yng 2 R
n
.
yi D
X
j2Ni
wj xj (11)
where Ni
is a set of indices of neighbours xi and
the weight wj . The computation of yi
is equivalent to
convolution operation of the input by the weight vector.
Thus it can be written using the convolution operator
as
y D x  w (12)
where w D .w0; w1; : : : :; wn1/ 2 R
n
.
3.1.2 Pooling layer
After the convolution layer is the pooling layer. In
this paper, average pooling is used in connection with
multiresolution analysis. The output of the pooling layer
is the vector with fewer number of components as
compared to the input vector. The output of the pooling
layer is defined as
yj D
1
p
p
X1
kD0
xpjCk; y 2 R
m (13)
where p is the support of pooling and m D
n
p
.
The value of p defines the value by which the number
of parameters is reduced. For example, if the value of
p is 3, then the number of parameters is reduced to
one third by taking triplets in average. Pooling can be
written in the form of down sampling as follows:
y D .x  p/ # l (14)
Average pooling performs convolution by p followed
by down sampling by l.
3.2 Activation function
The activation function used is the ReLU function.
Activation function is significant in the convergence
of the network. ReLU is the rectified linear activation
function, and is the most used activation function[21]
.
This function overcomes the vanishing gradient
problem and makes the model more efficient and faster.
Mathematically, it can be expressed as
f .x/ D max .0; x/ (15)
Thus, the function brings all negative values to
zero whereas positive values remain as it. The ReLU
function is used in the hidden layers. In the last
layer, softmax activation function is used. The softmax
function is
Softmax .xi/ D
e
90 Big Data Mining and Analytics, June 2021, 4(2): 84–93
where xi
is the observed output and divided by the sum
of all possible output.
3.3 Training method
The training of the network is one of the most
significant tasks. The weight vector of the network is
updated to minimize the value of the cost function.
The probabilities over the classes for classification
are computed. The loss function used in this paper
is categorical cross entropy[22]. The other important
task in training is to balance the dataset. The data are
balanced with the help of data augmentation. With data
augmentation, new samples are generated. A rotation
angle of 15 degrees to C15 degrees is used for
augmenting the dataset. The optimization method used
here is Adam optimization with weight decay. This
leads to faster convergence and higher performance
of the network. The other parameters are number of
epochs which are chosen to be 100 and the batch
size is set to 8. The model is evaluated using metrics
like F1-score, precision, validation accuracy, sensitivity,
specificity, etc., which is detailed in Section 5.
4 Dataset
The dataset used for the experiments comprises of chest
X-Ray images of COVID-19, viral pneumonia patients,
and healthy individuals. The annotated Post Anterior
(PA) view of chest X-Ray images is used[23, 24]. A total
of 1439 images from the three classes are available in
the dataset. The number of images of COVID-19 is 132;
viral pneumonia is 629; and the number of images of
normal case is 678. The images are of both males and
females from all over the world. For model building
process, we split the dataset into training and test set
that 80% for training the model and 20% for validation
purpose. Table 2 presents the distribution of the images
present in the dataset. The sample images depicting
normal, viral pneumonia, and COVID-19 patients are
shown in Fig. 3[19]
.
Table 2 Distribution of images in train and test sets.
Image type Train Test
Normal 542 136
Viral pneumonia 503 126
COVID-19 106 26
Total 1151 288
5 Experiment and Result
The implementation of the proposed network is done
using Keras library in Python. The experimental setup
and results are presented in this section. The model
was tuned to obtain the best results. The decomposition
of the image was done using Haar wavelet transform.
A total of twelve separable and six convolution layers
are used. Adam optimizer with weighted decay is
used for optimization of the network. The quantitative
analysis of the results obtained is done using sensitivity,
precision, and F1-score[25]. These metrics are computed
using Eqs. (17) – (20). Sensitivity represents the
correctness of classification. It can be computed as
Sensitivity D
TP
TP C FN
 100% (17)
The misclassifications are reported by precision. If
there are no misclassifications, the precision will be
100%. F1-score is the harmonic mean of precision and
sensitivity. The F1-score of value one represents perfect
precision and sensitivity.
Precision D
TP
TP C FP
 100% (18)
F1-score D 2
precision  sensitivity
precision C sensitivity
 100% (19)
Accuracy D
TP C TN
TP C TN C FP C FN
 100% (20)
where TP; FP, and FN represent the true positive,
false positive, and false negative, respectively. The
confusion matrix for the three classes normal, COVID19, and viral pneumonia is shown in Table 3. The values
Fig. 3 Sample images of normal, viral pneumonia, and COVID-19 infected patients[9]

Krishna Kant Singh et al.: Diagnosis of COVID-19 from Chest X-Ray Images Using : : : 91
Table 3 Confusion matrix.
Disease type Predicted result
Normal COVID-19 Viral pneumonia
Normal 130 1 5
COVID-19 1 24 1
Viral pneumonia 3 1 122
obtained for the proposed method are summarized in
Table 4.
Figure 4 shows the Grad-CAM for the three classes.
The Grad-CAM visualization is used along with the
classifier predictions for diagnosis of the disease
accurately.
The performance of the proposed method is
Table 4 Value for the proposed method. (%)
Disease type Accuracy Precision Sensitivity F1-score
Normal 96.53 97 96 96
COVID-19 98.61 92 92 92
Viral pneumonia 96.53 95 97 96
Fig. 4 Grad-CAM visualization of (a) normal, (b) COVID19, and (c) viral pneumonia.
compared with other existing methods. The results are
compared with four latest techniques that have used
deep learning models for the diagnosis of COVID-19
using chest X-RAY images. The results are summarized
in Table 5. The analyses of the results reveal that the
proposed method outperforms the existing methods.
DarkCovidNet uses You Only Look Once (YOLO)
network with 17 layers for detection of COVID-19
from chest X-Ray images[26]. The performance of
DarkCovidNet is average with an overall accuracy of
approximately 87%. The second and third methods are
based on EfficientNet[27]. Two variations of the method
are presented namely flat and hierarchical. These two
methods have an overall accuracy of approximately
93%. The DeTraC-ResNet18 performs better than these
methods and has an overall accuracy of 95.12%. The
proposed method has further improved the overall
accuracy. The overall accuracy of the proposed method
is 95.83%. The bar graph of the comparative study is
shown in Fig. 5.
6 Conclusion
The paper presented an automated method for
detection of COVID-19 from chest X-Ray images. An
improved depthwise convolution network is designed
that incorporates spectral analysis. The convolution and
pooling layers are reformulated as a generalized case of
filtering and down sampling. With this reformulation,
multiresolution analysis is integrated with depthwise
Table 5 Comparative analysis. (%)
Method Accuracy Precision Sensitivity F1-score
DarkCovidNet 87.02 89.96 85.35 87.37
Flat-EfficientNet B3 93.34 93.93 93.96 93.94
HierarchicalEfficientNet B3 93.51 93.93 93.55 93.73
DeTraC-ResNet18 95.12 93.36 97.91 95.58
Proposed 95.83 95.67 96.07 95.63
Fig. 5 Comparative study.
92 Big Data Mining and Analytics, June 2021, 4(2): 84–93
network. The input images are decomposed using
Haar wavelet for multiresolution analysis. The wavelet
is applied in the form of fixed weight filters. The
developed model is applied on chest X-Ray images for
detection of COVID-19 disease. The model classifies
the images into three classes: normal, viral pneumonia,
and COVID-19. A comparative study is also performed
to evaluate the performance of the proposed method.
The developed methodology can be used for diagnosis
of COVID-19 from chest X-Ray images. The use of XRay images will help in controlling the disease.



NEW_PAPER



Effect of E-Learning on Public Health and Environment During
COVID-19 Lockdown
Avani Agarwal, Sahil Sharma, Vijay Kumar, and Manjit Kaur
Abstract: E-learning is the most promising venture in the entire world. During the COVID-19 lockdown, e-learning is
successfully providing potential information to the students and researchers. In developing nations like India, with
limited resources, e-learning tools and platforms provide a chance to make education available to middle and low
income households. This paper gives insights about three different online services, namely Google Classroom,
Zoom, and Microsoft Teams being used by three different educational institutions. We aim to analyze the efficiency
and acceptability of e-learning tools among Indian students during the COVID-19 lockdown. The paper also aims to
evaluate the impact of e-learning on the environment and public health during COVID-19 lockdown. It is found that
e-learning has potential to reduce carbon emissions, which has beneficial impact on the environment. However, the
mental health is impacted as e-learning may lead to self-isolation and reduction in academic achievements that may
lead to anxiety and mental depression. Due to usage of electronic devices for learning, the eyes and neck muscles
may be put in strain, having deleterious effects on physical health.
Key words: e-learning; environment; health; COVID-19
1 Introduction
E-learning and online education provide an opportunity
for students to increase their knowledge base in a
flexible environment while using limited resources
and capital. For a developing country like India,
online tools can help students achieve productive and
diverse education by incorporating various themes in
different areas of interest. The online platforms are
slowly gaining popularity due to the improvements in
design, visuals, ease of navigation, and quality content.
 Avani Agarwal and Sahil Sharma are with the Department
of Computer Science, Thapar Institute of Engineering and
Technology, Patiala 147001, India.
 Vijay Kumar is with Department of Computer Science and
Engineering, National Institute of Technology, Hamirpur,
Himachal Pradesh 177005, India.
 Manjit Kaur is with Department of Computer Science
Engineering, School of Engineering and Applied Sciences,
Bennett University, Greater Noida 201310, India. E-mail:
manjit.kaur@bennett.edu.in.
To whom correspondence should be addressed.
Manuscript received: 2020-06-15; accepted: 2020-08-05
Many studies have shown that e-learning can help
improve the knowledge base and make understanding
of concepts easier by providing bite-sized, collaborative,
and interactive content. Studies have proven that a
personalized and assisted learning-based curriculum is
better than the traditional curriculum. The best quality
of education can be provided through e-learning tools by
personalizing the guidance and mentorship according to
the needs of students[1, 2]. The e-learning platforms give
students flexibility and empower students by allowing
them to learn at their own pace and schedule. A student
can choose the time and day to learn or consume the
content provided on these various platforms. We have
material available at our disposal, which can be either
free of cost or paid, open for a lifetime or a limited
amount of time.
Moreover, the content consumed on an online platform
is consistent and standardized in comparison to the
different teaching styles of professors. A diverse range
of options are provided to users by e-learning[3, 4]. Open
online course providers are edX, Udacity, and Coursera,
and Udemy provides both free and paid online courses
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 105
that cover various topics from diverse fields. These
online platforms not only fulfill the current need of
educators but also create new demands which then
help improve the current services being provided to
students[5]. There are websites like GeeksforGeeks
and Tutorials point which enjoy popularity among
engineering students. YouTube also provides the content
to students pursuing different majors and fields, for
example, Khan Academy is one of such YouTube
Channels that helped build basic concepts of high school
students by keeping the material easy to understanding,
participation, and interaction. The YouTube channel
posts videos after thoroughly researching the topics to
help students understand even the small and hidden
concepts of mathematics[6]
.
In India, universities and colleges integrate the Internet
and web pages into classroom teaching. Teaching
staff makes lecture slides, assignments, and important
notifications available to the students via a course site.
The study material may be downloadable as a PDF file
or a PowerPoint file. Students may participate via onlinediscussion forums and examinations may be conducted
by using an e-learning tool. However, despite the
advancing technologies in higher education, institutes
have failed to incorporate the e-learning practices in
main-stream activities and tap the benefits of online
learning[7, 8]. The teachers may be interested in adopting
online tools, however the student’s attitude and aptitude
learning towards online platforms, standardization, and
interactive content of an online platform play critical
roles in determining the behavior roles of students
towards the e-learning environment[9–12]
.
Usually the mode of instruction through e-learning
platforms is designed by professionals who lack the
knowledge of psychological aspects of the domain
on students. Quality of interactive content needs to
be controlled and updates regularly to capture the
interests of the students. A learning context model helps
realize adaptive technological implementations and
personalizing learning environments. Such environments
improve the quality and increase the quantity of learnings
of the students[13]. In the recent years, robots have helped
increase learning in Science, Technology, Engineering,
and Mathematics (STEM) concepts. A constructionbased approach which collaborates educational robots
can be used to teach complex principles and algorithms
like that of computer science programming languages.
LEGO multi-robots may be used for construction-based
approach towards collaborating learning[14]
.
The main objective of this paper is to evaluate the
impact of e-learning on the environment. This paper
also evaluates the effects of e-learning on health of
the students and researchers. Finally, the case study
of e-learning tools adopted in India during COVID-19
lockdown is also considered.
The remaining paper is organized as follows: Section
2 discusses the impact of e-learning on environment.
Section 3 discusses the implication of e-learning on
social life. Section 4 presents the case study of e-learning
during COVID-19 lockdown. Section 5 concludes the
paper.
2 Impact of E-Learning on Environment
E-learning can effectively reduce the energy usage and
emission of carbon dioxide. According to a study in the
Netherlands, e-learning not only has potential to reduce
carbon emissions but also helps decrease the carbon
footprint and carbon impact of students and travel staff.
Moreover, e-learning not only reduces cost and time
but also is helpful to restore the environment. It is also
helpful to eliminate the necessity of traveling from one
place to another. There are some impacts on environment
due to e-learning[15]
.
2.1 Impact on forest
According to National Wildlife Foundation, 60% of
schools and universities’ waste is paper. Sixteen trees
are needed to generate the one-ton paper. The recycling
of ten tons paper is equivalent to the use of 100 barrels
crude oil[16]. E-learning not only reduces the cutting of
trees for paper generation but also reduces the resource
required for recycling the paper. The registration,
administration, curriculum, and study materials are
digitalized and will also reduce 50% of students’ cost.
2.2 Impact on air
University of West Georgia studied that if hundred
students did not travel to schools/universities, carbon
dioxide emissions may be reduced by 10 tons. The
study of the Netherlands reported that e-learning reduced
the percentage of carbon dioxide emissions and carbon
footprint of students and staff[15]. As per literature, 350
million printer’s cartridges became dead every year
and 1000 years are required to decay these cartridges.
These materials can be easily eliminated through the
e-learning[16]
.
3 Implication of E-Learning on Social Life
The e-learning contents are responsible for solving the
environmental issues. However, it can significantly affect
106 Big Data Mining and Analytics, June 2021, 4(2): 104–115
the social and mental health of students[16]
.
3.1 Impact on mental health
The excessive exposure of electronic device greatly
affected the mental health of users. According to
American Psychiatric Association, the extreme use of
e-learning may lead to social isolation. The e-learning
not only reduces the academic achievement but also is
responsible for mental depression. The e-learning is also
responsible for sleep deprivation due to the deadline of
assignment submissions. According to Harvard analysis,
it is observed that sleep deprivation has direct relation
with the academic outcomes.
3.2 Impact on physical health
The study of materials and completion of assignment on
digital media require a lot of time on electronic devices.
The excessive use of electronic device has a great effect
on physical health of users. These are responsible for
mortality rate due to over-sitting on electronic gadgets.
The eyestrain and muscle injuries may be possible due
to overuse of computers.
4 E-Learning Tools Adopted During
COVID-19 Lockdown in India
On March 25th, 2020, India’s Prime Minister
Mr. Narendra Modi imposed a nationwide lockdown as
a countermeasure to control the coronavirus pandemic.
The lockdown was later extended on April 11th, 2020
in various states of India due to the increase in the
number of coronavirus patients across different regions
of the country. Universities, schools, and educational
institutions were closed, and students went back to their
homes. Hence, the educational institutions had to rely
on e-learning and online education tools to provide
students the necessary study material, schedule lectures,
and to conduct examinations. The lockdown acted as a
catalyst to help teachers adopt online tools. As of April
2020, according to the Ministry of Human Resource
Development, India, platforms like Diksha, e-pathshala,
NROER, NIOS, e-yantra, and FOSSEE are endeavors
of the government to help educate the masses online.
SWAYAM, an initiative by the Indian government, gets
50 000 views daily. Some other online methods adopted
in different universities across India are (1) video and
audio meetings, tools like Zoom, Loom, Gotomeeting,
Skype, Bluejeans, Webex, and Google meet are being
used; (2) discussion and collaboration boards make use
of slack and flock; (3) storage and sharing files are
supported by Dropbox and Nextcloud; and (4) document,
presentation, spreadsheet, and videos are made using
G-suite, Prezi, GitBook, Confluence, Office365, and
Adobe Acrobat. With teachers adopting and using elearning techniques and tools to educate students, we
aim to analyze the efficacy and acceptability of teaching
aids provided and adopted among students of educational
institutions, during the COVID-19 lockdown in India,
by conducting a survey in three different educational
institutions — Google Classroom, Zoom, and Microsoft
Teams. The objective was to analyze the students are
willing to adopt e-learning practices as a part of their
classroom learning by conducting surveys in various
educational institutions.
While conducting the surveys at the three educational
institutions, it was presumed that the students had an
internet connection, access to a mobile or a laptop,
previous knowledge to operate a mobile phone or
personal digital device, understood the default language
of the platform, and the sampling done can be mapped
to larger scales with minimum errors.
Case study 1: Thapar Institute of Engineering and
Technology (TIET), Patiala, India
Thapar Institute of Engineering and Technology is a
private engineering college located in Patiala, Punjab,
India. The educational institution offers various courses
in different fields of engineering. The traditional methods
used for classroom teaching are whiteboard, blackboard,
and a smart board that enable teachers to display
presentations and write notes. In the laboratories,
computers and necessary hardware and software
are provided to students for experimentation and
performing assignments. 75% attendance is mandatory
to pass a course. Each course has an official website
where course coordinators post important information,
syllabus, marking scheme, lecture slides, and laboratory
assignments. Details regarding quizzes and tests are
notified to students via group representatives or via
an update on the course site. Mid-semester tests and
end-semester tests are conducted every semester, which
are scheduled according to a date sheet that is made
available on the web portal— Webkiosk, which is
allocated to every student. Apart from these official
websites, students have access to myHerupa, an initiative
taken by Thapar students, where updates regarding
coursework for each subject are made available for
the first-year, second-year, and third-year engineering
students. During the COVID-19 lockdown, the college
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 107
was temporarily shut down. All classroom activities
and lectures were suspended on campus. Students
and teaching faculty members went back to their
homes; many situated far from college. The teachers
of the university used e-learning tools and methods to
provide education online for students. Lectures were
pre-recorded and shared via WhatsApp and Google
Drive links. Videos of laboratory assignments were prerecorded and uploaded on course sites. Many teachers
scheduled live online lectures using Zoom application
to make material accessible to students. Zoom Video
Communication provides a remote conferencing service.
It allows video conferencing of 100 participants up to
forty minutes free of cost. Paid subscriptions are also
available to allow more participants and to increase the
time limit. The service also allows one-to-one video
conferencing and group conferencing, and allows users
to message all members of a meeting at once or message
a selective group of people, providing stimuli to activate
students’ auditory and visual senses, thus enhancing and
replicating their in-person interactions[9, 10]. Slides were
uploaded on the course site, and students were notified.
For the courses, Image processing (UCS615) and
Innovation and Entrepreneurship (UTA012), the thirdyear students pursuing the BEng degree in computer
science submitted their assignments via Google forums.
A Google form was then circulated among the students
of the Thapar Institute of Engineering and Technology,
where students answered questions regarding the elearning platforms used by educators to impart education
online (see Figs. 1–3).
Case study 2: National Institute of Technology,
Hamirpur (NIT-H), India
National Institute of Technology is a public college
located at Hamirpur, Himachal Pradesh, India. The
Ministry of Human Resource Development, India
funds it. It is an engineering college for undergraduate
students in various engineering courses. The on-campus
practices include classroom teaching using tools such
as whiteboards and blackboards. Teachers sometimes
use slides to deliver their lectures. Apart from these
tools, there is a web portal for students, which
notifies them about their semester grades. All relevant
information is circulated using messaging applications
like WhatsApp. The use of smartphones helps make
material accessible to students[11]. To make study
material available and to conduct tests for the first-year
students pursuing the MEng degree in Computer
Vision and Image Processing during the COVID-19
lockdown, Google Classroom has been adopted by
Fig. 1 Most important feature of e-learning for Thapar Institutes.
Fig. 2 Mode of preference for learning during COVID-19 lockdown.
108 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Fig. 3 Response to the question of whether e-learning
methods should be adopted in daily classroom teaching.
the institute. To use this platform, a user has to sign
into the Google Classroom. While using the G Suite
for education account, the user clicks on whether they
are a teacher or a student. The G Suite account is set
up by an accredited college. Using Google Classroom
services, slides are uploaded, and assignments are
given to the students. This study material is available
to the students via Google Classroom, and they turn
in their assignments by submitting them to a private
electronic mail account. Video links are also provided
using Google Classroom. The marks and grades of
students are made available on the platform. Timed and
pre-scheduled quizzes are also being conducted via this
platform. Computer Vision and Image Understanding
assignments were submitted via the Google Classroom
platform. A survey was conducted by circulating a
Google forum among the first-year students pursuing the
MEng degree in computer vision to gain the feedback
and viewpoint of students on e-learning tools and
teaching aids being provided during the COVID-19
lockdown (see Figs. 4–6).
Case study 3: Manav Rachna International School,
Mohali, India
Manav Rachna International School is a private school
for primary and secondary education. The school has
traditional tools like whiteboards and blackboards to
teach students from Class One to Class Ten. The
school also has smart boards, smart class, and projector,
which allow teachers to display slides, play videos,
and make interactive content for the students. The
pupils of a class make notes in their notebooks. These
notebooks may be evaluative or checked by an assigned
teacher. During the COVID-19 lockdown, the online
Fig. 4 Best feature of Google Classroom according to the National Institute of Technology, Hamirput students.
Fig. 5 Online education tool preferred by NIT-H students.
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 109
Fig. 6 Response towards the e-learning methods in NIT-H.
education tool used is Office365, a solution provided
by Microsoft. The products provided by Office365
to educators and teachers include Outlook, Teams,
Excel, Word, PowerPoint, OneNote, Publisher, and
Access, according to the official Office365 website.
The school is using the e-learning tool Teams provided
by Office365. The lockdown initiated the process of
providing official IDs to teachers and students using
manavrachna.net. The teachers can make various teams
for different classes. The chat option allows teachers
to chat with parents and students either one to one,
or by making a group of all students or selected
students. The assignment section provided by Teams
allows teachers to post assignments. Its design notifies
teachers if a student has viewed the assignment, has
turned in the assignment, and if the student has not
opened the assignment by displaying view, turned in
and not turned in, respectively. The students can submit
their assignments by clicking on the add work button
to upload their solved assignments. The class notebook
section allows students to solve mathematics questions
easily due to user-friendly design. It allows the teachers
to view all the notebooks at once. However, students can
only view their notebook. The quizzes and tasks assigned
may be timed, and time bounds are facilitated by the
class notebook section. The files tab allows the teachers
to post relevant study material or reading material for
students to view. Along with these tabs and options,
the post tab is used to view all the notifications, tasks,
and assignments uploaded by the teachers of different
subjects for a team. The students from Class One to
Class Nine were surveyed to gain insight about the
acceptability of e-learning tools being used to combat
COVID-19 lockdown among young children, aged 5 – 15
years old.
4.1 Results from case study 1: Thapar Institute of
Engineering and Technology
The students pursuing the BEng degree in different
majors at the Thapar Institute of Technology were
surveyed. Out of 167 students surveyed, 126 were males
and 41 females. 43.1% of students surveyed were thirdyear students going to the fourth year while 31.1%,
21%, and 4.8% of students surveyed were the firstyear, second-year, and fourth-year students, respectively.
Although the number of female students surveyed is
significantly less than that of male students, the modal
choice of preferences for every question asked on the
survey was the same for the two genders. Hence, it can
be said that gender does not influence e-learning.
The survey was conducted in April 2020 and questions
included the most important feature for students for an
e-learning platform, there preferred choice of online
education tools, how often were users using Zoom
application to view live college lectures on a weekly
basis, if users were satisfied with the e-learning methods
adopted by their institution, and if the user thinks that
educational institutions should adopt tools provided
by e-learning platforms on a daily basis. 118 students
out of 167 students regarded the quality of services
provided by e-learning platforms as an important feature,
while 101 students and 81 students were in support of
ease of accessibility and user interface, respectively.
Other students regarded the price point of e-learning
tools to be the most important feature of an e-learning
platform. 70.7% of students surveyed preferred prerecorded video lectures provided via YouTube links
as the most convenient e-learning tool. Pre-recorder
lectures provided via Google Drive links and Slides
uploaded on course sites enjoyed a majority of 71
students and 77 students, respectively. It is observed
that 33.5% of students are satisfied with e-learning tools.
However, 32.9% of students are not satisfied with these
tools. 52.7% of students agreed on using the Zoom
application to view live lectures at least three times
a week. The majority of the students (60.5%) were
not satisfied with the e-learning methods adopted by
the institute. However, 49.7% of students thought that
educators should try to utilize tools provided by online
education platforms daily (see Table 1).
110 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 1 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Thapar Institute
of Engineering and Technology.
Item No. Item in detail
Number of
students
(max nD 167)
Number
of males
(nD126)
Number of
females
(nD41)
Model
Distribution of
students
1 First-year students 52 32 20
–
2 Second-year students 35 25 10
3 Third-year students 72 61 11
4 Fourth-year students 8 8 0
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
User interface is the most important feature of
e-learning platforms 81 61 20
Quality of service is
the most important
feature of elearning platforms
2
Quality of service is the most important feature
of e-learning platforms 118 93 25
3
Ease of access is the most important feature of
e-learning platforms 101 77 24
Preferred choice
of e-learning tool
during COVID-19
lockdown. (Multiple
choice correct)
1
Pre-recorded lectures shared via YouTube links
are a preferred choice of online education tools
during COVID-19 lockdown.
118 95 23
Pre-recorded
lectures shared
via YouTube links
are a preferred
choice of online
education tools
during COVID-19
lockdown.
2
Pre-recorded lectures shared via Google Drive
links are a preferred choice of online education
tools during COVID-19 lockdown.
70 55 15
3
Google Slides uploaded on the official course
site are a preferred choice of online education
tools during COVID-19 lockdown.
77 60 17
4
Live lectures using Zoom application are the
preferred choice of online education tools
during COVID-19 lockdown.
37 29 8
How frequently
was the Zoom
application used
weekly to access
lectures? (Single
choice correct)
1
Zoom application used at least thrice a week to
access live lectures. 88 65 23
Zoom application
used at least thrice
a week to access
live lectures.
2
Zoom application used twice a week to access
live lectures. 30 22 8
3
Zoom application used once a week to access
live lectures. 49 39 10
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Not satisfied with the e-learning methods
adopted by the institute during COVID-19
lockdown.
101 79 22
Not satisfied with
the e-learning
methods adopted
by the institute
during COVID-19
lockdown.
2
Satisfied or may be satisfied with the elearning methods adopted by the institute
during COVID-19 lockdown.
66 47 19
Should e-learning
tools be adopted
in daily classroom
teaching? (Single
choice correct)
1
E-learning tools should be or may be adopted
in daily classroom teaching. 128 98 30 E-learning tools
should be or may
be adopted in daily
classroom teaching. 2
E-learning tools should not be adopted in daily
classroom teaching. 39 28 11
4.2 Results from case study 2: National Institute of
Technology, Hamirpur
Sixteen first-year students pursuing computer vision at
NIT-H, were surveyed in April 2020. Out of 16 students,
5 were females, and 11 were males. Table 2 shows the
survey of Google Classroom services were being used
during the COVID-19 lockdown. The questions included
in the survey were if Google Classroom was helpful
in teaching outside the classroom, what was the best
feature of Google Classroom according to the students, if
students were satisfied with Google Classroom teaching,
if the submission of assignment for Computer Vision
and Image Processing using the Google Classroom
was convenient, was it easy to conduct quizzes on the
online platform, if it is easy to access Google Classroom
material, if the laptop or mobile devices were preferred
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 111
Table 2 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of National
Institution of Technology, Hamirpur.
Item No. Item in detail
Number of students
(n D 16/
Number of males
.n D 11/
Number of females
.n D 5/
Most important
feature of an elearning platform.
(Multiple choice
correct)
1
Ease of accessibility is the most
critical feature of e-learning platforms. 13 8 5
2
User Interface is the essential feature
of e-learning platforms. 7 5 2
3
Quality of services is the most crucial
feature of e-learning platforms. 9 7 2
Preferred choice of
e-learning tool during
COVID-19 lockdown,
other than Google
Classroom. (Multiple
choice correct)
1
Pre-recorded lectures shared via
YouTube links are a preferred choice
of online education tools during
COVID-19 lockdown.
13 8 5
2
Pre-recorded lectures shared via
Google Drive links are a preferred
choice of online education tools
during COVID-19 lockdown.
2 2 0
3
Live lectures via Zoom or Google
meet are a preferred choice of online
education tools during COVID-19
lockdown.
1 1 0
What are the benefits
of e-learning?
(Multiple choice
correct)
1
With online learning, there is the ease
of access. 11 7 4
2
With online learning, there is
consistency. 7 5 2
3
With online learning, the schedule is
flexible. 13 8 5
4
With online learning, there is the use
of limited resources. 8 5 3
Is the student satisfied
with the e-learning
tools adopted by
the institute during
COVID-19 lockdown?
(Single choice correct)
1
Satisfied or may be satisfied with the
e-learning methods adopted by the
institute during COVID-19 lockdown.
16 11 5
2
Not satisfied with the e-learning
methods adopted by the institute
during COVID-19 lockdown.
0 0 0
Should the features
of online learning be
adopted into daily
classroom teaching?
(Single choice correct)
1
Some features of online learning
should be or may be adopted in daily
classroom teaching.
15 10 5
2
Some features of online learning
should not be adopted in daily
classroom teaching.
1 1 0
to access Google Classroom, what was the best feature
of the platform provided according to students, what was
another online educational tool that students preferred,
what were the advantages of online education according
to students, if the students were satisfied with the online
learning tool adopted by the university, and if students
wanted to incorporate few features of online education
with daily classroom teaching. For a few questions,
responses were recorded on a scale of 1–5, one being
unsatisfactory, and five being satisfactory. 81.3% of the
students surveyed thought that the ease of accessibility
was the best feature of Google Classroom and prerecorded lectures shared via YouTube links enjoyed a
majority of 13 students out of 16 as the preferred online
education tool (see Table 3). The majority of students
voted for the flexibility of schedule as the advantage of
online education.
4.3 Results from case study 3: Manav Rachna
International School
Table 4 shows the survey conducted in Manav Rachna
112 Big Data Mining and Analytics, June 2021, 4(2): 104–115
Table 3 Students’ response to survey conducted regarding Google Classroom practices adopted by teaching faculty of National
Institute of Technology, Hamirpur on a scale of 1 – 5, with five being maximum. The values are averaged.
No. Item Number of students
(max n D 16)
Number of males
.n D 11/
Number of females
.n D 5/
1
Google Classroom helped in teaching outside of
the classroom. 4.125 4.182 4
2
Students are satisfied with Google Classroom
as an e-learning tool during the COVID-19
lockdown.
4.187 4.273 4
3
Submission of digital image processing
assignments using Google Classroom was
convenient.
4.500 4.636 4.2
4
It was convenient to answer quizzes on Google
Classroom. 4.187 4.272 4
5
It is easy to access learning material in Google
Classroom. 4.812 4.818 4.8
6
It was easier to use Google Classroom on the
laptop than on Mobile. 3.937 3.909 4
Table 4 Students’ response to survey conducted regarding e-learning practices adopted by teaching faculty of Manav Rachna
International School, Mohali.
Item No. Item in detail
Number of
students
(nD91)
Number of
males
(nD49)
Number of
females
(nD42)
Students division among
various levels from nursery
to Class 9.
1 Nursery and Kindergarten 42 21 21
2 Grades 2–5 31 15 16
3 Grades 6–9 18 5 13
Are students satisfied with
the Microsoft Teams tool
being used during COVID19 lockdown? (Single
answer correct)
1
Students are satisfied or may be satisfied by the
Microsoft Team tool being used during COVID-19
lockdown.
90 48 42
2
Students are not satisfied with the Microsoft Teams
tool being used during COVID-19 Lockdown. 1 1 0
Features of Microsoft
Teams preferred by
students. (Multiple answers
correct)
1
Students like the Chat/Call Tab feature supported
by Teams. 70 37 33
2
Students like the Assignment Tab feature
supported by Teams. 56 29 27
3
Students like the Post Section Tab feature
supported by Teams. 23 11 12
4
Students like the Files Section feature supported
by Teams. 21 10 11
5
Students like the Class notebook Tab feature
supported by Teams. 35 20 15
Are students able to achieve
their learning outcomes
through e-learning? (Single
choice correct)
1
You will be or may be able to achieve the required
learning outputs from these sessions? 82 41 41
2
You will not be able to achieve the required
learning outputs from these sessions. 9 8 1
What are the benefits of elearning? (Multiple choice
correct)
1 With online learning, there is the ease of access. 45 25 20
2 With online learning, the schedule is flexible. 39 18 21
3
With online learning, there can be interactive
content.
36 16 20
Should the features of online
learning be adopted into
daily classroom teaching?
(Single choice correct)
1
Some features of online learning should be or may
be adopted in daily classroom teaching. 77 41 36
2
Some features of online learning should not be
adopted in daily classroom teaching. 14 8 6
Avani Agarwal et al.: Effect of E-Learning on Public Health and Environment During COVID-19 Lockdown 113
International School, Mohali, India. Out of 91 students
surveyed, 49 students (53.85%) were males, and 42
students (46.15%) were females. 98.90% of students
were satisfied with the Microsoft Teams tool being used
during the COVID-19 lockdown. Students preferred
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application. 61.54%, 25.27%, 23.07%, and 38.46% of
students liked the assignment tab, post section tab, files
tab, and class notebook tab feature, respectively. 90.10%
of students felt that they could achieve their learning
outcomes via Microsoft Teams application being used
during COVID-19 lockdown. 49.45%, 42.85%, and
39.5% of students felt that ease of access, the flexibility
of schedule, and interactive bite-sized content are the
benefits of e-learning platforms. 84.61% of students were
in favor of the adoption of online learning tools into daily
classroom teaching (see Table 5).
4.4 Results from the three case studies
For all three institutions, the majority agreed with
adopting some e-learning practices with daily classroom
education. For TIET students, mode of preference
for e-leaning was pre-recorded lectures via YouTube
links. The students of NIT-H also gave preference to
pre-recorded lectures via YouTube links apart from
Google Classroom as a preferred choice of e-learning
tool. Majority of students of Manav Rachna International
School and NIT-H found ease of access as the best
advantage of e-learning platforms. From the surveys,
it can be seen that the students of all three educations
would like some features of e-learning tools to be
adopted in daily classroom education.
5 Conclusion
In this paper, initially, the impact of the COVID-19
lockdown is discussed on the environment. Thereafter,
the impact of COVID-19 lockdown is discussed on
the health of the students and researchers. Finally, elearning environment for three educational institutions
during COVID-19 lockdown is discussed. Zoom,
Google Classroom, and Microsoft Teams were not
being previously used by TIET, NIT-H, and Manav
Rachna International School, respectively. The student’s
preferences and choices were successfully identified and
noted in the three institutions by conducting surveys.
From the surveys, it can be seen that the students
of all three educations would like some features of
e-learning tools to be adopted in daily day to day
classroom teaching. For NIT-H and Manav Rachna
International School, it was successfully identified that
students enjoyed the ease of access of material via
e-learning tools. Such tools can be thought to be
incorporated in daily classroom teaching. For TIET,
students already have online portals where information
is updated regularly. Apart from TIET, students at NIT-H
and Manav Rachna International School were satisfied
with the e-learning platforms being used during the
COVID-19 lockdown. From the survey conducted at
Thapar Institution of Engineering and Technology, we
came to know that even if 60.4% of students were not
satisfied with the e-learning practices being used by
their institution during COVID-19 lockdown, 49.7%
of students were still willing to incorporate e-learning
practices in their daily classroom education. From
the three surveys conducted, it can be seen that the
majority of students are eager to adopt the e-learning
platform features in their regular classroom teaching.
Out of 274 students, 220, that is, 80.2% of students
felt that e-learning platforms’ features should be or may
be integrated with the daily classroom teaching. The
maximum number of students, that is, 73.59% of both
the universities preferred pre-recorded lectures being
provided via YouTube links as the preferred means of
e-learning practice during COVID-19. YouTube links
allow students to access the videos any time they like,
making the material easily accessible and providing the
flexibility of the schedule. Out of the students who
answered what they prefer feature of online education,
52.3% supported ease of access, and 48.5% supported
the flexibility of the schedule. Students preferred
Table 5 Students from three institutions respond to the adoption of e-learning practices in daily classroom education.
Item No. Item in detail Number of students
.n D 274/
Number of
males .n D 186/
Number of
females .n D 88/ Mode
Should the features
of online learning
be adopted into
daily classroom
teaching? (Single
choice correct).
1
Some features of online learning
should be or may be adopted in
daily classroom teaching.
220 149 71
Some features of
online learning
should be or may
be adopted in
daily classroom
teaching.
2
Some features of online learning
should not be adopted in daily
classroom teaching.
54 37 17
114 Big Data Mining and Analytics, June 2021, 4(2): 104–115
interaction and personalization as 76.92% of students
favored the Chat/Call option of the Microsoft Teams
application at Manav Rachna International School. At
the National Institute of Technology, Hamirpur, 100%
of students were satisfied with the Google Classroom
practices adopted by their institution. At Manav Rachna
International School, Mohali, 98.90% of students were
satisfied with the Microsoft Teams’ platform adopted
during the COVID-19 platform.
To access these platforms, a mobile device and an
internet connection are required. It is necessary for
the student to be proficient in the English language,
which is the standard or default language for many
e-learning platforms. There are 560 million internet
connections in India, making it the second-largest online
market in the world after China[12]. During the COVID19 lockdown in India, institutions have adopted many
e-learning practices. With the world moving towards
digitization, COVID-19 may act as a catalyst to make
education online. With students and teachers using
these services to educate themselves and masses, new
problems and solutions may be discovered, which may
help popularize online education in India. In the future
studies, from the three case studies, the choices and
preferences of the students should be implemented in
e-learning platforms and in-depth analysis of student
behavior and their choices regarding user interface and
flexibility should be underscored.



NEW_PAPER



A Proactive and Practical COVID-19
Testing Strategy
—KUAN SONG
Gago Ltd., Beijing 100870, China
—SHIQI JIAO
Gago Ltd., Beijing 100870, China
—QIANG ZHU
Gago Ltd., Beijing 100870, China
—HUITAO WU
Zhejiang Lab, Hangzhou 311122, China
(Corresponding author: Kuan Song.)
IEEE DOI 10.1109/EMR.2020.3017648
Abstract—To reopen the economy safely during the COVID-19 pandemic,
governments need the capability to proactively identify new and often
asymptomatic infections, as well as contact tracing. Policymakers and public
health professionals need a sampling-testing method that can achieve broad
population coverage without overwhelming medical workers. We observe that
COVID-19 high-risk groups are located in the hubs and cliques of our geosocial network, formed by the close encounters of people during daily life.
These individuals are the de facto “canary in a coal mine”. We propose that
nations offer free and anonymous testing service to them. With open-source
computer algorithms and datasets, only a small fraction of the population
selected for COVID-19 testing can cover the majority of high-exposure-risk
individuals. A 0.3% sampled testing for a megacity covers 3/4 of its entire
population. A 3% sampled testing for a rural town covers 3/4 of its entire
population. With government oversight and public consent, this approach can
serve each province/state or city/township for decentralized daily testing
planning. However, to protect privacy, we recommend constructing the geosocial network of anonymized cellphones, not named individuals. This
infrastructure should be dismantled once the pandemic is largely over. This
can be achieved by policymakers, health workers, and engineers together in
solidarity.
Key words: COVID-19, decisions under risk and uncertainty, geo-social
networks, network theory, sampling strategy
PROBLEM FORMULATION
THE COVID-19 pandemic puts
global governments in a dilemma.
Before social distancing and stay-athome orders, rapid chain infection
happened. Strict stay-at-home orders
save lives but risk economic
recession. Public opinions are
growing increasingly polarized and
led to armed protesting [1]. If the
economy collapses in any nation, the
ensuing mass unemployment and
social unrest can expose the most
fragile families to the pandemic.
Reopening the economy safely is,
thus, a necessary public health policy.
However, recklessly loosening
stay-at-home policies and reopening
the economy in hard-hit nations can
be risky. Asymptomatic COVID-19
patients can infect others in offices or
onboard public transportation.
Droplets and aerosols from people
talking can carry the virus [2]. If the
chain of community infection goes
undetected, it can grow like wildfire.
Hospitals will again be overwhelmed
and the pandemic can become
endemic. Thus, a prerequisite to
reopening the economy is the ability
to rapidly identify new cases among
the asymptomatic population [3]. That
enables contact tracing of community
infection, and subsequent containing
local outbreaks. There are other
prerequisites such as a declining
number of patients, universal
availability of PPEs, which are as
important but will not be discussed in
this study.
To that end, Mr. B. Gates prescribed a
drastically increase of nucleic testing
capability for COVID-19 [4].
IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020 63
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/Meanwhile, a Harvard panel report
proposed daily proactive testing of 5–
20 million people in the United States
alone or 2–6% of the total population
[5]. The study did not specify how
they come to that estimation nor how
good that estimation is. The
challenge to that testing capability lies
not only in the production and
distribution of test kits but more
crucially in the logistics of the actual
tests. There might not be enough
medical workers and lab technicians
in the US to conduct 20 million tests a
day. Peto et al. [3] advocate universal
weekly random testing of 13% of the
U.K. population to reach 90%
coverage. That translates to 2%
daily testing of the entire population.
This is a huge logistic challenge for
the U.K. as well. Similar random
sampling schemes are being
developed for India [6]. However,
none of these testing schemes
materialized since their conception.
This probably is because
governments deem them impractical.
This logistical challenge can be
readily solved, if only a selected
0.1–0.3% sample of the total
population is needed to tested
daily or weekly. As of now, megacities
in the United States, Europe, and
China already have that testing
capacity.
We propose the daily testing of only a
small subset of the asymptomatic
population, specifically targeting the
hubs and cliques in a geo-social
network of anonymous cellphones. If
any result comes back positive, then
the people around them need further
testing as contact tracing. The geosocial network of anonymous
cellphones in a given area during a
given time period consists of vertices
and links. The vertices are the
cellphones, carried by their owners
active in the economy. The links
among them indicate significant close
encounter, such as working in the
same office, living in the same house,
and sharing the same ride.
The following graph illustrates a
simple geo-social network of three
young working professionals. Mary,
Giuseppe, and Lee work in a small
consulting firm. Mary shares her
house with a partner and jogs with a
group of X (5 to 20) people to the
office daily. Giuseppe shares a house
with his parents and 2 siblings and
drives alone to the office daily. Lee
lives alone in his condo and takes a
40-min metro ride to the office daily
with Y (10 to 50) people in a train car.
In the geo-social network graph, we
use F to denote family members, and
C to denote commuters they meet
daily. For simplicity we assume that
other family members stay strictly at
home, the commuters interact with no
one else, and all the people in this
graph are asymptomatic.
Given such a geo-social network,
who should we administer COVID-19
tests to if we only have three test kits
available every day? What about two
test kits? Or even just a meager one
test kit per day? We might want to
reserve testing to the people who are
most exposed to the virus, and who
have the highest potential to infect
others. Very often the same people
meet both criteria. Naturally, we
would choose to first test Mary,
Giuseppe, and Lee because they
connect to more people than others.
Lee has the highest exposure risk
because of the packed subway ride
with dozens of commuters, and thus,
he should get the test if only one test
kit is available. In our opinion, each
municipality and/or CDC office should
have the tools to automatically
analyze such geo-social networks
and provide testing service to the
individuals with the highest exposure
risks.
There exists no full-scale study on
COVID-19 exposure on individuals.
Patients of old age or with preexisting medical conditions have the
highest death rate once infected, but
not necessarily the highest exposure
chances before getting ill. We
observed that two types of people
might be the most exposed to
COVID-19 due to their distinctive geosocial network niches. We could
focus our limited testing capabilities
on them.
Around the world, senior government
officials have been disproportionately
hit by COVID-19. The list includes
prime ministers of Britain and Russia,
the first Ladies of Spain and Canada,
the first family of Brazil, and countless
ministers around the world. Likely this
situation resulted from their busy daily
schedule to meet with a large number
of people, often internationally. In
other words, the “hubs” in our geosocial network are most exposed to
infection risks. In a sense, they are
the canary in a coal mine. Timely
testing for them could buy time for
their local communities.
People spending long hours in
close quarters have seen horrendous
local outbreaks of COVID-19.
Well-known cases include the
Diamond Princess, USS Theodore
Roosevelt, USS Kidd, and many
hospital wards, retirement homes,
factories [7], and prisons [8] around
the world. In a geo-social network,
these communities are known as
clique’s because each member is
within close vicinity of all other
members and, therefore, geo-socially
interconnected. Such cliques are
often exposed to airborne droplets
carrying the virus, which leads to
unusually high percentages of local
infection.
Thus, our goal is to identify, in each
geo-social network of a workforce
embracing economic reopening, the
hub’s and clique’s people for daily
COVID-19 testing even though they
are asymptomatic. If any hub’s or
clique’s individual turns up positive
for COVID-19, the geo-social network
of his/her immediate daily interaction
circle needs to be tested, and the
patients quarantined. We argue that
this is an efficient sampling strategy
64 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020for COVID-19 testing in a reopened
economy.
Each city has its own logistical
constraints on testing. Some cities
can afford to test daily 1% of its
workforce, others may afford to test
0.1%, which testing percentage is
sufficient? How to measure
sufficiency? How can each city
perform its own rapid assessment on
a daily basis?
METHODOLOGY AND
EXPERIMENT
To address the abovementioned
questions, we conducted a pilot study
using existing social network tools on
two real-world social network
datasets. The simplest approach is to
single out individuals with the most
links in the geo-social network for
testing. But the problem with that
approach is that those individuals are
often in the same local community
and, thus, have highly overlapped
geo-social networks [9]. For example,
doctors and nurses working in the
same ER room, or the congress
members of the same nation. If we
concentrate our testing resources on
them, we will miss out on the big
picture in the population and have a
social inequality issue.
Thus, we aim to find the individuals
with the most links in the geo-social
network, while the individuals directly
linked to them cover the maximum
percentage of the population. This
can be achieved by dividing the geosocial network of mega-cities like
Wuhan or NYC into small
communities or cliques. We can then
identify the hub’s in each community.
Unfortunately, in mathematics and
computer science, this problem is
NP-hard. To find the exact optimal
solution takes exponentially
computation time as the size of the
population grows. There exist
heuristic solutions that can produce
imperfect yet useable solutions with a
limited time budget. These solutions
were developed over the past two
decades not just to analyze social
networks and internet traffic [9].
These algorithms are also the
workhorses behind Internet search
engines such as Google [10] and
Microsoft Bing [11].
The heuristic algorithms examined
here are developed in academia and
open-source. We also share crude
yet simple Python snippets [12], [13]
to make use of these models with
real-world datasets. We hope that the
public health sector can integrate
these methods without hiccups. In our
pilot study, both algorithms can
analyze geo-social networks with
millions of vertices (people) in several
minutes on a Linux workstation. This
indicates the feasibility of
decentralized day-to-day operations
in each municipality without additional
charges.
The Louvain algorithm was created
by Blondel et al. [14] from the
University of Louvain, Belgium. It is a
bottom-up clustering algorithm to find
communities large or small, often very
different in size. The METIS algorithm
[15],[16] was created by G. Karypis
and V. Kumar from the University of
Minnesota, USA. It enables parallelprocessing to partition social
networks into communities of similar
Figure 2. Selecting the hubs from a sample geo-social network. sizes.
Figure 1. Sample geo-social network of a small consulting company.
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 65The first dataset we tested on is a
Googleþ social network dataset [17],
including 107 614 people, and 13 673
453 links among them. On average
each person is connected to 127
others. This number is comparable to
the number of people a working
professional meets daily in a busy
metropolis using public
transportation. It is a densely
connected network.
The second dataset we tested on is
an Internet server topology dataset
[18] originally assembled to study the
transmission of computer viruses. It
has 1 696 415 vertices (machines)
and 11 095 298 links among them. On
average each machine is connected
to 6.5 others. This number is
comparable to the number of people
a working professional meets daily in
a small town without using public
transportation. It is a sparsely
connected network.
To be clear, we do not assume that
COVID-19 transmits along with cybersocial networks. We consider the two
datasets previously because they
have network structures similar to
geo-social networks of the workforce,
which has close-range physical
interactions daily in a reopened
economy.
Our study is designed in the following
four steps. First, we partition the
network datasets into U clusters
using the METIS algorithm and the
Louvain algorithm. Then in each
cluster, we single out K individuals
who have the most connections
within the cluster. In total, we have
U
K individuals chosen for COVID-19
testing. As a simpler baseline choice,
we single out the top U
K individuals
with the most connection links in the
complete geo-social network. We
adopted the value of parameter U as
the total number of individuals S
divided by 100 or 1000. In this way,
the total amount of individuals chosen
[U
K] will be a percentage of the total
population. The evaluation metric is
the coverage of the tested individuals,
defined as the number of individuals
immediately linked to the tested
individuals divided by the total
number of individuals. The four steps
are illustrated in Figure 2 using the
sample described in Figure 1.
FINDINGS
The following two tables list the
coverage rates from three different
algorithms on two real-world
datasets. They can tell us to an extent
how well the geo-social network
sampling and testing cover the
population in a reopened economy.
The “Coverage” percentages are
calculated as the percentage of
people who had close contacts with
the COVID-19 test subjects, out of the
general population.
On both datasets and all sampling
percentages, the METIS algorithm
steadily outperforms other algorithms
in terms of coverage rate. This does
not indicate that the Louvain
algorithm is inferior. It was designed
to identify natural-looking
subcommunities large and small. Its
most suitable use would be to
visualize and trace local community
transmission.
On the densely connected Googleþ
dataset, we are indeed running a
simulation of busy urban life such as
that in NYC, or Wuhan. Results listed
in Table 1 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
Table 2. Coverage Percentage out of Geo-Social Network Sampling
Test on Skitter Dataset.
Table 1. Coverage Percentage out of Geo-Social Network Sampling
Test on Googleþ Dataset.
66 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020an immediate-connection coverage of
74.1% of the population. By sampling
2% of the population, we can
effectively represent an immediateconnection coverage of 92.3% of the
population. Beyond 2% sampling,
extra sampling and testing work offer
marginal benefit.
On the sparsely connected Skitter
dataset, we are indeed running a
simulation of quiet small-town life
such as that in Ithaca upstate NY, or
Suifenhe China. Results listed in
Table 2 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
an immediate-connection coverage of
51.4% of the population. By sampling
3% of the population, we can
effectively represent an immediateconnection coverage of 77.7% of the
population. Beyond 3% sampling,
extra sampling and testing work offer
marginal benefit.
DISCUSSIONS
In summary, our study shows that a
highly efficient sampling, testing, and
tracing scheme can be achieved by
constructing the geo-social network of
a city or township, safeguarding the
economy reopening. The busier the
city is, the smaller percentage we
need to test for COVID-19. We
estimate that 0.3% to 3% can monitor
COVID-19 transmission covering the
majority of the population. This is not
to say that our sampling can keep
COVID-19 from happening, but rather
a realistic managed low-occurrence
live-with-COVID approach. Also
arguably this is also not as important
as the universal wearing of masks as
PPE.
This pilot study assumes that a geosocial network dataset for each city/
township can be constructed every
day. Indeed it can, only if with public
consensus and government
oversight. Our cellphones currently
produce multiple location-tracking
data streams, including
telecommunication tracking,
operating system tracking, and map
API-based tracking. In each nation,
the cellphone service providers
acquire coarse-resolution tracking
data streams via the triangulation of
3G/4G base stations. Operating
system tracking data stream exists in
each Android phone and IPhone as
an essential service by integrating
GPS and WiFi signals. In addition,
most of the cellphone apps on the
market call various precision map/
location service APIs from Google
Map, Amap, Bing Maps, Baidu maps,
HERE maps, or Tencent maps for
location upon App use. That tracking
computes the 3G/4G signal along
with GPS and WiFi. The current data
records link location to each unique
cellphone, but not to individual
persons. These data records are
highly confidential and literally
guarded by laws like the European
GDPR against wanton usage.
Societies already embraced some of
their usages in real time, such as
Google traffic alert [33]. Hence, a
geo-social network of anonymous
cellphones can be quickly computed
out of existing data streams, with the
right permission clearance. This
study does not advocate collecting
cellphone location data with personal
IDs.
Geo-social network could be
constructed through another
process, arguably less intrusive.
Google and Apple are developing a
Bluetooth contact-alert service [19].
It can tell the user whether his/her
phone was within Bluetooth
distance of a COVID-19 patient’s
phone recently. However, this
feature is only valid if everyone
turns Bluetooth on and, thus, may
not eventually work out. By now,
this effort has largely died OFF.
With location data sitting idle with the
telecommunication service providers
and tech giants, the general public,
and national governments may want
to discuss and decide whether or not
to make use of it during the pandemic
[20], [21]. People have valid reasons
to worry about privacy,[22] but these
are not normal times [23]. Safe and
moral usages of this data flow require
mandatory erasure of any and all
personal details from the dataset and
render it anonymous except to
oneself. For example, only the citizen
him/herself can know that he/she is a
hub of the geo-social network. If he/
she wants to show up for work without
endangering coworkers, he/she
needs to have a free COVID-19 test.
When a patient’s test comes back
positive, then the people who had a
recent interaction with him/her have
the right to be notified via their
phones. Automatic contact tracing
can be done with technology instead
of spreading thin our medical
workforce in the field. When the
pandemic is about to be fully
eliminated, this “war-time”
infrastructure should be dismantled
so as not to be abused in peacetime.
We find it is logistically feasible for
local facilities to operate a daily
routine. First, every night, the local
locational data flows from either
telecommunication providers or tech
giants are used to construct the geosocial network of the previous day.
Residents who are the identified
0.3%–3% hubs in that network wake
up the next morning with a text
message notification for a quick test
before showing up for work. Testing
capacities vary from region to region.
Some developed nations might afford
to test them every day. Developing
nations might afford to test once a
week. Either way helps.
To further alleviate the pressure on
logistics, nations can consider a
recent practice [30] in Wuhan,
China during May 13–22, 2020.
Nasal swabs from multiple persons
from the same neighborhood are
mixed into one testing. This is
known as pooled testing. It reduces
logistics pressure of testing to 1/5
or even 1/10, compared to
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 67conducting 1 test for each
individual. In the United States, the
importance of pooled testing is just
gaining recognition [31], but not yet
implemented en masse.
Pooled testing and geo-social
network sampling can boost each
other in many ways. First, each batch
in pooled testing can consist of
individuals from the same “clique” of
the geo-social network because they
share similar risks of infection.
Second, when testing resources are
very scarce, pooled testing of
selected “hubs” in the geo-social
network can be highly efficient. Third,
tracing of infection chains can be
achieved with geo-social networks
after pooled testing.
Another possibility to improve this
approach is to integrate the infection
rate of population groups into the geosocial network. A vanilla geo-social
network can measure the chance of
exposure to infection. When
multiplied by the infection rate of age
groups, it can measure the chance of
infection.
Around the world, pilot experiments
on locational tracking to fight the
pandemic are sprouting, for example
in Israel [24], South Korea [21], and
China [25]. In China, Alibaba and
Tencent scrambled to work with
government oversight creating
location-based health-checkup Apps
starting in late January 2020. The
initial version went online on February
11 after 2 weeks of intensive
development [26]. It can only trace
location down to city blocks and tell
the user whether they have been to
COVID-19 hot zones in the past 14
days. The majority of the Chinese
public chose to adopt this
infrastructure. Along with other
measures such as universal maskwearing and quarantines, it
contributed significantly to the
Chinese effort of containing and
almost total elimination of COVID-19.
This effort released openly its
technical whitepapers [25] on May 1,
2020. However, at the time being
there is yet no reported effort to use
that infrastructure for proactive
nucleic or antibody testing for the
general public.
On April 27, Science Magazine
recently called for the utilization of
mobile phone data for modeling and
contact tracing [27]. Gradually,
policymakers, scientists, and
engineers globally are coming to
realize that data from mobile phones
can help them combat COVID-19. It is
important that peoples are aware of
this option, can debate about it, and
make a decision for their own nation.
We do not yet know how long this
pandemic lasts and how bad it can
go. Therefore, all options should stay
on the table. For epicenters of the
pandemic, government might want to
integrate all possible measures
together to turn the tide against the
pandemic.
This pilot study is a baby step to
introduce to the field of public health
the importance of social network
analyses. We have already seen the
use of traditional S-I-R modeling for
infectious diseases since the onset of
the pandemic. The S-I-R models
assume equal infection risk for all
individuals and, thus, is insufficient
alone. Social network analyses
provide insights into exposure risks of
each individual and, thus, can be
integrated into S-I-R models for
S-E-I-R modeling. We assume that
everyone has equal immunity in our
model because of limited data. If
possible to collect more detailed
information about individuals, we
hope to improve our model
considering the covariates affecting
personal immunity. To battle the
pandemic and potentially endemic
COVID-19 as a planetary challenge,
interdisciplinary teamwork among
epidemiologists, computer scientists
and data scientists, and lawmakers is
needed. We hope to see our model
revised and applied in policies and
day-to-day operations [28]. Modeling
can only tell us so much. Politics does
the rest [29]. The bottom line against
dystopian use of location data is to
construct a geo-social network of
anonymous cellphones, not of people
without privacy. Make this a service
instead of surveillance. And this
service should only be temporary
during the pandemic. Our planet after
the pandemic does not need
Geoslavery [22].
CONTRIBUTORS
Conceptualization: KS/HW;
Programming and Analysis: ZQ/SJ/
KS; Writing: KS/HW.
ACKNOWLEDGMENT
The authors would like to thank L. Yu,
C. Deng, C. Pei, W. Jiang, L. Xu, and
K. Dong for many rounds of fruitful
discussions. The open access fee for
this article was provided by Gago
Inc,. Beijing, China.



NEW_PAPER

Received May 13, 2020, accepted June 17, 2020, date of publication June 19, 2020, date of current version July 1, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3003810
Iteratively Pruned Deep Learning Ensembles
for COVID-19 Detection in Chest X-Rays
SIVARAMAKRISHNAN RAJARAMAN 1
, (Member, IEEE), JENIFER SIEGELMAN2
,
PHILIP O. ALDERSON3
, LUCAS S. FOLIO4,5, LES R. FOLIO6
,
AND SAMEER K. ANTANI 1
, (Senior Member, IEEE)
1Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD 20894, USA
2Takeda Pharmaceuticals, Cambridge, MA 02139, USA
3School of Medicine, Saint Louis University, St. Louis, MO 63104, USA
4Functional and Applied Biomechanics Section, Clinical Center, National Institutes of Health, Bethesda, MD 20892, USA
5Walt Whitman High School, Bethesda, MD 20817, USA
6Radiological and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, MD 20894, USA
Corresponding author: Sivaramakrishnan Rajaraman (sivaramakrishnan.rajaraman@nih.gov)
This work was supported by the Intramural Research Program of the National Library of Medicine (NLM), and the U.S. National Institutes
of Health (NIH).
ABSTRACT We demonstrate use of iteratively pruned deep learning model ensembles for detecting
pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus
(2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are
trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific
feature representations. The learned knowledge is transferred and fine-tuned to improve performance
and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or
COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and
improve memory efficiency. The predictions of the best-performing pruned models are combined through
different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that
the weighted average of the best-performing pruned models significantly improves performance resulting in
an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The
combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning
resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening
using chest radiographs.
INDEX TERMS COVID-19, convolutional neural network, deep learning, ensemble, iterative pruning.
I. INTRODUCTION
Novel Coronavirus disease 2019 (COVID-19) is caused
by the new Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2) that originated in Wuhan in
the Hubei province in China and has spread worldwide.
The World Health Organization (WHO) declared the outbreak a pandemic on March 11, 2020 [1]. The disease is
rapidly affecting worldwide population with statistics quickly
falling out of date. As of April 12, 2020, there are over
1.8 million confirmed cases reported globally with over
100,000 reported deaths. Lung disease that causes difficulty
in breathing has been reported as an early indicator along
with hyperthermia in the COVID-19 infected population [1].
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque .
The lung abnormalities caused by non-2019-nCOV viruses
are observed as peripheral or hilar and visually similar to,
yet often distinct from, viral pneumonia and other bacterial
pathogens [2].
Reverse transcription-polymerase chain reaction
(RT-PCR) tests are performed to detect the presence of
the virus and are considered the gold standard to diagnose
COVID-19 infection. However, they are reported to have
variable sensitivity and in some geographic regions may not
be widely available [3]. While not currently recommended
as primary diagnostic tools, chest X-rays (CXRs) and computed tomography (CT) scans have been used to screen for
COVID-19 infection and evaluate disease progression in
hospital admitted cases [3], [4]. While chest CT offers greater
sensitivity to pulmonary disease, there are several challenges
to its use. These include the non-portability, the requirement
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 115041S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 1. Graphical abstract of the proposed study.
to sanitize the room and equipment between patients followed
by a delay of at least an hour [4], the risk of exposing
the hospital staff and other patients, and persons under
investigation (PUIs) to the virus. Although not as sensitive,
portable CXRs are considered as an acceptable alternative
[4] since the PUIs can be imaged in more isolated rooms,
limiting personnel exposure and because sanitation is much
less complex to obtain than with CT.
Automated computer-aided diagnostic (CADx) tools
driven by automated artificial intelligence (AI) methods
designed to detect and differentiate COVID-19 related thoracic abnormalities should be highly valuable given the heavy
burden of infected patients. This is especially important in
locations with insufficient CT availability or radiological
expertise and CXRs produce fast, high throughput triage such
as in a mass casualty [5]. Automated approaches, once validated, have been shown to reduce inter- and intra-observer
variability in radiological assessments [6]. Additionally,
CADx tools have gained immense significance in clinical
medicine by supplementing medical decision making and
improving screening and diagnostic accuracy [7]. These tools
combine elements of radiological image processing with
computer vision for identifying typical disease manifestations and localizing suspicious regions of interest (ROI).
At present, recent advances in machine learning, particularly
data-driven deep learning (DL) methods using convolutional
neural networks (CNNs), have shown promising performance
in identifying, classifying, and quantifying disease patterns
in medical images. This is particularly true for CT scans
and CXRs [7]. These models learn the hierarchical feature
representations from medical images to analyze for typical
disease manifestations and localize suspicious densities for
ROI evaluation [7].
In this study, we highlight the benefits offered through the
use of an ensemble of iteratively pruned DL models toward
distinguishing CXRs showing COVID-19 pneumonia-related
opacities, from bacterial pneumonia, and normals using publicly available CXR collections. Fig. 1 shows the graphical abstract of the proposed study. Fig. 2 shows instances
of CXRs being normal, showing bacterial pneumonia, and
COVID-19-related pneumonia.
A custom CNN and a selection of pretrained CNN models are trained on a large-scale selection of CXRs to learn
CXR modality-specific feature representations. The learned
knowledge then is transferred and fine-tuned to classify the
normal and abnormal CXRs. We leverage the benefits of
modality-specific knowledge transfer, iterative pruning, and
FIGURE 2. CXRs showing (A) clear lungs, (B) bacterial pneumonia
manifesting as consolidations in the right upper lobe and retro-cardiac
left lower lobe, and (C) COVID-19 pneumonia infection manifesting as
peripheral opacities in the left lung.
ensemble strategies to reduce model complexity, improve
robustness, generalization, and inference capability of the DL
model.
The remainder of the manuscript is organized as follows:
Section II discusses prior works. Section III discusses
the datasets and methods used toward modality-specific
knowledge transfer, iterative pruning, and ensemble learning. Section IV elaborates on the results obtained, and
Section V concludes the study with a discussion on the merits
and limitations of the proposed approach and future work
directions.
II. PRIOR WORK
A. COVID-19 DETECTION
A study of the literature reveals several AI efforts for
COVID-19 screening. The authors of [3] distinguished
COVID-19 viral pneumonia manifestations from that of other
viral pneumonia on chest CT scans with high specificity.
It was observed that COVID-19 pneumonia was found to be
peripherally distributed with ground glass opacities (GGO)
and vascular thickening. The authors of [8] established
a publicly available collection of 275 CT scans showing
COVID-19 pneumonia manifestations and trained a deep
CNN to achieve 0.85 F-score in classifying CTs as normal or showing COVID-19 pneumonia-related opacities.
The authors of [9] used a customized CNN and pretrained
AlexNet model to classify CXRs as normal or showing
COVID-19 pneumonia with 94.1% and 98% accuracy respectively. The authors of [10] used a ResNet-50 [11] CNN to
classify normal, pneumonia, and COVID-19 viral pneumonia manifestations in CXRs and achieved an accuracy of
98.18 % and F-score of 98.19. CXRs are also commonly
analyzed to diagnose and differentiate other types of pneumonia including bacterial and non-COVID-19 viral pneumonia
[2]. The authors of [12] proposed a custom CNN model
that was designed by combining manual design prototyping with a machine-driven designing approach to classify
CXRs as normal or showing non-COVID-19 or COVID-19
pneumonia-related opacities with 92.4% accuracy.
B. MODALITY-SPECIFIC KNOWLEDGE TRANSFER
With limited amounts of COVID-19 pneumonia CXR data,
traditional transfer learning strategies offer promise [13]
where the learned feature representations are fine-tuned to
115042 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
improve performance. However, unique challenges posed
in the appearance of medical images [6] including high
inter-class similarity and low intra-class variance lead to
model bias and overfitting resulting in reduced performance and generalization. These issues can be alleviated
through modality-specific knowledge transfer by retraining
CNN models on a large CXR image collection to learn
modality-specific feature representations. Modality-specific
model knowledge transfer [14] and ensembles [15] have
demonstrated superior disease ROI localization compared to
individual constituent models.
C. MODEL PRUNING
To alleviate burdens from computing resources, DL models
can be pruned to reduce the inference cost and facilitate
deployment in low-resource conditions with no loss or even
improvement in performance. Reed [16] performed a neural model pruning to decrease computational complexity.
Hassibi et al. [17] deleted network parameters by leveraging
the second derivative term in the Taylor series and improved
model generalization. The authors of [18] found that the
earlier layers in the neural networks have low activations
that can effectively be excluded from the network without
affecting the model performance. They proposed an iterative
optimization method to gradually eliminate the neurons with
the least activations toward reducing the memory and power
requirements and promoting faster model inference. When
applied to medical imaging, the authors of [19] proposed a
genetic algorithm-based pathway evolution strategy to prune
DL models. This resulted in a 34% reduction in the network
parameters and improved the mass classification performance
in breast mammograms. A systematic weight pruning strategy [20] was used to prune a YOLO-model [21] based pneumonia detector for classifying CXRs as normal or showing
pneumonia-like manifestations using the Radiological Society of North America (RSNA) [22] CXR collection. However,
there is room for further research in this area.
D. ENSEMBLE CLASSIFICATION
CNNs are non-linear models that learn complex relationships
from the data through error backpropagation and stochastic
optimization, making them highly sensitive to random weight
initializations and the statistical noise present in the training
data. These issues can be alleviated by ensemble learning
by training multiple models and combining their predictions
where an individual model’s weaknesses are offset by the
predictions of other models. Combined predictions are shown
to be superior to individual models [23]. There are several
ensemble strategies reported in the literature including max
voting, simple and weighted averaging, stacking, boosting,
blending, and others that are shown to minimize the variance
error and improve generalization and performance of CNN
models. Applied to CXRs, the authors of [7], [14], and [24]
leveraged the use of an ensemble of CNN models toward
improving TB detection in CXRs. An averaging ensemble
of pretrained CNNs was used by the authors of [25] toward
improving cardiomegaly detection using CXRs.
TABLE 1. Dataset characteristics. Numerator and denominator denotes
the number of train and test data respectively (N = Normal,
UP = Pneumonia of unknown type, BP = Bacterial (proven)
pneumonia, CP = COVID-19 pneumonia).
III. MATERIALS AND METHODS
A. DATA COLLECTION AND PREPROCESSING
Table 1 shows the distribution of CXRs across different
categories. We used the following four publicly available
CXR collections in this retrospective analysis:
1) PEDIATRIC CXR DATASET [2]
The authors collected from Guangzhou Women and
Children’s Medical Center in Guangzhou, China, the anteriorposterior (AP) CXRs of children from 1 to 5 years of
age, showing normal lungs, bacterial pneumonia, and
non-COVID-19 viral pneumonia. Expert radiologists curated
the CXR collection to remove low-quality chest radiographs.
2) RSNA CXR DATASET [22]
This multi-expert curated dataset includes images from the
National Institutes of Health (NIH) CXR-14 dataset [26].
The dataset was released for the Kaggle pneumonia detection challenge, organized jointly by RSNA and NIH. The
collection includes normal CXRs and abnormal images with
non-pneumonia and pneumonia-like opacities. The images
are made available at 1024×1024 pixel resolution in DICOM
format.
3) TWITTER COVID-19 CXR DATASET
A cardiothoracic radiologist from Spain made available a
collection of 134 CXRs with 2K×2K pixel resolution in
JFIF format via Twitter of SARS-CoV-2 positive subjects.
(https://twitter.com/ChestImaging)
4) MONTREAL COVID-19 CXR DATASET [27]
A publicly available periodically updated GitHub repository
that includes COVID-19 CXR cases and other pulmonary
viral disease manifestations in AP, posterior-anterior (PA),
and AP-Supine views. As of April 7, 2020, the repository had
179 CXRs showing COVID-19 pneumonia-related opacities.
We performed patient-level splits of these CXR collections
to allocate 90% for training and 10% for testing at different stages of learning discussed in this study. We randomly allocated 10% of the training data to validate the DL
models. The ground truth (GT) for the test set, comprising
of 27 CXRs showing COVID-19 pneumonia-related opacities
is set by the verification of publicly identified cases from
expert radiologists who annotated the test set.
B. LUNG ROI SEGMENTATION
While mild COVID-19 cases mimic common upper
respiratory viral infections, advanced disease results in
VOLUME 8, 2020 115043S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 3. The segmentation approach showing U-Net based mask
generation and Lung ROI cropping.
FIGURE 4. Architecture of the customized CNN model. (I/P = Input,
CONV = Convolution, GAP = Global average pooling, DO = Dropout,
D = Dense with Softmax activation, N = Normal predictions,
A = Abnormal Predictions).
respiratory dysfunction and is the principal cause for
triggering mortality. In developing DL solutions for detecting
the disease, it is important to guard them against irrelevant
features that could severely affect reliable decision-making.
For this study, we performed U-Net based semantic segmentation [28] to segment the lung pixels from the background.
We used a U-Net with Gaussian dropout layers [29] added to
the U-Net encoder. A dropout ratio of 0.2 was empirically
determined and used in this study. Fig. 3 illustrates the
segmentation steps performed in this study.
We used a collection of CXRs with lung masks from
[30] to train the U-Net model to generate lung masks of
256 × 256 pixel resolution for the aforementioned datasets.
We used model checkpoints to monitor its performance and
stored only the best model weights to generate the final lung
masks. These masks then are superimposed on the CXR
images to crop them as a bounding box containing the lung
pixels. The cropped lungs are resized to 256×256 pixel resolution. The lung crops are further preprocessed by performing
pixel rescaling, median filtering for noise removal and edge
preservation, normalization for mean, and standardization for
identical feature distribution. The preprocessed lung crops are
used for model training and evaluation at different stages of
learning discussed in this study.
C. MODELS AND COMPUTATIONAL RESOURCES
We evaluated the performance of a customized CNN and
a selection of ImageNet pretrained CNN models, viz.,
a) VGG-16 [31], b) VGG-19 [31], c) Inception-V3 [32], d)
Xception [33], e) InceptionResNet-V2 [32]; f) MobileNet-V2
[34], g) DenseNet-201 [35], and h) NasNet-mobile [36].
Our customized CNN is a linear stack of strided separable
convolution layers, global average pooling (GAP), and a
dense layer with Softmax activation. Fig. 4 shows the architecture of the custom CNN used in this study. We used
Dropout to reduce issues due to model overfitting by providing restricted regularization and improving generalization
by reducing the model sensitivity to the specifics of the
training input [29]. We used strided convolutions that were
shown to improve performance on several visual recognition
benchmarks, compared to max-pooling layers [37]. Separable
convolutions were used to reduce model parameters [33] and
FIGURE 5. Architecture of the pretrained CNNs. (I/P = Input,
PCNN = truncated model, ZP = Zero-padding, CONV = Convolution,
GAP = Global Average Pooling, DO = Dropout, D= Dense with Softmax
activation, O/P = Output).
improve performance compared to conventional convolution
operations. The number of separable convolutional filters are
initialized to 32 and increased by a factor of two in the
successive convolutional layers. We used 5 × 5 filters and
a stride length of 2 in all convolutional layers. We added a
GAP layer to average the spatial feature dimensions that are
fed into the final dense layer with Softmax activation.
We used the Talos optimization package [38] to optimize
the parameters and hyperparameters of the customized CNN
that include a) dropout ratio, b) optimizer and c) non-linear
activation function. The model is trained and evaluated
with the optimal parameters to classify the CXRs to their
respective categories.
We instantiated the pretrained CNN with their ImageNet
weights and truncated them at the fully-connected layers.
The following layers are added to the truncated model:
(a) zero-padding, (b) a strided separable convolutional layer
with 5 × 5 filters and 1024 feature maps, (c) GAP layer,
(d) Dropout layer with an empirically determined dropout
ratio of 0.5, and (e) final dense layer with Softmax activation.
Fig. 5 shows the customized architecture of the pretrained
models used in this study.
We optimized the following hyperparameters of the
pretrained CNNs using a randomized grid search method
[39]: (a) momentum, (b) L2-regularization, and (c) initial
learning rate of the Stochastic Gradient Descent (SGD) optimizer. The search ranges were initialized to [0.85 0.99],
[1e−10 1e−3], and [1e−9 1e−2] and for the momentum,
L2-regularization, and the initial learning rate respectively.
The pretrained CNNs were retrained with smaller weight
updates to improve generalization and categorize the CXRs
to their respective classes. Class weights were used during
model training to penalize the overrepresented classes to
prevent overfitting and improve performance [40]. We used
model checkpoints to store the best model weights for further
analysis.
D. MODALITY-SPECIFIC TRANSFER LEARNING
AND FINE-TUNING
We performed modality-specific transfer learning where
the customized CNN and ImageNet pretrained models are
retrained on the RSNA CXR collection to learn CXR
modality-specific features and classify the CXRs into
normal and abnormal categories. The RSNA CXR collection includes normal CXRs and abnormal images containing pneumonia-related opacities. In this way, the weight
layers are made specific to the CXR modality through
learning the features of normal and abnormal lungs. The
learned knowledge is transferred and fine-tuned to a related
task of classifying CXRs that are pooled from pediatric,
115044 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
Twitter COVID-19, and Montreal COVID-19 CXR collections, respectively, as normal, or showing bacterial pneumonia, or COVID-19 pneumonia-related opacities, to improve
classification performance.
The top-3 performing modality-specific CNNs are
instantiated and truncated at their deepest convolutional
layer and added with the following layers: (a) zero-padding,
(b) a strided separable convolutional layer with 5 × 5 filters and 1024 feature maps, (c) GAP layer, (d) Dropout
layer and (e) final dense layer with Softmax activation. The
modified models are fine-tuned to classify CXRs as being
normal or showing bacterial pneumonia or COVID-19 viral
pneumonia. Class weights were used during model training to
award higher weights to the under-represented class to reduce
issues due to class imbalance and improve generalization
and performance. Fine-tuning is performed through SGD
optimization and model checkpoints were used to store the
best weights for further analysis.
E. ITERATIVE MODEL PRUNING
We iteratively pruned the fine-tuned models to find the
optimal number of neurons in the convolutional layers to
reduce model complexity with no loss in performance.
We gradually eliminated the neurons with fewer activations
at each time step through iterative pruning and model retraining. We used the average percentage of zeros (APoZ) [18],
the percentage of zero neuron activations observed with the
validation dataset, as the measure to rank the neurons in each
convolutional layer. We iteratively pruned a percentage of
neurons with the highest APoZ from each layer at each time
step and retrained the pruned model. The process is repeated
until the maximum percentage of pruning is achieved. The
best-pruned model is then selected from the collection of
iteratively pruned models based on their performance with
the test set. The retrained pruned model is expected to achieve
similar or better performance than the unpruned models with
reduced model complexity and computational requirements.
The algorithm for iterative pruning performed in this study is
described below:
F. LEARNING ITERATIVELY PRUNED ENSEMBLES
The best performing pruned models are selected to construct
the ensemble to improve prediction performance and generalization as compared to any individual constituent model.
We used several ensemble strategies including max voting,
averaging, weighted averaging, and stacking to combine the
predictions of the pruned models toward classifying CXRs as
normal or showing bacterial or COVID-19 viral pneumoniarelated opacities. For the stacking ensemble, we used a neural
network-based meta-learner that learns to optimally combine the predictions of the individual pruned models. The
meta-learner consisting of a single hidden layer with nine
neurons is trained to interpret the multi-class input from
the top-3 pruned models and a final dense layer outputs
the predictions to categorize the CXRs to their respective
classes.
Algorithm 1 Iterative Pruning
Input: B = {(xi, yi)|xi ∈ X, yi ∈ Y }, pruning percentage
(P), maximum pruning percentage (M)
1. Train and evaluate the base models on B and store the
best model weights
2. while percent pruned (PP) <= M do
a. Calculate the number of filters in each convolutional layer
b. Identify and delete P percentage of filters in each
convolutional layer with the highest average percentage of zeros
c. Retrain and evaluate the pruned model on B and
store the best-pruned weights
d. PP + = P
e. Incrementally prune the network, retraining it each
time and save the pruned model
end while
Return: M + 1 number of pruned models
G. VISUALIZATION STUDIES
Visualizing the learned behavior of the DL models is a
debated topic, particularly in medical visual recognition
tasks. There are several visualization strategies reported in
the literature that include (a) visualizing the overall network structure and (b) gradient-based visualization that
performs gradient manipulation during network training.
Gradient-weighted class activation mapping (Grad-CAM)
is a gradient-based visualization method that computes the
scores for a given image category concerning the feature maps of the deepest convolutional layer in a trained
model [41]. The gradients that are flowing backward are
pooled globally to measure the importance of the weights
in the decision-making process. In this study, we verified
the learned behavior of the pruned models by comparing
salient ROI with consensus GT annotations from experienced
radiologists.
H. STATISTICAL ANALYSES
We analyzed the model’s performance for statistical
significance at different stages of learning. We used confidence intervals (CI) as the measure to analyze the skill
of the CNN models. A shorter CI infers a smaller margin
of error or a relatively precise estimate while a larger CI
allows more margin for error and therefore results in reduced
precision [42]. We computed the 95% CI values for the
AUC at different learning stages to explain the models’
predictive performance. The CI values are computed to be
the Clopper–Pearson exact interval that corresponds to the
separate 2-sided interval with individual coverage probabilities of (0.95)1/2
. We used StatsModels version 0.11.0 to
compute CI measures. The codes associated with this study
are made available at https://github.com/sivaramakrishnanrajaraman/Iteratively-pruned-model-ensembles-for-COVID19-detection-in-CXRs.
VOLUME 8, 2020 115045S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 2. Optimal values for the parameters and hyperparameters for the
custom and pretrained models obtained through optimization tools
(M = Momentum, ILR = Initial learning rate, L2 = L2-weight decay,
and D = Dropout ratio).
TABLE 3. Performance metrics achieved during modality-specific transfer
learning using the RSNA CXR dataset (Acc. = Accuracy; Sens. = Sensitivity,
Prec. = Precision, F = F-score, MCC = Matthews correlation coefficient,
and Param. = trainable parameters). The values in square brackets show
the 95% CI that are computed to be the Clopper–Pearson exact interval
corresponding to the separate 2-sided interval with individual coverage
probabilities of (0.95)1/2.
IV. RESULTS AND DISCUSSION
The optimal values for the parameters and hyperparameters
obtained for the customized and pretrained CNNs with
the Talos optimization tool and randomized grid search,
respectively, are shown in Table 2.
Table 3 shows the performance achieved through
modality-specific knowledge transfer, by the customized and
pretrained CNNs using the RSNA CXR dataset.
It can be observed that the VGG-16, VGG-19, and
Inception-V3 models were more accurate than the other models under study. The aforementioned models demonstrated
promising AUC values with a shorter CI and hence a smaller
margin of error, thereby offering precise estimates compared
to the other models. This is because the architecture depths
of the VGG and Inception-V3 models are optimal to learn
the hierarchical representations of features from the CXR
data and classify them into normal and pneumonia classes.
Considering the F-score and MCC that give a balanced
measure of precision and recall, the aforementioned models
delivered performance that was superior to the other models.
TABLE 4. Performance metrics achieved by the top-3 modality-specific
knowledge transfer models on the target tasks.
The top-3 performing modality-specific knowledge
transfer models (VGG-16, VGG-19, and Inception-V3) are
instantiated with their modality-specific weights and truncated at their fully connected layers and appended with the
task-specific heads. Table 4 shows the performance achieved
by the task-specific models toward the following classification tasks: (a) binary classification to classify CXRs as
normal or COVID-19 pneumonia and (b) multi-class classification to classify CXRs as normal or as showing bacterial
pneumonia or COVID-19 pneumonia.
It can be observed that for the binary classification task, all
the models are 100% accurate, however, VGG-16 has the least
number of trainable parameters. For multi-class classification, it can be observed that the Inception-V3 model was more
accurate with a shorter CI for the AUC metric, signifying that
it has the least margin for error and hence provides a more precise estimate. Considering F-score and MCC, the InceptionV3 model delivered superior performance compared to
VGG-16 and VGG-19 models.
For the multi-class classification task, the predictions
of the task-specific models (VGG-16, VGG-19, and
Inception-V3) are combined through several ensemble
methods including max voting, simple averaging, weighted
averaging, and model stacking. We didn’t perform ensemble
learning for the binary classification task since the individual models are 100% accurate in classifying CXRs as
normal or showing COVID-19 pneumonia-related opacities.
Table 5 shows the performance achieved for the multi-class
classification with different ensemble strategies. It can be
observed that a simple average of the models’ predictions
is more accurate with a shorter CI for the AUC metric,
signifying a smaller margin of error and therefore, higher
precision, compared to other ensemble methods. Considering
the F-score and MCC, the averaging ensemble outperformed other ensemble strategies in classifying CXRs as
normal, or as showing bacterial pneumonia or COVID-19
viral pneumonia.
For the multi-class classification task, we iteratively
pruned the task-specific models (VGG-16, VGG-19, and
115046 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 5. Performance metrics achieved by the unpruned models through
different ensemble strategies for the multiclass classification task.
TABLE 6. Performance metrics achieved by the best iteratively pruned
models and compared with the baseline unpruned models from Table 4
(U-unpruned and P-pruned).
Inception-V3) by removing 2% of the neurons with the
highest APoZ in each convolutional layer at a given time
step and retrained the pruned model to evaluate its performance on the validation set. We used model checkpoints to
store the best-pruned model that gave a superior performance
with the validation set. The process is repeated until the
maximum pruning percentage of 50% is reached. We then
evaluated the performance of all the pruned models on the test
set. The pruned model that achieved superior performance
with the test set is used for further analysis.
Table 6 shows a comparison of the performance achieved
by the pruned models to that of the baseline, unpruned
task-specific models shown in Table 4. It can be observed
that the pruned models are more accurate than their unpruned
counterparts. Considering the F-score and MCC metrics,
the pruned models are found to deliver superior performance than the unpruned models. It is interesting to note
that the performance improvement is achieved with a significant reduction in the number of parameters. As can
be seen, the number of parameters in the pruned VGG16 model reduced by 46.03% compared to its unpruned
counterpart. Similarly, the number of trainable parameters
reduced by 16.13% and 36.1% for the pruned VGG-19 and
Inception-V3 models, respectively, with the added benefit of
FIGURE 6. Grad-CAM Visualizations showing salient ROI detection by
different pruned models. (A) CXR showing COVID-19 viral
pneumonia-related opacities with GT annotations, (B) VGG-16 pruned
model, (C) VGG-19 pruned model, and (D) Inception-V3 pruned model.
Bright red corresponds to the pixels carrying higher importance and
hence weights for categorizing the test sample to the COVID-19 viral
pneumonia category.
performance improvement in terms of accuracy, F-score, and
MCC metrics, compared to their unpruned counterparts.
Fig. 6 shows the results of performing Grad-CAM
visualizations to localize the salient ROIs used by the different pruned models to classify a sample test CXR into the
COVID-19 viral pneumonia category. The visualizations are
compared with consensus GT annotations provided by the
expert radiologists. The predictions of the pruned models are
decoded for the test sample. Two-dimensional heat maps are
generated in bright red, which corresponds to the pixels carrying higher importance and hence weights for categorizing
the test sample to COVID-19 pneumonia infected category.
Distinct color transitions are observed for varying ranges
of pixel importance toward making the predictions. Salient
ROIs are localized by superimposing the heat maps on the
input sample CXR. It is observed that the pruned models
precisely localize the salient ROI. This underscores the fact
that the pruned models have learned the implicit rules that
generalize well and conform to the experts’ knowledge about
the problem.
Table 7 shows a comparison of the performance metrics
achieved with the different ensemble strategies for the
unpruned and pruned models toward classifying the CXRs as
normal or showing bacterial pneumonia, or COVID-19 viral
pneumonia.
While performing weighted averaging ensemble for both
unpruned and pruned models, the predictions are awarded the
importance based on their F-score and MCC measures that
offer a balanced measure of precision and sensitivity. From
Table 6, it can be observed that the pruned and unpruned
VOLUME 8, 2020 115047S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 7. Comparing the performance metrics achieved with the pruned
and unpruned model ensembles from Table 4.
FIGURE 7. Confusion matrix obtained with the weighted-average pruned
ensemble.
Inception-V3 model delivered superior performance, followed by VGG-19 and VGG-16 models. In this regard, we
assigned weights of 0.5, 0.3, and 0.2 to the predictions of
Inception-V3, VGG-19, and VGG-16 models, respectively.
It can be observed that the weighted averaging ensemble
of the predictions of the pruned models delivered superior
performance in all aspects. Fig. 7 and Fig. 8 shows the confusion matrix and AUC curves, respectively, obtained with the
weighted-averaging pruned ensemble.
The 95% CI for the AUC metric has the shortest error
margin with a more precise estimate than that obtained with
the other ensemble methods. Considering the F-score and
MCC, the weighted averaging ensemble outperformed the
other ensemble strategies in classifying CXRs as normal,
bacterial pneumonia, or COVID-19 viral pneumonia.
FIGURE 8. ROC curves showing micro/macro-averaged and class-specific
AUC obtained with the weighted-average pruned ensemble.
V. CONCLUSION
The COVID-19 pandemic has had an enormously negative
impact on population health and national economies worldwide. Early diagnosis has often been suboptimal and serological tests have not been widely available. The opportunity to
utilize CXRs as part of the diagnostic approach could add an
important and nearly universally available tool to the battle
against COVID-19 or other respiratory viruses that might
emerge in the future. In the current study, we demonstrate
that this can be done by applying ensemble DL to findings
seen in CXRs.
Modality-specific transfer learning performed with a
large-scale CXR collection with a diversified data distribution helped in learning CXR modality-specific features. The
learned feature representations served as a good weight initialization and improved model adaptation and generalization
compared to ImageNet pretrained weights, when transferred
and fine-tuned for a related CXR classification task.
Iterative pruning of the task-specific models and selection
of the best performing pruned model not only improved
prediction performance on the test data but also significantly
reduced the number of trainable parameters. This is because
there are redundant network parameters (neurons) in a deep
model that do not contribute to improving the prediction
performance. If these neurons with lesser activations can be
identified and removed, it results in a faster and smaller model
with similar or improved performance than the unpruned
models. This would facilitate deploying these models on
browsers and mobile devices.
We further improved the performance by constructing
ensembles of the pruned models. By empirically evaluating
the performance of the pruned models and awarding weights
based on their predictions, we observed that the weighted
averaging ensemble of the pruned models outperformed the
other ensemble methods.
We performed visualization studies to validate the
pruned model localization performance and found that the
pruned models precisely localized the salient ROI used in
categorizing the input CXRs to their expected categories.
115048 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
We observe that combined use of CXR modality-specific
knowledge transfer, iterative model pruning, and ensemble learning reduced prediction variance, model complexity,
promoted faster inference, performance, and generalization.
However, the success of this approach is controlled by two
broad factors: (i) dataset size and inherent variability, and
(ii) computational resources needed for successful deployment and use. With dataset size, we specifically refer to the
minimum number of topically relevant images, in this case,
CXRs with viral pneumonia that are distinct from bacterial and normal images, that are needed to build confidence
into the ensemble. With computational resources, we recognize the training time and memory constraints required for
practicable deployment. However, low-cost GPU solutions,
high-performance computing (HPC), and cloud technology
would address the feasibility in this regard. Future studies
could explore visualizing and interpreting the learned behavior of the pruned model ensembles and their application
to other screening situations like COVID-19 detection and
localization in 3D CT scans, etc. At present, we expect that
the proposed approach can be quickly adapted for detection
of COVID-19 pneumonia using digitized chest radiographs.



NEW_PAPER



Received August 21, 2020, accepted August 26, 2020, date of publication September 18, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025010
DL-CRC: Deep Learning-Based Chest Radiograph
Classification for COVID-19 Detection: A Novel
Approach
SADMAN SAKIB 1
, TAHRAT TAZRIN 1
, MOSTAFA M. FOUDA 2,3, (Senior Member, IEEE),
ZUBAIR MD. FADLULLAH 1,4, (Senior Member, IEEE),
AND MOHSEN GUIZANI 5
, (Fellow, IEEE)
1Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada
2Department of Electrical and Computer Engineering, College of Science and Engineering, Idaho State University, Pocatello, ID 83209, USA
3Department of Electrical Engineering, Faculty of Engineering at Shoubra, Benha University, Cairo 11629, Egypt
4Thunder Bay Regional Health Research Institute (TBRHRI), Thunder Bay, ON P7B 7A5, Canada
5Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar
Corresponding author: Sadman Sakib (ssak2921@lakeheadu.ca)
This work was supported in part by the MITACS Accelerate under Grant IT18879, and in part by the Natural Sciences and Engineering
Research Council of Canada (NSERC) under Discovery Grant RGPIN-2020-06260.
ABSTRACT With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians
continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities.
Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely
available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be
used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the
COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph
classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other
abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available
sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal
cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI)
algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and
generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train
a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our
customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection
accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few
actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify
our customized CNN model by extensively comparing it with widely adopted CNN architectures in the
literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based,
and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it
can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence
of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.
INDEX TERMS COVID-19, convolutional neural network (CNN), deep learning, generative adversarial
network (GAN), pneumonia.
I. INTRODUCTION
The severe acute respiratory syndrome coronavirus 2 (SARSCoV-2), first observed in Wuhan, China, turned into a global
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
pandemic of COVID-19 (coronavirus disease 2019) [1].
COVID-19 has a destructive impact on the well-being of people, particularly senior citizens and patients with underlying
health conditions and compromised immunity levels. By midJuly 2020, the COVID-19 pandemic already contributed to
over 570,000 mortalities and more than 13 million cases
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 171575S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
of COVID-19 infection [2]. A critical step to combat the
pandemic is to effectively detect COVID-19 infected patients
as early as possible so that they may receive appropriate
attention and treatment. Early detection of COVID-19 is
also important to identify which patients should isolate to
prevent the community spread of the disease. However,
considering the recent spreading trend of the COVID-19,
an effective detection remains a challenging task, particularly
in communities with limited medical resources. While the
reverse transcription polymerase chain reaction (RT-PCR)
test-kits emerged as the main technique for COVID-19 diagnosis, chest X-ray (chest X-ray), computed tomography (CT)
scans, and biomarkers (i.e. high C-reactive protein (CRP),
low procalcitonin (PCT), low lymphocyte counts, elevated
Interleukin-6 (IL6), and Interleukin-10 (IL10)) are also being
increasingly considered by many nations to aid diagnosis
and/or provide evidence of more severe disease progression [3]–[5].
As depicted in Fig. 1, the existing system for detecting
COVID-19 using the aforementioned virus and antibody testing modalities is time-consuming and requires additional
resources and approval, which can be a luxury in many developing communities. Hence, at many medical centers, the test
kits are often unavailable. Due to the shortage of kits and
false-negative rate of virus and antibody tests, the authorities
in Hubei Province, China momentarily employed radiological scans as a clinical investigation for COVID-19 [6].
FIGURE 1. Challenges of existing system and our research focus for
COVID-19 screening in rural areas.
Motivated by this, several researchers and sources
recommend the use of chest radiograph for suspected
COVID-19 detection [7]–[9]. Therefore, radiologists can
observe COVID-19 infected lung characteristics (e.g., ground
glass opacities and consolidation) by harnessing non-invasive
techniques such as CT scan or chest X-ray. However, it is
difficult to differentiate the COVID-19-inflicted features
from those of community acquired bacterial pneumonia [10].
Therefore, for many patients, manual inspection of the radiograph data and accurate decision making can be overwhelming for the radiologists, and an automated classification technique needs to be developed. In addition, radiologists may get
infected and need to isolate that may impact rural communities with a limited number of hospitals, radiologists, and
caregivers. Moreover, as the second wave of COVID-19 is
anticipated in the fall of 2020, preparedness to combat such
scenarios will involve increasing use of portable chest X-ray
devices due to widespread availability and reduced infection
control issues that currently limit CT utilization [10]. Therefore, as depicted in Fig. 1, in this paper, to automate the
COVID-19 detection using X-ray images, we aim to develop
an artificial intelligence (AI)-based smart chest radiograph
classification framework to distinguish the COVID-19 cases
with high accuracy from other abnormal (e.g., pneumonia)
and normal cases. In this vein, the main contributions of the
paper can be summarized as follows:
• A deep learning-based predictive analytics approach is
employed to propose a smart and automated classification framework for predicting COVID-19, pneumonia,
and normal cases. Our proposed deep learning-based
chest radiograph classification (DL-CRC) framework
consists of a data augmentation of radiograph images
(DARI) algorithm and a customized convolutional neural network model.
• A uniquely compiled dataset from multiple publicly
available sources is prepared with radiographs of healthy
(normal), COVID-19, and pneumonia cases reported to
date. The limited number of COVID-19 instances in
the dataset is identified as the prime reason for training bottleneck of deep learning algorithms. As a solution, our proposed DARI algorithm essentially combines
a customized generative adversarial network (GAN)
model with several generic augmentation techniques
to generate synthetic radiograph data to overcome the
COVID-19 class imbalance problem due to limited
dataset availability.
• We train a customized CNN model based on combined
real and synthetic radiograph images that contributes to
significantly improved accuracy of 93.94% in contrast
with 54.55% when only actual COVID-19 instances in
public datasets are used for training. While chest X-ray
is regarded as a less sensitive modality in detecting
COVID-19 infection in lungs compared to CT scans
in the literature [10], we demonstrate the good performance of our custom CNN model in identifying
COVID-19 cases in the real dataset with high accuracy implying that our approach nullifies the need
for using expensive CT scan machines because the
COVID-19 detection accuracy using our custom CNN
model is much higher compared to the reported baseline [10].
• We rigorously analyze the computational complexity
of the DARI, training, and running/inference steps of
our proposed DL-CRC framework. The analyses, further corroborated by experimental results, reveal that
our proposed methodology leads to significantly lower
training time, and particularly much improved inference time, which is crucial for deploying the trained
model into portable X-ray devices for fast and reliable
COVID-19 feature detection in lung radiographs.
171576 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
• The performance of our customized CNN model is
extensively compared with the state-of-the-art CNN
architectures in the literature (i.e., depth-based CNNs,
multi-path-based CNNs, and so forth) [11]. Our proposal
is demonstrated to substantially outperform the contemporary models in terms of classification efficiency.
The remainder of the paper is organized as follows.
Section II surveys the relevant research work regarding
COVID-19 and the relevant use of AI. The problem of traditional COVID-19 detection and challenges associated with it
to apply in developing communities is discussed in section III.
Our proposed input representation and deep learning model
are presented in section IV. The performance of our proposal
is evaluated in section V and extensively compared with those
of well-known CNN architectures. Some of the limitations of
the study is briefly explored in section VI. Finally, section VII
concludes the paper.
II. RELATED WORK
This section explores the relevant research work in the literature from two perspectives, i.e., imaging modalities for
COVID-19 detection, and AI-based analysis of radiograph
samples.
A. IMAGING MODALITIES FOR COVID-19 DETECTION
Most nations had to take measures to react to the sudden
and rapid outbreak of COVID-19 within a relatively short
period of time. According to [12], radiology departments
have started to focus more on preparedness rather than diagnostic capability, after sufficient knowledge was gathered
regarding COVID-19. The study in [5] stated the resemblance
of COVID-19 with other diseases caused by other coronavirus variants such as the severe acute respiratory syndrome
(SARS) and the middle east respiratory syndrome (MERS).
The importance of a tracking the lung condition of a recovering coronavirus patient using CT scans was also mentioned
in the study. Chest imaging techniques were highlighted to be
a crucial technique for detecting COVID-19 by capturing the
bilateral nodular and peripheral ground glass opacities in the
lung radiograph images [13].
B. AI-BASED RADIOGRAPH ANALYSIS
The application of AI, for early detection, diagnosis, monitoring, and developing vaccines for COVID-19, were elaborately discussed in [14]. Several research work exist in the
literature that exploited various deep learning techniques on
X-ray data to demonstrate reasonable performance [15]–[18].
In [19], a model, referred to as DarkCovidNet, for early
detection of COVID-19 was proposed which utilized 17 convolutional layers to perform binary and multi-class classification involving normal, COVID, and pneumonia cases.
While the model reported an overall accuracy of 98.08%
for the binary classification and 87.02% for multi-class classification, our reconstruction of the DarkCovidNet using
multiple datasets indicated overtraining and much lower
accuracy when non-biased test data are presented to the
model. Several other papers applied deep learning models on
CT scan images to detect and monitor COVID-19 features
in the radiograph data [20], [21]. Ardakani et al. in [22]
employed implemented the state-of-the-art CNN architectures such as AlexNet, ResNet-18, ResNet-50, ResNet-101,
SqueezeNet, VGG-16, VGG-19, MobileNet-V2, GoogleNet,
and XceptionCT to differentiate between COVID-19 and
non-COVID-19 cases. Their experiments showed that deep
learning could be considered as a feasible technique for identifying COVID-19 from radiograph images. To avoid poor
generalization and overfitting due to lack of COVID-19 samples in available datasets, a GAN model was used in [23]
to generate synthetic data, which achieved a dice coefficient
of 0.837. The applicability of GAN for COVID-19 radiograph
data synthesis can be confirmed from the broader spectrum of
GAN applications on various medical data according to the
survey in [24]. The survey identified various unique properties of GAN such as domain adaptation, data augmentation,
and image-to-image translation that encouraged researchers
to adopt it for image reconstruction, segmentation, detection,
classification, and cross-modality synthesis for various medical applications.
III. PROBLEM STATEMENT
With the rapidly surging pandemic, the demand for efficient
COVID-19 detection has dramatically increased. The lack of
availability of COVID-19 viral and antibody test-kits, and the
time required to obtain the test results (in the order of days
to weeks) in many countries are posing a great challenge in
developing/rural areas with less equipped hospitals or clinics.
For instance, in many developing countries, hospitals do
not have sufficient COVID-19 test-kits, and therefore, they
require the assistance of more advanced medical centers to
collect, transport, and test the samples. This creates a bottleneck in mass testing for COVID-19. Therefore, to meet
the daily demand for an enormous amount of new test cases,
an automated and reliable complementary COVID-19 detection modality is necessary, particularly to confront the second wave of the pandemic. Radiograph image utilization for
initial COVID-19 screening may play a pivotal role in areas
with inadequate access to a viral/antibody testing. In several
studies, CT scans were used for analyzing and detecting features of COVID-19 [25] due to higher resolution of features
of ground glass opacities and lung consolidation compared
to chest X-ray images. However, due to infection control
matters associated with patient transport to CT suites, relatively high cost (for procurement, operation and maintenance
of CT equipment), and the limited number of CT machines
in developing/rural areas, CT scan is not a practical solution for detecting COVID-19 [10]. On the other hand, chest
X-ray can be employed to identify COVID-19 or other pneumonia cases as a more practical and cost-effective solution
because X-ray imaging equipment are pervasive at hospital
ERs, public healthcare facilities, and even rural clinics. Even
for trained radiologists, detecting chest X-ray images pose
VOLUME 8, 2020 171577S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
challenges to distinguish between features of COVID-19 and
community acquired bacterial pneumonia [10]. Moreover,
the influx of patients into hospital ERs during pandemic,
manual inspection of radiograph data and accurate decision
making can lead to a formidable tradeoff between detection
time and accuracy that can overwhelm the radiologist department. Therefore, an automated classification technique needs
to be designed. As the second wave of COVID-19 is expected
in many countries, preparedness to combat the pandemic
will involve increasing use of portable chest X-ray devices
due to widespread availability and reduced infection control
issues that currently limit CT utilization [10]. In the following
section, we address the aforementioned problem and present
a deep learning-based approach to effectively solve the problem.
FIGURE 2. Our customized generative adversarial network (GAN) model
for data augmentation.
IV. PROPOSED DEEP LEARNING-BASED CHEST
RADIOGRAPH CLASSIFICATION (DL-CRC) FRAMEWORK
Deep learning in smart health analytics is a prominent interdisciplinary field that merges computer science, biomedical engineering, health sciences, and bioinformatics. Various
medical imaging devices have a dedicated image and signal
analysis and processing module, on which deep learningbased models can be implemented to provide accurate, realtime inferences. Motivated by this, we conceptualize a deep
learning-based chest radiograph classification (DL-CRC)
framework, which can used for automating COVID-19 detection from radiograph images.
Our proposed DL-CRC framework consists of two components: (i) the data augmentation of radiology images (DARI)
algorithm, and (ii) a deep learning model. Our proposed
DARI algorithm generates synthetic X-ray images by adaptively switching between a customized GAN architecture
and generic data augmentation techniques such as zoom and
rotation. The synthetic X-ray images are combined with the
actual radiograph data to build a robust dataset for efficiently
training the deep learning model, i.e., the second component
of our DL-CRC framework. A custom CNN architecture is
designed to construct the deep learning model to carry out
automated feature extraction and classification of the radiograph images.
Next, the details of the proposed DARI algorithm and
custom CNN model of our envisioned DL-CRC framework
are presented, followed by a rigorous complexity analysis of
the proposed methodology in training and inference phases.
A. PROPOSED DARI ALGORITHM
Here, we propose an adaptive data augmentation of radiograph images algorithm, referred to as DARI. Our proposed
DARI algorithm performs an on-demand generation of synthetic X-ray images, triggered by class imbalance in the original dataset. The generated synthetic images are combined
with actual radiograph images to construct a robust training
dataset. This is essential, in the COVID-19 context, where
enough representative samples of COVID-19 chest X-ray
images are not sufficient in the currently available datasets.
DARI leverages a custom GAN model, as depicted in Fig. 2,
along with generic data augmentation techniques such as
zoom and rotation. The GAN model is invoked if the number
of samples in a class is less than a certain pre-defined threshold (δ). In the GAN model, a generator (G) and a discriminator (D) are trained simultaneously until the discriminator
is unable to separate the generated data samples from the
original ones. The generator receives random noise as input
and produces chest X-ray images, which are, in turn, received
by the discriminator. Thus, the GAN can be regarded as a
two-player minimax game between a discriminative model
(D) and a generative model (G) [26]. By exerting a noisy
sample nx with the data distribution of p(nx ) as the input,
the generative network G outputs new data X
0
, distribution
of which, denoted by p(X
0
), is supposed to be identical to that
of the distribution of original data, p(X). The discriminative
network, D, is employed to distinguish the true data sample X
with the distribution of p(X) and the generated sample X
0 with
a distribution of p(X
0
). Then, this adversarial training process
can be formulated as follows,
minG maxDV(D, G) = EX∼p(X)
log(D(X))
+ Enx∼p(nx )
log(1 − D(nx )). (1)
We customize the GAN model for chest X-ray image
augmentation as follows. The generator is constructed with
a stack of ng hidden layers. Each layer comprises a dense
layer, followed by Leaky Rectified Linear Unit (LeakyReLU)
as the activation function. In each successive layer (i
th) of the
generator, the number of neuron units (i.e., nodes) is twice
the number of nodes in the preceding layer. On the other
hand, in the discriminator model, it receives collections of
original (X) and generated (X
0
) X-ray radiograph data with
COVID-19 infected lung images. Here, the inputs to the discriminator are X = [x1, x2, . . . xn] and X
0 = [x
0
1
, x
0
2
, . . . x
0
n
],
where each xi represents an original image while each x
0
i
denotes an augmented chest X-ray image. Similar to the
171578 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
generator, the discriminator’s structure also consists of nd
hidden layers, and each i
th layer contains a sequence of a
dense layer with LeakyReLU as the activation function [27].
A dropout layer is then included. Let pi denote the dropout
rate. The number of nodes in each i
th layer is denoted by Di
.
Note that Di =
1
2
· Di−1. The discriminator aims to optimize
the loss function by distinguishing generated images from the
original ones. Our custom GAN model is trained for ξmax
number of iterations, where ξmax ∈ Z
+. The detailed steps of
our proposed DARI algorithm are presented in Algorithm 1.
Here, we either invoke the GAN or a more generic type of
data augmentation, based upon a given condition as illustrated
in Algorithm 1. This procedure takes two inputs: (i) type
of augmentation, and (ii) data for augmentation. For one
condition, the proposed GAN model gets executed from steps
2 to 22. When the other condition is fulfilled, the generic data
augmentation is performed as described in steps 23 to 25,
which includes enlarging the image by Z quantity and rotating
by θ amount.
B. PROPOSED CUSTOM CNN MODEL FOR
COVID-19 DETECTION IN X-ray IMAGES
Next, we need to train a deep learning model which can take
advantage of the robust dataset obtained from our proposed
DARI algorithm in section IV-A. Since the problem can
be regarded as a classification task of normal, COVID-19,
and other abnormal cases (e.g., pneumonia), we investigate
the contemporary deep learning architectures suited for classification. In contrast with other variants of deep learning
architectures (i.e., long-short term memory (LSTM), deep
belief networks, and so forth) and extreme learning machines,
CNNs are regarded as the most powerful deep learning
architecture for image classification. Therefore, we explore
the robust CNN models recently employed to gain reasonable classification accuracy with chest X-ray data [19].
By applying the contemporary CNN models on the latest
dataset compiled from four public repositories, we realize that
their reported performances are constrained by overfitting
and influenced by biased test data. To address this issue,
we propose a two-dimensional (2-D), custom CNN model
for classifying X-ray images to predict COVID-19 cases as
depicted in Fig. 3. The 2-D CNN structure is utilized to learn
the discriminating patterns automatically from the radiograph
images.
The proposed CNN model consists of three components.
The first component is a stack of nc convolution layers while
the second segment consists of nd fully connected layers.
The final component is responsible for generating the output
probability. At first, the convolution layers (i.e., the first component of the model) receive radiograph images (X) as input,
identify discriminative features from the input examples, and
pass them to the next component for the classification task.
Each i
th layer among the nc convolution layers consists of a
filter size of z
i
. Initially, the filter size is set to xir
in the 1st
layer, and it is decreased by λ in each successive layer. In the
Algorithm 1 Data Augmentation of Radiograph Images
(DARI)
Input: type (type of data augmentation,
possible values ‘generic’,
‘GAN’), D (collection of data
for augmentation)
Output: γ (augmented sample data)
1 γ ← ∅
2 if (type=‘GAN’) then
3 Initialize ξmax (maximum number of
epochs), B (mini-batch size), and
naug (number of data to augment)
4 mg ← construct generator model as
depicted in Fig. 2
5 md ← construct discriminator model
as depicted in Fig. 2
6 foreach e ∈ ξmax do
7 for (i=1 to B) do
8 nx ← generate naug samples of
random noise to initialize
the generator
9 gi ← generate image by
passing nx to the generator mg
10 ri ← select random set of
samples from D
11 X
∗ ← construct collection
from generated (gi) and
original samples (ri)
12 md ← update the discriminator
model by batch training using
X
∗
13 end
14 nx ← generate naug samples of
random noise
15 mg ← update the generator model
parameters
16 if e=ξmax then
17 γ ← generate collection of
augmented images by using nx
18 foreach img ∈ γ do
19 save img to corresponding
directory
20 end
21 end
22 end
23 else
24 γ ← augment data by applying
zooming rate of Z and rotation of θ
on each item from data collection D
25 end
26 return γ
forward pass, the convolution operation is performed between
the input image and the filter coefficients using Eq. 2. Here,
VOLUME 8, 2020 171579S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 3. Proposed DL-CRC framework consisting of our envisioned
DARI algorithm and custom CNN model. (1) The test data is obtained by
splitting the original images that are not used for training. (2) DARI
algorithm adaptively uses GAN and generic data augmentation
techniques to generate synthetic chest X-ray images which are combined
with the remaining original radiograph images to construct a robust
training dataset. (3) The training input is passed to our customized CNN
model, which performs automated feature extraction and classification.
x
l
ij and w
l
ij denote the output and the filter weights of the l
th
layer, respectively.
x
l
ij =
X
i∈xir
,j∈xic
(x
l−1
ij × w
l
ij). (2)
Hyper-parameter tuning is conducted to select the optimal
activation function, , as shown in in Eq. 2. The activation
function considers a constant, denoted by α > 0.
Next, we apply a dropout of rate pi as the regularization
technique that will assist the network in evading overfitting and achieve better model generalization by randomly
disregarding randomly selected neurons in the hidden layers [28]. To reduce the feature size and computational power
need, we introduce the max-pooling layer with a pool size
of ki = (k
i
r
, k
i
c
) in the hidden layers where ki
is set to a
fraction µ of the initial dimension of the input xi
. The maxpooling layers assist the model in capturing abstract spatial
information more robustly and enhancing the model’s generalization ability of the model [29]. The output features of
the convolution layers are converted into a one-dimensional
(1-D) vector by flattening the layer, and then forwarded to the
stack of nd fully-connected or dense layers for the automated
classification stage. The number of nodes in the first dense
layer is equal to xir
, and it is decreased by a factor of λ in each
successive i
th layer with respect to the number of nodes in the
previous layer. The output of the n
th dense layer is propagated
through a dropout layer of rate pi
.
Finally, the output layer computes the probability of the
input xi belonging to each class. The learning is set to a
constant ηc throughout the training of the model. The classification task receives radiograph samples as input X =
[x1, x2, . . . xn], and outputs a sequence of labels Y =
[y1, y2, . . . yn]. Here, each xi corresponds to the pixel values
of the input images. On the other hand, each yi denotes a
distinct class. Each xi has the dimension of (xir
, xic
, ϑi). In this
case, xir
, xic
, and ϑi denote the image height, width, and the
number of channels for the i
th sample. The augmented and
real samples are passed to the training data during the training
phase, and some part of the real samples are considered as the
test dataset during the testing phase.
C. TRAINING AND RUNNING PHASES OF PROPOSED
DL-CRC
From hereon, we discuss the steps of the training and running
phases of our proposed DL-CRC algorithm.
The steps of the training phase of our proposed DL-CRC
framework is presented in Algorithm 2. The training stage of
DL-CRC commences from Algorithm 2, which takes C, k, B,
λ, and δ as inputs to our custom CNN model. The description
of each input parameter is provided in the input section of the
algorithm. Steps 1 to 3 of Algorithm 2 initialize the required
parameters. In steps 4 to 10, all data are loaded from location,
and the test data are split by the ratio of λ to be utilized in the
running phase for evaluating the model. Initially, all data are
171580 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
Algorithm 2 Training Phase (DL-CRC)
Input: C (collection for training,
testing, and validation data
location), k (number of fold
in cross-validation), ξ
(number of epoch), B
(mini-batch size), λ (test
ratio), δ (threshold value for
class imbalance ratio), N
(total number of samples
across all classes)
Output: Mt (Trained model)
1 Mt ← ∅
2 X ← []
3 Y ← []
4 X
∗ ← read all data from C[train]
5 if (len(X
∗
)> 0) then
6 I
∗ ← generate random values in
range[0, λ × len(X
∗
)]
7 foreach index i ∈ I
∗ do
8 move C[train] + X
∗
[i] to C[test] + X
∗
[i]
9 end
10 end
11 foreach class ci ∈ C[train] do
12 x
∗
i ← read all data from ci
13 if (len(x
∗
i
)/N < δ) then
14 x
∗
i
+= DARI(‘gan’, x
∗
i
)
15 end
16 foreach class data ∈ x
∗
i
do
17 X+=data
18 Y+=ci
19 end
20 end
21 for (fold no. j=1 to k) do
22 Xtrain, ytrain, Xval, yval ← set data and
labels of j
th fold from X, Y
23 Xtrain += DARI(‘generic’, Xtrain)
24 Xval += DARI(‘generic’, Xval)
25 Mt ← update the CNN model depicted
in Fig. 3 by training it using Xtrain
for ξ and B
26 evaluate Mt by using Xval, yval
27 end
28 save the model parameters of Mt
29 return Mt
stored in the training directory. Hence, they are loaded from
the location of training data. Steps 11 to 20 are responsible for
checking whether any data augmentation is required or not,
and accordingly preparing all the training and validation data
from the dataset. Specifically, steps 13 to 15 check whether
the training data in any class is less than a predefined threshold δ or not, based on the condition if it can exploit the
Algorithm 3 Running Phase (DL-CRC)
Input: testPath (location of test
images)
Output: ypred (prediction of testing
samples)
1 Xtest ← read all data from testPath
2 Mt ← load the saved pre-trained model
3 yprob ← predict the probabilities of
each data from Xtest
4 ypred ← argmax(yprob)
5 return ypred
proposed data augmentation of radiograph images (DARI)
algorithm described in Algorithm 1. Our customized CNN
model is trained in steps 21-27, utilizing the model structure
illustrated in Fig. 3. At the penultimate step, the trained
model (Mt) is stored for further testing and validation. Finally,
in step 29, the algorithm returns the trained model.
Next, in the running phase, the CNN model of our proposed
DL-CRC framework follows Algorithm 3. It receives the
location of sample data for inference and returns the predicted
class labels (ypred) for the corresponding data. After reading
the data from step 1, the pre-trained model (Mt) is loaded in
the following step. In step 4, the model Mt
is employed to
predict the probabilities for a sample test data to be in each of
the possible classes. Finally, in the last step, the class with the
maximum probability is identified for each sample data, and
then returned as a collection of predictions for all the data.
D. COMPUTATION OVERHEAD ANALYSIS
In the remainder of the section, we rigorously analyze the
computational overhead of our proposed model in terms of
time-complexity. The analyses are divided into training and
running phases.
1) TRAINING PHASE
The training phase includes both our proposed DARI (Algorithm 1) for data augmentation and training our customized
CNN model (Algorithm 2). Particularly for the analysis
of Algorithm 2, we consider that the appropriate hyperparameters of our CNN model are already selected after
hyperparameter tuning. We partition the analysis of the training phase into three main segments, i.e., DP (required data
preparation), DA (data augmentation), and CNN (the execution of the CNN model). Therefore, the total computational
complexity can be expressed as follows.
C(T ) = O(DP) + O(DA) + O(CNN). (3)
In the first three steps (1-3) of Algorithm 2, where initialization is conducted, the time complexity can be denoted as
constant time, O(1). In the 4th step, all the data from the train
path are read. So, if there are fn number of data available to
train, the time complexity will be O(fn). Steps 5-9 split the test
data by the λ ratio. Therefore, the complexity associated with
VOLUME 8, 2020 171581S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
these steps is O(λ). Hence, the computational complexity of
the data preparation phase can be denoted as:
O(DP) = O(3) + O(fn) + O(λ) ≈ O(fn) + O(λ). (4)
The data augmentation part of the complexity analysis mainly consists of our proposed DARI (Algorithm 1),
invoked in steps 13-15 of Algorithm 2. This requires loading
data from each class in step 12 that results in the computational complexity of O(cl × f
i
n
). Here, cl denotes the number
of classes while f
i
n
refers to the number of data read from
i
th class. Then, through steps 13-15, the DARI algorithm is
invoked and its complexity is denoted as ODARI. Suppose
that ng and nd denote the numbers of layers in the generator and discriminator, respectively. Then, the computations
required by the generator and the discriminator models can
be denoted as Gc (Eq. 5) and Dc (Eq. 6), respectively:
Gc = 2(Xng
i=1
x
i
g × w
i
g + b
i
g
), (5)
Dc = 2(Xnd
i=1
x
i
d × w
i
d + b
i
d
). (6)
Combining the previous two expressions of Gc and Dc,
the overall overhead of DARI (Algorithm 1) is evaluated as
follows.
O(DARI) = O(cl×ξmax×B×(Gc+Dc))+O(cl × naug),
(7)
where naug, ξmax, and B denote the number of data to augment,
maximum number of epochs, and mini-batch size, respectively.
In steps 16-19 of the training algorithm, assuming the
length of each x
∗
i
as lx∗
i
, the computational overhead is O(lx∗
i
).
Therefore, the overall complexity of the data augmentation
stage can be expressed as:
O(DA) = O(cl × f
i
n
) + O(DARI) + O(lx∗
i
). (8)
From steps 21 to 27, the training algorithm invokes the
adopted 2-D CNN structure. The computational overhead for
this part can be derived from Eq. 9:
O(CNN) = O(CNNcl) + O(CNNdl), (9)
where O(CNNcl) and O(CNNdl) denote the computational
overheads in the convolutional layers and dense layers,
respectively. If we consider for a layer i, the number of filters
in the i
th layer z
i
, input image x
i with the dimension of
(x
i
r
, x
i
c
) and kernel k
i with the dimension of (k
i
r
, k
i
c
), then the
computational complexity of the convolutional layers can be
expressed as:
O(CNNcl) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
))). (10)
After the convolutional layers, for n layers, assuming w
i
and b
i
are the weight vector and the bias of i
th layer, the complexity of the fully connected layers is given by:
O(CNNdl) = O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (11)
Hence, combining the aforementioned equations, to finalize the computational complexity of the proposed CNN,
we can re-write Eq. 9 as follows:
O(CNN) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
)))
+ O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (12)
Finally, to determine the total time complexity of the training phase of the DL-CRC algorithm, we can substitute the
corresponding values from Eqs. 4, 8, and 12 into Eq. 3.
2) RUNNING PHASE
The running phase is conducted to infer classes of each test
data using the pre-trained model and then evaluate the model.
As shown in Algorithm 3, if we consider the number of test
data to be ntest, the computational overhead in the testing
phase can be given by:
C(R) = O(ntest). (13)
Eq. 13 demonstrates that the model is able to produce results in linear time. This implies that our proposed
DL-CRC framework comprising DARI algorithm and the
customized CNN model can be deployed on clinical-grade
X-ray machines with image processing capability, computing
resources having access to digitized radiograph images from
analog X-ray machines, and even portable X-ray machines
in movable booths and trucks with adequate shielding and
power supply. Thus, our model is viable for automating the
radiograph image classification with fast turn-around time for
COVID-19 detection.
V. PERFORMANCE EVALUATION
To evaluate the performance of our proposed DL-CRC framework, in this section, we describe the collected datasets used
to train our customized CNN model, followed by extensive
experimental results and discussion.
A. DATASET PREPARATION
The dataset employed for the supervised radiograph image
classification using our proposed DL-CRC framework consists of three classes: COVID-19, pneumonia, and normal
chest X-ray images. We collected the dataset using four different existing datasets of Posteroanterior (PA) chest X-rays,
and combined those into a single dataset to utilize it for the
classification purpose. We developed the dataset from GitHub
for COVID-19 X-rays [30], X-ray data collected in this study
for cases of pneumonia, and normal images [31], CheXpert
171582 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 1. Brief description of the used dataset for X-ray image
classification.
dataset collected by Stanford ML group [32], and the rest of
the normal and pneumonia chest X-ray images were collected
from the dataset in [33]. Table 1 lists the initial class distribution of the collected chest X-ray dataset. The number of
samples collected for COVID-19 is significantly lower than
the other two classes because this is a novel disease, and at this
moment, data regarding COVID-19 is challenging to obtain.
In other words, the number of COVID-19 class samples in
the merged dataset is lower than the threshold value for class
imbalance ratio, δ. Therefore, to overcome the effect of the
low amount of COVID-19 data, we employed our proposed
DARI algorithm to increase the number of samples. We then
applied our proposal along with contemporary CNN models
to verify which one yields the best COVID-19 detection
performance.
B. PERFORMANCE INDICATORS
To evaluate the classification results, we primarily adopted
the combination of three measurement indicators, accuracy,
weighted precision, and weighted F1 score. The accuracy of
a test is its ability to correctly differentiate the three cases.
Assume that C denotes the number of classes in the considered classification task, |yi
| refers to the number of samples
in the i
th class, and |Y | indicates the total number of samples
in all the classes. Then, the accuracy can be represented as
follows.
Accuracy =
PC
i=1
(TPi)
|Y |
. (14)
Next, we define the weighted precision. Our aim is to
measure how precise the model is in terms of the number of
samples actually present in the i
th class out of those predicted
to be in that class. This number is multiplied by the weight of
the i
th class to obtain the weight precision as follows.
Weighted precision =
X
C
i=1
(
|yi
|
|Y |
×
TPi
TPi + FPi
). (15)
Next, the weighted F1 score is defined as the weighted
average of precision and recall. Although we did not use
recall directly as a performance measure, because of using
the F1 score, it is implicitly used. The weighted F1 score can
be obtained as follows,
Weighted F1 score =
X
C
i=1
(
|yi
|
|Y |
× 2
Pi × Ri
Pi + Ri
). (16)
Here, Pi and Ri are the precision and recall of i
th class,
respectively. Pi can be expressed as TPi/(TPi + FPi) and
Pi can be denoted as TPi/(TPi + FNi). TPi
, FPi
, and FNi
denotes True Positive, False Positive, and False Negative
for i
th class respectively. TPi
indicates the number of cases
correctly identified to be in the i
th class; FPi represents the
number of cases incorrectly identified to be in the i
th class,
and FNi denotes the number of cases incorrectly identified
as a class other than the i
th class. In addition, for evaluating
our results more comprehensively we also employed class
specific classification accuracy (i.e., normal, COVID-19, and
pneumonia detection accuracy) for all three classes.
C. RESULTS AND DISCUSSION
We have followed a systematic approach by applying different techniques to find the optimal model for the classification
task. All the experiments were conducted on a workstation
with Intel Core i7, 3.00GHz CPU, 16 GB RAM, powered
by Nvidia RTX 2060 Graphics Processing Unit (GPU). The
simulations were implemented employing Python’s Keras
and TensorFlow library. The visualization of the experimental
results was achieved by utilizing Python’s Matplotlib library.
During the simulations, we have resized the image samples by
setting both xir
and xic
to 100 to keep the images consistent in
terms of size. The number of channels of the samples (ϑi) was
set to 1 as the input images were grayscale in nature. The values of xir
and xic were selected based on manual tuning. Using
our proposed DARI algorithm, on-demand data augmentation
is performed by adaptively employing GAN, rotation (θ) of 5
degrees, and zooming (Z) rate of 0.50. The value of δ was
set to 0.1. We systematically constructed three experimental
scenarios to conduct a comprehensive performance comparison of our proposed DL-CRC framework consisting of DARI
algorithm and our customized CNN models with the stateof-the-art CNN models which have been recently reported to
provide reasonable accuracies for COVID-19 detection. The
three scenarios, constructed in an incremental fashion, are
described below.
1) In our first scenario, we designed our customized deep
CNN model architecture depicted in Fig. 3. The parameters of the model were selected based on the results of
the grid search technique.
2) In the second scenario, we implemented the proposed
DARI algorithm to analyze the effect of the generic and
GAN-based data augmentation to train the CNN-based
model in a robust fashion to significantly improve the
COVID-19 detection accuracy.
3) In the third and final scenario, we trained several stateof-the-art CNN models using different deep learning
paradigms on our compiled dataset. The same test data
(unknown chest X-ray original images with normal,
COVID-19, and pneumonia cases) were presented to
the customized CNN model of our proposed DL-CRC
framework as well as the contemporary CNN models.
The results were used to compare the performances of
our proposal and these contemporary models in terms
of COVID-19 and pneumonia detection efficiency.
VOLUME 8, 2020 171583S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 4. Performance in terms of accuracy for different combinations of
activation functions and optimizers.
FIGURE 5. Performance in terms of precision for different combinations
of activation functions and optimizers.
FIGURE 6. Performance in terms of F1 score for different combinations of
activation functions and optimizers.
In the first scenario, we implemented the customized CNN
model of our proposed DL-CRC framework and carried out
a grid search to achieve the optimal model parameters (i.e.,
FIGURE 7. Performance comparison for diverse ratios of the
COVID-19 X-ray images generated by the GAN with respect to the existing
number of samples in the dataset.
the best activation functions and optimizer). It is worth noting that other customized CNN models revealed a performance bottleneck in terms of validation accuracy and we
found the model in Fig. 3 to be the most lightweight yet
efficient for automating the chest X-ray classification task.
Figs. 4, 5, and 6 demonstrate the results obtained from the
hyper-parameter tuning in terms of accuracy, precision, and
F1 score, respectively. These performances were extensively
evaluated across six optimizers (Stochastic Gradient Descent
(SGD), Adaptive Moment Estimation (Adam), Root Mean
Square Propagation (RMSProp), Adaptive Delta (AdaDelta),
Nesterov and Adam (Nadam), and Adaptive Gradient Algorithm (Adagrad)) and five activation functions (tanh, sigmoid, Scaled Exponential Linear Unit (SELU), Rectified
Linear Unit (ReLU), and Exponential Linear Unit (ELU)). As
depicted by the results in these figures, SELU demonstrated
better performances on average when compared with the
other activation functions. However, the best performance
was exhibited when ELU is adopted as the activation function
with the value of constant α = 1.0 and the optimizer set to
Adagrad with the learning rate of 0.001. For this first experimental setting for selecting the optimal hyper-parameters
of the deep learning-based model, the mini-batch size (B)
was set to 8, and the number of epochs (ξ ) was set to 20.
With this configuration, the validation accuracy, precision,
and F1 score were found to be 97.25%, 97.24%, and 97.21%,
respectively. Therefore, for further analysis, we applied this
configuration in the customized CNN model of our DL-CRC
framework. Furthermore, in the max-pooling layer of our
proposed CNN architecture, we conducted manual parameter
tuning, and the pool size ki was assigned as µ, where µ = 2%
of the initial size of the input xi
.
In the second experimental scenario, as the number of
COVID-19 samples in the collected dataset was lower than
the pre-defined threshold δ, we applied our proposed DARI
algorithm to increase the number of COVID-19 samples so
that the model can be trained with a robust training data
171584 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 8. Confusion matrix of testing phase employing 5-fold stratified cross-validation.
and eventually predict positive COVID-19 cases with high
accuracy. In Fig. 7, we altered the proportions for our customized GAN model in the DARI algorithm with respect to
the original sample size of the COVID-19 class. The ratios
of GAN-generated samples of the proposed approach were
varied from 50% to 200% with respect to the number of
COVID-19 examples in the original dataset. The number of
iterations for producing the augmented samples using the
GAN-based method was set to 200. Among the proportions
mentioned earlier, the COVID-19 detection performance of
our customized CNN model was found to be the highest
(with an accuracy of 93.94%) when the number of newly
generated samples was 100% of the size of the original
COVID-19 samples. Therefore, we picked this configuration to be used in our conducted experiments in the next
scenario.
After producing the augmented samples for the COVID-19
class, we analyzed the effect of combining the adaptive
generic data augmentation and GAN-based DARI algorithm
with the CNN architecture to fully implement and fine-tune
the DL-CRC framework, and compared the performance with
the base CNN model only (i.e., without adopting DARI
algorithm). The experiment was conducted utilizing a fivefold stratified cross-validation. Using the stratification technique, the samples are rearranged so that each fold has a
stable representation of the whole dataset by maintaining
the percentage of samples for each class [34]. In our third
experimental setup, the number of epochs (ξ ) was set to
100, and the mini-batch size (B) was set to 8. The number of convolutional layers, nc, was set to five. The number of fully-connected/dense layers, nd , was also fixed to
five. Note that these hyperparameter values were manually
tuned. To analyze the results more critically in terms of
COVID-19 detection efficiency, in this experimental setting,
we also investigated the normalized and non-normalized values of the confusion matrices of our customized CNN model
TABLE 2. Performance comparison of the proposed DL-CRC and CNN
with generic and GAN-based data augmentation.
without (i.e., CNN-only model) and with the proposed DARI
algorithm (i.e., the complete DL-CRC framework). Fig. 8
represents the normalized confusion matrix where the proposed CNN model is implemented without applying the data
augmentation, and Fig. 8 depicts the same for the combined
CNN and DARI algorithm. Despite similar performances of
both approaches, the normalized confusion matrix demonstrates that our proposed DL-CRC framework is much more
robust for classifying positive COVID-19 and pneumonia
cases. The proposed DL-CRC exhibited 93.94% and 88.52%
accuracies while detecting positive COVID-19 and pneumonia cases, respectively. The encouraging classification
performance indicates that our proposed deep learningbased DL-CRC framework is able to classify the radiograph images with high efficiency, specifically for COVID-19
detection.
Furthermore, we analyzed the impact of generic and GANbased data augmentation separately combined with our customized CNN model and compared the COVID-19 detection
accuracy with the proposed DL-CRC framework. Table 2
exhibits the simulation results, which proves that both the
generic and GAN-based data augmentation had significant
influence in enhancing the COVID-19 detection efficiency.
The simulation results in the table show that our CNNonly base model achieved 54.5%, CNN with generic data
augmentation obtained 63.4%, and CNN with the proposed
VOLUME 8, 2020 171585S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 3. Performance comparison of our proposed DL-CRC architecture
with the existing CNN architectures for all three classes.
GAN-based data augmentation delivered 84.5% COVID-19
detection accuracy. On the other hand, the proposed DL-CRC
framework demonstrated the highest COVID-19 detection
accuracy (93.94%). This good performance is attributed to
the combination of our customized CNN model with the proposed DARI algorithm where both generic and GAN-based
data augmentation are adaptively performed, Therefore, it is
evident from these results that our proposed DL-CRC framework made the customized CNN model much more robust
with DARI algorithm.
In the third experimental scenario, we compared the performance of our customized CNN model with the performances
of the state-of-the-art CNN models such as Inception-Resnet
V2, Resnet, and DenseNet. The reason behind choosing these
contemporary models is their good performances reported
in the recent literature for COVID-19 detection. It is worth
noting that Inception-ResNet v2 and DenseNet belong to the
depth-based and multi-path-based CNN paradigms, respectively. On the other hand, ResNet combines both depthbased and multi-path-based CNN architectures. Table 3
demonstrates the comparative analysis, which indicates
the efficiency of our proposed DL-CRC framework in
terms of COVID-19 and pneumonia detection using chest
X-ray images. Our proposed model, outperformed ResNet,
Inception-ResNet v2, and DenseNet. Although Densenet
achieves 98.01% prediction performance for normal test
cases, its accuracy is only 72.42% for pneumonia detection
while it exhibits the poorest performance of 60.61% for
identifying COVID-19 cases. This implies that multi-pathbased structure, although reported in recent work, is not suitable for COVID-19 detection. On the other hand, Inception
ResNet v2, using the depth-based CNN modeling paradigm,
achieves improved COVID-19 detection accuracy (69.70%).
The combination of these two modeling paradigms is incorporated in ResNet, which is able to predict test cases having
COVID-19 samples slightly elevated accuracy of 72.72%.
On the other hand, our proposed DL-CRC framework, combining our envisioned DARI algorithm and customized CNN
model, is able to detect the COVID-19 cases with a significantly high accuracy of 93.94%. Note that the pneumonia (the other abnormal case) present in the test dataset is
also detected with much higher accuracy (88.52%) compared
to the contemporary models. Even though the performance
slightly drops for normal case identification, the accuracy
is still close to 96% in case of our proposal. Furthermore,
in the final column of Table 3, the AUC (area under the ROC
(receiver operating characteristic) curve) values are also listed
for the proposed DL-CRC and contemporary models. The
AUC score of our proposed DL-CRC is 0.9525 which demonstrates the reasonable accuracy of identification across all
samples in the test data. Thus, the encouraging performance
of the proposed DL-CRC algorithm over prominent CNN
models clearly demonstrates that the proposed technique can
be useful for detecting COVID-19 and pneumonia cases with
a significantly high (i.e., reliable) accuracy.
Furthermore, we compare the performance of our proposal
with a recent custom model, referred to as DarkCovidNet
[19]. For multi-class classification, the accuracy of DarkCovidNet was reported to be 87.02%, which is considerably
lower than that of our proposed model’s performance
(93.94%), which we believe ensures the effectiveness of our
proposed model. In addition, we have conducted two-fold
experiments to validate and compare our proposed technique (DL-CRC) with DarkCovidNet. Table 4 demonstrates
the results obtained when our proposed model is tested on
both datasets, and the DarkCovidNet model is tested on
both datasets. Both models were trained by employing the
respective dataset used by the work in [19] and our current work. These experimental results presented in Table 4
were produced after training the models for 25 epochs for
each case, and then the trained models were tested on both
datasets. Our proposed technique outperformed DarkCovidNet for detection accuracies for both normal and COVID-19
cases. In addition to the classification efficiency, our proposed DL-CRC framework is more lightweight than that of
used in DarkCovidNet. Our customized CNN model of DLCRC consists of 5 convolutional layers while the DarkCovidNet model comprises 17 convolutional layers, making our
model’s training phase more lightweight and computationally
less expensive than the DarkCovidNet model.
Moreover, while some researches reported overall accuracy, they did not mention the COVID-19 detection accuracy.
On the other hand, most researches applying deep learning
techniques did not report the AUC score, which is a robust
representative performance metric for practically evaluating
the COVID-19 detection ability of the model. In summary,
by applying various contemporary CNN models (Inception
with Resenet V2, Resnet, Densenet) and a recent customized
model (DarkCovidNet) for COVID-19 detection on the latest
dataset compiled from four public repositories, we realized
that their reported performances are constrained by overfitting and influenced by biased test data. Thus, the accuracy
bottleneck of those existing models justifies why we required
to build a customized CNN model in this research and combine it with the DARI algorithm to perform robust training
and avoid overfitting to ensure high COVID-19 detection
accuracy and a significantly high AUC score.
VI. LIMITATIONS OF THE STUDY
In this section, we briefly discuss some limitations and possible future work that can be conducted to extend the study.
171586 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 4. Comparison of the performance our proposed model with that of DarkCovidNet [19] on both datasets.
• Our study and experiments have been conducted at a
very critical stage and time-sensitive manner to combat the COVID-19 pandemic with a proof-of-concept
COVID-19 using radiograph images. Despite compiling
datasets from multiple sources with X-ray images containing COVID-19 samples, the used data was considerably small in size. Therefore, synthetic images were
generated using our customized GAN-assisted data augmentation technique that were used to train a robust
CNN model to perform binary (normal and COVID-19)
and three-way classification (normal, pneumonia, and
COVID-19) with significantly high accuracy. Due to
the lack of real datasets consisting of other diseases
(e.g., SARS, MERS, and so forth) which exhibit acute
respiratory distress syndrome (ARDS) and pneumonialike conditions in the lungs, more class labels were not
considered in our work.
• From a physician’s perspective, it is important to diagnose the severity of COVID-19. However, due to the lack
of labeled data, in this work, our model could not be
used to classify the various stages of COVID-19 such
as asymptomatic, mild, high and severe.
• The proposed technique performed efficiently when we
utilized it to analyze X-ray samples. However, the study
can be extended to evaluate the system’s performance
in COVID-19 detection while using other radiograph
techniques such as CT scan, lung ultrasound, and lung
PET (positron emission tomography) scan.
• The dataset used in this study is limited by only
one modality type, i.e., X-ray images containing
COVID-19 features. Further customization in our CNN
model will be required if we want to combine multiple
imaging modalities (e.g., lung CT scan, ultrasound, PET
along with X-ray images), other modalities (e.g., body
temperature, ECG, MCG, diabetes level, renal function,
and so forth), and patient parameters (e.g., age, gender, ethnicity, travel history, and contact history) to perform an in-depth COVID-19 classification. Therefore,
a multi-modal input characterization and corresponding
AI model customization will be needed in the future for
interpreting and explaining the classification results.
VII. CONCLUSION
In this paper, we addressed the emerging challenges of
detecting COVID-19. Due to the shortage of efficient diagnosis equipment and personnel in many areas, particularly
in developing and/or rural zones, numerous people remain
non-diagnosed. This results in a substantial gap between the
number of confirmed and actual cases. Radiographs such as
chest X-ray images and CT scans have been demonstrated
to have the potential for detecting COVID-19 infection in
the lungs that can complement the time-consuming viral
and antibody testing. While CT scans have higher resolution or fine-grained details compared to X-ray images, X-ray
machines are pervasive in hospital emergency rooms, public
health facilities, and even rural health centers or clinics.
In addition, because X-ray is a much cheaper alternative
and an appealing solution for portability in mobile trucks
and COVID-19 screening booths with adequate shielding
and power supply, how to identify COVID-19 infection of
the lung by recognizing patterns such as glass opacities and
lung consolidations raised a formidable research problem,
that we addressed in this paper. Also, we discussed why
it is necessary to automate the X-ray image classification
to be well prepared for the next wave of COVID-19 pandemic, when radiologists and caregivers are expected to be
overwhelmed by patient influx as well as the need to selfisolate in case they themselves become infected. This means
there is a pressing need to automate the classification of
radiographs, particularly X-ray images, to minimize the turnaround time for COVID-19 detection. Therefore, to leverage
the availability and cost-efficiency of chest X-ray imaging,
in this paper, we proposed a framework called DL-CRC
(Deep learning-based chest radiograph classification) to automate COVID-19 detection that can complement existing viral
and antibody testing methods.
Our proposed DL-CRC framework consists of two parts:
the DARI algorithm (which adaptively employs a customized
generative adversarial network and generic data augmentation techniques such as zoom and rotation) and a twodimensional convolutional neural network (CNN) model. We
employed a unique dataset for multiple publicly available
sources, containing radiograph images of COVID-19 and
pneumonia infected lungs, along with normal lung imaging.
The classification accuracy significantly increased to 94.61%
by adopting our proposed DL-CRC framework. Our proposal was compared with existing deep learning models from
diverse categories such as depth-based CNN (e.g., InceptionResNet v2), multi-path-based CNN (DenseNet), and hybrid
CNN (ResNet) architectures. Extensive experimental results
demonstrated that our proposed combination of DARI and
custom CNN-based DL-CRC framework significantly outperformed the existing architectures. Thus, incorporating our
proposed model with significantly high accuracy into the
VOLUME 8, 2020 171587S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
clinical-grade as well as portable X-ray equipment can allow
an automated and accurate detection of COVID-19 in the
scrutinized patients.




NEW_PAPER


C The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
Collaborative City Digital Twin for the COVID-19 Pandemic:
A Federated Learning Solution
Junjie Pang, Yan Huang, Zhenzhen Xie, Jianbo Li
, and Zhipeng Cai
Abstract: The novel coronavirus, COVID-19, has caused a crisis that affects all segments of the population. As the
knowledge and understanding of COVID-19 evolve, an appropriate response plan for this pandemic is considered
one of the most effective methods for controlling the spread of the virus. Recent studies indicate that a city Digital
Twin (DT) is beneficial for tackling this health crisis, because it can construct a virtual replica to simulate factors,
such as climate conditions, response policies, and people’s trajectories, to help plan efficient and inclusive decisions.
However, a city DTsystem relies on long-term and high-quality data collection to make appropriate decisions, limiting
its advantages when facing urgent crises, such as the COVID-19 pandemic. Federated Learning (FL), in which
all clients can learn a shared model while retaining all training data locally, emerges as a promising solution for
accumulating the insights from multiple data sources efficiently. Furthermore, the enhanced privacy protection
settings removing the privacy barriers lie in this collaboration. In this work, we propose a framework that fused city
DT with FL to achieve a novel collaborative paradigm that allows multiple city DTs to share the local strategy and
status quickly. In particular, an FL central server manages the local updates of multiple collaborators (city DTs),
providing a global model that is trained in multiple iterations at different city DT systems until the model gains the
correlations between various response plans and infection trends. This approach means a collaborative city DT
paradigm fused with FL techniques can obtain knowledge and patterns from multiple DTs and eventually establish a
“global view” of city crisis management. Meanwhile, it also helps improve each city’s DT by consolidating other DT’s
data without violating privacy rules. In this paper, we use the COVID-19 pandemic as the use case of the proposed
framework. The experimental results on a real dataset with various response plans validate our proposed solution
and demonstrate its superior performance.
Key words: COVID-19; Digital Twin (DT); Federated Learning (FL); deep learning
 Junjie Pang is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, and is also with
the Business School, Qingdao University, Qingdao 266000, China. E-mail: pangjj18@163.com.
 Yan Huang is with the College of Computing and Software Engineering, Kennesaw State University, Atlanta, GA 30060, USA.
E-mail:yhuang24@kennesaw.edu.
 Zhenzhen Xie is with the College of Computer Science and Technology, Jilin University, Changchun 130012, China. E-mail:
xiezz14@mails.jlu.edu.cn.
 Jianbo Li is with the College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, E-mail:
lijianbo@188.com.
 Zhipeng Cai is with the Department of Computer Science, Georgia State University, Atlanta, GA 30303, USA. E-mail: zcai@gsu.edu.
To whom correspondence should be addressed.
Manuscript received: 2021-02-26; accepted: 2021-03-18760 Tsinghua Science and Technology, October 2021, 26(5): 759–771
1 Introduction
Coronavirus (COVID-19), an infectious disease
caused by the recently discovered coronavirus, was
identified on December 31th 2019[1] (https://www.who.
int/emergencies/diseases/novel-coronavirus-2019). The
virus has spread worldwide in less than three months,
infected more than 116 million people, and caused
over 2 575 196 deaths (https://www.worldometers.info/
coronavirus/). This widespread coronavirus outbreak
received tremendous attention from the research and
medical perspective. However, a specific antiviral
treatment of COVID-19 remains unavailable. Therefore,
an early and radical government response can be
considered the most effective method when facing a
novel infectious disease. However, determining the
response plan properly can be challenging because of a
lack of experience and efficient data sources.
A mathematical model is a possible solution for
the intervention and surveillance of the infectious
disease[2]. For example, the Susceptible-InfectedSusceptible (SIS) epidemic model is widely used in
describing the spreading process for a virus in a static
network with an assumption of a constant population.
This model can also combine with a time-varying
dynamic network to describe more complex propagation.
We also observe that the significant proliferation of
machine learning techniques has resulted in the rapid
development of intelligent forecasting models[3]. Recent
works demonstrate their comparable performance in
capturing non-trivial atypical trends and typical patterns
for epidemic control, such as the Wiener-series-based
machine learning model for measuring the H1N1 virus
spread after an intervention[4], and the representation
learning model that generates interpretable epidemic
forecasting results for seasonal influenza forecasting[5]
.
However, these models still have several challenges
and limitations in predicting infection trends of a novel
infectious disease, such as COVID-19:
Uncertain influence: In contrast to other pandemic
predictions, the prediction model of unknown infectious
diseases, such as COVID-19, must learn the influence
of various response plan settings, such as mask-wearing,
shelter in place, and statewide school closures.
Cold start problem: When a new virus starts to
spread, the local health department always needs a long
time to properly collect sufficient data to generate a
response to the pandemic. Note that the same response
plan could have varied effects in different locations: a
radical response plan may only bring economic risks
to a low-risk areas, while the same actions could result
in losing control of the spreading virus and economic
damage for severely affected areas.
Privacy protection: The data resources related to a
health crisis, such as COVID-19 pandemic, unavoidably
contain sensitive information. This situation means that
we cannot collaboratively share these data unless we can
provide a strong privacy guarantee[6]. However, medical
institutions and local governments may expect a highperformance model for epidemic control, which means
massive data collection is required for deep learningbased models. Because of privacy and confidentiality
concerns, these applications can possibly be prevented,
such that data silos emerge[7]. These silos are isolated
islands of data, which can make health data management
disorganized and inefficient. Moreover, they make it
prohibitively costly for the local agencies to extract
knowledge, share insights, and realize collaborations
with other regions[8]
.
As shown in Fig. 1, we proposes a Digital Twin
(DT) enabled collaborative training framework based
on a federated learning paradigm to resolve the
above problems. We use a city DT to build a virtual
replica of the city/state that provides a digital view of
Federated Learning (FL) central server
City DT
Real world
Fig. 1 Overview of the collaborative framework for a multiple city DT.Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 761
city/state facilities, human activities, and other types
of information to enable information convergence in
multiple aspects of infection trend, thus enabling the
prediction of the uncertain influence caused by different
events. City DT allows each region to accumulate
historical data efficiently, while demonstrating a
remarkable potential for offering continuous interaction
with the physical world to refine prediction[9, 10]
.
Specifically, Time Convolutional Networks (TCN) is
adopted to implement a city DT, ensuring superior
performance for modeling the temporal information
dynamics and the future infection trend prediction under
a local response plan.
To further resolve the cold start problem and privacy
concerns, FL[11] is introduced as the collaborative
training paradigm. It only involves the parameters
shared among multiple parties in training collaborative
machine learning models. Thus, FL can significantly
lower the privacy risks in collaborative knowledge
exchange[12]. These features, combined with the highquality contribution from local city DT, are essential
for establishing a prediction model and accumulating
knowledge and insights for an unknown virus, such as
COVID-19, in a short period.
Our contributions can be summarized as follows:
 To resolve the uncertain influence challenge for
COVID-19 pandemic management, we are among the
first to propose a novel collaborative learning framework
with city DT embedding.
 The proposed TCN-based city DT helps determine
the effects of various local response plans for each
city/area, which is the first attempt to utilize a nontrivial deep learning model for epidemic forecasting
considering fine-granularity time pattern features.
 Considering the cold start problem and privacy
concerns, we use the FL as the solution, which offers
collaborative learning via only parameter-sharing not to
disturb each city DT’s privacy rules.
 Extensive simulations with a real dataset reveal that
our proposed framework significantly outperforms the
non-trivial baseline and the non-FL city DT solution
with a strong privacy guarantee.
The remainder of the paper is organized as
follows. Section 2 introduces related works. The basic
definitions and problem statements are presented in
Section 3. Section 4 explains the detailed structure
and methodology of the proposed framework. The
experiments and results are analyzed in Section 5.
Finally, conclusions and future work are presented in
Section 6.
2 Related Work
In this section, we start with a brief review of traditional
methods for epidemic prediction, and then discuss the
related techniques and the need for the collaborative
training framework.
Deep learning-based epidemic control: Historical
insights from temporal infection data have been
crucial for epidemic control and prevention, and could
benefit other problems in smart city systems[13, 14] or
enhanced social network analysis[15]. Deep learningbased techniques have demonstrated a remarkable
performance to model such temporal correlations and
recognize multiple patterns[16, 17], including the deep
neural network-based short-term and high-resolution
epidemic forecasting for influenza-like illness[18], the
semi-supervised deep learning framework that integrates
computational epidemiology and social media mining
techniques for epidemic simulation, called SimNest[19]
and EpiRP[20], which use representational learning
methods to capture the dynamic characteristics of
epidemic spreading on social networks for epidemicsoriented clustering and classification.
Moreover, recent breakthroughs in infectious disease
modeling, forecasting, and real-time disease surveillance
have further convinced us that these activities mitigate
the effects of disease outbreaks. In addition, with
the rapid growth of cloud computing and wireless
data communication architectures[21, 22], deep learningmodels demonstrate constantly improving efficiency.
Given various application scenarios and objectives,
deep learning-based models can be different. A typical
solution for localized flu “nowcasting” and flu activity
inferring is ARGONet[23], which is a network-based
approach leveraging spatio-temporal correlations across
different states to improve the prediction accuracy.
ARGONet uses a spatial network to capture the
spatio-temporal correlations across different states and
produces more precise retrospective estimates based on
the information from influenza-related Google search
frequencies, electronic health records, and historical
influenza trends. Instead of leveraging multiple data
source, such as ARGONet, the studies in Ref. [24]
proposed a multi-task learning-based model that is only
uses user-generated content (Web search data). They
investigate linear and nonlinear model capabilities and
find that disease rate estimates can be significantly762 Tsinghua Science and Technology, October 2021, 26(5): 759–771
improved in the case study of an influenza-like illness.
However, these successful attempts are based on largescale data sources or massive historical information
of the disease with similar spreading patterns, which
means that high-dimensionality, irregularity forms,
noise, privacy concerns, or sparsity problems may
affect these learning-based models’ performance[25, 26]
,
especially when we face unexpected infectious disease
outbreaks, such as the COVID-19 pandemic.
For filling the data gap, the city DT is proposed as
a promising solution. It is a virtual representation of a
device or a specific application scenario that can interact
with the target environment to collect data continuously
for real-time decision-making. Several successful
research attempts include a disaster city DT[27, 28]
,
energy management[29], and city-scale Light Detection
and Ranging (LiDAR) point clouds[30]. Furthermore,
Singapore[31] and Germany[32] have launched the cityscale DT to monitor and improve utilities, which enhance
the transparency, sustainability, and availability of a DT.
In this way, the city DT offers us a high-quality and
real-time data resource to describe the spread of an
epidemic, whereas data silos naturally emerge because
of privacy barriers[33, 34]. To maintain the advantages of
DT and tolerate the data sparsity challenge, FL, which
allows multiple stack-holders to share data and train a
global model, has become a preferred scheme[11]. In
typical FL scheme settings, each data owner (FL client)
engages in a collaborative training process without
transferring the raw data to the others. Through FL,
the central server manages each client’s local training
updates and aggregates their contributions to enhance the
global model’s performance. Several concrete scenarios,
including Google’s Gboard[35], health AI[36], and smart
banking[37], show the advantages of FL in handling
collaborative training issues and data difficulties among
diverse data owners. Therefore, we are motivated
to utilize FL techniques to resolve the data sparsity
challenges and design a collaborative city DT for
COVID-19 pandemic control.
3 Preliminary and System Model
In this section, we first explain the preliminaries of
the proposed framework. The structural design, which
combines DT and FL for COVID-19 pandemic control,
will be explained with a mathematical definition of
the problem objective. The detailed methodology and
proposed solution will be illustrated in Section 4.
3.1 Preliminaries
TCN: Given these advantages and a delicate-designed
convolutional architecture, TCN can handle variable
length inputs, such as those of Recurrent Neural Network
(RNN)-based methods[38], and convincingly outperform
baseline recurrent architectures across various sequence
modeling tasks. By leveraging a much simpler, 1-D
fully-convolutional network, TCN can build a very
long sufficient history size for a variable length of a
input sequence, avoiding large memory requirements
and intricate network architecture, such as those of
gated RNNs. Its model pipeline has two distinguishing
features: causal convolution and dilated convolution.
The causal convolutions consider that the output at time
t is convoluted only with elements that occurred before t,
which suggests that current spatial-temporal information
depends only on the past and not on any future inputs.
Then, to further achieve longer history data without
introducing an extremely deep network or very large
filters, a TCN uses a dilated convolution to enlarge
the sequence data’s maximum length (receptive field).
Notably, the receptive field can be changed by stacking
more dilated convolution layers or increasing the filter
sizes, which fully explain the robustness and flexibility.
FL: FL is a privacy-enhanced distributed learning
framework with an emphasis on using mobile and edge
devices for collecting data and scaling the computation
resources[11]. Unlike previous research handling with
training data in a centralized manner, FL’s essential
property uses a “parameter-only” collaborative training
to avoid disturbing each FL clients’ privacy rules. Thus,
various participating clients can solve the learning task
through a hub-and-spoke topology for model aggregation
while maintaining the raw data on their devices. In
particular, for a new FL training task, (1) the FL
central server trains a global model for initialization,
then distributes this model to the existing collaborators
(clients); (2) after receiving the global model, each
collaborator uses the local dataset to update the local
parameters and generates the local updates; (3) based
on specified synchronization settings, all these updates
are sent to the FL central server for aggregation, and the
global model is improved; (4) these distributed update
iterations are repeated until the global model converges
or achieves the expected performance.
DT: A DT is a digital representation of a physical
asset, environment, or system, that was initially
developed to automatically aggregate, analyze, andJunjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 763
visualize complex information through continuous
interactions with the physical world.
3.2 City DT for COVID-19 pandemic control
From the above facts, we observe explicit advantages
of using FL to establish the collaborative training
framework of multiple city DTs. First, by separating
local model training and global model updates, FL
offers a strong capability to deal with the isolated data
island problem between multiple DTs. Secondly, with
enhanced privacy settings, each city DT can obtain the
collaboration achievements without violating its privacy
rules. These properties are essential for COVID-19
pandemic control, because different regions need a
collaboration paradigm with lower privacy risks to
quickly realize an effective response plan. Furthermore,
for each city DT using a TCN as the time-series data
modeling method, the shared global model can provide
more temporal correlation perspectives, which is a
complementary approach to make the city DT quickly
converge to a robust performance.
In our proposed work, a city DT has three primary
components: the physical environment of the city,
a virtual replica describing the city’s architecture,
functions, and behaviors, and active communications
between the two to obtain real-time spatiotemporal
data from various infrastructure and human systems[39]
.
According to the three components, we compose a city
DT for COVID-19 pandemic control using the following
metrics:
COVID-19 case number: The COVID-19 case
number is the number of identified confirmed cases. It
is the direct evidence to describe the characteristics of
human-to-human transmission. Daily updates of case
numbers represent infection trend changes and show
whether a response plan is operated efficiently. In our
framework, each DT model is from a specific area, so
that the case number is bounded with the area and time
information.
COVID-19 testing number: This metric measures
how many individuals get tested of COVID-19 in the
affected regions. The actual total number of people
infected with COVID-19 cannot be obtained. In this
situation, the number of confirmed cases depends on the
testing number, because it can be used to further interpret
and revise the COVID-19 case number. Meanwhile,
the positive rate, computed as the testing number in
a particular time window, is an essential metric for
describing if the target area controls the spread properly.
Therefore, we must use both numbers to estimate the
current infection status and mitigate the risks of underreporting cases and deaths.
COVID-19 confirmed death number: The
confirmed death number describes the ability of
COVID-19 to cause death, which is another direct piece
of evidence of how a region is affected. Furthermore, it
is an important metric for identifying at-risk populations
and guiding the response plan to adjust the medical
resource allocations. The confirmed death number and
case number can have very different trends because the
same response plan may affect these metrics differently.
For example, several infected regions can bring the
number of deaths down for the same response plan, but
other areas may only lower the case number. Thus, the
death rate helps us understand the severity of this virus
and evaluate each response plan’s fine-grained function.
Response plan: For COVID-19 pandemic control,
various organizations and governments develop several
local-level response plans or even a country-level
response plan to prepare for and respond to COVID-19.
In our DT model, we use Ri D .li
; tst; tend / to represent
a response plan, where li
is the location, with tst and
tend denoting the starting time and end time of Ri
. We
include the following response plans in the proposed
model: 14-day quarantine, domestic travel limitations,
gathering limits and stay-at-home orders, nonessential
business closures, reopening plans, mask policy, etc.
The effectiveness of different response plans can vary
because they may be affected by several external factors,
such as a sudden emergency, adverse weather conditions,
or vaccinations.
Temporal effects: In our work, two types of temporal
effects are considered as the primary factors in each city
DT model: temporal effects of historical infection status
(e.g., historical case numbers and historical deaths) and
external factors (e.g., selected response plans, events,
and gatherings). Note that our proposed city DT
model’s primary goal is to determine whether the specific
response plan can flatten the infection curve and evaluate
the period of validity of the plan. We thus need a robust
epidemic forecasting model that can consider multiple
temporal factors and hidden periodicity.
Historical infection status: For a fast-evolving
pandemic, such as the COVID-19 pandemic, the
historical case numbers are direct evidence of the
correlation between past conditions and the current
infection status. In Fig. 2, we take the historical daily
case information of three states (NV: Nevada, UT: Utah,764 Tsinghua Science and Technology, October 2021, 26(5): 759–771
Fig. 2 Correlation between the current infection trend and
the historical infection numbers.
and WI: Wisconsin) as examples of these temporal
effects. From the early March data of all three states, we
observe the same immediate effect of historical infection
numbers, because they lead to a continuously increasing
number of infections until April 2nd, which indicates
that the temporal correlations can play an essential role
in explaining and predicting future infection trends.
External factors: To determine whether external
factors can have an immediate or delayed effect on future
infection trends, we observe the correlation between
each specific factor and the infection status in the next
few days. In our work, the response plans are considered
the primary external factor, because the choice of a
specified response plan can also significantly affect
the number of infections. This effect can be various,
depending on the strictness of that policy, people’s
acceptance of it, and many other factors, such as
various climate conditions or the population density.
For example, in Fig. 2, we observe that after taking
a specified response plan, such as domestic travel
limitations or gathering limits, the infection trend of
all three states can be significantly decreased. However,
for different reasons, the validity period of the response
plan can vary, so all three states exhibit an increasing
infection trend over time. Thus, the temporal effect of
a specific response plan can be complicated because
external factors, such as the 14-day time window, the
indeterminate period that a response plan starts to
take effect, and a paroxysmal public crisis, may also
lead to infection trend changes, which suggests that
it is a challenge to estimate the temporal effects of a
specific response plan from such a complicated physical
environment.
3.3 Problem statement
To place the COVID-19 pandemic under control,
different local agencies in each city/region may choose
their own strategy to meet the local requirements. This
divergence occurs mainly because different regions
should consider the local intrinsic properties. For
instance, Area A, which is a thinly populated district
with very low infection rates, would prefer to choose
a less radical response plan; while the another Area
B, where has severe infection conditions, is very
likely to choose a less radical response plan, like
restricting activities and closing most of the facilities.
This situation means that each region can only obtain
knowledge by trial-and-error operation schemes for
seeking an effective response plan, and the increasing
time cost could lead to a delayed response plan with
poor performance. Moreover, to train a city DT model
to predict future infection trends after a response plan,
enough features must be used to construct the temporal
correlations, which suggests that a collaborative city
DT-training framework must be considered instead.
In coping with these challenges and limitations,
the FL protocol is used in our collaborative city DT
framework. In this paper, we study the problem of
forecasting future infection trends for specific response
plans. Formally, this problem is stated as follows:
Given multiple city DTs, D D D1; D2; : : : ; Di
, each
expects collaborations and is bounded with a local data
sensing method to generate individualize data source
si;1; si;2; : : : ; si;mi
, our federated training problem is to
optimize the following function:
min
w
(
F .w/ ,
X
N
iD1
piFi.w/
)
;Junjie Pang et al.: Collaborative City Digital Twin for the COVID-19 Pandemic: A Federated Learning Solution 765
where N is the number of city DTs, w represents the
parameter of FL global model, pi D mi=m, where m
is the number of data points in all city DT’s data source
and mi
is the number of data points of i-th city DT. For
city DT Di
, f ./ is the loss function of a data point, so
that the local objective Fi./ of Di can be defined as
Fi.w/ ,
1
mi
Xmi
jD1
f




NEW_PAPER



Received November 25, 2020, accepted December 8, 2020, date of publication December 14, 2020,
date of current version December 31, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3044858
Artificial Intelligence Applied to Chest X-Ray
Images for the Automatic Detection of COVID-19.
A Thoughtful Evaluation Approach
JULIÁN D. ARIAS-LONDOÑO 1
, (Senior Member, IEEE), JORGE A. GÓMEZ-GARCÍA 2
,
LAUREANO MORO-VELÁZQUEZ3
, (Member, IEEE), AND
JUAN I. GODINO-LLORENTE 2
, (Senior Member, IEEE)
1Department of Systems Engineering, Universidad de Antioquia, Medellín 050010, Colombia
2Bioengineering and Optoelectronics Laboratory (ByO), Universidad Politécnica de Madrid, 28031 Madrid, Spain
3Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD 21218, USA
Corresponding author: Juan I. Godino-Llorente (ignacio.godino@upm.es)
This work was supported in part by the Ministry of Economy and Competitiveness of Spain under Grant DPI2017-83405-R1, and in part
by the Universidad de Antioquia, Medellín, Colombia.
ABSTRACT Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or
antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the
significant number of false negatives of these tests and provide complementary evidence about the presence
and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest
X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence
for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network.
These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to
differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed
to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from
different sources, including more than 8, 500 COVID-19 examples. Three different experiments following
three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to
evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical
analysis of different variability issues that might compromise the system and its effects is performed. With
the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for
the worst but most explainable experiment, which requires a previous automatic segmentation of the lung
region.
INDEX TERMS COVID-19, deep learning, pneumonia, radiological imaging, chest X-ray.
I. INTRODUCTION
COVID-19 pandemic has rapidly become one of the biggest
health world challenges in recent years. The disease spreads
at a fast pace: the reproduction number of COVID-19 ranged
from 2.24 to 3.58 during the first months of the pandemic
[1], meaning that, on average, an infected person transmitted
the disease to 2 or more people. As a result, the number
of COVID-19 infections dramatically increased from just
a hundred cases in January –most of them concentrated in
The associate editor coordinating the review of this manuscript and
approving it for publication was Wenming Cao .
China– to more than 43 million in November spread all
around the world [2].
COVID-19 is caused by the coronavirus SARS-COV2, a
virus that belongs to the same family of other respiratory
disorders such as the Severe Acute Respiratory Syndrome
(SARS) and Middle East Respiratory Syndrome (MERS).
The symptomatology of COVID-19 is diverse and arises
after incubation of around 5.2 days. The symptoms might
include fever, dry cough, and fatigue; although, headache,
hemoptysis, diarrhea, dyspnoea, and lymphopenia are also
reported [3], [4]. In severe cases, an Acute Respiratory Distress Syndrome (ARDS) might be developed by underlying
pneumonia associated with COVID-19. For the most severe
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 226811J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
cases, the estimated period from the onset of the disease to
death ranges from 6 to 41 days (with a median of 14 days),
being dependent on the patient’s age and the patient’s immune
system status [3].
Once the SARS-COV2 reaches the host’s lung, it gets
into the cells through a protein called ACE2, which serves
as the ‘‘opening’’ of the cell lock. After the virus’s genetic
material has multiplied, the infected cell produces proteins
that complement the viral structure to produce new viruses.
Then, the virus destroys the infected cell, leaves it, and
infects new cells. The destroyed cells produce radiological
lesions [5]–[7] such as consolidations and nodules in the
lungs, that are observable in the form of ground-glass opacity
regions in the X-Ray (XR) images (Fig. 1c). These lesions
are more noticeable in patients assessed 5 or more days after
the onset of the disease, and especially in those older than
50 [8]. Findings also suggest that patients recovered from
COVID-19 have developed pulmonary fibrosis [9], in which
the connective tissue of the lung gets inflamed, leading to a
pathological proliferation of the connective tissue between
the alveoli and the surrounding blood vessels. Given these
signs, radiological imaging techniques –using plain chest
XR and thorax Computer Tomography (CT)– have become
crucial diagnosis and evaluation tools to identify and assess
the severity of the infection.
Since the declaration of the COVID-19 pandemic, the
World Health Organization identified four major key areas
to reduce the impact of the disease in the world: to prepare
and be ready; detect, protect, and treat; reduce transmission;
and/or innovate and learn [10]. Concerning the area of detection, significant efforts have been undertaken to improve the
diagnostic procedures of COVID-19. To date, the gold standard in the clinic is still a molecular diagnostic test based on a
polymerase chain reaction (PCR), which is precise but timeconsuming, requires specialized personnel and laboratories,
and is in general limited by the capacities and resources
of the health systems. An alternative to PCR is the rapid
tests such as those based on real-time reverse transcriptasepolymerase chain reaction (RT-PCR), as they can be more
rapidly deployed, decrease the load of the specialized laboratories and personnel, and provide faster diagnosis compared
to traditional PCR.
Other tests, such as those based on antigens, are now
available but are mainly used for massive testings (i.e. for
non-clinical applications) due to a higher chance of missing
an active infection. In contrast with RT-PCR, which detects
the virus’s genetic material, antigen tests identify specific
proteins on the virus’s surface, requiring a higher viral load,
which significantly shortens the sensitivity period.
In clinical practice, the RT-PCR test is usually complemented with a chest XR, in such a manner that the combined analysis reduces the significant number of false negatives and, at the same time, brings additional information
about the extent and severity of the disease. In addition to
that, thorax CT is also used as a second-row method for
evaluation. Although the evaluation with CT provides more
accurate results in the early stages and have been shown to
have greater sensitivity and specificity [11], XR imaging has
become the standard in the screening protocols since it is fast,
minimally-invasive, low-cost, and requires simpler logistics
for its implementation.
In the search for rapid, more objective, accurate and sensitive procedures, which could complement the diagnosis and
assessment of the disorder, a trend of research has emerged
to employ clinical features extracted from thorax CT or chest
XR with automatic detection purposes. A potential benefit of
studying the radiological images is that these can characterize pneumonic states even in asymptomatic population [12].
However, more research is needed in this field as the lack
of findings in infected patients is also reported [13]. The
consolidation of such technology will permit a speedy and
accurate diagnosis of COVID-19, decreasing the pressure
on microbiological laboratories in charge of the PCR tests
and providing more objective means of assessing the disease’s severity. To this end, techniques based on deep learning have been employed to leverage XR information with
promising results. Although it would be desirable to employ
CT for detection purposes, some significant drawbacks are
often present, including higher costs, a more time-consuming
procedure, thorough hygienic protocols to avoid infection
spread, and the requirement of specialized equipment that
might not be readily available in hospitals or health centers.
By contrast, XR imaging procedures are available as first
screening tests in many hospitals or health centers, at lower
expenses.
Several approaches for COVID-19 detection based on
chest XR images and different deep learning architectures
have been published in the last few months, reporting classification accuracies around 90% or higher. However, the central
analysis in most of those works is focused on the variations
of network architectures, whereas there is less attention to
the variability factors that a real solution should tackle before
it can be deployed in the medical setting. In this sense, no
analysis has been provided to demonstrate the reliability of
the networks’ predictions, which in the context of medical
solutions acquires particular relevance. Moreover, most of
the works in state of the art have validated their results with
data sets containing dozens or a few hundreds of COVID-19
samples, limiting the proposed solutions’ impact.
With these antecedents in mind, this paper uses a deep
learning algorithm based on CNN, data augmentation, and
regularization techniques to handle data imbalance for the
discrimination between COVID-19, controls, and other types
of pneumonia. The methods are tested with the most extensive
corpus to date, to the authors’ knowledge. Three different
sets of experiments were carried out in the search for the
most suitable and coherent approach. To this end, the paper
also uses explainability techniques to gain insight about the
manners on how the neural network learns, and interpretability in terms of the overlapping among the regions of interest
selected by the network and those that are more likely affected
by COVID-19. A critical analysis of factors that affect the
226812 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 1. Experiments considered in the paper. First row: raw chest XR images belonging to the control, pneumonia, and
COVID-19 classes. Second row: Grad-CAM activation mapping for the XR images. Despite the high accuracy, the model
focuses its attention on areas different from the lungs in some cases. Third row: Grad-CAM activation mapping after
zooming in, cropping to a squared region of interest and resizing. Zooming to the region of interest forces the model to
focus its attention to the lungs, but errors are still present. Fourth row: Grad-CAM activation mapping after a zooming and
segmentation procedure. Zooming in and segmenting force the model to focus attention in the lungs. The black background
represents the mask introduced by the segmentation procedure.
VOLUME 8, 2020 226813J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
performance of automatic systems based on deep learning is
also carried out.
This paper is organized as follows: section II presents some
background and antecedents on the use of deep learning for
COVID-19 detection. section III presents the methodology,
section IV presents the results obtained, whereas V presents
the discussions and main conclusions of this paper.
II. BACKGROUND
A large body of research has emerged on the use of Artificial
Intelligence (AI) to detect different respiratory diseases using
plain XR images. For instance, in [14] authors developed
a 121-layer Convolutional Neural Network (CNN) architecture, called Chexnet, which was trained with a dataset of
100, 000 XR images for the detection of different types of
pneumonia. The study reports an area under the Receiving
Operating Characteristic (ROC) curve of 0.76 in a multiclass
scenario composed of 14 classes.
Directly related to the COVID-19 detection, three CNN
architectures (ResNet50, InceptionV3 and InceptionResNetV2) were considered in [15], using a database of just
50 controls and 50 COVID-19 patients. The best accuracy
(98%) was obtained with ResNet50. In [16], seven different
deep CNN models were tested using a corpus of 50 controls
and 25 COVID-19 patients. The best results were attained
with the VGG19 and DenseNet models, obtaining F1-scores
of 0.89 and 0.91 for controls and patients. The COVID-Net
architecture was proposed in [17]. The net was trained with
an open repository, called COVIDx, composed of 13, 975 XR
images, although only 358 -from 266 patients– belonged to
the COVID-19 class. The attained accuracy was of 93.3%. In
[18] a deep anomaly detection algorithm was employed for
the detection of COVID-19, in a corpus of 100 COVID-19
images (taken from 70 patients), and 1, 431 control images
(taken from 1008 patients). 96% of sensitivity and 70% of
specificity was obtained. In [19], a combination of a CNN for
feature extraction and a Long Short Term Memory Network
(LSTM) for classification were used for automatic detection
purposes. The model was trained with a corpus gathered from
different sources, consisting of 4, 575 XR images: 1, 525 of
COVID-19 (although 912 come from a repository applying
data augmentation), 1, 525 of pneumonia, and 1, 525 of controls. In a 5-folds cross-validation scheme, a 99% accuracy
was reported. In [20], the VGG16 network was used for
classification, employing a database of 132 COVID-19, 132
controls and 132 pneumonia images. Following a hold-out
validation, about 100% accuracy was obtained identifying
COVID-19, being lower on the other classes.
Authors in [21] adapted a model for the classification of
COVID-19 by using transfer-learning based on the Xception
network. Experiments were carried out in a database of 127
COVID-19, 500 controls, and 500 patients with pneumonia gathered from different sources, attaining about 97%
accuracy. A similar approach, followed in [22], used the
same corpus for the binary classification of COVID-19 and
controls; and for the multiclass classification of COVID-19,
controls, and pneumonia. With a modification of the Darknet
model for transfer-learning and 5-folds cross-validation, 98%
accuracy in binary classification and 87% in multiclass classification was obtained. Another Xception transfer-learningbased approach was presented in [23], but considering two
multi-class classification tasks: i) controls vs. COVID-19
vs. viral pneumonia and bacterial pneumonia; ii) controls
vs. COVID-19 vs. pneumonia. To deal with the imbalance
of the corpus, an undersampling technique was used to
randomly discard registers from the larger classes, obtaining 290 COVID-19, 310 controls, 330 bacterial pneumonia,
and 327 viral pneumonia chest XR images. The reported
accuracy was 89% in the 4-class problem and 94% in the
3-class scenario. Moreover, in a 3-class cross-database experiment, the accuracy was 90%. In [24], four CNN networks
(ResNet18, ResNet50, SqueezeNet, and DenseNet-121) were
used for transfer learning. Experiments were performed on
a database of 184 COVID-19 and 5, 000 no-finding and
pneumonia images. Reported results indicate a sensitivity of
about 98% and a specificity of 93%. In [25], five state-of-theart CNN systems –VGG19, MobileNetV2, Inception, Xception, InceptionResNetV2– were tested on a transfer-learning
setting to identify COVID-19 from control and pneumonia
images. Experiments were carried out in two partitions: one
of 224 COVID-19, 700 bacterial pneumonia, and 504 control
images; and another that considered the previous normal and
COVID-19 data but included 714 cases of bacterial and viral
pneumonia. The MobileNetV2 net attained the best results
with 96% and 94% accuracy in the 2 and 3-classes classification. In [26], the MobileNetV2 net was trained from
scratch and compared to one net based on transfer-learning
and to another based on hybrid feature extraction with finetuning. Experiments performed in a dataset of 3905 XR
images of 6 diseases indicated that training from scratch
outperforms the other approaches, attaining 87% accuracy
in the multiclass classification and 99% in the detection
of COVID-19. A system, also grounded on the InceptionNet and transfer-learning, was presented in [27]. Experiments were performed on 6 partitions of XR images with
COVID-19, pneumonia, tuberculosis, and controls. Reported
results indicate 99% accuracy, in a 10-folds cross-validation
scheme, in the classification of COVID-19 from other classes.
In [28], fuzzy color techniques were used as a preprocessing stage to remove noise and enhance XR images
in a 3-class classification setting (COVID-19, pneumonia,
and controls). The pre-processed images and the original
ones were stacked. Then, two CNN models were used to
extract features: MobileNetV2 and SqueezeNet. A feature
selection technique based on social mimic optimization and a
Support Vector Machine (SVM) was used. Experiments were
performed on a corpus of 295 COVID-19, 65 controls and 98
pneumonia XR images, attaining about 99% accuracy.
Given the limited amount of COVID-19 images, some
approaches have focused on generating artificial data to train
better models. In [29], an auxiliary Generative Adversarial
Network (GAN) was used to produce artificial COVID-19
226814 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
XR images from a database of 403 COVID-19 and 1, 124
controls. Results indicated that data augmentation increased
accuracy from 85% to 95% on the VGG16 net. Similarly,
in [30], GAN was used to augment a database of 307
images belonging to four classes: controls, COVID-19, bacterial and viral pneumonia. Different CNN models were
tested in a transfer-learning-based setting, including Alexnet,
Googlenet, and Restnet18. The best results were obtained
with Googlenet, achieving 99% in a multiclass classification approach. In [31], a CNN based on capsule networks
(CapsNet), was used for binary (COVID-19 vs. controls)
and multi-class classification (COVID-19 vs. pneumonia
vs. controls). Experiments were performed on a dataset of
231 COVID-19, 1, 050 pneumonia and 1, 050 controls XR
images. Data augmentation was used to increase the number of COVID-19 images to 1, 050. On a 10-folds crossvalidation scheme, 97% accuracy for binary classification,
and 84% multi-class classification were achieved. The CovXNet architecture, based on depth-wise dilated convolution
networks, was proposed in [32]. In the first stage, pneumonia (viral and bacterial) and control images were employed
for pretraining. Then, a a refined model of COVID-19 is
obtained using transfer learning. In experiments using twodatabases, 97% accuracy was achieved for COVID-19 vs.
controls, and of 90% for COVID-19 vs. controls vs. bacterial and viral cases of pneumonia. In [33], an easy-to-train
neural network with a limited number of training parameters was presented. To this end, patch phenomena found on
XR images were studied (bilateral involvement, peripheral
distribution, and ground-glass opacification) to develop a
lung segmentation and a patch-based neural network that
distinguished COVID-19 from controls. The basis of the
system was the ResNet18 network. Saliency maps were also
used to produce interpretable results. In experiments performed on a database of controls (191), bacterial pneumonia
(54), tuberculosis (57) and viral pneumonia (20), about 89%
accuracy was obtained. Likewise, interpretable results were
reported in terms of large correlations between the saliency
maps’ activation zones and the radiological findings found
in the XR images. The authors also indicate that when the
lung segmentation approach was not considered, the system’s
accuracy decreased to about 80%. In [34], 2D curvelets transformations were used to extract features from XR images. A
feature selection algorithm based on meta-heuristic was used
to find the most relevant characteristics, while a CNN model
based on EfficientNet-B0 was used for classification. Experiments were carried out in a database of 1, 341 controls, 219
COVID-19, and 1, 345 viral pneumonia images, and 99%
classification accuracy was achieved with the proposed
approach. Multiclass and hierarchical classification of different types of diseases producing pneumonia (with 7 labels and
14 label paths), including COVID-19, were explored in [35].
Since the database of 1, 144 XR images was heavily imbalanced, different resampling techniques were considered. By
following a transfer-learning approach based on a CNN architecture to extract features, and a hold-out validation with
5 different classification techniques, a macro-avg F1-Score of
0.65 and an F1-Score of 0.89 were obtained for the multiclass
and hierarchical classification scenarios, respectively. In [36],
a three-phases approach is presented: i) to detect the presence
of pneumonia; ii) to classify between COVID-19 and pneumonia; and, iii) to highlight regions of interest of XR images.
The proposed system utilized a database of 250 images of
COVID-19 patients, 2, 753 with other pulmonary diseases,
and 3, 520 controls. By using a transfer-learning system
based on VGG16, about 0.97 accuracy was reported. A
CNN-hierarchical approach using decision trees (based on
ResNet18) was presented in [37], on which a first tree classified XR images into the normal or pathological classes;
the second identified tuberculosis; and the third COVID-19.
Experiments were carried out on 3 partitions obtained after
having gathered images from different sources and data augmentation. The accuracy for each decision tree –starting from
the first– was about 98%, 80%, and 95%, respectively.
A. ISSUES AFFECTING RESULTS IN THE LITERATURE
Table 1 presents a summary of state of the art in the automatic detection of COVID-19 based on XR images and deep
learning. Despite the excellent results reported, the review
reveals that some of the proposed systems suffer from certain
shortcomings that affect the conclusions extracted in their
respective studies, limiting the translational possibilities to
the clinical environment. Likewise, variability factors have
not been deeply studied in these papers and their study can
be regarded as necessary.
For instance, one of the issues that affect most of the
reviewed systems to detect COVID-19 from plain chest XR
images is the use of very limited datasets, which compromises
their generalization capabilities.
Indeed, to date and from the authors’ knowledge, the
paper employing the largest database of COVID-19 considers
1, 525 XR images gathered from different sources. However,
912 images belong to a data augmented repository, which
does not include additional information about the initial number of files or the number of augmented images. In general
terms, most of the works employ less than 300 COVID-19
XR images, having systems that use as few as 50 images.
However, this is understandable given that some of these
works were published during the onset of the pandemics when
the number of available registers was limited.
On the other hand, a good balance in the patients’ age is
considered essential to avoid the model to learn age-specific
features. However, several previous works have used XR
images from children to populate the pneumonia class.1 This
might be biasing the results given the age differences of
COVID-19 patients.
Despite many works in the literature report a good performance in detecting COVID-19, most of the approaches follow
1First efforts used the RSNA Pneumonia Detection Challenge dataset,
which is focused on the detection of pneumonia cases in children.
https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview
VOLUME 8, 2020 226815J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 1. Summary of the literature in the field.
a brute force approach exploiting deep learning’s potentiality
to correlate with the outputs (i.e., the class labels) but provide
low interpretability and explainability of the process. It is
unclear if the good results are due to the system’s actual
capability to extract information related to the pathology or
because it leart other aspects during training that are biasing
and compromising the results. As a matter of example, just
one of the studies reported in the literature follows a strategy that forces the network to focus on the most significant
areas of interest for COVID-19 detection [33]. It does so by
proposing a methodology based on semantic segmentation of
the lungs. In the remaining cases, it is unclear if the models
are analyzing the lungs or if they are categorizing given
any other information available, which might be interesting
for classification purposes but might lack diagnostic interest. This is relevant, as in all the analyzed works in literature, pneumonia and controls classes come from a certain
repository, whereas others such as COVID-19 comes from
a combination of sources and repositories. Having classes
generated in different conditions might undoubtedly affect
the results, and as such, a critical study about this aspect is
needed. In the same line, other variability issues such as the
sensor technology employed, the type of projection used, the
sex of the patients, and even age, require a thorough study.
Finally, the literature review revealed that most of the
published papers showed excellent correlation with the disease but low interpretability and explainability (see Table 1).
Indeed, it is often more desirable in clinical practice to
obtain interpretable results that correlate with pathological
conditions or a particular demographic or physiological variable than a black box system that yields a binary or a multiclass decision. From the revision of literature, only [33] and
[32] partially addressed this aspect. Thus, further research on
this topic is needed.
With these ideas in mind, this paper addresses these aspects
by training and testing with a wide corpus of RX images,
proposing and comparing two strategies to preprocess the
images, analyze the effect of some variability factors, and
provide some insights to more explainable and interpretable
results. The primary goal is to present a critical overview
of these aspects since they might be affecting the modeling
capabilities of the deep learning systems for the detection of
COVID-19.
III. METHODOLOGY
The design methodology is presented in the following
section. The procedure followed to train the neural network
is described first, along with the process that was followed to
create the dataset. The network and the source code to train
it are available at https://github.com/jdariasl/COVIDNET, so
results can be readily reproduced by other researchers.
A. THE NETWORK
The core of the system is a deep CNN based on the
COVID-Net2 proposed in [17]. Some modifications were
2Following the PyTorch implementation available at
https://github.com/IliasPap/COVIDNet
226816 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
made to include regularization components in the last two
dense layers and a weighted categorical cross-entropy loss
function to compensate the class imbalance. The network
structure was also refactored to allow gradient-based localization estimations [38], which are used after training in the
search for an explainable model.
The network was trained with the corpus described in III-B
using the Adam optimizer with a learning rate policy: the
learning rate decreases when learning stagnates for some time
(i.e., ’patience’). The following hyperparameters were used
for training: learning rate = 2
-5, number of epochs = 24,
batch size = 32, factor = 0.5, patience = 3. Furthermore,
data augmentation for pneumonia and COVID-19 classes was
leveraged with the following augmentation types: horizontal
flip, Gaussian noise with a variance of 0.015, rotation, elastic
deformation, and scaling. The variant of the COVID-Net
was built and evaluated using the PyTorch library [39]. The
CNN features from each image are concatenated by a flatten
operation, and the resulting feature map is fed to three fully
connected layers to generate a probability score for each
class. The first two fully connected layers include dropout
regularization of 0.3 and ReLU activation functions. Dropout
was necessary because the original network tended to overfit
since the very beginning of the training phase.
The network’s input layer rescales the images keeping the
aspect ratio, with the shortest dimension scaled to 224 pixels.
Then, the input image is cropped to a square of 224 × 224
pixels located in the center of the image. Images are normalized using a z-score function with parameters mean =
[0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225], for
each of the three RGB channels respectively. Even though we
are working with grayscale images, the network architecture
was designed to be pre-trained on a general-purpose database
including colored images; this characteristic was kept in case
it would be necessary to use some transfer learning strategy
in the future.
The network’s output layer provides a score for each of
the three classes (i.e. control, pneumonia, or COVID-19),
which is converted into three probability estimates –in the
range [0, 1]– using a softmax activation function. The class
membership’s final decision is made according to the highest
of the three probability estimates obtained.
B. THE CORPUS
The corpora used in the paper have been compiled from a set
of Posterior-Anterior (PA) and Anterior-Posterior (AP) XR
images from different public sources. The compilation contains images from participants without any observable pathology (controls or no findings), pneumonia, and COVID-19
cases. After the compilation, two subsets of images were
generated, i.e., training and testing. Table 2 contains the
number of images per subset and class. Overall, the corpus
contains more than 70, 000 XR images, including more than
8, 500 images belonging to COVID-19 patients.
The repositories of XR images employed to create the corpus used in this paper are presented next. Most of these conTABLE 2. Number of images per class for training and testing subsets.
tain solely registers of controls and pneumonia patients. Only
the most recent repositories include samples of COVID-19
XR images. In all cases, the annotations were made by a
specialist as indicated by the authors of the repositories.
The COVID-19 class is modelled compiling images coming from three open data collection initiatives: HM Hospitales COVID [40], BIMCV-COVID19 [41] and Actualmed
COVID-19 [42] chest XR datasets. The final result of the
compilation process is a subset of 8, 573 images from more
than 3, 600 patients at different stages of the disease.3
Table 3 summarizes the most significant characteristics of
the datasets used to create the corpus, which is presented next:
1) HM HOSPITALES COVID-19 DATASET
This dataset was compiled by HM Hospitals [40]. It contains all the available clinical information about anonymous
patients with the SARS-CoV-2 virus treated in different centers belonging to this company since the beginning of the
pandemic in Madrid, Spain.
The corpus contains the anonymized records of 2, 310
patients and includes several radiological studies for each
patient corresponding to different stages of the disease. A
total of 5, 560 RX images are available in the dataset, with
an average of 2.4 image studies per subject, often taken in
intervals of two or more days. The histogram of the patients’
age is highly coherent with the demographics of COVID-19
in Spain (see Table 3 for more details).
Only patients with at least one positive PCR test or positive
immunological tests for SARS-CoV-2 were included in the
study. The Data Science Commission and the Research Ethics
Committee of HM Hospitales approved the current research
study and the data for this purpose.
2) BIMCV COVID19 DATASET
BIMCV COVID19 dataset [41] is a large dataset with chest
radiological studies (XR and CT) of COVID-19 patients
along with their pathologies, results of PCR and immunological tests, and radiological reports. It was recorded by the
Valencian Region Medical Image Bank (BIMCV) in Spain.
The dataset contains the anonymized studies of patients with
at least one positive PCR test or positive immunological tests
for SARS-CoV-2 between February 26th and April 18th,
2020. The corpus is composed of 3, 013 XR images, with an
average of 1.9 image studies per subject, taken in intervals
of approximately two or more days. The histogram of the
patients’ age is highly coherent with the demographics of
3Figures at the time the datasets were downloaded. The datasets are still
open, and more data might be available in the next future.
VOLUME 8, 2020 226817J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 3. Demographic data of the datasets used. Only those labels confirmed are reported.
COVID-19 in Spain (Table 3). Only patients with at least
one positive PCR test or positive immunological tests for
SARS-Cov-2 were included in the study.
3) ACTUALMED SET (ACT)
The actualmed COVID-19 Chest XR dataset initiative [42]
contains a series of XR images compiled by Actualmed and
Universitat Jaume I (Spain). The dataset contains COVID-19
and control XR images, but no information is given about the
place or date of recording and/or demographics. However, a
metadata file is included. It contains an anonymized descriptor to distinguish among patients and information about the
XR modality, type of view, and the class to which the image
belongs.
4) CHINA SET - THE SHENZHEN SET
The set was created by the National Library of Medicine,
Maryland, USA, in collaboration with the Shenzhen No.3
People’s Hospital at Guangdong Medical College in Shenzhen, China [43].
The dataset contains normal and abnormal chest XR with
manifestations of tuberculosis and includes associated radiologist readings.
5) THE MONTGOMERY SET
The National Library of Medicine created this dataset in
collaboration with the Department of Health and Human
Services, Montgomery County, Maryland, USA. It contains
data from XR images collected under Montgomery County’s
tuberculosis screening program [43], [44].
6) ChestX-ray8 DATASET (CRX8)
The ChestX-ray8 dataset [45] contains 12, 120 images from
14 common thorax disease categories from 30, 805 unique
patients, compiled by the National Institute of Health (NIH).
For this study, the images labeled with ’no radiological findings’ were used to be part of the control class, whereas the
images annotated as ’pneumonia’ were used for the pneumonia class.
7) CheXpert DATASET
CheXpert [46] is a dataset of XR images created for an
automated evaluation of medical imaging competitions and
contains chest XR examinations carried out in Stanford Hospital during 15 years. For this study, we selected 4, 623 pneumonia images using those annotated as ’pneumonia’ with
and without additional comorbidity. COVID-19 never caused
these comorbidities. The motivation to include pneumonia
with comorbidities was to increase the number of pneumonia
examples in the final compilation for this study, increasing
this cluster’s variability.
8) MIMIC-CXR DATABASE
MIMIC-CXR [47] is an open dataset complied from 2011 to
2016, and comprising de-identified chest RX from patients
admitted to the Beth Israel Deaconess Medical Center. In
our study, we employed the images for the pneumonia class.
The labels were obtained from the agreement of the two
methods indicated in [47]. The dataset reports no information
about gender or age; thus, we assume that the demographics are similar to those of CheXpert dataset and those of
pneumonia [48].
C. IMAGE PRE-PROCESSING
XR images were converted to uncompressed grayscale ’.png’
files, encoded with 16 bits, and preprocessed using the
DICOM WindowCenter and WindowWidth details (when
needed). All images were converted to a Monochrome 2
photometric interpretation. Initially, the images were not rescaled to avoid loss of resolution in later processing stages.
Only AP and PA views were selected. No differentiation
was made between erect, either standing or sitting, or decubitus. This information was inferred by a careful analysis of
the DICOM tags and required manual checking due to certain
labeling errors.
D. EXPERIMENTS
The corpus collected from the aforementioned databases was
processed to compile three different datasets of equal size
to the initial one. Each of these datasets was used to run a
different set of experiments.
1) EXPERIMENT 1. RAW DATA
The first experiment was run using the raw data extracted
from the different datasets. Each image is kept with the original aspect ratio. Only a histogram equalization was applied.
226818 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
2) EXPERIMENT 2. CROPPED IMAGE
The second experiment consists of preprocessing the images
by zooming in, cropping to a squared region of interest, and
resizing to a squared image (aspect ratio 1 : 1). The process
is summarized in the following steps:
1) Lungs are segmented from the original image using
a U-Net semantic segmentation algorithm.4 The algorithm used reports Intersection-Over-Union (IoU) and
Dice similarity coefficient scores of 0.971 and 0.985
respectively.
2) A black mask is extracted to identify the external
boundaries of the lungs.
3) The mask is used to create two sequences, adding
the grey levels of the rows and columns respectively.
These two sequences provide four boundary points,
which define two segments of different lengths in the
horizontal and vertical dimensions.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated with the lungs,
taking advantage of the higher added values outside the
lungs (Fig. 2). The process to obtain the squared region
requires identifying the middle point of each of the
identified segments and cropping in both dimensions
using the length of the longest of these two segments.
5) The original image is cropped with a squared template
placed in the centre of the matrix using the information
obtained in the previous step. No mask is placed over
the image.
6) Histogram equalization of the image obtained.
This process is carried out to decrease the variability of the
data, to make the training process of the network simpler, and
to ensure that the region of significant interest is in the centre
of the image with no areas cut.
3) EXPERIMENT 3. LUNG SEGMENTATION
The third experiment consists of preprocessing the images by
masking, zooming in, cropping to a squared region of interest,
and resizing to a squared image (aspect ratio 1 : 1). The
process is summarized in the following steps:
1) Lungs are segmented from the original image using
the same semantic segmentation algorithm used in
experiment 2.
2) An external black mask is extracted to identify the
external boundaries of the lungs.
3) The mask is used to create two sequences, adding the
grey levels of the rows and columns respectively.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated to the lungs,
taking advantage of the higher added values outside
them (Fig. 2).
4Following the Keras implementation available at https://github.com
/imlab-uiip/lung-segmentation-2d
FIGURE 2. Identification of the squared region of interest. Plots in the top
and left represent the normalized accumulated gray level in the vertical
and horizontal dimension respectively.
5) The original image is cropped with a squared template
placed in the center of the image.
6) The mask is dilated with a 5 × 5 pixels kernel, and it is
superimposed to the image.
7) Histogram equalization is applied only to the segmented area (i.e. the area corresponding to the lungs).
This preprocessing makes the training of the network much
simpler and forces the network to focus the attention on
the lungs region, removing external characteristics –like the
sternum– that might influence the obtained results.
E. IDENTIFICATION OF THE AREAS OF SIGNIFICANT
INTEREST FOR THE CLASSIFICATION
The areas of significant interest used by the CNN for
discrimination purposes are identified using a qualitative
analysis based on a Gradient-weighted Class Activation
Mapping (Grad-CAM) [38]. This is an explainability method
that serves to provide insights about the manners on how
deep neural networks learn, pointing to the most significant
areas of interest for decision-making purposes. The method
uses the gradients of any target class to flow until the final
convolutional layer, and to produce a coarse localization map
which highlights the most important regions in the image
identifying the class. The result of this method is a heat map
like those presented in Fig. 1, in which the colour encodes the
importance of each pixel in differentiating among classes.
IV. RESULTS
The model has been quantitatively evaluated computing
the test Positive Predictive Value (PPV), Recall, F1-score
(F1), Accuracy (Acc), Balanced Accuracy (BAcc), Geometric
Mean Recall (GMR) and Area Under the ROC Curve (AUC)
for each of the three classes in the corpus previously described
in section III-B. The performance of the models is assessed
using an independent testing set, which has not been used
VOLUME 8, 2020 226819J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 4. Performance measures for the three experiments considered in the paper.
FIGURE 3. ROC curves and confusion matrices for each one of the experiments, considering each one of the classes separately. Top: ROC curves. Bottom:
Normalized confusion matrices. Left: Original images (experiment 1). Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
during development. A 5-folds cross-validation procedure
has been used to evaluate the obtained results (Training/Test
balance: 90/10 %). The performance of the CNN network on
the three experiments considered in this paper is summarized
in Table 4. Likewise, the ROC curves per class for each of the
experiments, and the corresponding confusion matrices are
presented in Fig. 3. The global ROC curve displayed in Fig. 4
for each experiment summarizes the global performance of
the experiments.
Considering experiment 1, and although slightly higher for
controls, the detection performance remains almost similar
for all classes (the PPV ranges from 91-93%) (Table 4). The
remaining measures per class follow the same trend, with
similar figures but better numbers for the controls. ROC
curves and confusion matrices of Fig. 3a and Fig. 3d point out
that the largest source of confusion for COVID-19 is the pneumonia class. The ROC curves for each one of the classes reach
in all cases AUC values larger than 0.99, which, in principle
is considered excellent. In terms of global performance, the
system achieves an Acc of 91% and a BAcc of 94% (Table 4).
This is also supported by the average ROC curve of Fig. 4,
which reveals the excellent performance of the network and
226820 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 4. Average ROC curves for each experiment, including AUC values.
the almost perfect behaviour of the ROC curve. Deviations
are small for the three classes.
When experiment 2 is considered, a decrease in the performance per class is observed in comparison to experiment 1.
In this case, the PPV ranges from 81-93% (Table 4), with a
similar trend for the remaining figures of merit. ROC curves
and confusion matrices in Fig. 3a and Fig. 3d report AUC
values in the range 0.96-0.99, and an overlapping of the
COVID-19 class mostly with pneumonia. The global performance of the system -presented in the ROC curve of Fig. 4
and Table 4- yields an AUC of 0.98, an Acc of 87% and a
BAcc of 81%.
Finally, for experiment 3, PPV ranges from 78% − 96%
(Table 4). In this case, the results are slightly worse than those
of experiment 2, with the COVID-19 class presenting the
worse performance among all the tests. According to Fig. 3c,
AUCs range from 0.94 to 0.98. Confusion matrix in Fig. 3f
reports a large level of confusion in the COVID-19 class
being labelled as pneumonia 18% of the times. In terms of
global performance, the system reaches an Acc of 91% and a
BAcc of 87% (Table 4). These results are consistent with the
average AUC of 0.97 shown in Fig. 4.
A. EXPLAINABILITY AND INTERPRETABILITY OF THE
MODELS
The regions of interest identified by the network were analyzed qualitatively using Grad-CAM activation maps [38].
Results shown by the activation maps, permit the identification of the most significant areas in the image, highlighting
the zones of interest that the network is using to discriminate.
In this regard, Fig. 1, presents examples of the Grad-CAM
of a control, a pneumonia, and a COVID-19 patient, for each
of the three experiments considered in the paper. It is important to note that the activation maps are providing overall
information about the behaviour of the network, pointing to
the most significant areas of interest, but the whole image is
supposed to be contributing to the classification process to a
certain extent.
The second row in Fig. 1 shows several prototypical results
applying the Grad-CAM techniques to experiment 1. The
examples show the areas of significant interest for a control,
pneumonia and COVID-19 patient.
The results suggest that the detection of pneumonia or
COVID-19 is often carried out based on information that is
outside the expected area of interest, i.e. the lung area. In the
examples provided, the network focuses on the corners of the
XR image or in areas around the diaphragm. In part, this is
likely due to the metadata which is frequently stamped on
the corners of the XR images. The Grad-CAM plots corresponding to the experiment 2 (third row of Fig. 1), indicates
that the model still points towards areas which are different
from the lungs, but to a lesser extent. Finally, the Grad-CAM
of experiment 3 (fourth row of Fig. 1) presents the areas of
interest where the segmentation procedure is carried out. In
this case, the network is forced to look at the lungs, and
therefore this scenario is supposed to be more realistic and
more prone to generalizing as artifacts that might bias the
results are somehow discarded.
On the other hand, for visualization purposes, and in order
to interpret the separability capabilities of the system, a t-SNE
embedding is used to project the high dimensional data of the
layer adjacent to the output of the network, to a 2-dimensional
space. Results are presented in Fig. 5 for each of the three
experiments considered in the paper.
Fig. 5 indicates that a good separability exists for all
the classes in both training and testing data, and for all
experiments. The boundaries of the normal cluster are very
well defined in the three experiments, whereas pneumonia
and COVID-19 are more spread, overlapping with adjacent
classes.
In general terms, the t-SNE plots demonstrate the ability
of the network to learn a mapping from the input data to the
desired labels. However, despite the shape differences found
for the three experiments, no additional conclusions can be
extracted.
B. POTENTIAL VARIABILITY FACTORS AFFECTING THE
SYSTEM
There are several variability factors which might be biasing
the results, namely: the projection (PA vs. AP); the technology of the detector (Computed Radiography (CR) vs.
Digital Radiography (DX)); the gender of the patients; the
age; potential specificities of the dataset; or having trained
with several images per patient.
The use of several images per patient represents a certain
risk of data leak in the COVID-19 class due to its underlying
imbalance. However, our initial hypothesis is that using several images per COVID-19 patient but obtained at different
instants in time (with days of difference), would increase the
variability of the dataset, and thus that source of bias would
be disregarded. Indeed, the evolution of the associated lesions
often found in COVID-19 is considered fast, in such a manner
that very different images are obtained in a time interval
as short as one or two days of the evolution. Also, since
VOLUME 8, 2020 226821J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 5. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
TABLE 5. Performance measures considering the XR projection (PA/AP).
every single exploration is framed differently, or sometimes
even taken with different machines and/or projections, the
potential bias is expected to be minimized.
Concerning the type of projection, and to evaluate its
effectiveness, the system has been studied taking into
account this potential variability factor, which is considered to be one of the most significant. In particular,
Table 5, presents the outcomes after accounting for the
influence of the XR projection (PA/AP) in the performance of the system. In general terms, the system demonstrates consistency with respect to the projection used,
and differences are mainly attributable to smaller training and testing sets. However, significant differences are
shown for projection PA in class COVID-19/experiment 3,
decreasing the F1 up to 65.61%. The reason for the
unexpected drop in performance is unknown, but likely
226822 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 6. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3). Labels correspond to data sets and classes.
attributable to an underrepresented class in the corpus (see
Table 3).
Besides, Table 6 shows –for the three experiments under
evaluation and for the COVID-19 class– the error distribution with respect to the sex of the patient, technology of
the detector, dataset and projection. For the four variability
factors enumerated, results show that the error distribution
committed by the system follows –with minor deviations– the
existing proportion of the samples in the corpus. These results
suggest that there is no clear bias with respect to these potential variability factors, at least for the COVID-19 class which
is considered the worst-case due to its underrepresentation.
Similar results would be expected for control and pneumonia
classes, but these results are not provided due to the lack of
certain labels in some of the datasets used (see Table 3).
Concerning age, the datasets used are reasonably well
balanced (Table 3), but with a certain bias in the normal class:
COVID-19 and pneumonia classes have very similar average
ages, but controls have a lower mean age. Our assumption
has been that age differences are not significantly affecting
the results, but the mentioned difference might explain why
the normal cluster in Fig. 5 is less spread than the other two.
In any case, no specific age biases have been found in the
errors committed by the system.
An additional study was also carried out to evaluate the
influence of potential specificities of the different datasets
used to compile the corpus (i.e. the variability of the results
with respect to the datasets merged to build the corpus). This
variability factor is evaluated in Fig. 6 using different t-SNE
plots (one for each experiment in a similar way than in Fig. 5)
but differentiating the corresponding cluster for each dataset
and class.
Results for the different datasets and classes are clearly
merged or are adjacent in the same cluster. However, several datasets report a lower variability for certain classes
(i.e. variability in terms of scattering). This is especially
clear in Chexpert and NIH pneumonia sets, which are successfully merged with the corresponding class but appear
VOLUME 8, 2020 226823J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 6. Percentage of testing samples and error distribution with
respect to several potential variability factors for the COVID-19 class.
(% in hits represents the percentage of samples of every factor under
analysis in the correctly predicted set).
clearly clustered, suggesting that these datasets have certain
unknown specific characteristics different to those of the
complementary datasets. The model has been able to manage
this aspect but is a factor to be analyzed in further studies.
V. DISCUSSION AND CONCLUSION
This study evaluates a deep learning model for the detection
of COVID-19 from RX images. The paper provides additional evidence to the state of the art, supporting the potential of deep learning techniques to accurately categorize XR
images corresponding to control, pneumonia, and COVID-19
patients (Fig. 1). These three classes were chosen under the
assumption that they can support clinicians in making better
decisions, establishing potential differential strategies to handle patients depending on their cause of infection [17]. However, the main goal of the paper was not to demonstrate the
suitability of deep learning for categorizing XR images but to
make a thoughtful evaluation of the results and the different
preprocessing approaches, searching for better explainability
and interpretability of the results while providing evidence of
potential effects that might bias results.
The model relies on the COVID-Net network, which has
served as a basis for the developing a more refined architecture. This network has been chosen due to its tailored
characteristics and given the previous good results reported
by other researchers. The COVID-Net was trained with a
corpus compiled using data gathered from different sources:
the control and pneumonia classes –with 49, 983 and 24, 114
samples respectively– were collected from the ACT, Chinaset, Montgomery, CRX8, CheXpert, and MIMIC datasets;
and the COVID-19 class was collected from the information
available at the BIMCV, ACT, and HM Hospitales datasets.
Although the COVID-19 class only contains 8, 573 chest
RX images, the developers of the data sources are continuously adding new cases to the respective repositories, so the
number of samples is expected to grow in the future. Despite
the unbalance of the COVID-19 class, up to date, and to the
authors’ knowledge, this is the most extensive compilation of
COVID-19, images based on open repositories. Despite that,
the number of COVID-19 RX images is still considered small
compared to the other two classes. Therefore, it was necessary
to compensate for the class imbalance by modifying the
network architecture, including regularization components in
the last two dense layers. To this end, a weighted categorical
cross-entropy loss function was used to compensate for this
effect. Likewise, data augmentation techniques were used for
pneumonia and COVID-19 classes to generate more samples
for these two underrepresented classes automatically.
We stand that automatic diagnosis is much more than a
classification exercise, meaning that many factors have to be
considered to bring these techniques to clinical practice. In
this respect, there is a classic assumption in the literature
that the associated heat maps –calculated with Grad-CAM
techniques- provide a clinical interpretation of the results,
which is unclear in practice. In light of the results shown in
the heat maps depicted in Fig. 1, we show that experiment 1
must be carefully interpreted. Despite the high-performance
metrics obtained in experiment 1, the significant areas identified by the network are pointing towards certain areas with
no clear interest for the diagnosis, such as corners of the
images, the sternum, clavicles, etc. From a clinical point of
view, this is biasing the results. It means that other approaches
are necessary to force the network to focus on the lung
area. In this respect, we have developed and compared the
results with two preprocessing approaches based on cropping
the images and segmenting the lung area (experiment 2 and
experiment 3). Again, given the heat maps corresponding
to experiment 2, we also see similar explainability problems to those enumerated for experiment 1. The image area
reduction proposed in experiment 2 significantly decreases
the system’s performance by removing the metadata that
usually appears in the top left or right corner. This technique
removes areas that can help categorize the images but have
no interest from the diagnosis point of view. However, while
comparing experiments 2 and 3, performance results improve
in the third approach, which focuses on the same region
of interest but with a mask that forces the network to see
only the lungs. Thus, results obtained in experiments 2 and
3 suggest that eliminating the needless features extracted
from the background or non-related regions improves the
results. Besides, the third approach (experiment 3) provides
more explainable and interpretative results, with the network
focusing its attention only on the area of interest for the
disease. The gain in explainability of the last method is still
at the cost of a lower accuracy with respect to experiment
1, but the improvement in explainability and interpretability
is considered critical in translating these techniques to the
clinical setting. Despite the decrease in performance, the
proposed method in experiment 3 has provided promising
results, with an 91.53% Acc, 87.6 BAcc, 87.37% GMR,
and 0.97 AUC.
Performance results obtained are in line with those presented in [17], which reports sensitivities of 95, 94, and 91
for control, pneumonia, and COVID-19 classes respectively
–also modeling with the COVID-Net in similar conditions as
our experiment 1–, but training with a much smaller corpus
of 358 RX images from 266 COVID-19 patients, 8, 066
226824 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
controls, and 5, 538 RX images belonging to patients with
different types of pneumonia.
The paper also critically evaluates the effect of several
variability factors that might compromise the network’s performance. For instance, the projection (PA/AP) effect was
evaluated by retraining the network and checking the outcomes. This effect is important, given that PA projections are
often practiced in erect positions to observe pulmonary ways
better and are expected to be examined in healthy or slightly
affected patients. In contrast, AP projections are often preferred for patients confined in bed, and as such are expected
to be practised in the most severe cases. Since AP projections
are common in COVID-19 patients, in these cases, more
blood will flow to the lungs’ apices than when standing;
thus, not considering this variability factor may result in
a misdiagnosis of pulmonary congestion [49]. Indeed, the
obtained results have highlighted the importance of taking
into account this factor when designing the training corpus,
as PPV decreases for PA projections in our experiments with
COVID-19 images. This issue is probably due to an underrepresentation of this class (Table 5), which would require a
further specific analysis when designing future corpora.
On the other hand, results have shown that the error distribution for the COVID-19 class follows a similar proportion to
the percentage of images available in the corpus while categorizing by gender, the detector’s technology, the projection,
and the dataset. These results suggest no significant bias with
respect to these potential variability factors, at least for the
COVID-19 class, which is the less represented one.
An analysis of how the clusters of classes were distributed
is also presented in Fig. 5, demonstrating how each class
is differentiated. These plots help identify existing overlap
among classes (especially that present between pneumonia
and COVID-19, and to a lesser extent between controls and
pneumonia). Similarly, since the corpus used to train the
network was built around several datasets, a new set of t-SNE
plots was produced, but differentiating according to each
of the subsets used for training (Fig. 6). This test served
to evaluate the influence of each dataset’s potential specific
characteristics in the training procedure and, hence, possible
sources of confusion that arise due to particularities of the
corpora that are tested. The plots suggest that the different
datasets are correctly merged in general terms, but with some
exceptions. These exceptions suggest that there might be
certain unknown characteristics in the datasets used, which
cluster the images belonging to the same dataset together.
The COVID-Net has also demonstrated being a good starting point for the characterization of the disease employing XR
images. Indeed, the paper’s outcomes suggest the possibility
to automatically identify the lung lesions associated with
a COVID-19 infection (see Fig.1) by analyzing the GradCAM mappings of experiment 3, providing an explainable
justification about the way the network works. However,
the interpretation of the heat maps obtained for the control
class must be carried out carefully. Whereas the areas of
significant interest for pneumonia and COVID-19 classes are
supposed to point to potential lesions (i.e. with higher density
or with different textures in contrast to controls), the areas of
significant interest for the classification in the control group
are supposed to correspond to something complementary,
potentially highlighting less dense areas. Thus, in the control
class, these areas do not point towards any kind of lesion in
the lungs.
Likewise, the system developed in experiment 3 attains
comparable results to those achieved by a human evaluator
differentiating pneumonia from COVID-19. In this respect,
the ability of seven radiologists to correctly differentiate
pneumonia and COVID-19 from XR images was tested in
[50]. The results indicated that the radiologists achieved sensitivities ranging from 97% to 70% (mean 80%), and specificities ranging from 7% to 100% (mean 70%). These results
suggest that AI systems have a potential use in a supervised
clinical environment.
COVID-19 is still a new disease, and much remains
to be studied. The use of deep learning techniques
would potentially help understand the mechanisms on
how the SARS-CoV2 attacks the lungs and alveoli and
how it evolves during the different stages of the disease. Despite there is some empirical evidence on the
evolution of COVID-19 –based on observations made by
radiologists [6]–, the employment of automatic techniques
based on machine learning would help analyze data massively, guide research onto certain paths, or extract conclusions faster. Nevertheless more interpretable and explainable
methods are required to go one step forward.
Inline with the previous comment, and based on the empirical evidence respecting the evolution of the disease, it has
been stated that during the early stages of the disease, groundglass shadows, pulmonary consolidation and nodules, and
local consolidation in the centre with peripheral groundglass density are often observed. However, once the disease
evolves, the consolidations reduce their density resembling
a ground-glass opacity that can derive in a ‘‘white lung’’ if
the disease worsens or in a minimization of the opacities
if the course of the disease improves [6]. In this manner,
if any of these characteristic behaviours are automatically
identified, it would be possible to stratify the disorder’s stage
according to its severity. Computing the extent of the groundglass opacities or densities would also be useful to assess the
severity of the infection or to evaluate the evolution of the
disease. In this regard, the infection extent assessment has
been previously tested in other CT studies of COVID-19 [51]
using manual procedures based on observation of the images.
Solutions like the one discussed in this paper are intended
to support a much faster diagnosis and alleviate radiologists and specialists’ workload, but not to substitute their
assessment. A rigorous validation would open the door to
integrating these algorithms in desktop applications or cloud
servers for its use in the clinic environment. Thus, its use,
maintenance, and update would be cost-effective and straightforward and would reduce healthcare costs and improve
diagnosis response time and accuracy. [52]. In any case,
VOLUME 8, 2020 226825J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
the deployment of these algorithms is not exempt from
controversies: hosting the AI models in a cloud service
would entail uploading the images that might be subject
to national and international regulations and constraints to
ensure privacy [53].



NEW_PAPER


Received October 21, 2020, accepted November 16, 2020, date of publication November 24, 2020,
date of current version December 9, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3040245
A Two-Dimensional Sparse Matrix Profile
DenseNet for COVID-19 Diagnosis
Using Chest CT Images
QIAN LIU 1,2, CARSON K. LEUNG 2
, (Senior Member, IEEE), AND PINGZHAO HU 1,2,3
1Department of Biochemistry and Medical Genetics, University of Manitoba, Winnipeg, MB R3E 0J9, Canada
2Department of Computer Science, University of Manitoba, Winnipeg, MB R3T 2N2, Canada
3Research Institute in Oncology and Hematology, CancerCare Manitoba, Winnipeg, MB R3E 0J9, Canada
Corresponding author: Pingzhao Hu (pingzhao.hu@umanitoba.ca)
This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).
ABSTRACT COVID-19 is a newly identified disease, which is very contagious and has been rapidly
spreading across different countries around the world, calling for rapid and accurate diagnosis tools. Chest
CT imaging has been widely used in clinical practice for disease diagnosis, but image reading is still a
time-consuming work. We aim to integrate an image preprocessing technology for anomaly detection with
supervised deep learning for chest CT imaging-based COVID-19 diagnosis. In this study, a matrix profile
technique was introduced to CT image anomaly detection in two levels. At one-dimensional level, CT images
were simply flatted and transformed to a one-dimensional vector so that the matrix profile algorithm could be
implemented for them directly. At two-dimensional level,a matrix profile was calculated in a sliding window
way for every segment in the image. An anomaly severity score (CT-SS) was calculated, and the difference
of the CT-SS between the COVID-19 CT images and Non-COVID-19 CT images was tested. A sparse
anomaly mask was calculated and applied to penalize the pixel values of each image. The anomaly weighted
images were then used to train standard DenseNet deep learning models to distinguish the COVID-19 CT
from Non-COVID-19 CT images. A VGG19 model was used as a baseline model for comparison. Although
extra finetuning needs to be done manually, the one-dimensional matrix profile method could identify the
anomalies successfully. Using the two-dimensional matrix profiling method, CT-SS and anomaly weighted
image can be successfully generated for each image. The CT-SS significantly differed among the COVID-19
CT images and Non-COVID-19 CT images (p − value < 0.05). Furthermore, we identified a potential
causal association between the number of underlying diseases of a COVID-19 patient and the severity
of the disease through statistical mediation analysis. Compared to the raw images, the anomaly weighted
images showed generally better performance in training the DenseNet models with different architectures for
diagnosing COVID-19, which was validated using two publicly available COVID-19 lung CT image datasets.
The metric Area Under the Curve(AUC) on one dataset were 0.7799(weighted)vs. 0.7391(unweighted),
0.7812(weighted) vs. 0.7410(unweighted), 0.7780(weighted) vs. 0.7399(unweighted), 0.7045(weighted)
vs. 0.6910(unweighted) for DenseNet121, DenseNet169, DenseNet201, and the baseline model VGG19,
respectively. The same trend was observed using another independent dataset. The significant results revealed
the critical value of using this existing state-of-the-art algorithm for image anomaly detection. Furthermore,
the end-to-end model structure has the potential to work as a rapid tool for clinical imaging-based diagnosis.
INDEX TERMS Rare pattern mining, matrix profile, COVID-19 CT images, risk score, DenseNet, mediation
analysis.
I. INTRODUCTION
Unsupervised anomaly detection using rare pattern mining
is one of the most intuitive medical imaging–based disease
The associate editor coordinating the review of this manuscript and
approving it for publication was Yudong Zhang .
diagnosis methods [1]. People without medical expertise
could find an obvious lesion in a medical image if the lesion
is extremely different from other parts in the image. Actually,
even radiologists also read the images in that way. As the
most obvious lesion is so conspicuous that it can be noticed
immediately by radiologists at their first glance of the image.
213718 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
This step is unsupervised, and it depends only on the intrinsic
information in the image itself. Then using the normal human
sectional anatomy knowledge, radiologists could further tell
whether this lesion is critical or not [2].
COVID-19 is a newly identified disease that is very
contagious and has been rapidly spreading across different
countries around the world [3]. Common symptoms from
COVID-19 are fever, dry cough, but in more serious cases,
patients can experience difficulty in breathing [4]. At present,
the NA-PCR (Nucleic Acid Polymerase Chain Reaction)
testing is considered as the most effective, cheap and rapid
detection method of COVID-19. However, a bottleneck to use
this technique is that there are a short of supplies of NA-PCR
in some countries [5]. Several alternative methods have been
considered for individuals to test positive for COVID-19,
including CT (computed tomography) scans of the lungs.
Lung CT scanning is fast and easy to detect COVID-19.
As the number of infected patients increases exponentially,
it can be hard to provide testing scans for patients because of
the limited number of doctors. It is recommended that artificial intelligence (AI) systems can be developed to analyse the
lung CT scans of patients to determine COVID-19 status [6].
To build the AI system, we used a two-step strategy: detection and enhancement of CT image anomaly and modelling
of the anomaly enhanced CT images. For the first step,
we used a naïve two-dimensional sliding window approach
to calculate the matrix profile of the image. Summing up
this matrix profile could make an image-specific severity
score (SS) indicating the severity of the image anomalous.
This CT-SS can be computed automatically as compared to
the manually calculated CT-SS [7], [8], and it has the potential
to rapidly identify COVID-19 patients. At the same time,
the matrix profile could be easily used to generate a salience
map [9] for each CT image to detect lung anomaly. A saliency
map is a topographic map that represents visual saliency of
an image [10]. Overlapping the image and its salience map
could further give us a weighted CT image to enhance the
anomaly; For the second step, the weighted CT images could
be input into a deep convolutional neural network for further
classification or regression tasks. This naïve two-dimensional
method is easy to apply, but the benefits of those ultra-fast
Fourier algorithms developed by Keogh et al. [11] are lost
in this situation. To speed up the calculation, raw images
were pooled to a lower resolution and the stride of the sliding
window was set to the same as the length of the image
segment. In this way, the nearest neighbour, matrix profile,
and deep learning technologies were effectively integrated
together. The proposed algorithm was tested using two publicly available COVID-19/Non-COVID-19 lung CT image
sets [12], [13], respectively. Please be noted that the NonCOVID-19 group contains the images from both healthy
controls and other types of lung disease cases.
The main contribution of this study could be divided into
two parts. The first one is the innovative application of a
classic low-dimensional time-series rare pattern mining technique to unsupervised high-dimensional medical imaging
anomaly detection. Another contribution is the application of
dense deep learning networks for COVID-19 diagnosis using
the anomaly enhanced CT images.
II. RELATED WORK
Unsupervised rare pattern mining in medical imaging has
been proved to be beneficial [14], but most of the classic rare pattern mining techniques (Apriori [15], [16] based
and FP-Growth [17] based) cannot be directly applied to
image data as it is two dimensional with space-related
information [18]. There are several methods developed
for unsupervised image anomaly detection. According to
Ehret et al., these unsupervised methods could be classified
as nearest neighbour-based anomaly detection, clusteringbased anomaly detection, statistical anomaly detection, spectral anomaly detection, and information theoretic anomaly
detection [19]. In fact, if applied in a static image situation,
they all belong to the first category to some extent [1],
since they all measure certain distances and try to identify
the discord distances of data instances. The assumption of
the nearest neighbour-based anomaly detection in a static
image is that normal pixel segments are always similar to
each other. Therefore they have a close distance with their
nearest neighbours, while anomalies are dislike their closest
neighbours [20].
If the aforementioned assumption of the nearest neighbourbased anomaly detection holds, then the problem of image
anomaly detection can be transformed as a problem of scanning of a given segment (or window) of images and the
retrieval of the nearest neighbours of the scanned segments.
This is exactly the same as the definition of a similarity
join problem defined by Yeh et al. [11]: given a collection
of data objects, retrieve the nearest neighbours for every
object. To solve the problem, Keogh et al. proposed a new
data structure called matrix profile and developed a series of
matrix profile based algorithms to solve the similarity join
problem for time series data [11], [21]–[24]. A matrix profile
consists of two components: a distance profile and a profile
index. The distance profile is a vector of minimum Euclidean
distances among the subsequences within the time-series. The
profile index contains the index of subsequences’ first nearest
neighbours. In other words, the profile index is the location
of a subsequence’s most similar subsequence. In order to
apply the matrix profile technique to large databases, Fast
Fourier transform was introduced to make the matrix profile
algorithm ultra-fast, therefore it can be applied to big timeseries data without sacrificing the time efficacy [11], [25].
These algorithms were proved to be efficient for onedimensional time series data. However, matrix profile technique has not been introduced to high dimensional data, such
as two-dimensional image data.
Besides the limitation of matrix profile in highdimensional data, there are also lack of studies exploring
its integration with advanced machine learning techniques.
Although nearest neighbour is a successful long-standing
technique, and the matrix profile provides us a strategy using
VOLUME 8, 2020 213719Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
FIGURE 1. Workflow of the proposed study. CT-SS refers to CT-severity score.
nearest neighbour technique for the anomaly detection, it has
not been well integrated with current advanced deep learning
techniques. A recent work designed a model to use nearest
neighbour for identifying anomaly at the image set level [26].
In their model, a set of normal images were input into a deep
learning-based feature extractor for building a feature library.
Once a new image is arrived, it would undergo the same
feature extractor. Then the nearest distances of these features
extracted from the new image with those features stored in the
feature library will be computed. By verifying if the distance
is larger than a predefined threshold, they could determine if
the new image is normal or anomalous [26], [27]. However,
as we mentioned, this design is at image set level which
could not detect the segment level anomalies. Moreover, it is
actually a semi-supervised approach as it needs the label
information to build the feature library.
CT-severity score(CT-SS) was proposed by a study for
COVID-19 rapid diagnosis [7]. In order to obtain the CT-SS,
the authors need to manually measure and access the groundglass opacity, interstitial opacity, and air trapping ratio of
the lungs in the CT images. These three features are typical pneumonia symptoms, and different doctors may obtain
different values of them even using the same image. Therefore, although the CT-SS has been proved to be significantly associated with the COVID-19 severity, the extra
manual measurement burden added to the radiologists and
the potential bias of their expertise limits its application in
clinic practice. Another consideration is the lack of theoretical analysis of why CT-SS is associated with COVID-19
severity. It was reported that medical image phenotypes,
such as CT-SS, could work as the mediators of genetic
variations or other basic clinical characteristics’ effects on
disease outcomes [28], [29]. Therefore, mediation analysis
could be used to test the significance of the indirect causal
relationship among patient’s clinical characteristics, CT-SS,
and COVID-19 severity.
Although there are no many studies on deep learning nearest neighbour-based image anomaly detection, supervised
deep learning has been widely involved in COVID-19 diagnosis. There were a lot of deep convolutional neural networks
(CNN) proposed by different studies on COVID-19 diagnosis [12], [13], [30]–[33]. In this study, we propose a stateof-the-art end-to-end matrix profile - based DenseNet [34]
model for COVID-19 diagnosis. We also compare the performance of different DenseNet architectures and the basic convolutional architecture called VGG (Visual geometry Group
Network) [35].
III. DATA AND METHODS
The whole workflow is summarized in Fig. 1. The proposed
anomaly detection algorithm first preprocesses the raw CT
images using the matrix profile technique, the CT-SS and the
213720 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
anomaly weighted images are then calculated. For the CT-SS,
differential analysis and mediation analysis are performed to
explore its potential application to diagnosis for COVID-19
and its clinical interpretability. The anomaly weighted images
are finally applied to build DenseNet-based deep learning
models for COVID-19 diagnosis.
A. ANOMALY DETECTION
Assume a chest CT image can be defined as a matrix P of
pixel values pij,
P =



p11 p12 · · · p1m
p21 p22 · · · p2m
.
.
.
.
.
.
.
.
.
.
.
.
pn1 pn2 · · · pnm



(1)
where m is the width of P, and n is the height of P. i ranges
from 1 to m, and j ranges from 1 to n. In principle, there are
two approaches to detect anomalies in the chest CT image.
The first method is to flatten the image matrix P into a long
vector. The vector could be treated as a time series, thus those
well-developed algorithms for the time series analysis could
be applied easily. The flattened operation could be done along
the row Prow as shown in Equation (2) or the column Pcol as
shown in Equation (3) of the P.
Prow = p11, p12, · · · , p1m, · · · , pn1, pn2, · · · , pnm (2)
Pcol = p11, p21, · · · , pn1, · · · , p1m, p2m, · · · , pnm (3)
For the flat image Pflat (Prow or Pcol), we can apply the
ultra-fast Fourier transform algorithms to speed up the calculation of the matrix profile to detect anomalies. The detailed
description of the algorithms can be found in the original
papers [11], [21]–[24]. After the anomalies are detected,
we could trace the anomalies back to the position in the matrix
P by joining them across the rows and columns. In this way,
the two-dimensional anomaly detection problem is transferred into two one-dimensional anomaly detection problems.
We could think of this as scanning the image along two
directions in a greedy snake way [36]. Then we can find the
overlapped anomalies detected by these two greedy snakes.
This is the proposed one-dimensional method to calculate the
matrix profile for a image.
The second method is to find the local anomaly
regions or two-dimensional segments of the image P directly.
We define a segment Pij,wh of P as a matrix, which has a size
of w × h and starts from Pij as shown in Equation (4).
Pij,wh =



pij · · · pi(j+w−1)
.
.
.
.
.
.
.
.
.
p(i+h−1)j
· · · p(i+h−1)(j+w−1)


 (4)
We define a sparse segment set S as shown in Equation (5)
of the P as an ordered set of sparsely selected segments of the
P obtained by a sliding window of size w × h and a stride s
across P. Where Sij could be used to denote Pij,wh.
S =





p11,wh p1(1+s),wh · · · p1(m−w+1),wh
p(1+s)1,wh p(1+s)(1+s),wh · · · p(1+s)(m−w+1),wh
.
.
.
.
.
.
.
.
.
.
.
.
p(n−h+1)1,wh p(n−h+1)(1+s),wh · · · p(n−h+1)(m−w+1),wh





(5)
We define a sparse two-dimensional matrix profile (2DM)
as a matrix of the Euclidean distances between each segment
Pij,wh in the sparse segments set S and its nearest neighbours
in S. The 2DM has the same size as S, but the elements
in S are matrices while the elements in 2DM are numbers.
To calculate 2DM, the pairwise Euclidean distance between
one element in S with every other element in S will be
calculated. The minimum of these distances will be stored
in the same position of 2DM as the element in S. According to the assumption of nearest neighbour-based anomaly
detection in a static image, a segment that has the smaller
nearest distance will probably be a normal segment,while a
segment that has the larger nearest distance will probably be
an anomaly. Therefore, the value of 2DM could represent the
anomaly level of the segments in S. The algorithm of building
the 2DM is shown in Algorithm 1.
Algorithm 1 Calculate 2DM
Input: an image P, window size w × h,stride s
Output: a matrix profile 2DM
1: 2DM ← inf
2: for Sij in SlidingWindow(P,s,w): do
3: for Si
0
j
0 in SlidingWindow(P,s,w): do
4: distance ← EuclideanDistance(Sij, Si
0
j
0)
5: if distance < 2DMij then
6: 2DMij ← distance
7: else
8: PASS
9: end if
10: end for
11: end for
After 2DM is calculated, the values in the 2DM matrix
are summed [8] and scaled to a range of 0 to 100 as CT-SS
of the image. The difference of the CT-SS between the
patient groups are tested using student t-test. And a statistic
mediation analysis [37] is performed to identify the indirect
effects of age, gender, and underlying diseases on COVID-19
severity through the two-dimensional matrix profile based
CT-SS using the R package ‘‘mediation’’. In the mediation
analysis model, the COVID-19 severity and CT-SS are treated
as dependent variable and mediator,separately. While the
age, gender, and the number of underlying diseases(how
many underlying diseases the patient has) are treated as
independent variable, separately. There are three steps for
conducting the mediation analysis. The first step is three
simple regression analyses with the dependent variable of
COVID-19 severity and the independent variable of the age,
VOLUME 8, 2020 213721Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 1. VGG and DenseNet architectures ∗ used in this study.
gender and the underlying diseases, respectively. The second
step is also three simple regression analyses predicting the
mediator, which is the two-dimensional matrix profile based
CT-SS, from the age, gender and the underlying diseases,
respectively. The third step is three multiple regression analyses predicting the dependent variable of COVID-19 severity
from the CT-SS and age, CT-SS and gender, CT-SS and the
underlying diseases, respectively.
An up-sampling step is performed to impute 2DM to the
same size of the image P. In this way, an anomaly mask is
made for P. This map is actually a salience map if we plot
it on top of the raw image P. The anomaly map is then used
as a weight matrix to be fed into a simple linear model for
making a weighted image Pw, which can potentially enhance
the anomaly in the raw CT image P.
Pw = P + 2DM · P (6)
Here, the 2DM is a matrix with the same dimension of
the raw image P. We calculate the dot product of these two
matrices (2DM and P). Then we add P with the product. Pw is
then passed to a classification-based deep learning model for
model training and testing.
B. VGG AND DenseNet
We treat the lung CT imaging-based diagnosis of COVID-19
as a binary classification problem (e.g. COVID-19 or NonCOVID-19). VGG and DenseNet model are applied to perform the classification. VGG has 16 convolutional layers and
3 fully connected layers and won the 2014 Large Scale Visual
Recognition Challenge. It is a CNN model with a deeper
architecture by increasing the number of convolutional layers
and reducing the size of convolutional layers [35].
DenseNet is a relatively new framework of convolutional
deep learning. The idea of DenseNet is to build a deeper architecture which has connections between each convolutional
layer to every other layer within the same dense block in a
feed-forward fashion. Unlike the ResNet [38], the connections of DenseNet are in feature-level instead of weight-level.
The parameters of each layer will be trained only once, and
the resulted feature-maps will be concatenated together as the
input of the layer they connect to. In this way, the weights
could be more efficient, and the gradients would not be
vanished. The performance of DenseNet has been estimated
on several benchmark datasets [34]. With different number
of convolutional layers in each dense block, DenseNet could
have different settings. The three architectures of DenseNet
(DenseNet121, DenseNet169, and DenseNet201) used in this
study are listed in Table 1.
The anomaly weighted images Pw are then used in the
training, validation and testing of the above mentioned VGG
and DenseNet models.
C. CHEST CT DATASETS
This proposed workflow of the deep learning models were
applied to analyse the weighted (Pw) and unweighted (P) raw
lung CT images, respectively. The raw data used in this study
came from two publicly available datasets. One was downloaded from a GitHub repository published by The University
213722 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 2. Data splits used in this study.
of California San Diego [12]. It contains 275 COVID-19 lung
CT images and 195 Non-COVID-19 lung CT images. This
dataset was built by reading the captions of the published
papers about COVID-19. The author of the dataset manually searched for quite a number of COVID-19 CT imaging
papers, and copied the CT images contained in those papers
as figures. The label information of these CT images, such as
whether they were obtained from COVID-19 patients or NonCOVID-19 patients, was collected by reading the captions of
the figures in those papers. The split of the training, testing,
and validation of this dataset followed the authors’ suggestion
(Table 2).
We did not borrow the data augmentation and transfer
learning steps as done by the authors of the dataset and our
training strategy is relatively simple in terms of the training
epochs and model structure because the goal of this work
is to test the effect of the anomaly detection-based image
preprocessing. The other dataset was published by Wuhan
Huazhong University of Science and Technology [13]. This
one has 4,001 COVID-19 lung CT images and 9,979 NonCOVID-19 lung CT images. The quality of this dataset is
better than the first one since it was directly obtained from
Wuhan’s hospitals. The images are all in DICOM (Digital
Imaging and Communications in Medicine) format with the
similar FOV (Field of View) and resolution (200K). We borrowed the lung parenchyma splitting algorithm from the
author of the dataset to split the lung regions from the other
body parts [13]. After this, we randomly selected 80% of
the images as a train set, 10% as a validation set, and 10%
as a test set. The detailed number of images are listed in
Table 2. We choose this data split strategy to be consistent
with the split strategy of the first data set. Images from both
datasets are resized to a uniform resolution of 224 × 224.
Training parameters are kept the same in both the anomaly
detection-based framework and anomaly detection-removed
framework.
D. PERFORMANCE EVALUATION
To evaluate our model performance, we used below performance measures: Accuracy (a ratio of correctly predicted
observations to the total observations), Precision (a ratio of
correctly predicted positive observations to the total predicted
positive observations), Recall (also called sensitivity, the ratio
of correctly predicted positive observations to the all observations in actual class), AUC (Area Under the Curve) and
F1 (a weighted average of Precision and Recall). All
performance metrics of anomaly weighted images were
stored in a vector, while all performance metrices of
raw images were stored in another vector. Then a ttest was done to test the significance between these two
vectors.
E. IMPLEMENTATION OF THE ALGORITHM
We made the data splits with our code publicly available
for reproducing our results (https://github.com/qianliu1219/
iMP). The raw data used in this study could be downloaded
from UCSD (https://github.com/UCSD-AI4H/COVID-CT)
and ICTCF (http://ictcf.biocuckoo.cn/index.php). The proposed two-dimensional matrix profile algorithm and the training of the VGG model and the three DenseNet models on the
two datasets took around 80 hours for a Nvidia GeForce GTX
1080 GPU machine.
IV. RESULTS
A. THE SPARSE MATRIX PROFILE AND CT-SS
After applying the ultra-fast matrix profile algorithm to the
one-dimensional flattened images, we could obtain meaningful patches, which indicate the potential anomaly pixels in the chest CT images. Fig. 2 showed one of the
examples.
FIGURE 2. Examples of sparse matrix profile. The row flattened image
(A) and the column flattened image (B). The one-dimensional matrix
profiles of A and B were plotted as black lines (C, D). The meaningful rare
patterns were highlighted using the red colours. Their overlap was traced
back to the raw image. A meaningful anomaly patch was observed (E).
However, the top discords (top smallest distances) require
to be carefully defined in order to find a meaningful patch
using the one-dimensional matrix profile algorithm. If we
VOLUME 8, 2020 213723Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
FIGURE 3. The results of CT-SS differential analysis and mediation
analysis. Top panel (A) is the density distributions of the two-dimensional
matrix profile algorithm-based CT severity scores (CT-SS) for COVID-19
and Non-COVID-19 groups, respectively. Bottom panel (B) is the causal
association analysis among the underlying diseases, CT-SS, and COVID-19
diagnosis. The total effect and its significance of underlying diseases on
COVID-19 diagnosis, the direct component of the total effect and indirect
effect through the CT-SS are showing on the paths.
select the top 1 discord, the highlighted patch sometimes
would present in the corner or along the edge of the
image or body parts in the image. Those meaningless
discords need to be manually filtered out, which is inconvenient. Therefore, the approach is not practical in clinical
reality.
Using the two-dimensional matrix profile algorithm,
we got an anomaly severity score (CT-SS) for each image.
The density distribution of the CT-SS is shown in Fig. 3A.
These CT-SS were significantly different between the
COVID-19 group and Non-COVID-19 group (p − value <
0.05).
The mediation analysis identified a significant causal relationship among the number of underlying diseases, CT-SS,
and COVID-19 severity as shown in Fig. 3B. The number of
underlying diseases has a total effect of 0.42 (p − value <
0.05) on COVID-19 severity. Five percentage of this effect,
which is 0.02 (0.02 ÷ 0.42 = 5%), could be explained by
the two-dimensional matrix profile based CT-SS. The rest
95% is the direct effect that needs to be explained by other
mechanisms.
Based on the two-dimensional matrix profile, we could get
a salience map pasted on the top of the raw image to suppress the meaningless pixel values without losing information
in meaningful regions such as the lung region and lesion
region (Fig. 4).
FIGURE 4. Examples of generation of salience maps. The raw image (A),
the lung regions (B), identified two-dimensional matrix profile
heatmap (C,D), and anomaly weighted image (E,F). In the weighted image,
valuable pixels in the lung regions and lesion regions were highlighted,
while meaningless regions were suppressed.
B. THE ANOMALY WEIGHTED LUNG CT IMAGES
IMPROVED THE COVID-19 DIAGNOSIS
We trained the VGG and DensNet models (Table 1) using
both the training sets of raw CT images and the anomaly
weighted CT images for the Datasets 1 and 2 (Table 2),
respectively, which were evaluated using their validation sets
(Table 2). As shown in Fig. 5 (Top), due to the small sample
size in Dataset 1, the performance of DenseNet121 on the raw
images and the anomaly weighted images is inconsistent for
different performance measures. Also due to the poor quality
(in terms of both the format (Normal image format, not medical image format) and the various of image resolutions(from
9K to 1.6M)) and small sample size, models trained on
Dataset 1 need more training epochs to converge than models
trained on Dataset 2. Except accuracy, the anomaly weighted
images have better performance than the raw images for
all other four performance measures in DenseNet121. For
Dataset 2, the anomaly weighted images have shown better
performance than the raw images for all the five performance
measures in Fig. 5 (Bottom). Other DenseNet architectures
as well as the VGG network as shown in Table 1 also showed
the similar trend (results were not shown). The overall performance winner was always the model trained with the anomaly
213724 VOLUME 8, 2020Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
TABLE 3. Classification performance on testing sets.
FIGURE 5. The validation performances of the DenseNet121 models on
the Datasets 1 and 2.
weighted images instead of the model trained with the raw
images (p − value < 0.05) as shown in Table 3.
The trained DenseNet models and the VGG model were
applied to the testing sets of the Datasets 1 and 2, respectively.
We showed the model performance on the testing sets in
Table 3. We also showed the performance of DenseNet121 on
the validation set as example Fig. 5. The performance on
validation set is relatively higher than that of the testing
set (Table 3) in the Dataset 1, which means there is a
potential over-fitting no matter whether we used the raw
data or the anomaly weighted data. This is not surprising
since the sample size is very small and the image quality in
the Dataset 1 is various. We were expecting that the sparsity
introduced by the anomaly mask could help avoiding overfitting [39]. However, it turns out that the anomaly mask has
limited effect on preventing over-fitting. This might because
the main content of the weighted images is still from the
raw images, and only a small proportion comes from the
anomaly mask. The sparsity introduced by the mask might be
not enough for avoiding over-fitting. For the second dataset,
over-fitting was not observed as the performance was stable
during validation and testing. As shown in Table 3, we also
observed that the DenseNet models under different network
architectures (Table 1) have better performance than the VGG
model (Table 1). Generally speaking, The DenseNet and the
VGG models also showed the improved performance using
the anomaly weighted images than raw images using the
testing sets in both Datasets 1 and 2 (Table 3).
V. DISCUSSION
Matrix profile is a successful technique in unsupervised
rare pattern-based time-series anomaly detection [40]. It was
developed based on the nearest neighbour algorithm. In this
study, matrix profile was introduced to static image anomaly
detection at one-dimensional level and two-dimensional
level, separately. At one-dimensional level, image matrix
was flattened to a long vector which could be considered
as a time-series. With this transformation, the set of entire
subsequences could be scanned efficiently using fast Fourier
algorithms. This method works fine in identifying anomalies
within an image. However, extra manual operations need to be
done for choosing a suitable discord. And it is unnecessary to
visit an image pixel by pixel for anomaly detection. Instead,
VOLUME 8, 2020 213725Q. Liu et al.: Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images
it is more reasonable to directly calculate the image matrix
profile at the two-dimensional level. In our two-dimensional
matrix profile method, a predefined size of sub-segment
is scanned and its nearest distance with other sub-segments is
calculated. The combination of all these nearest distances is
mapped to the same coordinates of the corresponding subsegments in the original images. The generated anomaly
mask has the ability to indicate the meaningful lesion pixels
in the original images. We further transformed each of the
images into a severity score as a fast tool to indicate the
normality of the images. This severity score showed significant difference between COVID-19 group and Non-COVID19 group, which means it could work as an automatic and
easy-calculated clinical tool to support COVID-19 diagnosis.
To understand the potential causal effect of the severity score
on COVID-19 diagnosis, we performed a statistical mediation analysis to examine the association between COVID-19
diagnosis and the number of underlying diseases through the
score. We identified the significant indirect effect of the number of underlying diseases on COVID-19 severity through this
severity score.
The anomaly mask can also be used to weight the original
image for completing further tasks. In this study, we evaluated
the performance of the anomaly weighted images to classify
the COVID-19 and Non-COVID-19 lung CT images using
a deep learning model. The anomaly weighted images were
shown to be better in training the deep classification model
than the raw images. This is likely due to the enhanced information introduced by the preprocessing. We made the whole
working flow connected so that it could be implemented
easily [41]. What’s more, unsupervised anomaly detection
and supervised deep convolutional neural network could be
combined together in an end-to-end manner.
To control the runtime of the algorithm, we downsized the
raw images to a smaller resolution. Although to obtain the
best classification performance of the deep learning model is
not the main task of this study, we realized the degradation
in resolution might decrease the performance of the deep
convolutional neural network based image classifier used in
this study [42]. It might be better to keep the original resolution if the runtime is not a consideration or the computer
configuration could be improved. Another potential future
direction of this study is to develop ultra-fast algorithms
for two-dimensional matrix profile calculation using a twodimensional fast Fourier transformation [43]. Also, for the
one-dimensional method, currently the one-dimensional fast
Fourier transformation (FFT) [44] involved in the core algorithm does not consider the sparsity of medical image data.
We could introduce sparse Fourier transform (SFT) [45] into
the core calculation of one-dimensional matrix profile algorithm. At the application level, this technique is not limited
to analysis of COVID-19 CT images, it could be extended
to other diseases and other image types. Although this study
focuses on the two-dimensional image anomaly detection
problem, the matrix profile technique could be potentially
further extended to analyze three-dimensional volume rendered CT scans which are more commonly used in medical
practice. The potential application of CT-SS could also be
explored if more clinical information are provided. For example, if the clinical outcomes (prognosis, treatment response,
etc.) of the patients are available, the associations of CT-SS
with these clinical outcomes could be further analysed [8].
Although this study is not intended to compete with the most
state-of-art work in completing a classification task, we could
integrate our sparse matrix profile method for enhancing
anomalies in images with other advanced deep learning models [46], [47] and some data augmentation techniques to
achieve the best classification performance.
VI. CONCLUSION
Inspired by the success of matrix profile in time-series data
anomaly detection, we attempted to extent its application
to image anomaly detection. Two possible clinical utilities
have been tested, which are the CT-SS and the anomaly
weighted images. The CT-SS could significantly distinguish
the COVID-19 and Non-COVID-19 patients. This ability
might come from the mechanism of its mediation effect on the
number of underlying diseases’ association with COVID-19
severity. The anomaly weighted images performed better in
training different settings of DensNet models than the raw
images. These significant results revealed its potential use for
the lung CT imaging-based COVID-19 rapid diagnosis. This
work has opened a window for raising the one-dimensional
rare pattern mining algorithm to solve two-dimensional rare
pattern detection problem. Unsupervised anomaly detection and advanced deep convolutional neural network were
utilized in an unbroken and connected manner. The proposed algorithm is also dimension-extendible and explainable, in terms of its nearest neighbour theory. Furthermore,
the implemented algorithm package might become a clinical
tool for COVID-19 rapid diagnosis and assessment.



NEW_PAPER


Technology
Detecting Regions At Risk for Spreading
COVID-19 Using Existing Cellular Wireless
Network Functionalities
Alaa A. R. Alsaeedy and Edwin K. P. Chong , Fellow, IEEE
Abstract—Goal: The purpose of this article is to introduce a new strategy to identify areas with high human density and mobility, which are at risk for spreading COVID-19.
Crowded regions with actively moving people (called at-risk
regions) are susceptible to spreading the disease, especially if they contain asymptomatic infected people together
with healthy people. Methods: Our scheme identifies at-risk
regions using existing cellular network functionalities—
handover and cell (re)selection—used to maintain seamless coverage for mobile end-user equipment (UE). The frequency of handover and cell (re)selection events is highly
reflective of the density of mobile people in the area because virtually everyone carries UEs. Results: These measurements, which are accumulated over very many UEs,
allow us to identify the at-risk regions without compromising the privacy and anonymity of individuals. Conclusions:
The inferred at-risk regions can then be subjected to further
monitoring and risk mitigation.
Index Terms—COVID-19, infectious diseases, tracking.
Impact Statement—Method to identify crowded regions
with actively moving individuals, at risk for spreading
COVID-19, by exploiting existing cellular-network functionalities. Requires no active participation by individuals and
introduces no privacy concerns.
I. INTRODUCTION
T HE global COVID-19 pandemic is easily spread by people in close proximity, especially in crowds with mobile
individuals (e.g., city centers). A widely accepted strategy to mitigate its spread is social distancing, avoiding crowded areas [1].
There is an urgent need for different mitigation strategies to slow
the spread of this disease. Spreading by “silent carriers” mostly
depends on how they move and gather, the two viral-spreading
risk factors motivating our new mitigation strategy.
Manuscript received May 3, 2020; revised May 15, 2020 and May 31,
2020; accepted June 7, 2020. Date of publication June 15, 2020; date of
current version July 2, 2020. Alaa A. R. Alsaeedy was supported by a
scholarship from the Iraqi Ministry of Higher Education and Scientific Research under Grant 4650/11/16/2014. Edwin K. P. Chong was supported
in part by the National Science Foundation under Grant CMMI-1638284.
(Corresponding author: Alaa Alsaeedy.)
The authors are with the Department of Electrical and Computer
Engineering, Colorado State University, Fort Collins, CO 80523 USA
(e-mail: alaa.alsaeedy@colostate.edu/outlook.com; edwin.chong@
colostate.edu).
This article has supplementary downloadable material available at
https://ieeexplore.ieee.org, provided by the authors.
Digital Object Identifier 10.1109/OJEMB.2020.3002447
Our strategy does not track individuals, unlike many existing contact-tracing mobile-phone apps [2], which require
widespread user adoption and have obvious privacy concerns.
Instead, we anonymously measure the aggregate density and mobility of mobile devices, without individual identities, as detailed
below. Moreover, these measurements do not require installation
of any app nor any other action on the part of mobile users.
II. MATERIALS AND METHODS
We exploit already existing cellular-network functionalities
intended to manage end-users’ mobility and to ensure seamless
coverage [3]. Because practically everyone carries cellular mobile devices (called user equipment (UE)), these serve as alwayson human trackers. More specifically, the higher the number and
mobility of UEs, the higher the number and mobility of people.
According to a recent study [4], SARS-CoV-2 can live in the
air for up to three hours (remaining viable in aerosols), exhaled
by infected people while speaking, coughing, or even breathing,
whether symptomatic or not [5]. We are particularly concerned
with the scenario where contagious people are present in areas
with many other continuously mobile people. Such areas, which
we call at-risk, naturally have high local basic reproduction
number (R0) [6]. Conversely, sparse areas with mostly stationary
people are not considered at-risk (e.g., residential areas with
people remaining at home). The main goal is to detect at-risk
areas, allowing prioritization for further monitoring and risk
management. Our strategy is based on inferring the crowdedness
and mobility using measurements of quantities already accessible to the cellular wireless network via UE mobility management
protocols.
A. UE Mobility Management
Our scheme detects at-risk regions by measuring UE mobility
and density over a day or more, to capture long-term behavior
rather than short-term transients. Specifically, we exploit existing network functionalities required to keep each UE connected
while moving, exchanging UE-specific information with the
network [7], as detailed below.
B. Handover and Cell Selection
Long Term Evolution (LTE) networks (and their 5G successors) have shifted toward ultra-dense small-cell deployment,
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 187188 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, 2020
TABLE I
CELL TYPES IN CELLULAR NETWORKS (ADAPTED FROM [3])
called Heterogeneous Networks (HetNets), comprising multiple
layers of different cell sizes: microcell, picocell, and femtocell;
see Table I [3]. HetNets need to accommodate the increasing
density of highly mobile UEs and keep power consumption low
in battery-limited UEs [8]—hence, small cells are deployed in
dense UE areas.
The mobility of each UE is handled by two essential protocols:
handover (HO) and cell (re)selection (CS) [9]. We use the
measurements from conventional HO/CS events only, intended
to handle moving pedestrians as they cross cell boundaries.
We exclude the HO/CS events triggered by moving vehicles,
handled by different procedures called fast HO/CS [10], who do
not contribute significantly to spreading COVID-19. Each UE.1
triggers these procedures while moving from one cell to another
(e.g., from femtocell to picocell), to maintain connectivity. As
UE density and mobility increases, so does the rate of HO/CS
events. Thus, measuring HO/CS rates can be used to identify
regions with high UE density and mobility, thereby identifying
at-risk regions. The higher the HO/CS rates, the higher the risk
of spreading COVID-19. Because crowded areas are likely to
have small cell sizes, the spatial resolution of the HO/CS measurements is also relatively high (10–20 meters in femtocells).
Continuously measuring HO/CS rates gives real-time updates of
regional at-risk status.
III. RESULTS
Fig. 1 depicts an example of multiple cell sizes of a HetNet, deployed according to a predefined network plan; i.e.,
where these cells are needed to accommodate UE connectivity
in high-density areas. While actively moving, UEs frequently
initiate HO/CS events. Typically, each cell (labeled m, p, and
f in Fig. 1) records these events to be used by the network as
key performance indicators (KPIs) [7], primary indicators used
to evaluate and measure network performance; e.g., handover
success/failure rate.
If the HO/CS rates from a certain cell are relatively high,
this cell should be classified at-risk, warranting further risk
mitigation. For example, the network might broadcast advisory
messages to the affected UEs: “Area A is at risk of COVID-19:
It has many actively moving people.”
For illustration, Fig. 2 shows that the HO/CS rates are higher
in busy areas than in areas with low UE density/mobility. In this
example, the following cells are at-risk: m3, m4, p1, f1, f2, f3,
f4, f21, f22, and f23 (also labeled in Fig. 1). When people tend to
stay home for a period of time, the corresponding HO/CS rates
1While moving, the UE triggers HO when it is in the CONNECTED state and
CS when it is in the IDLE state [11].
Fig. 1. Illustration of HetNet deployment in areas with healthy and
infected people.
Fig. 2. Illustration of HO/CS rates in regions with varying density and
mobility.
are lower than in crowded areas with high UE mobility (e.g., f8
and f10 in Fig. 2).
IV. DISCUSSION
A natural rule for deciding whether to classify an area as
at-risk is to compare the measured HO/CS rate with a threshold
value, prespecified according to the desired false-alarm probability. False alarms are not particularly problematic here because
of the need to be conservative. Dire consequences can result from
the presence of even a single carrier in an area with many actively
moving people. While our strategy aims to identify areas with
potentially high viral transmission, the HO/CS rates can also be
used to estimate, for example, the percentage of people staying
at home.
V. CONCLUSION
We have introduced a new strategy for identifying areas that
potentially contribute to the spread of COVID-19. Our strategyALSAEEDY AND CHONG: DETECTING REGIONS AT RISK FOR SPREADING COVID-19 189
exploits existing cellular network procedures, HO and CS, required to maintain connectivity for mobile UEs. The frequency
of HO/CS events reflects how the UEs move and gather within
the coverage area. High HO/CS rates imply at-risk areas—those
with high UE density and mobility over time. Measuring HO/CS
rates allows distinguishing high- from low-risk areas, enabling
prioritization of further risk mitigation.



NEW_PAPER


Received December 17, 2020, accepted January 5, 2021, date of publication January 11, 2021, date of current version January 20, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3050852
A Novel Bayesian Optimization-Based Machine
Learning Framework for COVID-19 Detection
From Inpatient Facility Data
MD. ABDUL AWAL 1
, MEHEDI MASUD 2
, (Senior Member, IEEE),
MD. SHAHADAT HOSSAIN 3
, ABDULLAH AL-MAMUN BULBUL 1
,
S. M. HASAN MAHMUD 4
, AND ANUPAM KUMAR BAIRAGI 5
, (Member, IEEE)
1Electronics and Communication Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
2Department of Computer Science, College of Computers and Information Technology, Taif University, Taif 21944, Saudi Arabia
3Department of Quantitative Sciences, International University of Business Agriculture and Technology, Dhaka 1230, Bangladesh
4School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China
5Computer Science and Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
Corresponding author: Md. Abdul Awal (m.awal@ece.ku.ac.bd)
This work was supported by Taif University Researchers Supporting Project number (TURSP-2020/10), Taif University,
Taif, Saudi Arabia.
ABSTRACT The whole world faces a pandemic situation due to the deadly virus, namely COVID-19. It takes
considerable time to get the virus well-matured to be traced, and during this time, it may be transmitted
among other people. To get rid of this unexpected situation, quick identification of COVID-19 patients is
required. We have designed and optimized a machine learning-based framework using inpatient’s facility
data that will give a user-friendly, cost-effective, and time-efficient solution to this pandemic. The proposed
framework uses Bayesian optimization to optimize the hyperparameters of the classifier and ADAptive
SYNthetic (ADASYN) algorithm to balance the COVID and non-COVID classes of the dataset. Although
the proposed technique has been applied to nine state-of-the-art classifiers to show the efficacy, it can be
used to many classifiers and classification problems. It is evident from this study that eXtreme Gradient
Boosting (XGB) provides the highest Kappa index of 97.00%. Compared to without ADASYN, our proposed
approach yields an improvement in the kappa index of 96.94%. Besides, Bayesian optimization has been
compared to grid search, random search to show efficiency. Furthermore, the most dominating features have
been identified using SHapely Adaptive exPlanations (SHAP) analysis. A comparison has also been made
among other related works. The proposed method is capable enough of tracing COVID patients spending
less time than that of the conventional techniques. Finally, two potential applications, namely, clinically
operable decision tree and decision support system, have been demonstrated to support clinical staff and
build a recommender system.
INDEX TERMS COVID-19, ADASYN, Bayesian optimization, classification, inpatient’s facility data.
I. INTRODUCTION
The world is currently experiencing a pandemic situation
due to the extensive spreading of the novel coronavirus
disease namely, COVID-19. It is an acute respiratory syndrome triggered by the Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2), which was primarily detected
in Wuhan under the Hubei province of China in late 2019.
The associate editor coordinating the review of this manuscript and
approving it for publication was Bilal Alatas .
Considering the alarming rate of infection and death from the
COVID-19, World Health Organization (WHO) announced
the COVID-19 as a pandemic disease in March 2020 [1]–[3].
As per the WHO report on the COVID-19 on
August 04, 2020, about 18,142,718 people have been infected
due to COVID-19 [4]. Among them, about 691,013 people
died so far. Due to its high contagious nature, both the
COVID-19 infection and death toll are rapidly increasing.
In most cases, this disease spreads from man to man
via respiratory droplets, transmitted from individual to
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10263M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
individual via air or any other surfaces. This virus lives
multiple hours to multiple days on a suitable surface at
room temperature [5], [6]. As suggested by WHO, the
COVID-patient should get himself isolated from others as
early as possible to resist its transmission. The COVID-19
should be detected as early as possible, reducing life, livelihood, and the economy. But a critical issue is the broad
maturation period of the COVID-19 that varies from 3 to
14 days. The usual symptoms of this disease include fever,
cough, dyspnea, loss of smell, loss of taste, diarrhoea,
etc. [7], [8]. People affected by COVID-19 should go through
a fruitful, real-time, fast, and accurate screening scheme to
ensure timely treatment, isolation, and safety for the patient.
Many pieces of research are going on to find out efficient
and speedy COVID-19 detection schemes in different dimensions. The Reverse Transcription Polymerase Chain Reaction
(RT-PCR) is a COVID-19 detection scheme that has shown its
efficiency and has been practised worldwide. Using samples
like the nasal or oral pharyngeal swab, this method can competently detect coronavirus and has attained the gold-standard
banner. However, these testing kits fail to meet the mounting
demand due to its limited supply, especially in developing
countries [9]. Another drawback of this method is that it
requires an extended period, ranging from one to two days.
Moreover, the situation is even worse in rural areas, because
people from remote areas get the results after two or more
days, even after a week [10]. This extended period increases
the vulnerability of the spreading of COVID-19 as the patient
does not usually keep himself isolated from others before
getting his result.
To optimize these limitations, the potentiality of Artificial
Intelligence (AI) and Machine Learning (ML) algorithms
in the analysis, characterization, and classification of different diseases have motivated the researchers to introduce
AI and ML in COVID-19 detection. Numerous researches
have already been carried out to design a COVID-19 detection model based on AI and ML [7]–[20]. Furthermore,
Rajaraman and Antani [10] proposed a COVID-19 detection model based on deep learning (DL) algorithms. Using
convolutional neural networks (CNNs), chest X-ray (CXR)
data from patients are analyzed in this model to evaluate the
presence of the SARS-CoV-2 virus. The model showed about
93% accuracy employing the VGG16 classifier. Another
DL and CNNs based automatic COVID-19 detection model
was proposed by Makris et al. [8]. Diagnosing the CXR
data, the model exhibited about 95.9% and 95.00% accuracy engaging VGG16 and the VGG19 classifiers, respectively. A transfer learning-based model was presented by
Abbas et al. [12] to trace COVID-19. This CNN based
model diagnosed the CXR images of patients to check the
COVID-19 presence, and the model attained about 97.5%
accuracy. He et al. [7] presented a DL model for the automatic
detection of COVID-19. This model employed the chest
computed tomography (CT) images from patients to detect
COVID-19. The anticipated 3D CNN model, MNas3DNet41,
revealed about 87% accuracy. Jim et al. [11] presented an
automatic COVID-19 detection model based on sequential CNN. This model took the CT images in its input to detect
COVID-19. The model attained almost 92.5% accuracy along
with 94.2% sensitivity and 95.6% specificity. A lot of more
automatic COVID-19 detection models have been proposed
so far based on the computer-based diagnosis of the CT and
CXR images.
Hence, all the anticipated models require CT or CXR
data of patients as the key input parameter, only available
from diagnostic centres. So, each patient or suspected patient
has to visit the diagnostic centre in person to check the
presence of COVID-19 in his body. Most of the families in
developing countries do not have private transport. Besides,
patients from rural areas have to travel a long distance to
reach a diagnostic centre. Therefore, they have to use public
transport to visit the diagnostic centre to check COVID-19.
This will create high vulnerability to COVID-19 spreading,
among others. From another point of view, a low percentage
of people tested for COVID-19 gets COVID-positive results
in most of the countries; as an example, as of July 30, 2020,
the positive rate is about 1.30% in France, 22.20% in
Bangladesh, 9.90% in Iran, 0.90% in Italy, 7.90% in
the USA, 11.10% in India, 2.10% in Russia, and 0.40% in the
UK [21]. Visiting the diagnostic or test centre, a large percentage of COVID-19 negative people may meet with COVID-19
positive patients, which will enhance the risk of getting contaminated by COVID-19 disease. So, an inpatient data-based
COVID detection will be the best option to avoid these types
of risks. Besides, this type of detection will be very user
friendly, cost-effective, and time-efficient.
Considering all the above issues, we have proposed a fast
and user-friendly model to detect the COVID-19 based on
machine learning. A large volume of data on COVID-19 is
available in different laboratories and test centres. The dataset
comprises other features like age, temperature, pulse rate,
systolic and diastolic pressure, fever, cough, loss of smell,
runny nose, diabetics, loss of taste, asthma, etc., which are
analyzed to design the automatic COVID-19 detection model.
The most promising advantage of this model is that it is
capable of detecting the COVID-19 within a few minutes as
well as help the doctors take adequate precautionary measures while treating the COVID patients. Different classification algorithms such as Linear Discriminant Analysis
(LDA), Quadratic-DA (QDA), Naive Bayes (NB), k-Nearest
Neighbors (KNN), Decision Tree (DT), Random Forest (RF),
eXtreme Gradient Boosting (XGB), Gradient Boosting (GB),
Support Vector Machine (SVM), etc. are used to characterize
the model. These classifiers have some hyper-parameters, and
proper tuning of these hyper-parameter improves the performance of the classification using state-of-the-art global optimizers such as Bayesian optimization [22], Gradient-Based
Optimizer (GBO) [23], Slime mould algorithm (SMA) [24],
and Harris hawks optimization (HHO) [25] etc. The evaluation of different performance metrics such as accuracy, specificity, sensitivity, etc. for the anticipated model
demonstrates higher efficiency in detecting COVID-19.
10264 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
The contribution and key topics covered by this study are as
follows:
• The proposed model can be easily tested on inpatients
or inhouse facilities discussed in Section II. Therefore,
the patient needs not to visit the clinic to test the
COVID-19.
• We have designed a machine learning framework
using Bayesian optimization adapted by the ADASYN
algorithm to detect COVID-19 which is presented in
Section II.D and II.E.
• The state-of-the-art machine learning technique is optimized using our method and compared with other commonly used Grid-search and random search techniques;
see Section III.H.
• The proposed method uses the ADASYN algorithm to
balance the model, and the effect of ADASYN has also
been demonstrated in III.A.
• Using SHapely Adaptive exPlanations (SHAP) analysis,
important features are calculated, and the SHAP values
are explained to interpret the model in Section III.F.
• A clinically operable decision tree is built that will
be helpful for the clinical staff stated in Section IV.A.
A decision support system has also been developed to assist the recommender system illustrated
in Section IV.B.
The remainder of the paper is organized as follows.
In Section II, we discuss the materials and methods used in
this work. We present the experimental results in Section III.
In Section IV, we present a systematic discussion and comparison of the work with other approaches. Finally, we draw
some conclusions in Section V.
II. MATERIALS AND METHODS
A. DATA SOURCE
The clinically-driven information on individuals who have
undergone through RT-PCR test was collected from the [26].
The dataset, containing 11169 person’s data with 2.82% of
patients’ COVID positive and 97.18% COVID negative tests
from the United States, was prepared by Carbon Health (CH)
and Braid Health (BH). The CH started RT-PCR testing of
a coronavirus in early April 2020. The dataset is compliant with the Health Insurance Portability and Accountability
Act (HIPAA) privacy rule’s de-identification standard. Five
clinical teams worked under the CH. The dataset prepared by
the CH covered multiple physiognomies on patients, including Epidemiological (Epi) Factors, comorbidity, vital signs,
lab technician-assessed symptoms, patient-stated symptoms.
Whereas, two clinical teams gathered the dataset under
the BH, which assembled the radiological information containing verdicts, CXR impressions, CXR labels, and CXR
link. We haven’t used radiological information as most of the
patient doesn’t have radiological details. The integration of
radiological information is beyond the scope of this study,
hence excluded from the analysis. The dataset consisted of
both positive and negative test results for patients having both
one or more symptoms and zero symptoms. In addition to
COVID-19 test results, the complete dataset, available on
the GitHub website, contains multiple features of patients
such as pulse rate, temperature, age, higher danger introducer
occupation, higher danger contacts, diabetics, cancer, asthma,
smoker, systole, diastole, diarrhoea, fatigue, fever, losing
smell, losing taste, runny nose, headache, muscle pain, pain
in the throat, cough, shortness of breath, etc. The vignette of
the entire data set has been illustrated through a tabular sketch
shown in Figure 1.
From the pictorial depiction (Figure 1), it is much clearer
that there are two types of data (numeric and boolean),
where the boolean variables are more than three times that of
the numeric data. Moreover, the highest age of the patients
in this data set is 90 years old, and the extreme values
of both systolic and diastolic pressures were dramatically
higher than the natural ones. It can be further added that
days_since_symptom_onset has about 68% missing data,
while the percentage of missing data in the entire data set is
around 17. Besides the tabular display, as shown in Figure 1,
the graphical example the green bars in Figure 2 efficiently
reveals that the variables cough, diabetes, chd, htn, cancer,
asthma, COPD, autoimmune_dis, and smoker have no missing data. In contrast, the variable days_since_symptom_onset
has the highest missing values compared to others.
B. DATA PRE-PROCESSING
The overall workflow of our study is presented in Figure 3.
For data pre-processing, the dataset has been imputed using
Multivariate Imputation by Chained Equations (MICE) algorithm [27]. After completing scaling, we used the ADASYN
algorithm to balance out COVID and non-COVID datasets.
ADAptive SYNthetic (ADASYN) algorithm [28] is an oversampling method where COVID positive is a rare instance.
It helped us generate synthetic data, solving the over-fitting
problem. In contrast, the under-sampling process is not
the right choice in COVID classification. The majority
class (i.e. COVID-no class) is downsampled to the amount
minority class (i.e., COVID-yes). This process will reduce
the amount of data that drastically cause data inefficiency,
and it loses the vital information of COVID-no class. Our
COVID data set is not a big dataset, and downsampling
could mislead the diagnosis and detection. Compared to
other correlated over-sampling methods such as AdaBoost
in conjunction with Over/Under-Sampling and Jittering of
the data (JOUS-Boost), Synthetic Minority Over-sampling
TEchnique (SMOTE), SMOTE-Boost and, DataBoost-IM
(DataBoost IMbalanced) algorithm, ADASYN can balance
the imbalanced dataset, for example, COVID-19 dataset by
reducing the bias introduced by the imbalanced data distribution [28]. Besides, ADASYN shifts the decision boundary
to harder to learn examples which ultimately improves the
classification accuracy. These two objectives, i.e. (i) bias
reduction and (ii) introducing harder to learn neighbourhoods
examples, are accomplished through the dynamic weight
adjustment and adaptive learning procedure [28].
VOLUME 9, 2021 10265M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 1. Characteristics of the Sample.
The Mathematical explanation behind the ADASYN algorithm is given below:
For illustration, if ml and ms represent the majority and
minority classes, respectively, then the Degree of imbalance
of the two classes can be figured as follows:
d =
ms
ml
. (1)
If d < dx (where dx is the preset threshold for the maximum
tolerated imbalance) then the total number of the synthetic
minority can be estimated as follows:
G = (ml − ms)d. (2)
Here d = 1 means there is a total balance between two
classes. If ri =
ml
k
, where k is the number of neighbours of
each minority, and rˆ = Pri
ri
such that Prˆ = 1, then the
amount of synthetic data to generate for each neighbourhood
can be calculated as:
Gi = Grˆ. (3)
If xi and xu are two minority examples within the same
neighbourhood, where xu is randomly selected, then the new
synthetic example,si can be enumerated using the followings:
si = xi + (xu − xi)λ, (4)
10266 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 2. Fill rate for all Variables.
where xu−xi
is the difference vector in n-dimensional spaces,
and λ is a random number over [0, 1].
C. CLASSIFICATION MODELS
These nine classifiers such as Linear Discriminant Analysis
(LDA), Quadratic Linear Discriminant Analysis (QLDA),
Naive Bayes (NB), KNN, DT, RF, XGB, GB, and SVM,
have been utilized in the proposed machine learning framework. Among nine classifiers LDA, QLDA, NB, KNN,
DT and, SVM are common classifiers and also used in
COVID-19 classification. RF, XGB and GBC are recent
state-of-the-art classifiers. For example, XGB is recently
applied to interpret the mortality prediction in COVID-19
patient and proposed a clinically operable simple tree-based
tool which can be suitable to take the right decision from an
expert point of view [56]. Considering the above rationale,
we have used both commonly used classifiers as well as
recently updated classifiers in this study. This will allow
us to compare the classification performance in different
classifiers. Moreover, RF, XGB and GBC classifiers can be
explained through SHAP analysis which is very useful to
clinical engineers. Finally, it can be seen from the results
that the XGB performed better in most of the classification
metrics, and we used SHAP to explain the XGB to interpret
the COVID-19 detection.
1) LINEAR DISCRIMINANT ANALYSIS (LDA)
The LDA, introduced by Ronald Aylmer Fisher in 1936 [29],
is a productive classification technique. It sorts-out
n-dimensional spaces into 2-dimensional spaces that split-up
by hyper-plane. The core objective of LDA is to trace the
mean function for each class, and the function is projected
on the directions that optimize between-groups variance and
reduces within-group variance. The LDA is generated from
the conditional distribution of the data P(X|Y = k) for
each class k, and it optimizes by taking the class k when
the measurements are made on standalone variables for each
observation are continuous quantities [30], [31].
2) QUADRATIC LINEAR DISCRIMINANT ANALYSIS (QLDA)
QLDA, an extension of LDA is exploited in machine learning and statistical analysis to classify two or more groups
by quadratic discernible using distance-based classification
techniques. There is no hypothesis like LDA that the covariance matrix for every class is identical. When the regularity
hypothesis is true, the best prospective test for the hypothesis
that an assumed measurement is from a given class is the
likelihood ratio test. QLDA can be found from the conditional
distribution like LDA of the data P(X|Y = k) like LDA, and it
maximizes by selecting the class k [30], [31]. More precisely,
for LDA and QLDA, P(X|Y = k) is resulting as a multivariate
Gaussian distribution with the following equation:
(Y = k) =

(2π)
d/2




X
k




1/2−1
exp
− 0.5(X − µk )
t X−1
k
(X − µk )

, (5)
where d is the number of features [32]. It needs to estimate
the class priors P(y = k) for using LDA and QDA model as
classifiers, e.g. the proportion of instances of class k from the
training data, the means µk and the covariance matrix.
3) NAIVE BAYES (NB)
NB classifier is authoritative and mainly useful in the large
dataset. It is used in both machine learning and medical
science, especially the diagnosis of different diseases like
COVID-19. It is a Bayes’ theorem, based on probabilistic
classifier objects with the strong independent supposition
between the features. It generates conditional probability
models that allocate class labels to a given problem [33]. Say,
P(Patient|Covid Positive)
=
P(Covid Positive|Patient) × P(Patient)
P(Covid Positive)
,
where, P(Patient|Covid Positive), a conditional probability is
the likelihood of the patient occurring that s/he is affected
VOLUME 9, 2021 10267M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 3. The overall workflow of the classification of COVID-19. The first phase is collecting raw data followed by pre-processing,
where the raw data is imputed, scaled, and most importantly, the imbalanced data is balanced using ADASYN algorithm. Secondly,
the pre-processed data are split into the train and test set used by different classifiers to measure the classification performance. In the
next step, Bayesian optimization has been implemented to tune the hyperparameters of the classifiers. This optimized classification
model is then tested, and different performance metrics (accuracy, precision, Confusion matrix, ROC, 10-fold cross-validation, ANOVA, and
multi-comparison test) have been used for evaluation. Finally, the important features have been efficiently traced using SHAP analysis.
with Covid; P(Covid Positive|Patient) is also a conditional
probability: the likelihood of the positive COVID occurring
that is truly a patient; P(Patient) is the prior probability of a
patient; P(Covid Positive) is the overall probability of observing COVID positive.
4) K-NEAREST NEIGHBOURS (KNN)
KNN is straightforward simplest algorithms in supervised
machine learning technique [34] uses data and classify new
data points based on similarity measures with the distance
function, be able to apply to solve both classification and
regression difficulty. It uses an integer number as 1, −1, or 0
for symbolizing the productivity (labels) of a classification
algorithm outputs. KNN is a memory-based classifier; for
example, it remembers all the training data-points to predict test data by computing the similarity between an input
sample and each training instance. For a given new data
point x0, it finds the k training points xr
,r = 1, . . . , k
closest in distance to x0 and then classify using majority vote
among the k neighbors [32]. For selecting k, it conducts the
KNN algorithm respective times with various values of k and
opts for the k that reduces the number of errors accurately.
5) DECISION TREE (DT)
DT is a hierarchical flow chart like structure that generate
some decision rules. The DT creates a model that predicts
the target variable by learning the decision rule from the data
feature [35]. The main hyper-parameters of DT are criterion,
max_depth, max_features. In DT, ‘‘Gini’’ or ‘‘entropy’’ is
used as a criterion. In contrast, the max_depth is utilized to
limit the number of nodes in the tree, and the max_features
represents the number of features to consider while searching
for the optimal split. By properly tuning the hyper-parameters
of DT (i.e., criterion, max_depth, max_features) applied on
the COVID training dataset, the classification performance
will be efficiently magnified.
6) RANDOM FOREST (RF)
RF is an ensemble learning technique for classification
that uses several DTs on different sub-samples of the
dataset to improve the classification performance and to
control over-fitting [36]. The main hyper-parameters of
RF are criterion, max_depth, max_features, n_estimators.
The criterion, max_depth, and max_features have already
been discussed in DT. Besides, n_estimators represent the
number of DTs in the forest. The performance of RF can
be increased by properly tuning the hyper-parameters of
RF through optimization.
7) GRADIENT BOOSTING CLASSIFIER (GBC)
GBC is also an ensemble classifier that combines different weak learners (typically DT) into a single strong
learner in a forward stage-wise fashion by optimizing the
differentiable loss function [37]. Generally, ‘deviance’ or
‘exponential’ is used as a loss function where ‘deviance’
refers to deviance (logistic regression) for classification with
probabilistic outputs. For thrashing, ‘exponential’ gradient
boosting recaptures the AdaBoost algorithm. Other controlling parameters of GBC contained different parameters
such as n estimators, learning rate, and max depth where
n estimators indicate individual boosting stages to accomplish; learning rate reduces the performance of each tree [32].
10268 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 1. Classifiers and their controlling parameters or hyperparameters.
8) eXtreme GRADIENT BOOSTING (XGB)
XGB is designed based on the principles gradient boosting
framework. It can be used for supervised learning tasks such
as regression, classification, and ranking; similarly, it generates a prediction model in the form of an ensemble of
weak prediction models. The model in a stage-wise approach
is compassed with it as other boosting methods do, and it
generalizes them by approving optimization of a random
differentiable loss function. The gradient descent is used
by ‘Gradient Boosting’ to generate new trees based on all
previous trees. It supervises the objective function toward
the minimum direction [38]. An objective function has a
form, and it divides into training loss and regularization. The
mathematical equation has been added as follows:
obj(θ) = L(θ) + (θ), (6)
where θ denotes the parameters,  symbolizes the regularization term, and L is the training loss. The main
hyper-parameters of XGB are N_estimators, learning_
rate, n_jobs, max_depth, Gamma, min_child_weight,
colsample_by_tree. The hyper-parameters such as
N_estimators, learning_rate, max_depth have already been
discussed. Besides, n_jobs are relevant to the number of
parallel threads used to run XGB; Gamma represents the
loss required to make a further partition on a leaf of the
tree. The min_child_weight denotes the minimum sum of
feature example, i.e., instance weight needed in a child, and
colsample_by_tree is used for the subsampling of columns.
9) SUPPORT VECTOR MACHINE CLASSIFIER (SVC)
SVC is one of the most powerful supervised classifiers and used mostly for data classification in medical
diagnosis [39], [40]. It aims to build a decision boundary
in such a way that it is as far as possible from the closest data points from each of the classes, which are known
as support vectors. For non-linear problems like COVID
detection, a Radial Basis function (RBF) kernel is used.
For RBF-SVC, the controlling hyper-parameters are Cost(C)
and Gamma(γ ). The Cost(C) represents the regularization
parameter that controls the misclassification of the training
instances. Gamma(γ ) controls the ‘‘spread’’ of RBF kernel and, therefore, the decision region. The lower value of
Gamma(γ ) will broaden the decision region and vice versa.
The proper value of C and γ will increase the classification
performance, which can be achieved by optimization.
D. REQUIREMENT OF OPTIMIZATION
Most of the classifiers used in our entire study have some
hyperparameters. The classifier itself is the function of hyperparameters, and these parameters control the hyper-plane.
As an exemplification, XGB requires 7 Hyperparameters,
while KNN and DT have one parameter each [Table 1].
Classifier performance indices, e.g., classification accuracy,
error, specificity, sensitivity, etc. depend on the proper choice
of these parameters. This is an optimization problem, whose
general framework can be written as:
lim
z∈Z
J(Clf (z); Z), (7)
where z ∈ Z denotes the hyper-parameters z1,z2,z3, . . . ..,zn
belongs to Z. Clf denotes the classifiers, e.g. RF, SVM,
DT, NB, etc. and J(.) represents the objective function. This
objective function is the user-defined function where users
can use different classifier metrics such as classification
error or accuracy or other metrics described in the following
section of statistical evaluation of classification measures.
The general framework of the optimization problem can be
interpreted as minimizing the classification objective J(.) as
a function of classifier’s hyperparameters z ∈ Z. In this
study; mean of the the 10-fold cross-validation error is used
as an objective function. We chose one of the state-of-the-art
optimization algorithms named Bayesian optimization. This
algorithm used a stochastic process, namely, as a Bayesian
process, and it tried to find the optimal parameters in a smaller
number of iterations saving both memory and time [41].
Although various meta-heuristic algorithms such as GWO,
GBO, SMA, and HHO etc. successfully integrated into
many applications [42]–[44], hyper-parameter optimization
in expensive-to-evaluate objective function e.g., 10-fold
cross-validation loss, used in this study, makes it more
complicated [45]. Besides, meta-heuristic algorithms require
a set of input parameters that need to be found out to
obtain an improved performance as the performance of
the meta-heuristic algorithms are very sensitive to the
VOLUME 9, 2021 10269M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
input parameters. Furthermore, comparison among various meta-heuristic algorithms is only valid if the proper
input parameters have been set, which requires domain
knowledge [46]. Bayesian optimization is used to set the
parameters of the meta-heuristic algorithm [45], [46].
The Bayesian optimization algorithm is a global optimization method that is specially designed to deal with
such expensive-to-evaluate objective function, which is the
population and genetic operator (mutation, cross-over, and
selection) free algorithm. Bayesian optimization utilizes a
Gaussian process to compute an acquisition function that
evaluates the objective function. Besides, Bayesian optimization memorizes its previous evolution and utilize these statistics towards good solutions. It has been recently used in
COVID-19 detection using x-ray images [22]. Considering
the above rationale, Bayesian optimization has been applied
in this study.
To justify further, the proposed Bayesian optimization is
compared with the recently proposed Harris Hawk Optimisation algorithm [25]. This popular swarm-based and
gradient-free optimization algorithm is based on the cooperative behaviour and chasing styles of Harris’ hawks in nature
called ‘‘surprise pounce’’ [25]. We have chosen this algorithm
for comparison as it is very recent and outperformed by many
popular meta-heuristic algorithms such as GWO, Multi-Verse
Optimizer, Moth-Flame Optimization, Whale Optimization Algorithm, Bat Algorithm, Cuckoo Search, Firefly
Algorithm.
E. BAYESIAN OPTIMIZATION
Bayesian optimization (BO) is superior to grid search, random search, and manual tuning and therefore used in this
study [47]. This algorithm keeps track of the past evaluation results and uses them to form a probabilistic Gaussian model of BO of the objective function and use it to
find out the most optimal hyper-parameters; as an exemplar, in the case of RBF-SVM, the hyper-parameters are
C and γ . The BO algorithm selects C and γ for which
objective function J(RBFSVM;(C, γ )) provides the minimum value. Note that, the classification error is used
as an objective function. The BO algorithm is given
below:
Step 1: Build a Gaussian probability model of the objective function. In this study, classification error is the
objective function.
Step 2: Find the controlling parameters or hyperparameters that perform best on the Gaussian process.
Step 3: Apply these hyper-parameters to the true objective function.
Step 4: Update the Gaussian model incorporating the
new results.
Step 5: Repeat Step 2-4 until maximum iteration is
reached.
The Mathematics behind the Bayesian Optimization for X =
(x1, x2, x3, . . . , xn) independent features and y target variable
is given below:
P(y|X) =
P(X|y)P(y)
P(X)
(8a)
=
P(x1|y)P(x2|y) . . . P(xn|y)P(y)
P(x1)P(x2) . . . P(xn)
(8b)
=
P(y)
Qn
i=1 P(xi
|y)
P(x1)P(x2) . . . P(xn)
(8c)
=

1
P(x1)P(x2) . . . P(xn)

× P(y)
Yn
i=1
P(xi
|y), (8d)
Since all the variables except the target variable are independent, P(x1)P(x2) . . . P(xn) = Constant, Then Eq. (8d) can
be simplified as:
P(y|x1x2 . . . xn) ∝ P(y)
Yn
i=1
P(xi
|y), (9)
Now, from Eq. (9), we find the probability of a given set of
inputs for all possible values of the target variable y and pick
up the output with maximum probability:
y = argmax
y
P(y)
Yn
i=1
P(xi
|y), (10)
F. STATISTICAL EVALUATION OF CLASSIFICATION METRICS
We have used several performance evaluation metrics to evaluate the performance of the proposed framework. The accuracy (ACC), error, false-positive rate (FPR), sensitivity (SE),
specificity (SP), positive predictive value (PPV), Matthew’s
correlation coefficient (MCC), F1_score, and Kappa index
can be calculated from confusion matrix [48], [49]. A lower
value of error and FPR, and a higher value of ACC, SE,
SP, PPV, MCC, F1_score, and Kappa index indicate a better
model. Besides, 10-fold cross-validation has been used [52]
on the overall dataset. The most significant point should
be mentioned here that the box-plot and Analysis of Variance (ANOVA) test are typically executed, relying on the
10-fold cross-validation result. The statistical significance
is determined by the p-value derived from the ANOVA
test [50], [51]. Furthermore, the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC)
has also been used to evaluate the performance of the classifier. The recall rate vs the decision boundary curve has been
used to examine the performance. In this study, we have used
the value of 0.5 as the decision boundary threshold to provide
the same importance to COVID-yes and COVID-no classes.
G. FEATURE IMPORTANCE USING SHAP VALUES
The SHapely Adaptive exPlanations (shortly known as
SHAP), proposed in recent papers by Lundberg and Lee [53],
are calculated for any tree-based model. The SHAP values from Game Theory to attribute φi value to each feature can be mathematically ascertained using the following
10270 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
formula [54]:
φi =
X
S∈N\i
|S|!(M − |S| − 1)!
M!
[fx (S ∪ {i}) − fx (S)], (11)
where M is the total input features, N is the set of all input
features, and S is a subset of the input features.
• In this plot, all the variables are ranked in descending
order.
• The horizontal line (x-axis) quantifies how much the
value is associated with a higher or lower prediction. All
the left-sided points represent the observations shifting
the predicted value in a negative direction. In contrast,
the points on the right contribute to shifting the prediction in a positive direction. All the features are on the
left y-axis.
• The color shows whether that variable is high (in red) or
low (in blue) for that observation.
III. EXPERIMENTAL RESULTS
In this paper, the Bayesian optimization has been used along
with and without the ADASYN algorithm. In the case of
ADASYN, sufficient adaptive synthetic data has been created to eliminate the imbalanced nature among the majority
and the minority classes. Firstly, the effect of ADASYN has
been evaluated along with ROC, shown in section III.A. The
balanced model has also been tested on the original test
data in section III.B. Box-plot and ANOVA are presented in
section III.C using cross-validation accuracy to evaluate the
statistical significance. The Recall rate vs. decision boundary
curve and Bootstrap ROC with ADASYN are discussed in
sections III.D and III.E, respectively. Then, the evaluation of
feature importance using SHAP and the analysis of SHAP
values have been presented in sections III.F and III.G, respectively. Finally, the performance of Bayesian optimization
has been compared with the Grid search and random search
in section III.H.
A. BAYESIAN OPTIMIZATION WITH AND WITHOUT
ADASYN
The newly obtained balanced dataset has been utilized; 67%
of the total dataset is used for training and validation, and
33% is used for testing. After that, multiple classifiers are
used, and various statistical measurements are presented. The
effect of ADASYN has been experimented and validated in
this subsection.
To begin, in the upper portion of Table 2, the performance analysis for the COVID Dataset with the utilization
of the ADASYN algorithm has been demonstrated. It can
be seen that; RF provides the highest classification performance. However, the performance of XGB and GBC is very
close to RF. LDA and QLD show the worst classification
performance among various classifiers presented in Table 2.
The same AUC value of 99.70% is observed among these
three classifiers, as shown in Figure 4. To demonstrate the
effect of the ADASYN algorithm, the original unbalanced
dataset is used. The dataset is also divided in the same manner,
FIGURE 4. ROC Curve with ADASYN.
i.e., 67% of the total dataset is used for training and validation,
and 33% is used for testing. We rerun the optimized code
on this dataset, and the results on the test dataset without
ADASYN is presented in the lower portion of Table 2. It can
be observed that the highest accuracy of 97.17% is obtained
by RF, which is close to the classification accuracy using RF
with ADASYN. This could happen in the imbalance dataset.
Therefore, accuracy is not a good performance indicator. The
Kappa index, MCC, and AUC are more robust and reliable
indicators in this case.
It can be seen that the highest Kappa, MCC, and AUC
values of 8.96%, 9.36% using NB, and 75.80% using XGB
(Figure 5), respectively, are obtained. Compared to the upper
portion of Table 2, i.e., results with ADASYN, the Kappa,
FIGURE 5. ROC curve without ADASYN. Note that the optimized model
has not been created by using a balanced dataset.
VOLUME 9, 2021 10271M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 2. Classification performance (in %) on the COVID dataset with and without ADASYN.
TABLE 3. Classification performance (in %) on the original test data of COVID.
MCC, and AUC values are 88.23%, 87.84%, and 23.90%
times lower ADASYN algorithm is not applied, respectively.
This can be happened due to an imbalanced model. This
significant improvement using ADASYN concludes that classification performance can significantly be improved through
directly applying the ADASYN algorithm.
B. RESULTS USING ORIGINAL TEST DATA ONLY
So far, we have seen the effect of ADASYN on classification
performance. The ADASYN is an oversampling method, and
the synthetic data is mixed with original test data during data
balancing. Therefore, it could be argued that what are the
results of the balanced model on the original test data only
where synthetic data is not mixed?
To answer this question, balanced and Bayesian-optimized
models have been applied to the original test data. Different performance measures, such as accuracy, sensitivity, specificity, and ROC, are presented in Table 3 and
Figure 6. It can be seen that XGB provides the highest
accuracy, error, F1_score, FPR, Kappa, MCC and sensitivity of 98.63%, 1.37%, 99.29%,24.21%,75.08%,75.08%, and
99.29%, respectively. In contrast, SVC provides the highest
PPV, specificity, and AUC of 99.94%, 97.89% and, 98.90%,
respectively. It can also be seen that XGB performs the best
in most of the classification metrics presented in Table 3.
10272 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 4. The accuracy score (in %) of the different optimized classifiers using 10-fold cross-validation.
FIGURE 6. ROC Curve for COVID on original test data only using each
model. The optimized model has been created by using a balanced
dataset and then applied to the original test dataset.
Furthermore, these results are mostly inclined with
ADASYN results (upper portion of Table 2), and results are
significantly better than without ADASYN in all classification measures. The ROC curve shown in Figure 6 is also
visually very close to Figure 4. Note that the same test dataset
has been used without ADASYN (i.e., in the lower portion of
Table 2) and in Table 3 for a fair comparison. Finally, it can
be concluded that a balanced model can significantly improve
the performance of the COVID dataset and XGB shows the
best classifiers. The confusion matrix of the best performing
balanced model with ADASYN and with original test data
have been presented in Figure 7 to show how much COVID
and Non-COVID patients are correctly classified.
C. K-FOLD CROSS-VALIDATION
In the standard train-test-split method, generally, a small portion of the data is taken as the test set, and the total dataset is
not tested. To overcome this issue, the k-fold cross-validation
(CV) is one of the helpful techniques exploited to test
the effectiveness of machine learning models. It is also a
re-sampling procedure to evaluate, and k = 10 is used in
this study. The first fold is used for testing, and the remaining
folds are used for training and repeated ten times to test the
total dataset fold-by-fold basis. The 10-fold cross-validation
result is presented in Table 4, where the classification result of
each fold is shown. The final row provides the average classification accuracy of the 10-fold results. From the Table 4, it is
observed that the least score has been obtained using QLDA,
whereas the XGB touched the mountain point, grabbing a
score of 96.70% and RF has attained an average accuracy
of 96.46%. On the other side, the classification performance
using Decision Tree, SVC, and GBC was less than XGB
and RF but above 90%. Note that, the data processed by
ADASYN is used only to train the classifier, but the original
test is used during testing and performance comparison.
Figure 8(a) showed the accuracy of different classifiers
using the COVID original dataset using a box-plot. Here
one-way ANOVA provided a p-value of 3.32 × 10−107 for
the original COVID test dataset, which is statistically significant (p < 0.005). It also provided an interactive plot of
multiple comparisons of means in Figure 8(b) that showed
the highest mean accuracy from XGB that is statistically
significant from seven classifiers (GBC, DT, SVC, NB, KNN,
QLDA, and LDA). In contrast, it is statistically not significant
from RF, because the mean of RF is almost identical. Note
that, Figure 8(b) is an interactive plot where the significance
of different classifiers can be visualized by clicking on the
specific classifier level. For instance, RF is blurred (shown
in grey) defining its insignificance as XGB is selected. Similarly, GBC and DT will also exhibit statistical insignificance
if one of them is selected.
D. RECALL RATE VS. DECISION BOUNDARY CURVE
The recall rate, in general, depends on the decision boundary
using a certain threshold. To exemplify, the recall rate vs.
decision boundary curve displayed in Figure 9(a), where
VOLUME 9, 2021 10273M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 7. Confusion matrix of the balanced model applied in (a) COVID
test Dataset with ADASYN, (b) original COVID test Dataset only. Figure 7(a)
depicts the percentage of the correct classification in with the first two
diagonal cells generated by the trained network. The numbers of patients
who are correctly classified as a COVID and non-COVID were 3150 and
3233, corresponding to 48.7% and 49.9% in each group’s patients,
respectively. Likewise, the numbers of patients who are incorrectly
classified as a COVID and non-COVID were 24 and 67, with 0.4% and 1.0%
correspondingly among all patients in each group. Similarly, the overall
99.2% were correctly, and 0.8% were incorrectly classified COVID, and
non-COVID were overall, 98.0% and 2.0% correctly and incorrectly
classified accordingly. In the case of prediction, the correct overall
predictions for COVID and non-COVID were 97.9% and 99.3%, respectively.
On the other hand, the incorrect results for COVID and non-COVID were
2.1% and 0.7%. Similarly, we can also interpret Figure 7(b).
0.5 decision boundary threshold (T ) has been used for the
‘‘COVID-19-yes’’ class. The recall rate of QLDA is about
0.98 at default threshold T = 0.5, meaning that about
98% times this optimized classifier can truly classify the
FIGURE 8. Box-plot for (a) COVID Dataset and (b) multi-comparison test.
Note that (b) is a graphical user interface tool by which one can test the
statistical significance of any classifiers. Here we only show the effect
of XGB. The effect of other classifiers can also be interpreted in the same
way.
‘‘COVID-19-yes’’. The XGB and RF provided a moderate performance of around 0.75 at default threshold
T = 0.5 defining the ‘‘COVID-19-yes’’ class. The SVC shows
the third highest performance of around 0.90. In contrast,
the recall rate of NB at this threshold is 0.25, meaning
that only 25% times NB can truly classify the ‘‘COVID19-yes’’ class. A similar scenario is observed for the
LDA classifier.
On the other hand, looking at Figure 9(b), the recall rate of
QLDA is drastically falling to a value of 0.1 at T = 0.5,
revealing that only 10% times QLDA can classify the
‘‘COVID19-no’’ class. The recall rate of XGB, GBC, and
RF is about 0.99 at this threshold whereas the recall rate
of SVC is 0.90. Finally, considering both ‘‘COVID19-yes’’
and ‘‘COVID-19-no’’ classification using recall rate vs.
decision threshold measure, it can be concluded that
SVC, XGB, and, RF provide the satisfactory recall
rate among different optimized classifiers predicting both
classes.
10274 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 9. Recall rate vs. decision boundary curve for (a) COVID positive and (b) COVID negative.
E. BOOTSTRAP ROC WITH ADASYN
To determine whether the optimized model is highly sensitive
to training data or not, bootstrapping is performed on the
XGB model as it is the best performing model. This gives
Nboot XGB having slightly different discriminative abilities.
To show the error, three ROC curves are plotted in Figure 10;
the middle one represents the average ROC where upper
and lower curves represent the 95% confidence interval (CI).
To obtain this bootstrap ROC, Nboot = 100 XGB models are trained and mean AUC of 0.98 with an upper and
lower confidence interval of 0.97 and 0.99, respectively, are
obtained. This indicates that training is not highly sensitive to
the training dataset.
F. FEATURE IMPORTANCE USING SHAP
In a variable importance plot, the most significant variables are sorted in descending order. The top variables
contribute more to the model than the bottom ones
and thus have high predictive power. By way of example, ‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’,
‘‘high_risk_interactions’’, ‘‘wheezes’’ are the most important
features, where ‘‘fever’’ touched the mountain point in this
case [shown in Figure 11]. Simultaneously, ‘‘pulse’’ and
‘‘sore_throat’’ received the least importance in classifying
the COVID-19 contaminated patients.
G. SHAP VALUE ANALYSIS
From the pictorial example of SHAP analysis [Figure 12] for
training data, it can be summarized that the three features,
‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’ and
‘‘loss_of _smell’’ have a massive positive impact is on the
target variable. The ‘‘high’’ comes from the red colour, and
the ‘‘positive’’ impact is shown on the X-axis. Whereas,
we conclude by mentioning that the features ‘‘ctab’’ and
‘‘wheeze’’ are highly negatively correlated with the target
variable. In this way, all the variables can be efficiently
explained. It should be mentioned that the behaviour of the
FIGURE 10. Bootstrap ROC curve of the COVID dataset using XGB
with 95% CI.
XGB model is defined by the SHAP and are not necessarily
causal in the real world. In other word, SHAP values do not
provide the causality; it only describes the model behaviour
and the behaviour of the data used to build the model [55].
As the model does not predict all the COVID patients accurately, it is plausible to get some false positives and false
negatives. However, the SHAP value can able to explain such
results, and the summary plot will be helpful to explain those
results.
H. PERFORMANCE ON THE GRID SEARCH, RANDOM
SEARCH, BAYESIAN OPTIMIZATION AND HARRIS
HAWKS OPTIMIZATION
We propose to use Bayesian optimization techniques in
our framework, and therefore, it is logical to compare
VOLUME 9, 2021 10275M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 5. Comparative search techniques.
FIGURE 11. Feature importance plot using SHAP for XGB.
FIGURE 12. The SHAP variable importance plot of training data using XGB.
the Bayesian optimization algorithm with commonly used
parameter search algorithms. Two popular and widely used
algorithms, namely, grid search and random search, compare
with our proposed techniques. Table 5 presents the comparison of different search algorithms in terms of several
parameters evaluated; the overall time is taken (in sec.) to
complete the program, cross-validation accuracy score, test
score. All the simulations were run on Intel core i9 computer
having 64GB RAM and used the XGB model. It can be seen
that it takes 10473.740 Sec. to complete the simulation using
grid search, whereas random search and proposed Bayesian
optimization take only 162.794 Sec. and 675.389 Sec, respectively. Furthermore, the random search and Bayesian algorithm take 30 parameters each, while the grid search requires
more parameters, which is 218 times than that of others. The
test score using Bayesian optimization is 98.20%, which is
better than grid search, random search.
The pictorial depiction of the comparative search methods has also been given in Figure 13, from where it can
be added that at the initial stage, the accuracy of Random
Search was nearly 97.50%, which was almost stable up to
12 iterations. Then, with a single iteration, it takes a
sharp change in its accuracy, touching closely the score
of 98%, which was followed by an unchanged condition until
30 iterations. In contrast, the score of our proposed Bayesian
Optimization technique commenced before 97%, which was
almost steep up to 2 iterations, touching the accuracy
FIGURE 13. Comparative optimization techniques applied to the XGB
model.
10276 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
above 98%. The most exciting information should be mentioned here that the score of our proposed method remains
unchanged, except for a slight change after 15 iterations.
Before finishing 30 iterations, its accuracy touched the mountain point.
The proposed Bayesian Optimisation Framework has
also been applied to the most recent Harris Hawks optimization algorithm calculated over 200 evolutions with
20 populations on the same train-test settings. It provides
98.39% cross-validation accuracy, whereas the testing accuracy is 98%. The result is very similar to the Bayesian Optimisation framework. However, it takes 6204.80 Sec. which is
9.4 times slower than our proposed framework as it requires
more evaluations and optimization calculations; see Table 5.
To further justify, a statistical significance test between
Bayesian optimization and Harris Hawks optimization algorithm is performed on 10-fold cross-validation using t-test.
After that, the p-value is calculated, and the box-plot is
plotted. A p-value of 0.47 is found, which suggests that
there is no statistically significant difference between these
two optimizations. The box-plot illustrated in Figure 14 also
justifies the same statements.
FIGURE 14. Box-plot of Bayesian optimization and Harris Hawks
optimization.
IV. DISCUSSION AND COMPARISON
In this research, a Bayesian optimization-based machine
learning framework with a class balancing strategy using
the ADASYN algorithm is proposed to identify COVID
patients from their inpatient facility data. Nine state-of-theart classifiers such as LDA, QLDA, NB, KNN, DT, RF,
XGB, GB, and SVC are utilized in this proposed framework to identify COVID patients. Different classification
measures such as accuracy, sensitivity, specificity, Kappa
index, Matthews correlation coefficient are used to show the
efficacy of different classifiers. This study also performed
10-fold cross-validation accuracy to achieve statistical significance using ANOVA, recall rate vs. decision boundary
threshold analysis, ROC, and bootstrap ROC. Finally, SHAP
analysis is performed to interpret the feature importance and
interpret the model. These different classification indicators
describe model performance from another point of view.
The primary intention to use these indicators is to describe
the classification performance from a different perspective.
It can be seen from Table 2 that RF yielded the highest
classification performance in terms of accuracy, kappa index,
and MCC, etc. However, the classification performance of
XGB and GBC is very close to RF. The ANOVA and
multi-comparison tests show that the average accuracy of
RF, XGB, and GBC are very close and are not statistically
significant. However, the 10-fold cross-validation accuracy
of XGB provides the highest value (see Table 4). Moreover, the balanced XGB model offers the highest classification performance when applied to the original test data (see
Table 3). Also, the recall rate vs. decision threshold boundary indicates the superior performance of XGB and SVC
(see Figure 9). This concludes that the balanced and optimized XGB model would be the best choice for detecting
COVID patients using their inpatient facility data. Therefore,
further analyses such as bootstrap ROC and SHAP analysis
and features importance analysis are done on a balanced and
optimized XGB model.
Regarding the ADASYN algorithm, it should be mentioned
that ADASYN adaptively generates synthetic data samples
for the COVID-yes class since it is a minority class to reduce
bias introduced by imbalanced data distribution. ADASYN
moves the classifier’s decision boundary towards harder-tolearn examples, improving the learning performance [28].
Therefore, applying the ADASYN algorithm enhances the
learning process and eventually improves our COVID classification performance; see Table 2 to understand the effect of
ADASYN in detail. Regarding Bayesian optimization (BO),
unlike grid search and random search, it can be mentioned
that BO takes the previous objective function evaluation
into account, and the function goes to the optimal solution.
Therefore, the hyperparameter using BO provides fine-tuning
parameters, which ultimately builds an optimized model and
consequently increases the classification performance. SHAP
is used to determine feature importance and model interpretation; it can be mentioned that SHAP uses a game-theoretic
approach, which has an excellent mathematical background
and current state-of-the-art approach.
Due to the salient features mentioned above, it can be
noted that the proposed framework can not only be applied to
COVID-19 detection but also applied to other classification
problems such as diabetic prediction, asthma prediction, etc.
While describing the significance and strength of this study,
it is also logical to explain the weaknesses of this study. The
database used in this study is a moderately large dataset.
It will be useful to apply the proposed framework on a larger
dataset and validate the proposed approach on a completely
independent dataset before clinical use. Clinical blood sample
data and integration to X-ray and CT-scan will enhance the
detection rate and validity. This is beyond the scope of this
study.
VOLUME 9, 2021 10277M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 6. Description of the clinically operable decision tree algorithm.
FIGURE 15. A decision rule using four key features and their thresholds
in absolute value.
A. DEVELOPMENT OF A CLINICALLY OPERABLE
DECISION TREE
A clinically operable decision tree would benefit clinical staff
as it is straightforward to understand the underlying process. As DT are simple classifiers consisting of sequences of
binary decisions organized hierarchically [56], we have built
a simple tree by using four important features, x1 = cough;
x2 = loss of smell; x3 = high-risk exposure occupation;
x4 = sats; Note that, the continuous value of oxygen saturation feature, i.e., x4 feature is discretized into three different
levels of 1, 2 and 3 to denote severe, moderate and normal
level, respectively. x4 feature value lies between 75 and 90
mm-Hg is treated as severe, 91 and 95 mm-Hg as moderate,
and 96 and 100 mm-Hg as a normal level. Figure 15 represents the corresponding DT, and the description of the tree
algorithm is given in Table 6.
B. DEVELOPMENT OF A DECISION SUPPORT
SYSTEM (DSS)
A DSS could be beneficial to support clinical staff for screening COVID-19 patients from their inpatient facility data.
A DSS is usually a graphical representation of decision,
FIGURE 16. Probabilistic output for the DSS. In the upper figure, the 0 has
represented a subject with COVID negative, whereas 1 represented a
subject with COVID positive. The lower figure represents a probabilistic
outcome of the subject affected by COVID, where the red dotted line
defines the threshold level. When the patient data level exceeds this
threshold level, then the subject will be considered as COVID positive.
Whereas the subject with the probability of less than 0.5, i.e., the
threshold value, will be regarded as COVID negative. In either way, we can
say that this the chance that a person is affected by COVID.
COVID-19, in this case, to visualize the probable state of the
patient. A possible outcome of COVID suspected patient’s
inhouse facility data is presented in Figure 16, in terms of the
posterior probability. A probabilistic result is more intuitive
to the clinical staff and, therefore, used in this DSS. Note
that 100 patients are used from the test database for illustration purposes. The patient is sorted in ascending order so
that patients with ‘‘COVID-no’’ labelled appears first, and
patients with ‘‘COVID-yes’’ appear.
C. COMPARISONS WITH OTHER METHODS/STUDIES
To delineate the superiority of our proposed research,
an illustrative comparison of our work has been accomplished to other COVID studies. From the tabular illustration
[Table 7], it can be mentioned that both Jim et al. [11] and
Ozturk et al. [57] used CNN to obtain the accuracy respectively 92.50% and 98.08%. Furthermore, multiples research
works have been carried out by [7], [63], [64] with the direct
10278 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 7. Comparison of performance with other methods.
implementation of XGB using mostly clinical data, where
the average of the accuracy obtained from [7], [63] was
less than 90%. On top of that, Wu et al. [58] used RF to
get a classification accuracy of approximately 96%, which
outperformed Brinati et al. [59], who utilized both DT and
RF. In addition, the lowest performance was obtained by Sun
et al. [60], who used the SVM classifier for clinical and
Demographic data. Most importantly, although the accuracy
of Wu et al. [58] is slightly higher than that of our proposed
method, the AUC and Specificity of our work far outweigh
the other methodologies mentioned here.
V. CONCLUSION
This paper presents the optimal use of different machine
learning techniques, including state-of-the-art classifiers,
to predict COVID. The proposed approach is aimed to handle
the real-time in-home dataset in detecting the COVID effectively. Thus, the proposed technique provides a user-friendly
and low-cost tool for COVID detection. In designing the
method, the COVID dataset, collected from CH-BH, has
been used to assess the performance using different classification metrics such as accuracy, sensitivity, specificity,
kappa index, etc. The hyper-parameters of different classifiers
have been optimized using Bayesian optimization, and the
ADASYN has been used to balance the dataset. Compared
to the studies presented in this study, it is evidenced that
both the classification accuracy and AUC for our proposed
framework has attained the highest values of 98.50% and
99.40% using XGB, respectively. As the proposed approach
has been applied to a moderately large dataset, it should be
used on a big dataset before clinical trials. However, our
primary intention is to test the feasibility of such settings.
A similar approach can be applied to design other classification problems. Finally, two potential applications of our
proposed technique, namely clinically operable decision tree
and decision support system, would be beneficial for clinical
staff and building an efficient recommender system. It could
easily be integrated into mobile devices which would be very
useful for the end-users.
DATA AVAILABILITY
The raw dataset can be accessed through Github:
https://github.com/mdcollab/covidclinicaldata. The processed data can be obtained from the first author (Md Abdul
Awal; m.awal@ece.ku.ac.bd) of this paper.



NEW_PAPER


Received August 25, 2020, accepted September 20, 2020, date of publication September 22, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025971
Balancing Personal Privacy and Public Safety
During COVID-19: The Case of South Korea
NA YOUNG AHN 1
, JUN EUN PARK2
, DONG HOON LEE 3
, (Member, IEEE),
AND PAUL C. HONG4
1
Institute of Cyber Security and Privacy, Korea University, Seoul 02841, South Korea
2Department of Pediatrics, Korea University College of Medicine, Seoul 02842, South Korea
3
Institute of Cyber Security and Privacy and The Graduate School of Information Security, Korea University, Seoul 02841, South Korea
4
Information, Operations, and Technology Management College of Business and Innovation, The University of Toledo, Toledo, OH 43606, USA
Corresponding authors: Dong Hoon Lee (donghlee@korea.ac.kr) and Paul C. Hong (paul.hong@utoledo.edu)
ABSTRACT There has been vigorous debate on how different countries responded to the COVID-19
pandemic. To secure public safety, South Korea actively used personal information at the risk of personal
privacy whereas France encouraged voluntary cooperation at the risk of public safety. In this article,
after a brief comparison of contextual differences with France, we focus on South Korea’s approaches
to epidemiological investigations. To evaluate the issues pertaining to personal privacy and public health,
we examine the usage patterns of original data, de-identification data, and encrypted data. Our specific
proposal discusses the COVID index, which considers collective infection, outbreak intensity, availability of
medical infrastructure, and the death rate. Finally, we summarize the findings and lessons for future research
and the policy implications.
INDEX TERMS COVID-19, COVID index, de-identification, epidemiological investigation, infectious
diseases, pandemic, personal information, personal privacy, policy, public safety, South Korea.
I. INTRODUCTION
Increasingly, the integration of big data and information and
communications technology (ICT) promises enormous social
value creation. In a pandemic crisis, public safety is a top
priority. Simultaneously, we cannot ignore potential privacy
breaches. The ‘‘old’’ debate over personal privacy and public
security is still relevant. Since personal information is crucial
to curtail the spread of a pandemic, policymakers and officials
can more likely expect ‘‘implicit’’ consent. However, in the
course of pursuing compelling public purpose, privacy rights
may be at risk [1]–[3].
In general, any epidemiological study is subject to an ethics
review to ensure privacy [4], [5]. For a face-to-face investigation, investigators respect confidentiality requirements. However, in view of the increasing social costs associated with the
prevention and treatment of serious infectious diseases, there
is a growing demand to gather accurate personal information
in real time. For example, Gilbert Beebe suggested that in
certain disastrous circumstances, public interest might be a
higher priority than privacy issues [7]. The widespread flu
The associate editor coordinating the review of this manuscript and
approving it for publication was Yu-Chi Chen .
epidemic in 2009 provided additional support for this line of
reasoning. While conducting epidemiological investigations,
researchers did not always obtain an individual’s explicit
consent. In the United States, the Health Insurance Portability
and Accountability Act (HIPAA) established the privacy rules
that set limits on the use and disclosure of any personal health
information [8], though aggregating personal information for
public health purposes is a somewhat different matter [9].
COVID-19 is an extraordinary circumstance that poses
enormous public health risks—potentially affecting millions
of people worldwide [10]–[12]. Nations are at war with the
coronavirus. In this context, what does it mean to balance
personal privacy and public safety? What are the boundaries and acceptable norms? This study considers these questions and examines the actual cases of two countries—South
Korea and France. The subsequent sections of this study proceed as follows. In Section 2, we discuss the characteristics
of the virus that causes COVID-19. We then introduce an
anti-displacement alternative to COVID-19. We further compare the results of the French and Korean governments’ quarantine measures against COVID-19. We apply the STRIDE
Threat Model to perform a risk analysis of the Korean government’s quarantine system. Our specific proposal considers
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 171325N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
collective infection, outbreak intensity, availability of medical infrastructure, and the death rate. Based on our findings,
we present lessons and implications for future epidemiological investigations.
II. COVID-19 RESPONSES
A new type of coronavirus (SARS-CoV-2) was first reported
in Wuhan, China, in December 2019. Since then, this respiratory infection epidemic, designated as COVID-19, spread
throughout China and worldwide. Upon infection, after a
2- to 14-day incubation period, patients experience respiratory symptoms including high fever (about 37.5 degrees) and
cough or dyspnea [13]–[19]. However, it seems that there
are several cases of asymptomatic infections. On January 21,
2020, the Chinese government officially reported 15 confirmed cases of COVID-19 [20]–[23]. The medical staff
involved in the incident became credible evidence of humanto-human transmission [24]. On January 30, 2020, the World
Health Organization (WHO) declared the continual spread
of this infection as an International Public Health Emergency (PHEIC). With an accelerating rate of confirmed
patients worldwide, on March 11, 2020 the WHO declared
the COVID-19 outbreak a pandemic [25].
COVID-19 is a respiratory virus that spreads primarily
through droplets generated when an infected person coughs
or sneezes, or through droplets of saliva or discharge from
the nose. The infected patient’s saliva can be transmitted
directly to another person’s eye or if a person rubs their
eyes with a virus-contaminated hand [24]. The rapid spread
of COVID-19 was expected to overwhelm limited medical
equipment and facilities with the sudden increase in the
explosive number of patients [26]. Consequently, the fight
against COVID-19 requires contact tracing for close contacts
of laboratory-confirmed or probable patients. In some countries, these responses were compulsory, while others implemented a voluntary system. Our study compares the cases
of France and South Korea, with special focus on the South
Korean government’s approaches in seeking the participation
of its citizens.
A. KOREAN GOVERNMENT’s APPROACH
At first, the South Korean government did not respond
appropriately by not knowing the precise nature of the
COVID-19 pandemic. The initial optimism was based on
confidence that Korea’s medical capabilities could handle any
major public health challenges. Additionally, how to assess
asymptomatic patients was determined somewhat later. For
example, a Chinese woman who arrived from Wuhan on
January 20, 2020 was identified as the first confirmed case.
Until then, foreign tourists without fever were free to enter
Korea, and there was not yet any serious effort to track
asymptomatic patients.
However, upon understanding the significance of asymptomatic patients and the nature of droplet infection, the next
task was to identify the pathogens of confirmed patients.
Fig. 1 describes the essential elements of the Disease Health
FIGURE 1. Disease health Integrated Management System for COVID-19.
Integration System (DHIMS), which collects and uses epidemiological survey data. Local governments conduct tests
for epidemiologic investigation. Medical staff at public health
centers and diagnostic screening centers follow-up with the
confirmed patients. Local governments are responsible for
operating screening clinics through large scale drive-through
or walk-through testing sites without harvesting virus
transmission [27].
If a person tests positive, then the health or diagnostic
center immediately uploads the relevant personal information of the patient to the DHIMS. The health or diagnostic
center immediately submits incident reports to the Korean
Centers for Disease Control (KCDC). The local government
health center also conducts an additional epidemiological
investigation. The public safety law requires that confirmed
patients disclose their recent movements and identify all contacted persons. The local government examines a confirmed
patient’s recent usage information from mobile phones and
credit cards and uploads all information about the contacted
persons including their name, address, contact information,
date of birth, gender, disease name, diagnosis date, age,
occupation, place of residence, telephone number, and health
status, to the DHIMS. In this way, a national database of epidemiological investigations maintains all the relevant information of the confirmed patient and all contacts.
A diagnostic test is performed immediately for persons
with symptoms. According to the severity of the COVID-19
symptoms, the individuals are either self-quarantines or hospitalized. Recent contacts who have no symptoms are quarantined for 14 days from the contact date of the confirmed
patient. Self-quarantined individuals are monitored daily at
local government call centers. If the additional diagnostic test
after 14 days shows that the individual is negative and he/she
has no symptoms, then the individual is released.
The Korean government implemented a COVID-19 response system with 3P (Preemptive, Prompt, and Precise)
and 3T (Trace, Test, Treat) plus P (Participate) quarantine
response model [27]. It used innovative ICT systems such as
self-isolation and diagnostic apps, drive-through and walkthrough clinics, and mobile phone location information analysis. The Korean government also counted on voluntary
171326 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
participation by citizens to develop additional app capabilities. For example, using these aggregated epidemiological
survey databases, real time COVID-19 maps and monitoring
apps were developed to benefit society at large.
B. FRENCH GOVERNMENT’s APPROACH
France established Public Health France (PHF) on
January 13, 2020 to monitor and respond to the COVID-19
epidemic [28], [29]. PHF’s Crisis Center monitors epidemiological prevention, mobilizes health protection organizations,
manages the strategic resources of medical facilities, and
offers support services. The PHF conducts daily epidemiological investigations and releases the aggregate details
including the area, gender, and age group of COVID-19
patients [30], [31].
The PHF set up a surveillance system to monitor the epidemiological and clinical aspects of COVID-19 using urban
medicine, measure the severity of the epidemic and its impact
on the medical system, and report the fatality rate. The PHF
took active preventative measures to control the spread of
COVID-19 with the aim of reducing the risk of transmission
by providing warning messages to people in affected areas.
In addition, the precautionary measures aimed to help people
maintain a better quality of life, even in social isolation.
The PHF also supported active health-related services
by operating a remote support system. The PHF allows
healthcare professionals (e.g., doctors, nurses, pharmacists,
physical therapists, midwives, etc.) and health professionals
(managers, supervisors, health facility personnel, and engineers) to be prepared for a request for help from the health
center. The French government implemented quarantine measures since March 16, 2020. The PHF monitors the behavioral responses and mental health practices in response to
these changes and assesses social anxiety levels. Certainly,
the COVID-19 pandemic disrupted the French ways of life
and restricted vital economic and social activities. From the
early days of the outbreak, the PHF’s main challenge has
been how to mobilize citizen participation in the fight against
COVID-19.
C. COMPARISONS OF FRANCE AND SOUTH KOREA
According to WHO data, the first confirmed case in South
Korea was January 20, 2020. In France, the first reported case
appeared on January 24, 2020. However, after little more than
two months, these two countries showed a marked difference
in terms of cumulative number of confirmed cases and total
deaths [25]. As Table 1 (as of June 7, 2020) reports, the cumulative total of confirmed cases in Korea is 11,776 and 153,634
in France. The cumulative deaths are 273 and 29,143 for
Korea and France, respectively.
Korea’s population is 51,269,183, and France’s population
is 65,273,512 as of June 7, 2020 [25], [32]. In France, 20%
of the population is over the age of 65, while it is about 14%
in Korea, indicating that France has many elderly people.
In addition, the number of beds per 1,000 people is 5.98 in
France and 12.27 in Korea. In general, mortality is closely
TABLE 1. Comparison of COVID-19 data for Korea and France.
related to the number of hospital beds and the elderly population [33], [34]. Therefore, when comparing the hospital
bed and proportion of the elderly population, more deaths
should be more likely in Korea than in France. Both countries
encouraged their citizens to join the fight against COVID-19.
Even so, France has relatively more fatalities than Korea.
These differences deserve careful analysis of other preventive
measures. In the next section, we examine the impact of the
epidemiological investigation database and the ICT technology usage in Korea.
III. SECURITY OF THE KOREAN RESPONSE SYSTEM
It is beyond the scope of this study to describe the development of the Korean government’s quarantine system processes and its operational mechanisms fully. For the purpose
of this research, we applied available response guidelines
released by the Korean government and explored other documents about the quarantine system [35], [36].
A. THREAT ANALYSIS USING THE STRIDE THREAT MODEL
We evaluated security by applying the STRIDE threat model
and examined the dynamic investigation data input and output
of the DHIMS [27], [37].
FIGURE 2. Potential data vulnerabilities in the system.
Fig. 2 shows the sequence of on-line and off-line data
collection, DHIMS storage, and third-party access. Potential data vulnerability spots are noted ( ) in the process
linkage sequences. Threats to data integrity occur in several
ways. Despite Korea’s effective response to COVID-19 using
epidemiological survey data, the entire process also contains
potential privacy violations.
Identity Spoofing: The appropriate security level of the
DHIMS system requires identity safeguarding and restricting
access to epidemiological investigation data. After performing the basic authentication operation procedures, the relevant
VOLUME 8, 2020 171327N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
medical personnel, epidemiologists, government agencies,
or civilians (i.e., third parties) are allowed to access the
epidemiological investigation database. Identity spoofing;
that is, misusing stolen identity data, is the most prevalent
security risk attack.
Data Tampering: The on-line/off-line epidemiological
data collection methods involve extensive personal information: name, address, contact information, gender, age, and
phone number of the confirmed patient / all contacted. The
DHIMS does not automatically de-identify such epidemiological survey data. During the data entry process, medical
personnel or epidemiologists may make mistakes or arbitrarily change some of personal information content.
Repudiation: Because a legitimate user has access to the
input and output of epidemiological survey data from the
DHIMS, there must be sufficient correcting and checking
procedures in the processing data operation. For example,
what if the epidemiological investigation results in an offline
state do not always exactly match the epidemiological data
entered in an online state? Therefore, a repudiation option
is necessary to ensure the integrity of the epidemiological
investigation data.
Information Disclosure: The retention period for epidemiological data in DHIMS is permanent or semipermanent. If the DHIMS has solid system security, then we
can assume that all personal information is safe. However,
when a third party requests a particular set of epidemiological investigation data, the DHIMS is supposed to conduct a
de-identification process and offer specific numbers instead
of names [37]. However, in the course of various information disclosures, an individual’s privacy might not always be
well-respected.
Denial of Service/ Elevation of Privilege: What might
be problematic is the fact that these epidemiological investigation data have a legally permanent or semi-permanent
retention period [37]. The DHIMS quality control measures
require an application of relevant parameters (e.g., proper
authorization and examination of usage patterns). Without the
full operation of strict safeguarding measures when issuing
permission or denial of personal information access, serous
privacy risk concerns remain.
Table 2 summarizes the various types of threat and risk
levels according to the DHIMS system access level.
B. PERSONAL PRIVACY vs. PUBLIC SAFETY
The Korean government disclosed the COVID-19 confirmatory movement paths and the addresses of quarantined
buildings and enforced two weeks of self-containment for all
confirmed patients and their contacts. In the early days of the
epidemic, COVID-19 maps tracked the movements of these
individuals, thus raising awareness of many people in affected
areas.
In the digital age, balancing public safety and personal privacy is still enormously challenging [38]–[40]. With the rapid
spread of COVID-19, unidentified aggregate information has
little value. Public safety requires the ‘‘right to know’’ about
TABLE 2. Threat type and threat level.
the status of infection. Individuals may waive their privacy
rights for public safety when it requires informing people
about relevant COVID-19 infection information. The question is, ‘‘For legitimate public safety purposes, how do government authorities rightfully use personal information?’’
C. EXAMPLE OF BIG DATA USE IN THE
COVID-19 PANDEMIC
From the early stage of the outbreak, the Korean government
collected detailed personal information about the confirmed
patients. Using these data (e.g., credit cards, phone number, and address), investigators could specify the paths of
infection, conduct disaster prevention, and implement selfcontainment measures of all contacts. Such active follow-up
methods had a considerable success.
On February 18, 2020, Korea had its 31st confirmed
patient from the Shincheonji church in the Daegu area.
With the sudden increase in confirmed patients among Shincheonji church members, the Korean government changed its
approach and implemented more aggressive follow-up measures [27]. Shincheonji church, as a new religious movement,
employ somewhat controversial elements in their recruitment
of new members and the education of its existing members.
In particular, their regular mass meeting often occurs in an
enormous, enclosed hall. Hundreds of the church’s leaders
attended their international missionary outreach gathering
in Wuhan, China and returned to Korea in January 2020.
In the meantime, the number of confirmed patients increased
explosively—up to 7,513 on March 10, 2020 [41]–[43].
Considering the rapid virus transmission among the church
members, the Korean government took aggressive action.
At the government’s request, the Shincheonji Church provided the social security and phone numbers of its members.
Local governments called the church members in their region,
looked for symptoms, and conducted COVID-19 tests. The
Shincheonji church ledger has more than 200,000 people.
Thus, nearly all the church’s members (about 212,000) were
contacted and examined. The Korean government used this
set of big data to prevent the COVID-19 pandemic. With the
use of this data and follow-up testing, the government effectively contained one of the main sources of the widespread
outbreak.
171328 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
FIGURE 3. Comparison of cumulative deaths in South Korea and
France [44].
Fig. 3 shows a comparison of the cumulative deaths in
Korea and France. The number of deaths before and after
the COVID-19 pandemic, declared on March 11, shows a
sharp difference. As we discussed in the case of Shincheonji
church, Korea’s aggressive and extensive use of personal
information made a significant difference. The question is,
‘‘What is the proper way to use personal information, even
in this pandemic?’’ Here, we consider the value of using
de-identified information.
D. DE-IDENTIFICATION IN EPIDEMIOLOGICAL
INVESTIGATIONS
As a proactive measure to contain and prevent the pandemic, the Korean government used epidemiological data
through ICT. Medical testing equipment expedited massive COVID-19 testing, which was instrumental in reducing
mortality. It is a public safety imperative to use personal information to control and prevent the spread of a pandemic. Managing personal information stored in big data sets requires
appropriate privacy protection measures. Privacy violation is
related to the use of identifiable personal information. Therefore, an effective safeguard of personal privacy requires the
use of non-identifiable personal information. The right type
of technological support is essential for such de-identification
options.
In the United States, the HIPPA set national standards for
the protection of an individual’s medical records and personal
health information. It applies to health plans, health care
information centers, and health care providers that transmit
any health care transactions electronically. This rule requires
appropriate safeguards to protect the privacy of personal
health information, sets limits, and specifies the conditions
for the use and disclosure of such information without patient
consent and approval [9], [45].
However, the Korean government uses identifiable personal information with limited restrictions, potentially leading to serious violations of the privacy of patients and their
contacts. Securing personal information for quarantine measures is appropriate. With respect to personal privacy, it is
important to use the information gathered for the specific
intended purpose only. Using identifiable personal information for any other purpose is a breach of confidence and trust.
Moreover, the legal provision of keeping quarantine investigation data either permanently or semi-permanently is not
reasonable at all. Requiring the de-identification of personal
information and rapid-deployment-relevant technology is an
urgent need [46].
IV. ADAPTIVE EPIDEMIOLOGICAL INVESTIGATIONS
The purpose of conducting epidemiological investigations is
to understand the nature of an epidemic and determine how to
control the spread of infectious diseases for public safety [47].
However, public safety does not justify privacy infringement.
In this section, we discuss the practical steps epidemiological
investigations can take to achieve a balance between privacy
and public health.
A. CLASSICAL TRADE-OFF BETWEEN PERSONAL PRIVACY
AND PUBLIC SAFETY
The HIPAA’s privacy rules propose two approaches to the
de-identification of personal health information: the safe
harbor method and the expert determination method [45].
The safe harbor method deletes 18 personal identification
variables such as name, social security number, contact information, IP address, fingerprints, photographs, and detailed
address. The method of using experts is to process personal
information using non-identifying algorithms.
The release and forget model, the data use agreement (DUA) model, and the enclave model are all useful to
achieve effective control in data storage and usage processes.
The general pre-sale model is to release unidentified personal
information to the public by posting data online. A DUA
establishes sharing rules between research collaborators who
are covered entities under the HIPAA privacy rule. Only
intended recipients can use certain information in a limited
data set. The closed room model maintains a safe analytic
environment that restricts unauthorized access and the export
of personal information in its original form. It is a physical
and technical control method to respond and export [48].
It is often challenging to enhance the scientific utilization
value of data collected with de-identified personal information. An increasing level of de-identification is negatively
related to the quality of the data and the precision of the
research results. Conversely, higher data quality and outcome
precision require lower levels of de-identification. A greater
level of personal identification is related to a higher possibility of privacy infringement [49].
Therefore, individual researchers aiming to achieve more
precise analysis results may prefer to use the original data,
which contains identifiable personal information. On the
other hand, reputable institutions satisfy personal privacy
requirements by ensuring the anonymity of the data.
B. BALANCING PERSONAL PRIVACY AND PUBLIC SAFETY
There are diverse approaches to data de-identification. In general, methods to determine the level of de-identification of
VOLUME 8, 2020 171329N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
personal information are known [48]. The National Institute
of Standards and Technology (NIST) proposes a method
determined by an expert and a safe hopper method for removing multiple identifiers [50], [51]. In recent years, differential
privacy technology that adds noise to personal information
has been attracting attention as a way to increase privacy in
big data analysis [52], [53]. This differential privacy technique is a de-identification method that performs a kind of
pseudonymization process.
With widely available de-identification technologies, it is
difficult to prevent individuals from being re-identified from
de-identification measures. Researchers at the Imperial College London, UK, conducted experiments with published
data from the United States, Turkey, and other countries, and
found certain attributes accurately even by using de-identified
data [54]. Their machine learning model could identify individuals with 99.98% accuracy from anonymized data using
only 15 demographic attributes (age, gender, marital status, etc.). This research team suggests a paradigm shift:
‘‘We need to de-identify, then move on. Anonymity is not
a property of the data set. It depends on how the person
who writes it uses it.’’ In other words, what matters is not
anonymizing, but designing and organizing data to be useful
and meaningful.
So then, what are the alternatives? It is time to move from
the idea of de-identification to the application of appropriate
technologies. The aim is to strike a balance between the public use of data and personal privacy [55], [56]. Technologies
such as secure multi-party computation and homomorphic
encryption are emerging. More innovations are certainly in
progress in the post-COVID-19 world of new big data technologies and ICT applications [57], [58].
The development of these new technologies can increase
our options when dealing with infectious diseases. It is imperative to balance personal privacy and public safety, even in the
context of COVID-19. Personal information with individual
consent may be used for specific research purposes.
C. THE NEED FOR AN INDEX TO BALANCE PERSONAL
PRIVACY AND PUBLIC SAFETY
There has been serious debate over the value priorities of the
epidemiological investigation. Healthcare policymakers are
more likely to lean toward public safety goals. On the other
hand, safeguarding personal privacy is important from the
individual rights perspective. In this context, developing an
effective mechanism for balancing public safety and personal
privacy is important and timely. We present an index measure
for balancing criteria. Our study provides a helpful practical
tool in epidemiological investigations.
D. COVID INDEX FOR EPIDEMIOLOGICAL INVESTIGATION
By applying the concept of DREAD modeling in security
engineering, we propose the COVID index as a method to
balance public health and privacy in epidemiological investigations [35]. This COVID model uses five parameters: collective infection, outbreak intensity, viral tiler, infrastructure
of medical faculties (e.g. number of medical beds per million
people), and death rates (or fatality rate).
TABLE 3. COVID index for intelligent epidemiological investigations.
Table 3 illustrates how adaptive epidemiological investigations may use the COVID index. Here, C represents collective
infection, O represents the outbreak intensity, and V represents the viral propagation power. Here, the value indicates
the minimum concentration at which the virus infects the cell.
I represents the level of medical infrastructure. D represents
the mortality rate of the virus. The COVID index can be
calculated as follows:
COVID index =
C + O + V + I + D
5
. (1)
Values from 0 (low) to 5 (high) are assigned to each item.
The values of each item are summed according to Equation 1,
and the COVID index is determined as the average value
of the results. The sum with be a value from 0 to 25, and
the COVID index will therefore be a value 0, 1, 2, 3, 4,
or 5. A high COVID index suggests a significant risk of the
virus’s propagation power and public health and an urgent
need to investigate the epidemiology. In this case, aggressive
epidemiological investigations should be conducted by collecting original data. Aggressive epidemiological investigations minimize the incidence of additional confirmed patients
from contact and suspected patients [59], [60]. Quarantine
measures can rapidly contain a virus. Thus, deploying the
available medical resources has the maximum prevention
effect.
If the COVID index is greater than or equal to 2, then the
epidemiological investigation should focus on collecting and
using de-identified data. On the other hand, for a COVID
index of either 0 or 1, researchers should collect and use
encrypted data instead.
E. SUGGESTIONS TO STRENGTHEN PRIVACY IN
EPIDEMIOLOGICAL INVESTIGATIONS
The primary purpose of the epidemiological investigation is
to minimize contact with a confirmed patient. Thus, isolating
individuals that test positive for a disease is imperative to
prevent the occurrence and spread of infectious diseases.
Here, we suggest several practical suggestions to enhance
security in the epidemiological investigations.
First, investigators should be required to obtain a personal
consent forms and use personal information within a specific
period. In the early breakout period of COVID-19, personal
information was often collected without a proper personal
consent process. Later, a mandatory requirement to specify
171330 VOLUME 8, 2020N. Y. Ahn et al.: Balancing Personal Privacy and Public Safety During COVID-19: The Case of South Korea
the data storage period and usage patterns of personal information was put in place. If proper consent forms are not
obtained, then the personal information collection process
should stop. All personal information stored in the database
should include the entry time and expiration date. The investigation system should automatically delete epidemiological
survey data after the expiration date. Further steps may also be
taken to remove personal information completely from other
databases and thus guarantee personal privacy [61].
Second, we should explore other options to use identifiable
personal information. What if de-identification is not practical for research purposes? Personal information is regarded as
similar to the copyright concept. For the sale of any products
with copyright, a certain amount of money is set aside to
compensate the copyright holder. Similarly, it is plausible
to compensate each individual for the use of their personal
information for specific research purposes.
Third, we should address de-identification technology.
An individual from the medical field or an epidemiologist
may apply de-identification technology when storing personal information. When the required information is collected
through off-line systems and then uploaded to a database,
then the individual under investigation should be notified
to check the accuracy and provide consent. Afterward,
the offline information should be destroyed immediately and
the individual should be notified of the destruction. Epidemiologists should do the same when they apply de-identification
technology to store personal information collected online.
Fourth, researchers should establish conditions for third
party access. Any personal information provided to a third
party should be made available in the form of non-identifying
numbers or symbols. In case a third party need to use
identified personal information, they should require personal
consent.
Fifth, researchers should design an operating system for
personal privacy. Google and Apple recently released a tracking system with privacy features [62], [63]. Other scholars
also introduced systems that encrypt data to ensure privacy in
applications [64], [65]. These options offer additional safeguards for ensuring personal privacy.
Adaptive epidemiological surveys may still contain human
errors in the course of using different types of technologies,
including artificial intelligence (AI)-based epidemiological
investigation systems. Implementing the suggestions above
should aim to improve personal privacy in epidemiological
investigations. In addition, our proposed COVID index can
provide a basis for epidemiological investigations to support
efforts to balance personal privacy and public safety.
F. IMPROVING THE INTEGRITY OF OFFLINE DATA IN
EPIDEMIOLOGICAL INVESTIGATIONS
People issues are too often related to data integrity and
information quality. In epidemiological investigations, offline
information gathering raises questions about the reliability. Incorrect information obtained from interviews with
patients may lead to wrong assessment and evaluation about
quarantine decisions. Therefore, it is important to check the
quality and assure the integrity of offline epidemiological
investigations. Specific security measures we propose are to
strengthen an epidemiological investigation system. It is to
cross-check the accuracy of offline information in real time
using other online information sources (e.g., usage history
of credit cards, bus and subway transportation cards). This
will enhance the integrity of data gathering process. It will
also prevent the rapid spread of infectious diseases through
monitoring of the history of patients contacts and taking
additional preventive measures for all those affected.
V. CONCLUSION
In the COVID-19 context, the Korean government actively
used personal information and achieved fairly successful public safety outcomes. However, that is only part of the whole
story. The extensive use of personal information may also
negatively impact personal privacy. Therefore, practical safeguard measures, including clear communication of the scope
of public disclosure and the de-identification of personal
information are required. This paper examined how to implement personal consent procedures and the appropriate use of
big data. Even in a devastating pandemic like COVID-19,
balancing personal privacy and public safety is still very
important. Future research may explore how to prepare for
other pandemic outbreaks by combining the capabilities of
governmental leadership, technological innovation, big data
use, and societal cooperation. However, such aggressive epidemic control measures involve personal privacy concerns.
Further investigations should consider cultural issues related
to privacy and public safety in different national contexts.
NOTE OF APPRECIATION
Authors of this article wish to express our deepest gratitude to
all the dedicated medical practitioners and numerous patients
worldwide who are at the frontline in the battle against
COVID-19.



NEW_PAPER


Received February 10, 2021, accepted March 7, 2021, date of publication March 10, 2021, date of current version March 23, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3065456
Bias Analysis on Public X-Ray Image Datasets
of Pneumonia and COVID-19 Patients
OMAR DEL TEJO CATALÁ 1
, ISMAEL SALVADOR IGUAL 1
,
FRANCISCO JAVIER PÉREZ-BENITO 1
, DAVID MILLÁN ESCRIVÁ 1
,
VICENT ORTIZ CASTELLÓ 1
, RAFAEL LLOBET 1,2
,
AND JUAN-CARLOS PERÉZ-CORTÉS 1,3
1
Instituto Tecnológico de Informática (ITI), Universitat Politècnica de València, 46022 Valencia, Spain
2Department of Computer Systems and Computation (DSIC), Universitat Politècnica de València, 46022 Valencia, Spain
3Department of Computing Engineering (DISCA), Universitat Politècnica de València, 46022 Valencia, Spain
Corresponding author: Ismael Salvador Igual (issalig@iti.upv.es)
This work was supported by Generalitat Valenciana through the ‘‘Instituto Valenciano de Competitividad Empresarial—IVACE’’ under
Grant IMDEEA/2020/69.
ABSTRACT Chest X-ray images are useful for early COVID-19 diagnosis with the advantage that
X-ray devices are already available in health centers and images are obtained immediately. Some datasets
containing X-ray images with cases (pneumonia or COVID-19) and controls have been made available
to develop machine-learning-based methods to aid in diagnosing the disease. However, these datasets
are mainly composed of different sources coming from pre-COVID-19 datasets and COVID-19 datasets.
Particularly, we have detected a significant bias in some of the released datasets used to train and test
diagnostic systems, which might imply that the results published are optimistic and may overestimate the
actual predictive capacity of the techniques proposed. In this article, we analyze the existing bias in some
commonly used datasets and propose a series of preliminary steps to carry out before the classic machine
learning pipeline in order to detect possible biases, to avoid them if possible and to report results that are
more representative of the actual predictive power of the methods under analysis.
INDEX TERMS
Deep learning, COVID-19, convolutional neural networks, chest X-ray, bias, segmentation, saliency map.
I. INTRODUCTION
Chest X-ray (CXR) radiography is the most widely accepted
imaging modality for detecting pneumonia and it is becoming crucial for tracking the clinical evolution of COVID-19
patients [1]. The COVID-19 disease is caused by Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2)
and has become a global pandemic in a few months. Early
diagnosis is a key factor due to the stealthy contagious nature
of the virus and a lack of vaccines or effective treatments
and, thus, it helps to prevent further spreading and to control
it under the existing healthcare facilities. The small size of
the acquisition devices, their ease of operation and their low
cost make them more widely available than the Computer
Tomography (CT) equipment, despite image quality and the
diagnostic performance of CT are superior.
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
As a response to the COVID-19 outbreak, the scientific
community has rapidly reacted and a lot of works using CXR
images for COVID-19 detection have been published. The
majority of them make use of well-known CNN architectures such as VGG [2], ResNet [3]–[5], SqueezeNet [3], [6],
DenseNet [7] and also combine them with decision trees [8]
and Support Vector Machines (SVM) [9]. Given the difficulty
of obtaining COVID-19 samples, GAN networks have been
used [10], [11] in order to enhance the performance. Moreover, other approaches [12], [13] based on multi-resolution
methods report results that are comparable to those obtained
by CNNs.
Machine learning models need large amounts of data
which, in this case, are difficult to acquire, being the existing
collections a mix of already well-known datasets and new
COVID-19 image datasets. This heterogeneous mixture of
observations provides more variety and usually reduces epistemic uncertainty. However, if these datasets, for instance, are
42370 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 1. Workflow of the different experiments. From left to right: Network activations, Image features evaluation and
background expansion and lung exclusion.
not equally balanced (label-wise), they may induce a certain
amount of dataset bias to the training phase. This happens
when the images can be easily discriminated by features not
relevant to the task, i.e. if the dataset inadvertently contains
some distinctive features which are not related to the disease
and are not shared among the source datasets. For instance,
let’s assume an extreme case. Two image datasets are formed
by two different classes, that is, dataset A made of class A
samples and dataset B of class B samples. Let’s assume in
most dataset A samples there is a white rectangle on the top
right corner, and the true class features are not as trivial.
Classifiers will focus on the easiest feature to discriminate
between classes and not the true class features. Therefore,
this leads to poor generalization; given a new dataset C
full of class A, samples with no white rectangle will be
misclassified.
We have detected significant biases in some of the
most commonly used datasets intended for pneumonia and
COVID-19 detection and we suspect that the accuracy
reported in some studies might be due in part to them, and thus
not directly related to the image features that could characterize the disease. These biases could arise, for example, when
using some specific devices to acquire images of patients with
a low probability of suffering the disease (mainly controls),
and different ones for those patients with a high probability of
suffering it (mainly cases). This could happen, for example,
when most of the patients are screened in certain health services and highly suspicious patients are derived to a different
area or, even worse, when, aiming to increase the number
of controls or cases, a dataset is expanded with samples
coming from significantly different origins and labeled with
unbalanced class identifiers. In these cases, a CNN trained
to discriminate between cases and controls could learn to
differentiate images from different origins rather than finding
features actually related to the disease.
Therefore, to effectively assess the performance of the
classifier, there must exist a previous study of the dataset bias,
so that the results can be validated. Thus, we present several
studies to assess the validity of the results. The following
datasets will be used to perform the experiments: BIMCV
Padchest, CheXpert, RSNA and a COVID-19 image data
collection that we will refer to as COVIDcxr, which will be
further described in Section II-A.
The main contributions of this work are:
• To propose a bias analysis methodology to assert the
validity of the results achieved on a dataset.
• To study the possible existence of bias in three broadly
used pneumonia classification datasets.
• To study the effect of mixing several datasets.
This work is structured as follows: Section I outlines the
problem of bias in CXR datasets. After that, the datasets
and networks used, along with the proposed methodology are
described in Section II. The workflow related to this section
can be seen in Figure 1. Section III shows the results achieved
using this article’s methodology over the proposed datasets
and Section IV gives an analysis of the results. Finally, conclusions are presented in Section VI.
II. METHODS
A. DATASETS
Several public datasets have been used in this article:
• PADCHEST1
[14] is a CXR dataset that includes
more than 160K images from 67625 patients that were
reported by radiologists at Hospital de San Juan (Spain)
1http://bimcv.cipf.es/bimcv-projects/padchest/
VOLUME 9, 2021 42371O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
from 2009 to 2017. The reports are labeled with
174 different radiographic findings, 19 differential diagnoses and 104 anatomic locations. 27% of the reports
were manually annotated by trained physicians and the
remaining set was labeled using a supervised method
based on a Recurrent Neural Network with attention
mechanisms. Generated labels were validated, achieving
a 0.93 Micro-F1 score using an independent test set.
For the experiments, only Posterior-Anterior images are
considered. Therefore, there are 9110 images in the
remaining dataset: 6790 control and 2320 pneumonia
images.
• RSNA pneumonia dataset2
is made up of images from
the National Institutes of Health (NIH) and labeled by
the Radiological Society of North America along with
the Society for Thoracic Radiology and MD.ai. The goal
of this dataset was to develop an AI classifier capable of
distinguishing between pneumonia and control images,
so it was released in a Kaggle competition in 2018.
It consists of 26684 images from which 20672 are control and 6012 are pneumonia images.
• CheXpert dataset3
[15] is provided by Stanford
University and contains 224316 chest radiographs
of 65240 patients with labels of 14 sub-categories. The
exams were performed at Stanford Hospital between
October 2002 and July 2017. Structured labels for the
images were created by an automated rule-based labeler,
which the researchers developed to extract observations
from free-text radiology reports. From the 224316 chest
radiographs, this article only takes the ones related to
pneumonia and control cases. Therefore, 5870 images
are remaining in the dataset: 4878 control and 992 pneumonia images.
• COVID-19 image data collection (COVIDcxr)4
[16] is
a project to collect X-ray and CT images that present
COVID-19, SARS, MERS and ARDS from online
sources. These sources are varied: scientific publications, websites, etc. As of June 2020, COVIDcxr has
around 424 COVID-19 images and is one of the largest
COVID-19 datasets publicly available to the best of our
knowledge.
B. MOTIVATION
The motivation for this study comes from analyzing the
results of a neural network trained to classify between
radiographic images of patients with pneumonia and healthy
control patients in order to determine the validity of the
classification. An interesting first validation can be done by
visualizing the network’s activation heatmaps. When we performed these checks against networks trained with pneumonia datasets, we observed many suspicious patterns, as these
heatmaps often highlighted areas of the image which did not
2https://www.kaggle.com/c/rsna-pneumonia-detection-challenge
3https://www.healthimaging.com/topics/artificial-intelligence/stanfordresearchers-release-chest-x-ray-dataset-train-ai
4https://github.com/ieee8023/covid-chestxray-dataset
contain lung tissue (see Figure 2). This made us suspect that
the networks were learning to classify, achieving large values
of AUC ROC, using features unrelated to the task. Thus,
the datasets might be biased.
FIGURE 2. Lung heatmaps for BIMCV’s dataset.
Grad-CAM [17] allows us to visualize the gradient of the
label in the final convolutional layer to produce a heatmap
depicting regions of the image that are relevant for the prediction. Blue pixels and red pixels correspond to low and
high values of the gradient at the final convolutional layer,
respectively.
As observed in Figure 2, there are highly activated regions
in areas without lung presence when the expected activation
should be inside the lung. It is not known how many pixels
inside the lungs should show an activation, as no detection
mask is available. However, we can assume that the activation
map in a control patient should not exceed a given threshold,
whilst a positive case’s map should show widespread activations within the lungs. Nonetheless, the activated area outside
the lungs should be minimal in all cases. For this reason,
a measure to inform about the distribution of the activated
pixels could be useful.
Given a heatmap image I = {pij} ∈ Matn,m(R), where
n is the number of rows, m the number of columns, and
pij represents the pixel value at row i and column j. Let A
be a region of interest and B its complement. Let t be the
activation map threshold, and let R and W be the number of
pixels with an activation value higher than t that are in A and
B respectively.
We can calculate the percentage of pixels with an activation
value over a threshold that fall outside an expected region as
the quotient between W and W + R (see Figure 3 and the
equations below, where p ∈ {pij} = I).
Considering activated pixels in region W as false positives (FP) and activated pixels in region R as true positives
(TP), the above quotient corresponds to the False Discovery
42372 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 3. Activation regions diagram.
Rate (FDR), which is the complement of the Positive Predictive Value (PPV).
R = TP = |(p > t) ∩ A|
W = FP = |(p > t) ∩ B|
FDR =
FP
FP + TP
FDR = 1 − PPV
For instance, in this task, any activated pixel that falls
outside the lungs is marked as wrong (W), as no information
should be found there. The lower this value, the better. This
score is designed to measure the validity of the trained CNN
classifier based on its activation maps and allows the selection
of different operation points depending on the threshold t to
be applied to the heatmaps. In this work, t is set to 90% of the
maximum heatmap value.
Table 1 shows the computed FDR for the activation maps
under three different datasets. It is worth noting that some
image findings are usually located on the border of the lungs,
so if the highlighted area is near the border, some pixels
might easily fall outside the region (A) and be considered as
wrong (W). On the grounds of the information provided by
the FDR, further experiments would be required to measure
the extent to which this phenomenon affects the datasets.
TABLE 1. False discovery rate of activation maps for three different
datasets.
Additionally, some suspicious patterns appeared when
visualizing the grayscale histograms of the images.
Ideally, gray levels of images from different sources should
be equally distributed, but in practice, this may not happen
and give rise to inaccurate conclusions. The histograms
of the images may be considered as Probability Density
Functions (PDFs) and may serve to measure the variability
among gray-level distributions using a methodology based
on information geometry [18]. This methodology has been
successfully applied to characterize EHR (Electronic Health
Record) data [19], [20], to assess the variability among
patients with different headache pain intensity [21], or to
detect pixel distribution differences among images acquired
from different mammographs [22].
Given a set of PDFs, this approach is based on the computation of the distance between each pair of PDFs using
the Jensen-Shannon distance. The simplex where each point
represents a PDF and the distance between two points is
the Jensen-Shannon distance between the two PDFs they
represent is known as a statistical manifold, which in turn
is a Riemannian manifold. For visualization purposes, this
simplex may be embedded in a real Euclidean space by using
Multidimensional Scaling [23] and, finally, projected into two
dimensions using a dimension reduction algorithm such as
Principal Component Analysis.
This methodology was applied three times to a random
balanced sample of 2000 individuals (1000 pneumonia cases
and 1000 controls) of each dataset mentioned, which will
be described in section II-A. Firstly, it was applied to the
histograms of the complete images and, after a segmentation step, which will be described in detail in section II-D,
the variability analysis was applied only to the histograms
of the backgrounds, and then to the histograms of the lungs
(see Figure 4). The variability of the three datasets is shown
in Figure 5.
In the center row of Figure 5, which depicts the distributions of the backgrounds of the different datasets, we can see
that the first two columns show distinct clusters composed
predominantly of cases or controls that allow a certain degree
of discrimination without taking into account the lung tissue.
In fact, the last row, which represents lung area, shows fewer
differences between the cases and control patient histograms.
In the last column, corresponding to CheXpert’s dataset, these
differences are not evident.
This could imply that, for some datasets, as BIMCV and
RSNA, a Machine Learning algorithm can classify pneumonia and control cases using features outside the lungs.
C. NETWORK
In this article, Convolutional Neural Networks (CNNs) are
used to classify the CXR images. These Machine Learning models have been widely employed in the last years
for image classification, particularly in the field of medical
imaging. The CNN topology used is VGG16 [24], which
is broadly reported as a good classifier for chest image
analysis [25]–[27]. In this scenario, a common practice with
this type of networks is to trim the last layers (usually
dense layers) and add a lighter classifier, which in this
VOLUME 9, 2021 42373O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 4. Example of case and control patient histograms. The first row shows the histogram of the whole image for an example of a case and a
control patient, the second row shows the histogram of the background (the image with the lung area subtracted) and, the last one shows the
histogram of the lungs.
case is a Global Average Pooling followed by a Multilayer
Perceptron, which projects the pooled features of VGG’s
last convolution to 64 dimensions before performing the
classification.
Transfer learning technique is a common practice within
Deep Learning models. It is proven that pretrained networks, in particular their first layers, are generic and
can be transferred to new domains without requiring
special training. In fact, it also facilitates training for
domains with a scarce amount of training samples. Therefore, the VGG16 network used is pretrained with Imagenet dataset, and the last 2 convolutional layers, along
with the classification layers, are unfrozen for domain
training.
It is noteworthy that the network structure is, up to a
point, not critical for the conclusions drawn in this article,
as it is not trying to present advancement in the state-of-theart classification for the datasets used. The focus is rather
on comparing the results obtained for images coming from
different datasets, and whether those results suggest the presence of classification biases within the data. Nonetheless,
it must at least achieve an acceptable accuracy in order to
ensure the extracted features are good enough and close to
the ones extracted in other articles.
D. SEGMENTATION
By segmenting the lungs, it is possible to remove parts of
the image that do not contain relevant information and that
can be a source of noise or bias, such as the presence of text
annotations that can identify a machine or a hospital, or the
appearance of images coming from specific medical devices
that have been used in more cases than control patients or vice
versa.
Lung segmentation in CXR images has been successfully
tackled with different approaches during the last years [28].
For this work, a U-Net network has been trained on the
Montgomery dataset [29]. Moreover, we have manually
labeled a total of 1115 images coming from BIMCV’s
42374 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 5. Image histogram variability. The first row represents the variability of the histograms of the complete images, the second row the variability of
the background histograms (the images with the lung area subtracted), and the third row the histograms of the lungs. The first column represents a
sample of BIMCV’s dataset, the second column a sample of RSNA’s, and the last, a sample of CheXpert’s.
Padchest dataset to increase the number of training images.
Figure 6 shows the segmentation results. This network
achieves 0.974 DICE and 0.934 IoU scores over the Montgomery test partition, where DICE and IoU are defined as
follows, being A and B the predicted segmentation mask and
the true segmentation mask.
DICE =
2 | A ∩ B |
| A | + | B |
IoU =
A ∩ B
A ∪ B
VOLUME 9, 2021 42375O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
E. BIAS ANALYSIS
This work proposes a methodology to measure the degree of
bias in a dataset. The focus is on the classification of pneumonia or COVID against control samples, but the methods
can be generalized to other classification tasks where prior
knowledge of the region of interest is available.
As stated before, areas that should not contain information about the problem can be possibly used to discriminate
between classes, for example, text annotations or image features related to the medical devices employed. In order to
solve this problem, we make use of a segmentation algorithm
to extract the relevant regions which in this case are the lungs
(see Figure 6). These regions will be referred to as masks.
The rest of the image will be considered as background
(see B in Figure 3).
FIGURE 6. Lung segmentation (left) and after post-process (right).
To check the previous hypothesis presented in II-B,
two experiments were carried out by training a model
with different image areas according to the following
ideas:
• We want to study how the background affects the results.
Starting from an image that contains only the lungs
(the background is erased), the visible region is progressively expanded to include more background by
means of sequential dilation operations over the mask
(see Figure 7a). An unbiased dataset should not increase
the classification accuracy along this process.
• We want to analyze how the lack of lung area affects
the results; this time starting from the whole image and
progressively removing the lungs (see Figure 7b). The
classification accuracy over an unbiased dataset should
progressively drop from its maximum value (whole
image) to 0.5 AUC ROC.
Thus, adjusting the expansion or exclusion of the lung region
will allow us to trace the variation of the accuracy metric.
We used images scaled to 256 × 256 pixels. For background
expansion, lung segmentation masks were dilated 0, 10, 30,
50, 80, 120 and 140 pixels and for lung exclusion, masks were
eroded 0, 10, 20, 30, 40 and 100 pixels (from right to left
in Figure 7).
Figure 7a shows the lung segmented area in blue and
the background expansion in green. Also, Figure 7b shows
the lung exclusion area in yellow. Additionally, a detailed
workflow for this experiment is shown in Figure 8
F. COMBINATION ANALYSIS
Combining datasets can be useful to enlarge the sample size,
increase the variability explained by the data, and reduce the
epistemic uncertainty of the classifiers. This latter is related
to the problem-domain knowledge of the model, being it the
uncertainty or lack of knowledge bound to the limited amount
of data. However, if the combination and the balance among
the classes are not carefully controlled, a classifier may learn
to discriminate between features of the different datasets.
To check this hypothesis, we mixed RSNA and CheXpert
datasets to achieve a balanced combination by adding positive
pneumonia observations from the RSNA dataset into CheXpert. The latter is a highly unbalanced dataset (83% of negative and 27% of positive observations after our pre-process
and segmentation validity filters), so it could be considered
a good idea to add positive samples from another dataset.
Needless to say, if the images from RSNA have distinct
features that allow the classifier to tell them apart from
CheXpert, for example including a large proportion of images
from a particular equipment brand or model, the system will
learn to classify the images from that equipment as positive,
regardless of any image content that could be related to the
disease.
Additionally, we simulated the combination of
COVID-19 and control datasets and evaluated their bias
with the proposed method. In particular, the datasets combined are positive COVID-19 cases from COVIDcxr with
CheXpert’s negative control samples. COVIDcxr is built with
datasets from different origins, hence this experiment illustrates the likely problematic effects of heterogeneous data
combinations.
Based on our methodology that probes the discrimination
induced outside the lungs, the expectations about the results
of the experiment, if there is bias in the dataset, are: (1) the
background expansion could increase the accuracy and
(2) the accuracy when occluding the lungs should differ
significantly from the 0.5 AUC ROC. Did the results follow
these predictions, the hypothesis would be confirmed.
III. RESULTS
A. BACKGROUND EXPANSION AND LUNG EXCLUSION
STUDY
In the previous section, we proposed to examine the performance of classification experiments varying the addition of
background and the reduction of the lung area. The expected
results of the first test for a non-biased dataset, where the
background area is added to the initial lung-only images,
is that the classification rate stays constant (or almost constant, due to possible imprecise segmentation and other random perturbations), as the disease information is already
present from the beginning.
In the second scenario, the accuracy should potentially
drop from the value achieved when the network sees the
complete image to a value close to 0.5 AUC ROC when the
lungs are completely removed. This drop is not necessarily
42376 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 7. Background expansion and lung exclusion. (a) The original contour area is shown in blue and the expanded area contour in green (b) The
contour of the removed area is shown in yellow.
FIGURE 8. Bias analysis’s workflow.
linear, but will be shown in the graphs as a straight red line,
as can be seen in the right part of Figure 9, to offer a simplified
graphical representation of the expected behavior. In the left
part of the figure, the green line represents the classification
rate obtained using only the lung area.
This analysis has been performed in the three datasets:
• The first one (see Figure 9a), BIMCV, clearly shows
a significant bias within the data, as the classification
rate steadily increases with the background expansion.
The second graph shows that removing the lung area is
not associated with a significant decrease in accuracy,
as it should, and even with the complete exclusion of the
lungs the classifier achieves almost 0.88 AUC ROC.
• The second one (see Figure 9b), RSNA, displays a
slightly lower but still consistent bias within the data
in both graphs. However, the RSNA dataset was harder
to segment than the other ones and, thus, part of the
variability shown could arise from poorly segmented
images. Nonetheless, a 0.79 AUC ROC is achieved with
the lungs completely occluded, which is far from the
expected 0.5 AUC ROC.
• The third one (see Figure 9c), CheXpert, conveys interesting results. The left graph’s trend is the one expected
for an unbiased dataset, as it doesn’t vary along with
the background expansion. Nevertheless, the precision
achieved when the lung is completely occluded is
around 0.74 AUC ROC. This implies that the bias is not
located specifically in the background, but it must lie in
the whole image.
B. COMBINATION STUDY
As mentioned before, the combination study seeks to evaluate
how the combination of datasets might provoke the creation
of biased data and how the methodology proposed can detect
these weaknesses in the final data collection.
The experiments of Section III-A have been reproduced
using the combined dataset. Figure 10(a) shows the effect
of varying background expansion and lung exclusion when
the combination is designed to balance CheXpert with RSNA
cases (4878 control and 992 positive pneumonia images from
CheXpert plus 3886 positive images from RSNA, giving a
balanced dataset with 50% observations from each class).
The last experiment explored a combination of 4878 images
of control patients from CheXpert and the whole set
of 424 COVID-19 images from COVIDcxr. This dataset
combination is typical of the recent crisis scenario, where few
images from the new disease are available, they are obtained
from different locations, under uncontrolled conditions, with
different equipment and acquisition protocols, etc. This is the
worst-case scenario and the results are in accordance with it,
as can be seen in Figure 10(b).
The results for these experiments show, in a similar fashion
to Chexpert’s base case, that the bias is ubiquitous in the
VOLUME 9, 2021 42377O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 9. Accuracy as a function of the background expansion and lung reduction. The green dotted lines
mark the correct behavior of a non-biased dataset when more and more background is included, and the
red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from the
analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line indicating the
standard deviation.
image. Despite increasing the amount of background inside
the images doesn’t affect the accuracy, the effect of the lung
occlusion is not remarkable within the results.
IV. DISCUSSION
Deep learning has been receiving a lot of attention
as a very powerful methodology for analyzing medical
images [30]. The ability of Convolutional Neural Networks (CNN) to obtain excellent results even when it is used
as a blackbox, as opposed to the classical design of ad-hoc
algorithms, has attracted many researchers.
Some works using CNNs for COVID-19 detection on
cxr images report high accuracies for a variety of network
architectures. In particular, studies using VGG16 report [9]
89.8% accuracy for a dataset built of 180 COVID-19 and
200 control samples, 90% accuracy is obtained [27] for a
dataset composed of 202 COVID-19 images, 300 of pneumonia and 300 negative and 93.48% accuracy [31] is achieved
using a dataset that contains 224 COVID-19 images, 700 of
pneumonia and 504 negative. The fact that VGG16 achieves
good results for detecting pulmonary diseases strengthens
the hypothesis that the features extracted by the network
are relevant to the task and therefore, as detected from our
experiments, related to some sort of bias within the images.
One of the drawbacks of CNNs is that they often need
large amounts of data to learn and, while generic CXR
databases are available, public existing COVID-19 datasets
are composed of a few images that were collected by
volunteers [16]. As a consequence, these datasets show
unbalanced labels and a mix of different data sources that
42378 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 10. Addition of positive samples from RSNA and COVIDcxr to CheXpert’s dataset. The green dotted
lines mark the correct behavior of a non-biased dataset when more and more background is included, and
the red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from
the analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line
indicating the standard deviation.
makes getting a robust model and reliable performance
measures difficult. In this regard, some articles report the
problem of small and unbalanced datasets for COVID-19
detection [4], [32], and propose solutions to mitigate the
problem.
Bias analysis has been tackled by other authors. For
instance, in [33] the authors proposed that train and test
partitions should come from different datasets (related to the
same task), as the classifier is trying to achieve maximum
performance over a certain task and not over a dataset. This
may also assert the true generalization capacity of the classifier. On the other hand, [34] sought to minimize the effects
of different biased datasets by way of converting different
dataset observations to prototypes, greatly reducing possible
intra-dataset specific features.
Recently, [35] addresses this issue for COVID-19 detection
and reports that the problem of mixing different datasets may
lead the network to learn background information. Our study
performs a similar approach to the one presented in thisarticle, i.e. both study possible biases within the lungs. [35]
occludes the lungs with rectangular fixed-size black boxes
and measures the accuracy achieved. However, the proposed
methodology extends the concept proposed to more precise
masks and progressive inclusion and exclusion of information
to the learning process. This allows the ability to detect
where the bias approximately is and enables more precise bias
estimation.
Furthermore, [36] studies bias within the nCov2019 dataset
using information about patients (symptoms, comorbidities,
age, and sex). This dataset collects clinical data from different sources rather than images. They found significant bias
related to the origin of the data and exposed several issues
related to multisource variability.
This article is focused on detecting some biases within
widely used CXR datasets to glimpse the degree to which
these biases affect the results and proposes a bias detection
methodology to assert the validity of results. This methodology makes use of techniques such as heatmap visualization,
histogram analysis and selective image occlusion which are
combined to evaluate which parts of the images are being
used as discriminative features for a classification task. In this
work, this methodology has been applied in two case scenarios, one for the existence of bias on individual pneumonia
datasets and another to detect the existence of bias in a mix
of datasets.
V. LIMITATIONS OF THE STUDY
Regarding possible limitations, there could be a problem with
the methodology proposed, since the segmentation masks
used for expansion and reduction may be biased themselves.
The segmentation process might be more prone to fail in
images with pneumonia since the borders of the lungs are
more diffuse, whereas this could not happen in images of
control patients. This could pose a significant difference
VOLUME 9, 2021 42379O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 11. Lung occlusion with fixed-size rectangular boxes.
between cases and controls masks, and therefore, we might
be introducing a new bias that would imply a problem with
the proposed methodology.
However, to rule this out, we designed an experiment where
the occlusion masks were substituted by rectangles the size
of the lungs. This experiment is similar to the one presented
in [35], but here we ensure that the lungs are completely
removed using the segmentation mask shape whereas in the
aforementioned work they just place a fixed size black rectangle in the central area leaving some lung area uncovered.
Some examples from our method can be seen in Figure 11.
The results achieved for BIMCV’s dataset can be seen
in Figure 12, where the differences found are not significant,
suggesting that the shape of the lung masks is not influencing
the bias detection algorithm proposed.
Furthermore, to increase the confidence in our conclusions,
we pre-processed all the images by means of CLAHE histogram normalization to assert how this pre-process affected
the results. As can be seen in Figure 13, there is no difference
in the results achieved between the normalized and plain
images.
Talking about strengths, the results of the experiments
described in Section III-B demonstrated that the classification
rate does not improve when the background area is included
in the images, which means that either there is no bias
specifically on the background or the most significant bias
is already within the lungs. However, when the lung area
is progressively removed from the image we find in both
experiments that the accuracy does not decrease, suggesting
FIGURE 12. Comparison between fine-grain and squared masks for BIMCV’s dataset.
42380 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 13. Comparison between normalized and plain BIMCV’s dataset.
that the system is classifying the images according to some
elements present in the whole image, not only inside the
lungs. That result confirms the hypothesis that powerful systems like Convolutional Networks can find subtle features
in the images and give optimistic classification results if no
measures are taken to avoid biases in the data.
To summarize, further research should be conducted to
reduce the impact of the intrinsic bias for the datasets whose
images are collected from several sources. Recent literature
has demonstrated the emergence of methodologies useful
to reduce the impact of such a bias. Image preprocessing methods [22] or deep learning architectures designed
to deal with biased datasets [37] may be a good starting
point.
VI. CONCLUSION
In this work, a novel methodology to assess the existence of
bias in CXR image datasets is presented. Techniques such
as activation heatmap visualization, histogram analysis and
selective image occlusion are combined to evaluate which
part of the images are being used as discriminative features
for a classification task. In this case, the regions of interest
were the lungs. The datasets used show different levels of
bias, these comprising datasets that try to make information quickly available in an urgent scenario like the current
COVID-19 crisis. Some examples are BIMCV’s collection or
the combination of datasets created for this purpose, which
are the ones with more problems. The results are confirmed
with the other methodologies used, such as the FDR of the
activation map or the histogram analysis.
The study of the effects of combining datasets from different sources is especially interesting because it shows that, if it
is not strictly controlled, important biases can be induced in
the final dataset. A typical solution for the lack of samples
of a given class is to compile different datasets into one that
collects all the categories to study, as the recent COVID-19
datasets. In particular, the widely used COVIDcxr dataset,
built from different sources, might in fact have included
significant biases that inadvertently affected the results published. This kind of heterogeneous dataset often mix observations coming from very diverse equipment, acquisition protocols and processing software. In that context, features found
by Deep Convolutional Networks in the images, including the
background areas, are enough to get a good classification rate,
whilst the actual performance of the classifier for the clinical
task attempted can be much lower.
ACKNOWLEDGMENTS
The authors would like to thanks of gratitude to BIMCV
and the other teams that compiled and made available the
datasets used in this work. The experiments were conducted employing Instituto Tecnológico de Informática (ITI)
High-Performance Computing platform, which is funded
by IVACE and AVI, and implemented within ITI Data
Space, being these experiments a TECH4CV’s project use
case.
VOLUME 9, 2021 42381O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets



NEW_PAPER



BIG DATA MINING AND ANALYTICS
ISSN 2096-0654 01107 pp65-75
Volume 4, Number 2, June 2021
DOl: 10.26599/BDMA.2020.9020013
Analysis and Predictions of Spread, Recovery, and Death Caused by
COVID-19 in India
Rajani Kumari, Sandeep Kumar*, Ramesh Chandra Paonia, Vijander Singh, Linesh Raja,
Vaibhav Bhatnagar, and Pankaj Agarwal
Abstract: The novel coronavirus outbreak was first reported in late December 2019 and more than 7 million people
were infected with this disease and over 0.40 million worldwide lost their lives. The first case was diagnosed on
30 January 2020 in India and the figure crossed 0.24 million as of 6 June 2020. This paper presents a detailed
study of recently developed forecasting models and predicts the number of confirmed, recovered, and death cases
in India caused by COVID-19. The correlation coefficients and multiple linear regression applied for prediction and
autocorrelation and autoregression have been used to improve the accuracy. The predicted number of cases shows
a good agreement with 0.9992 R-squared score to the actual values. The finding suggests that lockdown and social
distancing are two important factors that can help to suppress the increasing spread rate of COVID-19.
Key words: COVID-19; regression; correlation; machine learning; prediction
1 Introduction
The coronavirus disease spreads through getting in touch
with an infected person, touching a thing or object that
has the virus on its surface and then touching their
mouth, eyes, ears, or nose. The first case of COVID19 was detected in the last week of January 2020 in India
and only 3 cases were diagnosed in next month. As of
6 June 2020, the total number of confirmed cases in
India was 247857 with 119293 recovered cases and
6954 deaths. There is a need for the current situation
• Rajani Kumari is with Department of Information Technology
and Computer Application, JECRC University, Jaipur,
Rajasthan 303905, India. E-mail: rajanikpoonia@gmail.com.
• Sandeep Kumar is with CHRIST (Deemed to be University),
Bangalore, Karnataka 560029, India. E-mail: sandpoonia@
gmail.com.
• Ramesh Chandra Poonia and Pankaj Agarwal are with Amity
University Rajasthan, Jaipur, Rajasthan 303002, India. E-mail:
rameshcpoonia@gmail.com; mr.pankajagarwal@gmail.com.
• Vijander Singh, Linesh Raja, and Vaibhav Bhatnagar
are with Manipal University Jaipur, Rajasthan 303007,
India. E-mail: vijan2005@gmail.com;lineshraja@gmail.com;
vaibhav.bhatnagarI5@gmail.com.
*To whom correspondence should be addressed.
Manuscript received: 2020-05-07; revised: 2020-06-14;
accepted: 2020-07-28
to predict possible infected and death cases by using a
computational model to arrange the necessary resources.
The virus ofCOVID-19 shows great resemblance with
the Severe Acute Respiratory Syndrome (SARS) and
Middle East Respiratory Syndrome (MERS) coronavirus
as investigated by pathologists[l]. It is the seventh
member of the coronavirus family that can spread
among humans and easily transmit human-to-human
through droplets of coughs or sneezing by an infected
person[l]. Major symptoms of COVID-19 are fever,
cough, shortness of breath, and some patients show
symptoms of diarrhea. The major problem in the case of
this disease is that its symptoms generally appear after 2
to 14 days if an individual gets infected. This period is
known as the incubation period and the mean incubation
period is approximately 5 days[2]. An infected person
may infect the number of healthy persons during the
incubation period. These patients are asymptomatic and
major challenge is to identify them. The rate at which
one infected person transmits this disease into others
is termed as transmission rate (Ro)[l]. Recent studies
by leading research organizations estimated that Ro is
between 1.5 and 3.5[3-5]. This rate of transmission is very
high in comparison to SARS (2.0) and common flu (1.3),
and thus it is very dangerous. In the early stage, the Case
© The author(s) 2021. The articles published in this open access journal are distributed under the terms of the
Creative Commons Attribution 4.0 International License (http://creativecommons.orgllicenseslby/4.0f).66
Fatality Rate (CFR) for coronavirus was estimated at
2%[1]. While the fatality rate for SARS and MERS was
approximately 10% and 30%, respectivelyW Highest
CFR was reported in France (19%), followed by Belgium
(16.23%), Italy (14.4%), and UK (14.2%)[6]. Almost 5%
of the total infected persons lost their lives around the
world, while in India CFR was near to 2.8%. The actual
CFR can only be computed based on the identification
of the correct number of infected individuals. The major
contributions of this research are as follows:
• This paper performs a descriptive analysis of the
COVID-19 outbreak in different states of India.
• We propose a model for predicting the number of
confirmed, recovered, and death cases due to COVID-19.
• The proposed model deploys multiple linear
regression to analyze the existing data.
• This paper also employs the autoregression to
predict the cases.
The organization of this paper is as follows: Section 2
discusses some recent studies carried out by researchers,
medical practitioners, and scientists in the field of
infectious disease. In Section 3 the detailed analysis
is carried out from the considered dataset of COVID-19
for India. Section 4 introduces the proposed prediction
model to estimate the count of infection, recovery, and
death due to COVID-19. Section 5 concludes this study.
2 Recent Study on COVID-19
Many researchers involved in the study of novel
coronavirus after the outbreak at Wuhan, China in late
December 2019 and developed various types of models
for prediction of its spread, transmission, and death
caused by it. Some studies and researches are related to
the development of medicine and diagnostic tool for this
pandemic. Few of these recent studies discussed here.
Zhong et al.[7] developed a mathematical model for
the timely prediction of the coronavirus outbreak in
China. Harnzah et al.[8] developed an online platform
to provide real-time information related to COVID-19
and a statistical analysis of data. Susceptible-ExposedInfectious-Recovered (SEIR) predictive modeling was
used for forecasting on daily basis. They developed
their micro-services to fetch data from different
sources. Morawska and Cao[9] discussed how COVID-19
spreads especially through the air.
Li et al.[10] investigated the genetic evolution of the
virus that is responsible for COVID-19. This study
identified that novel coronavirus has a genetic similarity
with coronavirus derived from rhinolophus sinicus,
Big Data Mining and Analytics, June 2021, 4(2): 65-75
paradoxurus hermaphroditus, paguma larvata, aselliscus
stoliczkanus, and civet, while homology analysis shows
that it has close resemblance with bat coronavirus.
Ma et al.[ll] analyzed the effect of humidity and
changes in temperature on COVID-19 patients, but
the study was limited to Wuhan city only. This study
established a correlation with variation in temperature
and humidity on daily death due to the virus. Singh
et al.[12] studied and compared SARS, MERS, and
COVID-19 viruses based on transmission cycle, etiology,
genetics, hosts, diagnosis, reproductive rates, laboratory
diagnosis, clinical features, and radiological features. Pal
et al.[13] illustrated the classification of ribonucleic acid
group of viruses and origin of severe acute respiratory
syndrome coronavirus along with virion structure and
genetic characteristics of COVID-19. Dutheil et al.[14]
investigated the role of COVID-19 for decreasing air
pollution as most of the industries are shut down and
traffic is also significantly low.
Vellingiri et al.[15] discussed the cause of infection,
symptoms, and the structure of the virus in detail
and compared it with common flu, SARS, and MERS
at various parameters. They also discussed ongoing
treatment to the infected people and suggested some
Indian plants for medical use. Henry and Lippi[16]
suggested that Extracorporeal Membrane Oxygenation
(ECMO) is one of the options for survival therapy to
COVID-19 patients. Some limitations of ECMO were
also discussed here. Lai et al.[17] also discussed major
symptoms and ongoing methods of cure for COVID-19.
They raised some unresolved issues, like the presence
of SARS-CoV-2 in patient stool and the efficiency of
disinfection agents used for sanitization.
Ghosal et al.[18] developed a model to predict week
wise death in India due to COVID-19. They used
linear regression and multiple regression for prediction
and deployed autoregression to enhance the prediction
capability of the proposed model. The projected model
is based on data analysis of 15 highly infected countries.
Liang[19] compared the spread characteristics of novel
coronavirus with characteristics of SARS and MERS.
A new mathematical model was proposed to identify
the symptoms of coronavirus diseases. Nicola et al.[20]
suggested that veterinary medicine may be helpful in the
cure of COVID-19.
Lee et al.[21] discussed the importance of Computed
Tomography (CT) images in the diagnosis of COVID-19
infected individuals. As technology growing, there are
many applications and tools being produced that utilizeRajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 67
various algorithms. In many fields, computer-assisted
tools are being designed and employed successfully. The
efficient use of such computer-aided systems in medicine
is no exception. Medical images are very useful for
the doctor, and their detailing can have a decisive
influence on the correctness of the diagnosis. One
of the branches of the healthcare system that tightly
works with images is the radiology. There have
been generated several datasets containing CT scans,
Magnetic Resonance Imaging (MRI), etc., to detect
novel coronavirus pneumonia diseases. Pan et al.[22]
illustrated changes in the lung of COVID-19 patients
during the recovery process with the help of CT images.
Singh et al.[23] classified COVID-19 patients based on
their chest CT images. For this classification they
implemented a convolutional neural network based
on differential evolution algorithm. Jaiswal et al.[24]
deployed DenseNet20l for classification. The proposed
approaches achieved a higher rate of accuracy and
precision.
Singh et al.[25] analyzed time series data and predicted
the registered, deceased, and death numbers per reported
case (mortality rate) based on COVID-19's world health
data for the world population. This study concluded that
COVID-19's regular mortality is positively correlated
with the number of confirmed cases. It may also be
dependent upon the population's dietary routine and
robustness of the immune system. This study suggested
that an emergency can awaken before the proper vaccine
is invented. Some critical issues were measured by
several researchers, considering individual countries,
provinces, and derived some conclusions. Bhatnagar
et al.[26] presented a detailed analysis of the COVID-19
pandemic with the help of a boxplot and Q plot.
Ivanov et al.[27] analyzed and predicted the effect of
the ongoing pandemic on global supply chains. They
also performed a simulation-based analysis in the case
of supply chains and the impact of COVID-19 on
supply chains along with associated risks. Hou et
al.[28] performed SEIR model analysis to examine the
effectiveness of quarantine especially for Wuhan city
and developed a new variant of the SEIR model. They
concluded that quarantine and isolation are two powerful
and unique tools to reduce the risk of infection. Roosa et
al.[29] developed a system for forecasting the COVID-19
in real-time in China for a specific time period. Tuli
et al.[30] employed the latest technologies, like machine
learning and cloud computing, for predicting the growth
rate of COVID-19 pandemic with the help of the Weibull
model.
Xu et al.[31] explained the pathological characteristics
of COVID-19 and compared them with SARS and
MERS. These pathological features are highly similar
to SARS and MERS. This study provided some
recommendations to physicians so that they can timely
plan a therapeutic strategy for the patient. Kucharski
et al.[32] developed a mathematical model and analyzed
four datasets. This study revealed that the transmission
rate is between 1.6 to 2.6. Here they classified patients
into four different classes: susceptible, exposed (but not
yet infectious), infectious, and removed (i.e., isolated,
recovered, or otherwise no longer infectious). Yuvaraj
et al.[33] used a deep neural network for the analysis of
interactions of protein-ligand for SARS-CoV-2 against
selective drugs. Some studies focused on psychological
health of farmers engaged in the business of poultry[34].
Researchers are also working on test procedures and
trying to reduce testing time. In this sequence, Assad et
alPS] suggested that sample pooling is the best option to
reduce the testing time that leads to reduce fatality but
with a limitation of 10% positive cases. If positive cases
are very low, binary elimination algorithms are the better
option.
These studies revealed that symptoms of COVID19 are similar to SARS and MERS. COVID-19 is
more infectious but has a low fatality rate. The virus'
root cause is still unclear, and virologists are actively
working to establish its antidote. However, physicians
are continuously trying to cure patients by using antiviral
therapy, antibiotic treatment, systematic corticosteroids,
etc. Table I summarises a few of the recently developed
prediction and forecasting models. Most of the models
are based on the SEIR model and its extended
version, like symptomatic infectious, asymptomatic
infectious, quarantined, hospitalized, recovered, dead
model (SEIDIuQHRD)[36-38]. Machine learning and
deep learning models are also used for prediction and
forecasting[39-41] .
3 Analysis of COVID-19 Data
Analysis of the COVID-19 dataset for coronavirus
disease is performed on the basis of reported cases
(confirmed, recovered, and death) in India. We have
collected data from 29 February 2020 to 6 June 2020
(hereafter it is termed as WeekI to WeeklS) of some
states in India that are worst hit by this virus. The
dataset is taken from www.kaggle.com[54] and shown in
Table 2. Attributes which are considered in this dataset68 Big Data Mining and Analytics, June 2021, 4(2): 65-75
Table 1 Comparative study of recent prediction and forecasting models for COVID-19.
Author(s) Activity performed Methodology used Strength Drawback
Ghosal et al.[18]
Singh et aU23]
Prediction Linear regression analysis Statistical analysis results prove its Results are over-estimated and
reliability. significance of predictor is very low.
Prediction Gaussian mixture model Predicted values with 95% Predicted end dates are not true.
confidence intervals
Chakraborty Forecasts and risk
and Ghosh[49] assessment
Tiwari et aU50] Prediction
Maheshwari Forecasting
et al.[51]
Bhattacharjee Prediction
et aU52]
Sree[53] Prediction
Results are not consistent throughout the
study area.
Tested for 15 days only
Accuracy and reliability of this model
depend on the assumption of parameter
values and initial population size.
Accuracy and reliability of this model
depend on the assumption of parameter
values.
Data considered from 2 March 2020 to
2 April 2020 only.
Achieved accuracy (78.8%) is
significantly low.
Predicted number of infected persons
only
Results may be improved by deep
learning.
Considered only weather conditions that
less significant
Data were taken till 27 March 2020 only.
Proposed model used data till 3 April
2020 only
Achieved accuracy (93.695%, 86.96%,
87.94%, and 90.91 % for confirmed,
recovered, death, and death rate,
respectively) is significantly low.
Study is restricted till 24 April 2020.
Used different models for different states
Only 10 days data used for testing
purpose
Considered small size data (till 24 March
2020)
The error rate is very high.
Model is highly reliable
R statistical package used for
forecasting for the next 76 days
Predicted results with higher accuracy
Predicted peak time and end time
of the pandemic, this model also
analyzed the effect of lockdown.
Considered the impact of temperature
and humidity
Maximum-likelihood and bootstrap
strategy are used to analyze the Ro
and re-sampling, respectively.
Deep LSTM, convolutional LSTM,
and bi-directional LSTM are deployed
for accurate prediction.
Fbprophet model deployed for
forecasting in various countries
Deployed multilayered perceptron,
linear regression, and vector
autoregression for better results
Performed prediction for one month
Predicted the effect of social
distancing for 30 days and lockdown
also analyzed
Analyzed data of the USA and India
Cases load rate based on cumulative
confirmed cases and the recovery rate
are used for prediction.
Hybrid non-linear cellular automata
deployed for prediction
Considered six components: Susceptible
(S), Asymptomatic (A), Recovered (R),
Infected (I), Isolated Infected (Iq), and
Quarantined Susceptible (Sq)
Developed a reliable model using trustregion-reflective algorithm
Machine learning
LSTM and curve-fitting
Cellular automata classifier
Daily temperature and relative
humidity-weighted against cases
Mathematical model
New mathematical model
proposed
SEIRmodel
Analyzed reproduction number and
sensitivity analysis to decide the
preventive measure
Hybrid of wavelet-based A risk assessment performed using Forecasts for ten days only
forecasting and ARIMA regression tree
model
Generalized additive model.
Sen's slope, Man-Kendall
test, and Verhulst (logistic)
population model
Gene expression programming
Predictive error minimizationbased approach
Mathematical model developed
for predication
Logistic model and machine
learning technique
Machine learning
Deep learning
ARIMAmodel
SARIIqSq model
Developed a new model
(SEIDIuQHRD)
Prediction
Prediction
Prediction
Prediction and
analysis
Forecasting
Forecasting
Prediction and analysis
of meteorological
factors
Evaluation and
prediction
Prediction
Predicted risk based on
weather conditions
Prediction
Modeling and
forecasting
Forecasting
Kanagarathinam
and Sekar[38]
Nabi[37]
Mandai et al.[48]
Sarkar et al.[36]
Arora et al.[39]
Rafiq et al.[42]
Sahoo and
Sapra[43]
Salgotra
et aU45]
Tomar and
Gupta[46]
Gupta et aU47]
Wang et al.[40]
Goswami
et aU44]
Sujath et al.[41]
are mainly week wise confirmed cases in concerning
states. After collecting the required data, they are refined
and analyzed.
Tables 3 and 4 illustrate the mathematical description
of considered dataset and correlation among those data,
respectively. In Table 3, the notations: Count, Mean,Rajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 69
Table 2 Dataset from WeekI to WeekI5 including confirmed cases in different states of India. CH: Chandigarh, KR: Karnataka,
MP: Madhya Pradesh, MH: Maharashtra, and TL: Telengana.
Week
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Kerala
3
8
22
52
182
306
364
396
453
499
505
587
794
1208
1807
Gujarat
2
7
13
18
58
122
308
1272
2848
4948
7404
9931
13 268
15953
18584
CH
1
2
3
5
8
18
18
21
37
49
59
66
172
289
301
Delhi
1
4
7
29
49
503
903
1707
2501
4068
6261
8895
12319
17 415
25004
KR
1
3
6
26
76
144
214
371
482
611
750
1056
1743
2728
4329
Ladakh
1
2
3
12
13
14
15
18
19
32
42
43
44
74
90
MP
1
2
3
4
30
165
443
1355
1974
2838
3433
4595
6170
7672
8762
MH
1
2
32
67
186
490
1574
3323
7029
11823
19101
29100
44582
62357
77793
TL
1
1
3
22
66
269
504
791
988
1062
1143
1454
1761
2378
3147
Table 3 Mathematical description of datasets.
Week
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Count
23
23
23
23
22
18
9
9
9
9
9
9
9
9
9
Mean
2.13
4.22
13.74
38.04
104.5
254.44
482.56
1028.22
1814.56
2881.11
4299.78
6191.89
8983.67
12230.44
15535.22
Std
2.88
4.75
17.29
43.83
126.74
239.93
490.04
1049.76
2220.68
3806.50
6188.59
9382.13
14291.02
19916.79
24897.31
Min
1
1
1
3
6
14
15
18
19
32
42
43
44
74
90
25%
1
1
3
10
22.5
75.5
214
371
453
499
505
587
794
1208
1807
50%
1
2
7
26
57.5
171
364
791
988
1062
1143
1454
1761
2728
4329
75%
1.5
4.5
21
50.5
163
401.25
504
1355
2501
4068
6261
8895
12319
15953
18584
Max
14
18
80
190
485
911
1574
3323
7029
11823
19101
29100
44582
62357
77793
Std, Min, Max, 25%, 50%, and 75% are used to
denote the number of non-null values, mean of values,
the standard deviation of the values, minimum value,
maximum value, first quartile, second quartile, and
third quartile, respectively. These same notations also
used in Table 5 for the statistical description of the
considered dataset. The objective of this analysis is
to find the correlation between WeekI to WeekI5 for
all confirmed cases in different states. Through this
analysis, it is observed that there is a strong correlation
between the complete datasets. Table 4 represents the
correlation analysis which determines the relationship
among WeekI to WeekI5 data. According to descriptive
analysis concerning spread rate of coronavirus disease
in different states, it is observed that in the first four to
five weeks the spread rate of this virus is very less in
India, but after that spread rate is very high in some of
the states in India due to social gathering by a single
source (refer to Table 3). It is observed from Figs. I and
2 that till Wee~ the spread rate of confirmed cases is
very low and Week5 onwards spread rate is very high.
Figure 1 illustrates the confirmed cases in considered
states and shows that exponential growth in confirmed
cases occurs after the fourth week. Similarly, Figs. 2
and 3 also illustrate an exponential growth pattern for
confirmed cases in considered states and it indicates that
in the near future situation it will be very tough if it is
not controlled.70 Big Data Mining and Analytics, June 2021, 4(2): 65-75
Table 4 Correlation analysis of determining relationship between datasets.
Week Week
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
1 1.00
2 0.91 1.00
3 0.45 0.40 1.00
4 0.37 0.30 0.92 1.00
5 0.53 0.40 0.92 0.95 1.00
6 0.06 0.11 0.60 0.75 0.64 1.00
7 -0.15 -0.11 0.70 0.74 0.62 0.89 1.00
8 -0.11 0.13 -0.07 0.00 -0.19 0.45 0.28 1.00
9 -0.16 0.09 -0.15 -0.06 -0.25 0.43 0.23 0.98 1.00
10 -0.16 0.10 -0.18 -0.10 -0.28 0.39 0.19 0.97 1.00 1.00
11 -0.15 0.12 -0.18 -0.10 -0.28 0.39 0.18 0.96 0.99 1.00 1.00
12 -0.14 0.13 -0.17 -0.09 -0.27 0.41 0.20 0.95 0.99 1.00 1.00 1.00
13 -0.14 0.14 -0.17 -0.07 -0.25 0.43 0.21 0.95 0.99 0.99 1.00 1.00 1.00
14 -0.12 0.16 -0.15 -0.05 -0.24 0.45 0.22 0.94 0.98 0.98 0.99 1.00 1.00 1.00
15 -0.09 0.20 -0.13 -0.05 -0.22 0.45 0.22 0.95 0.98 0.98 0.99 0.99 1.00 1.00 1.00
Table 5 Statistical description of datasets.
Dataset Count Mean Std Min 25% 50% 75% Max
Confirmed cases 70.00 69595.39 70086.76 1024.00 12599.00 41102.00 110639.75 246622.00
Recovered cases 70.00 27765.33 34180.32 95.00 1516.00 11297.00 44643.75 118695.00
Death cases 70.00 2087.83 1981.72 27.00 415.75 1357.00 3401.00 6946.00
Fig. 1 Confirmed cases of COVID-19 in India.
Weelc1 Week2 Week3 Week4 Weeks Week6 Week 7
Week
Prediction using the proposed model is performed for
data from 20 March 2020 to 6 June 2020. This date
range is different from the date range considered for
analysis, because initially the number of cases is very
low and the use of that data may affect the accuracy
of the model, data after 20 March 2020 are considered
when the number of COVID-19 patients are significantly
higher. Data were collected in the CSV file (from
www.kaggle.com[54]) and imported in Jupyter notebook
through anaconda navigator and analyzed with Python
4 Proposed Model
Predictions
3.7.6 software. Attributes that were considered in this
dataset are mainly confirmed, recovered, and death
cases. Figure 3 shows the graphical representation
of the dataset. It is assumed that the coronavirusinfected persons are available in India and they come
into contact with other healthy persons. Since it is an
infectious disease, it is going to spread into others also.
Consequently, the number of cases is growing rapidly.
During the development of the model, the collected
data were analyzed by using functions in Python
Software. For understanding the dataset properly, a
statistical description was performed on the complete
dataset. The description of statistical data is shown in
Table 5.
The proposed model is summarised in Fig. 4. It
is important to discover and compute the degree of
variables in the dataset and this information is helpful
for better preparation of dataset to meet the expectations
of machine learning algorithms. A recovery strategy and
correlation analysis are performed on data using Python
Software. It reveals a statistical summary of confirmed,
recovered, and death cases and also finds a strong
relationship among current data. The consequential
correlation analysis is shown in Table 6.
Multiple regression analysis is used for predicting
for COVID-19
- Kerala
- GUjarat I
- Chandigarh / - Delhi / - Karnataka
- Ladakh
- Madhya Pradesh / - Maharashtra
Telengana //
~" .....-:
~ r7/
.............: I~ ~
1400
~ 1200
~1000
'E 800
8
b 600
:;;
~ 400
z
1600
o
200Rajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 71
80000 o
70000
o ~ 60000
~
'"
u
] 50000
E
g40000
u
'0
Qj 30000 .c
E
~ 20000
10000
o -e- -e- -e0
0
0
i 0
I I 0
• ...g",. I 0
-• .....Q- ~
Week, Weeks Week6
-
Week7 Weeks Weekg Week10 Week 11 Week12 Week13 Week14
Week
Fig. 2 Boxplot for confirmed cases of COVID-19 in India.
Parameter Value
Table 7 Summary of output for multiple linear regression
analysis.
death cases with the help of confirmed and recovered
cases. This regression technique has more than one
variables to predict the output. It is helpful in predicting
a target variable using more than one independent
variables. For predictive analysis, the multiple linear
regression techniques are used to explain the relationship
between two independent variables (confirmed and
recovered cases) and one dependent variable (death
cases). Here the dataset is divided into training and
test datasets as 70% for training and 30% for testing.
This model has a very strong predictive capacity after
training with the dataset and found Root Mean Square
Error (RMSE) as 3085.4305 and R2 score as 0.9992.
The summary of output for multiple linear regression
analysis is shown in Table 7.
Decision tree learning techniques are used to
continuously split training and test data according to
a certain parameter. It is a widely accepted supervised
learning approach that split our dataset based on
conditions. It is equally useful for regression and
classification. This approach assigns the most feasible
class for each record for classification. At the time of
testing with a different set of input values, it is observed
that predicted output is very close to actual values.
During the analysis of the complete dataset, it is
20 30 40 50 60 70
Number of days
o 10
Find cofficienl and
predicted values
50 OOOH----,..".,I----+--+-~~-----1;;;"."_____t--H
250 OOO~.::;::c=on:;::firm==e':=d=ca=:=se=:=s t===t==+===t====t==;R • Recovered cases
200 OOO~·,:::D::ea~th..::ca;::se::.s_-t----t---.~----t-----t------tFind slope,
intercept,
RMSE,and
A2 Sl.LJre
150000H--I----+--.AA---+--+-I'+--H
100000H--I--------"Ir--+---+--Jl'-------+--:IIIII"'---H
Fig. 3 Confirmed, recovered, and death cases in India.
Fig. 4 Proposed model for predictions of confirmed,
recovered, and death cases of COVID-19 in India.
Table 6 Correlation analysis of determining relationship
between datasets.
Confirmed cases Recovered cases Death cases
Confirmed cases
Recovered cases
Death cases
1
0.99373420
0.99813925
1
0.98584439
Slope
Intercept
RMSE
R2 score
[0.0418 -0.0280]
-43.5073
3085.4305
0.9992Lag
-O.sOf---+---+------1f---+----+--+---1
-0.751--+---+------11--+----+--+---1
72
[1] World Healthy Organization, Statement on the second
meeting of the international health regulations (2005)
emergency committee regarding the outbreak of novel
coronavirus (2019-nCoV), https://www.who.int/news/item/
30-01-2020-statement-on-the-second-meeting-of-theinternational-health-regulations-(2005 )-emergencycommittee-regarding-the-outbreak-of-novel-coronavirus-
(2019-ncov), 2019.
[2] M. Xie and Q. Chen, Insight into 2019 novel coronavirusBig Data Mining and Analytics, June 2021, 4(2): 65-75
Table 8 Prediction for the next 30 days (7 June 2020 to 6
July 2020).
Predicted Predicted Predicted
Date confirmed recovered death
cases cases cases
07-Jun-20 256972 132398 7230
08-Jun-20 268021 146535 7529
09-Jun-20 279935 154647 7834
IO-Jun-20 292 393 162747 8156
ll-Jun-20 304886 169880 8500
12-Jun-20 318185 175762 8851
13-Jun-20 331964 180 150 9215
14-Jun-20 346329 185 645 9589
15-Jun-20 361 364 193564 9971
16-Jun-20 377 129 210 844 10 373
17-Jun-20 393235 236021 10 789
18-Jun-20 410 083 256198 11223
19-Jun-20 427679 271631 11 676
20-Jun-20 445982 285667 12142
21-Jun-20 465005 295537 12626
22-Jun-20 484898 300267 13 128
23-Jun-20 505477 303 552 13 648
24-Jun-20 526898 311 531 14191
25-Jun-20 549246 332608 14753
26-Jun-20 572 521 370832 15337
27-Jun-20 596690 412622 15943
28-Jun-20 621 891 447115 16571
29-Jun-20 648083 476246 17223
30-Jun-20 675324 497 141 17899
01-Jul-20 703 696 504343 18602
02-Jul-20 733247 501616 19331
03-Jul-20 763961 501854 20088
04-Jul-20 795938 521520 20873
05-Jul-20 829215 572 506 21688
06-Jul-20 863836 645885 22534
in resource management, like health services, and timely
action may be taken with prior preparation to reduce the
loss of human life.
The proposed model may be extended to predict
the end of this pandemic in a particular region. Total
causality and total economic losses may be predicted
with the help of this model.
References
I
1--
,
Confi~med cas~s ,
_ Recovered cases I
I
- Death cases I
--- Predicted confirmed cases
--- Predicted recovered cases / --- Predicted death cases / ,-
/ /
V ./
, ~,--" V V- --
1.00~
0.7sl-----'...-,,+---+------1f---+----+--+---1
0.50 ~ _
0.25 I I~I
o I -- -0.2si-"""'~-F-~"""~""""'ii-"""'~+~"""~~-F-~""'i
100000
150000
o
200000
250000
300000
Fig. 5 Autocorrelation plot.
50000
-1.00 '----------,1""0------=2.':-0-----='3':-0-----"40=---'"'50-----,-6""0-------='70
observed that the model can use regression against
itself and also able to use the autocorrelation plot to
check the randonmess within the data. Figure 5 shows
the autocorrelation plot. Now create an autoregression
model that uses observation from the previous steps as
input. The time-series model is used to predict the values
at the next time step. Results prove that the forecasted
range of time series is accurate. Now fit the model using
the existing dataset and find the lag and coefficients.
Based on the lag value, a separate analysis is performed
for confirmed, recovered, and death cases. It is observed
from Table 8 that the testing of existing data is very close
to the actual dataset and predicted values are also very
relevant to the existing dataset.
Fig. 6 Actual and predicted: confirmed, recovered, and
death cases in India.
o w m ~ ~ ~ ~ ro Number of days
5 Conclusion and Future Scope
This study discussed the spread of COVID-19 in
different states of India and proposed a model for
predicting the number of confirmed, recovered,
and death cases. Multiple linear regression and
autoregression were used to predict the possible number
of cases in the future. The predicted confirmed cases of
India for the next 30 days are recorded in Table 8. The
predicted values and actual values are together in good
agreement (see Fig. 6). This prediction may be helpfulRajani Kumari et al.: Analysis and Predictions ofSpread, Recovery, and Death Cansed by COVID-I9 in India 73
An updated intrim review and lessons from SARS-CoY and
MERS-CoY, International Journal ofInfectious Diseases



NEW_PAPER


Received May 6, 2020, accepted May 8, 2020, date of publication May 11, 2020, date of current version May 28, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2993967
INVITED PAPER
Quantifying COVID-19 Content in the Online
Health Opinion War Using Machine Learning
RICHARD F. SEAR 1
, NICOLÁS VELÁSQUEZ 2,3, RHYS LEAHY 2,4
,
NICHOLAS JOHNSON RESTREPO 2,4, SARA EL OUD 5
, NICHOLAS GABRIEL5
,
YONATAN LUPU 6
, AND NEIL F. JOHNSON 2,5
1Department of Computer Science, George Washington University, Washington, DC 20052, USA
2
Institute for Data, Democracy, and Politics, George Washington University, Washington, DC 20052, USA
3Elliott School of International Affairs, George Washington University, Washington, DC 20052, USA
4ClustrX LLC, Washington, DC 20007, USA
5Department of Physics, George Washington University, Washington, DC 20052, USA
6Department of Political Science, George Washington University, Washington, DC 20052, USA
Corresponding author: Neil F. Johnson (neiljohnson@gwu.edu)
ABSTRACT A huge amount of potentially dangerous COVID-19 misinformation is appearing online. Here
we use machine learning to quantify COVID-19 content among online opponents of establishment health
guidance, in particular vaccinations (‘‘anti-vax’’). We find that the anti-vax community is developing a
less focused debate around COVID-19 than its counterpart, the pro-vaccination (‘‘pro-vax’’) community.
However, the anti-vax community exhibits a broader range of ‘‘flavors’’ of COVID-19 topics, and hence can
appeal to a broader cross-section of individuals seeking COVID-19 guidance online, e.g. individuals wary
of a mandatory fast-tracked COVID-19 vaccine or those seeking alternative remedies. Hence the anti-vax
community looks better positioned to attract fresh support going forward than the pro-vax community. This
is concerning since a widespread lack of adoption of a COVID-19 vaccine will mean the world falls short of
providing herd immunity, leaving countries open to future COVID-19 resurgences. We provide a mechanistic
model that interprets these results and could help in assessing the likely efficacy of intervention strategies.
Our approach is scalable and hence tackles the urgent problem facing social media platforms of having to
analyze huge volumes of online health misinformation and disinformation.
INDEX TERMS COVID-19, machine learning, topic modeling, mechanistic model, social computing.
I. INTRODUCTION
Scientific experts agree that defeating COVID-19 will depend
on developing a vaccine. However, this assumes that a sufficiently large proportion of people would receive a vaccine
so that herd immunity is achieved. Because vaccines tend to
be less effective in older people, this will require younger
generations to have very high COVID-19 vaccination rates
in order to guarantee herd immunity [1]. Yet there is already
significant opposition to existing vaccinations, e.g. against
measles, with some parents already refusing to vaccinate
their children. Such vaccine opposition increased the number
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
of cases in the 2019 measles outbreak in the U.S. and
beyond [2]. Any future COVID-19 vaccine will likely face
similar opposition [3], [4]. Mandatory COVID-19 vaccinations for schoolchildren could trigger a global public health
conflict. A better understanding of such opposition ahead of
a COVID-19 vaccine is therefore critical for scientists, public
health practitioners, and governments.
Online social media platforms, and in particular the builtin communities that platforms like Facebook (FB) feature,
have become popular fora for vaccine opponents (anti-vax)
to congregate and share health (mis)information. Such misinformation can endanger public health and individual safety
[1], [4]. Likewise, vaccine supporters (pro-vax) also congregate in such online communities to discuss and advocate for
91886 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
professional public health guidance. Well before COVID-19,
there was already an intense online conflict featuring antivax communities and pro-vax communities. Within anti-vax
communities, the narratives typically draw on and generate
misinformation about establishment medical guidance and
distrust of the government, pharmaceutical industry, and new
technologies such as 5G communications [1], [4], [5]. Adding
fuel to this fire, the January 2020 birth of the COVID-19
‘‘infodemic’’ has led to a plethora of misinformation in
social media surrounding COVID-19 that directly threatens
lives [6]. For example, harmful ‘‘cures’’ are being proposed
such as drinking fish tank additives, bleach, or cow urine,
along with coordinated threats against public health officials
like Dr. Anthony Fauci, director of the U.S. National Institute of Allergic and Infectious Diseases [7]. Moreover, false
rumors have been circulating that individuals with dark skin
are immune to COVID-19. These may have contributed to
more relaxed social distancing among some minorities and
hence their over-representation as victims. In Chicago and
Louisiana as of early April 2020, ∼70% of the fatalities were
African Americans even though this demographic only makes
up ∼30% of the population [8], [9]. In addition, the world
has witnessed an alarming rise in COVID-19 weaponization
against the Asian community [10]–[12]. It is also clear that
such misinformation is not a fringe phenomenon, and can
instead be very widely held as true within the general population. Indeed, a recent Pew study [13] found that ∼30%
of Americans believe the COVID-19 virus was likely created
in a laboratory, despite statements from infectious disease
experts to the contrary.
Unfortunately, the sheer volume of new online content and
the speed with which it spreads, means that social media
companies are struggling to contain such health misinformation [14], [15]. Making matters worse, people around the
world are spending more time on social media due to social
distancing imposed during the COVID-19 pandemic. This
increases the likelihood that they become exposed to such
misinformation, and as a result they may put themselves and
their contacts at risk with dangerous COVID-19 remedies,
cures and falsehoods.
The present study is motivated by both these needs: (1) the
need for a deeper understanding of this intersection between
online vaccination opposition and the online conversation
surrounding COVID-19; and (2) the need for an automated
approach since the sheer volume of new online material every
day makes manual analysis a non-viable option going forward. We pursue an automated, machine learning approach
that avoids the scalability limitations of manual content analysis. While the present paper is just the first step in a challenging longer-term goal, the automated approach that we
present allows the following questions to be addressed: How
did COVID-19 change the online conversation within antivaccination and pro-vaccination communities over the two
month period in early 2020 when the disease became a global
threat; and what do the topical changes that we observe in the
anti-vax and pro-vax online communities’ narratives, imply
about their relative abilities to attract new supporters going
forward?
Unlike many existing works, this study does not use Twitter
data [16], [17] since it is known that Twitter is more of a
broadcast medium for individual shout-outs, whereas discussions and narratives tend to be nurtured in in-built online
community spaces that are a specific feature of platforms
like Facebook (e.g., fan page) [18]. Twitter does not have
such in-built community spaces. In the present methodology,
generalized from [19] and [20], data is collected from these
online communities, specifically Facebook Pages that support either anti-vaccination or pro-vaccination views. This
information is publicly available and does not require any
individual details, thereby avoiding any privacy concerns –
just as understanding the content of a conversation among
a crowd of people in an open, real-world public space does
not require knowledge of any personal details about the individuals within that crowd. Details of our approach are given
in Sec. II and the Appendix. A third difference between this
study and previous ones is that the machine learning findings
here are interpreted in terms of a mechanistic model (Sec. IV)
that captures the general trend for the coherence in the online
conversations over time. Though much work still needs to be
done, this study therefore provides a first step toward a fully
automated but interpretable understanding of the growing
public health debate concerning vaccines and COVID-19.
II. DATA AND MACHINE LEARNING ANALYSIS
The terms ‘Facebook Page’ and ‘cluster’ are used interchangeably here since each Facebook Page is a cluster of
people. Facebook Pages, also known as fan pages or public
pages, are accounts that represent organizations, causes, communities, or public figures. According to Facebook’s policies,
‘‘Content posted to a Page is public and can be viewed by
everyone who can see the Page’’ [see 21, Sec. 5]. A Facebook
Page is different from a Facebook personal account. Personal
accounts represent private individuals, and their posts and
interactions are considered more private and targeted to their
immediate contacts. This paper does not analyze data from
personal accounts. Our methodology follows [19] and [20] by
analyzing the public content of Facebook Pages for both antivaccination (‘‘anti-vax’’) and pro-vaccination (‘‘pro-vax’’)
communities. The publicly available content of these online
communities is obtained using a snowball approach, starting
with a seed of manually identified pages discussing either
vaccines, public policies about vaccination, or the pro-vs-anti
vaccination debate. Then their connections to other fan pages
are indexed. At each step, new clusters are evaluated through
a combination of human coding and computer-assisted filters.
To classify a cluster as being (1) anti-vax or pro-vax and
(2) including COVID-19 content or not, we reviewed its
posts and the Page’s ‘‘about’’ section. Pro-vax and anti-vax
classifications required that either (a) at least 2 of the most
recent 25 posts dealt with the pro-vax or anti-vax debate,
or (b) the page’s title or ‘‘about’’ section described it as
pro-vax or anti-vax. At least two researchers classified each
VOLUME 8, 2020 91887R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
cluster independently. If they disagreed on their suggested
classification, a third researcher reviewed the posts and then
all three reviewers discussed these cases. Agreement was
reached in each case. This also enabled us to distinguish
between content that is intended to be serious versus merely
satirical. The self-weeding tendency within Facebook Pages
tends to reduce material from bots and fake profiles. We kept
the present study focused on English, though this can be
easily generalized using our same procedure. Beyond that,
our study was global and not limited to a particular region.
The content of these clusters was then bundled together
separately for the anti-vax community and the pro-vax community, and the two resulting sets of content were analyzed
using machine learning. Specifically, we used an unsupervised machine learning technique called Latent Dirichlet
Allocation (LDA) [22] to analyze the emergence and evolution of topics around COVID-19. The LDA method models
documents as distributions of topics and topics as distributions of words. During its training process, these distributions
are adjusted to fit the dataset. The LDA method is described
correctly in Wikipedia as [23] ‘‘[quote] .. a generative statistical model that allows sets of observations to be explained by
unobserved groups that explain why some parts of the data
are similar. For example, if observations are words collected
into documents, it posits that each document is a mixture
of a small number of topics and that each word’s presence
is attributable to one of the document’s topics. LDA is an
example of a topic model and belongs to the machine learning toolbox and in wider sense to the artificial intelligence
toolbox.’’
The coherence score provides a quantitative method for
measuring the alignment of the words within an identified
topic (see [22]). It is generated from a separate algorithm
which is run over a trained LDA model. The overall coherence
score of a single model is the arithmetic mean of its pertopic coherences. There are many different coherence metrics
to evaluate per-topic coherence. We use CV which is based
on a sliding window, one-set segmentation of the top words
and an indirect confirmation measure that uses normalized
point-wise mutual information and the cosine similarity. It
comprises collections of probability measures on how often
top words in topics co-occur with each other in examples
of the topics. We refer to [22] for a full explanation and
discussion of CV.
Machine learning automation can, in principle, help
address the significant issues facing social media platforms
by mechanically picking out material that requires attention from the huge haystack of online content. While this
could help to better curtail online misinformation, one might
rightly ask about its accuracy and reliability as compared to
human analysts. This has been recently addressed in [24]. We
use the same coherence metric (CV) as these authors. They
addressed the problem that topic models had previously given
no guarantee on the interpretability of their output. Specifically, they produced several benchmark datasets with human
judgements of the interpretability of topics and they found
results that outperformed existing measures with respect to
correlation to human ratings. They achieved this by evaluating 237,912 coherence measures on 6 different benchmarks
for topic coherence, making this the biggest study of topic
coherences at that time. Separately, we have done our own
comparison for the general area of online hate and have found
comparable consistency.
In summary, our machine learning approach identifies topics in the online narratives with high coherence, meaning the
word groupings identified are strongly related according to
the coherence scoring approach discussed earlier. Our human
inspection of the word distribution making up each grouping
showed that they do indeed correspond to reasonably distinct
conversation topics. Details and examples are given in the
Appendix.
III. RESULTS
The main focus here is in the endogenous development of
COVID-19 conversation at the beginning of the global pandemic and prior to the first officially reported U.S. COVID-19
death on February 29, 2020 [25]. Hence we collected Facebook public post data for the period 1/17/2020-2/28/2020
inclusive. To assess the change over time, this period was
divided into time intervals. Since having more time intervals
would mean smaller amounts of data within each and hence
more fluctuations, and since we are just interested in the
change over time, two intervals were chosen of equal duration, T1 and T2. The first time-interval 1/17/2020-2/7/2020
(T1) contains 774 total pro-vax posts and replies, and 3630
total anti-vax posts and replies. The second time-interval
2/7/2020-2/28/2020 (T2) contains 673 total pro-vax posts and
replies, and 3200 total anti-vax posts and replies. Hence our
two equal time windows contains similar amounts of data. We
checked that our results are relatively robust to other choices
of time interval. Interestingly, T1 roughly corresponds to
the time when COVID-19 was largely seen as a problem
in Asia, while T2 roughly corresponds to the time during
which it became a serious problem in Europe. For further
reassurance that our data was representative of the COVID-19
conversation during these intervals, we also checked that the
data split is similar to that for mentions of COVID-19 in
article counts from worldwide anglophone newspapers and
worldwide Google trends.
The LDA models were trained over posts in the following
distinct groups: anti-vaccination posts in T1, anti-vaccination
posts in T2, pro-vaccination posts in T1, and pro-vaccination
posts in T2. For each of these sets, 10 separate LDA models
were trained with the number of topics parameter ranging
from 3-20, for a total of 180 models in each of the four groups.
Fuller details are given in the Appendix. The CV coherence
algorithm was then run over each of these models and the
coherence scores were averaged for each number of topics.
These averaged scores are plotted in Figures 1B and 1C.
Figure 1A shows the result of the same procedure applied to
all posts in our dataset, and to all anti-vaccination posts, and
to all pro-vaccination posts.
91888 VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
FIGURE 1. Coherence scores CV
for (A) anti-vax (dashed line), pro-vax
content (dotted line), and anti-vax combined with pro-vax (dashed-dotted
line), calculated over the entire time period of study (T1 + T2
). (B) Anti-vax
content for the separate time periods T1
(blue line) and T2
(orange line).
The number of topics for which the coherence score CV
is a maximum is
indicated, i.e. the optimal number of topics. The optimal number of topics
for anti-vax moves from 15 to 10 from T1
to T2
. (C) Pro-vax content for the
separate time periods T1
(blue line) and T2
(orange line). The optimal
number of topics for pro-vax moves from 19 to 5 from T1
to T2
.
The coherence score CV for the entire period of study (i.e.
T1 + T2) in Fig. 1A, is consistently larger across the number
of topics for pro-vax than for anti-vax, suggesting that the
pro-vax community overall has a more focused discussion
around COVID-19 than the anti-vax. This is consistent with
the pro-vax community featuring a more monolithic discussion around public health – namely, it is focused on advising
people to follow professional medical guidance.
The bad news for the pro-vax community from this higher
overall coherence, is that it is less well positioned to engage
with the wide variety of more blurry, and often more extreme,
COVID-19 narratives that are now circulating online. This
represents a significant potential disadvantage for the pro-vax
community in that it may therefore be less able to attract the
attention of the many different types of users who are now
entering this online space in search of a particular nuanced
‘flavor’ of COVID-19 narrative that appeals to them. These
users could consequently be pulled toward the anti-vax cause.
Figures 1B and 1C indicate the change over time by comparing the curves of the coherence score across number of
topics, for time periods T1 and then T2. The curve moves
up from T1 to T2 for the pro-vax community (Fig. 1C) and
the optimal number of topics shows a dramatic decrease
from 19 to 5. This is consistent with the notion that the provax community is working toward a common COVID-19
interpretation and narrative with fewer ‘flavors’ of discussion
and interpretation than the anti-vax community. Again, while
this may sound like a strength, it suggests that the pro-vax
community overall is actually becoming less appealing over
time to the many different types of new users who are in
search of their own COVID-19 narrative ‘flavor’. By contrast,
the curves for the anti-vax community from T1 to T2 (Fig. 1B)
show a far smaller reduction in the optimal number of topics
(15 to 10) and the curves move down, in the opposite direction to the pro-vax. Hence the anti-vax compensates a small
increase in focus (reduction in the optimal number of topics)
with an overall reduction in coherence, i.e. these 10 topics
for T2 are effectively more blurry than the original 15 for T1,
and hence the overall anti-vax community is becoming more
accommodating to the diverse population of new additions
coming into the online health space over time.
Figure 2 shows a visualization with more detail about the
information structure of the individual topics, and how far
these topics are from one another in terms of informational
distance. The plot is obtained using the pyLDAvis package
[26] which provides a global view of the topics and how
they differ from each other, while at the same time allowing
for a deeper inspection of the terms most highly associated
with each individual topic. This provides a novel method for
implying the relevance of a term to a topic. The study in [26]
showed that ranking terms purely by their probability under a
topic, by contrast, is suboptimal for topic interpretation. We
refer to [26] for full details of LDAvis.
The change in the pro-vax community from time period
T1 (Fig. 2C) to T2 (Fig. 2D) is such that the optimal number
of topics decreases (i.e., the number of circles decreases
from 19 to 5 following Fig. 1C) and the topics evolve to
become located mostly in the same portion of the space (i.e.,
toward the right-hand side of Fig. 2D). Following Fig. 1B,
the change in the anti-vax community from time period T1
(Fig. 2A) to T2 (Fig. 2B) is such that the optimal number
of topics starts off slightly smaller than the pro-vax, but
although it also decreases over time (i.e., the number of
circles decreases) there are more topics (i.e., more circles
VOLUME 8, 2020 91889R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
FIGURE 2. Visualization of the informational structure of the individual
topics, and how they relate to each other. This plot is obtained using
pyLDAvis. The circles in each plot are the topics from Fig. 1 for which the
average coherence score is highest, i.e. the optimal number of topics.
Their size indicates the marginal topic distribution as discussed in detail
in [26], while the two axes are principal components in the distribution
analysis.
in Fig. 2B) than for the pro-vax in time period T2 (Fig. 2D).
Also, the topics seem more spread out across the space in
Fig. 2B as compared to Fig. 2D. These observations are
consistent with our earlier interpretations that the pro-vax
community is more focused (equivalently, narrower) than the
anti-vax community in terms of COVID-19 narratives, and
that the pro-vax community is evolving toward a common
COVID-19 interpretation and narrative with a lower diversity
on offer than the anti-vax community.
IV. TOWARD A MECHANISTIC MODEL INTERPRETATION
We created a mechanistic model that further supports these
empirical findings and provides a microscopic interpretation
of the machine learning output. Specifically, we generated a
computer simulation of an ecology of online components of
the overall community content, each of which is characterized
by a vector x = (x1, x2, . . . ) in which each component xi
signifies the strength of a given factor surrounding the online
health debate, e.g. government control. The exact nature of
these components does not need to be specified, i.e. whether
they are words or short phrases. It just matters that there is
a diverse ecology of such building blocks. This mechanistic
model setup, while seemingly very simplistic, does indeed
reflect the empirical observations and literature surrounding
the themes of online discussions of vaccination opposition, as
listed and studied in detail by Kata in [1]. We then carry out a
simulation whereby these components are selected randomly
to build up content. Components cluster together (or their
clusters cluster together, if they are already in a cluster) if their
FIGURE 3. Output from our mechanistic model in which clusters form if
the component x-values are sufficiently similar (i.e., homophily in
panel A) or different (i.e., heterophily in panel B).
x values are sufficiently similar (i.e. homophily in Fig. 3A) or
different (i.e. heterophily in Fig. 3B). To illustrate the output
of our model, Fig. 3 shows a one-dimensional version. We
checked that a two-dimensional version gives similar results,
though it is visually more complicated because of having the
time component along the third dimension. Most importantly,
it produces plots that are visually similar to those in Fig. 2.
As can be seen from Fig. 3, the case of homophily (which
is akin to building a more monolithic topic discussion with
few flavors, like the pro-vax community) has a convergence
that is quicker, as observed in Figs. 1 and 2 for the pro-vax
community. By contrast, the case of heterophily (which is
akin to building diverse topic discussions with many flavors,
like the anti-vax community) is slower to gel, which is consistent with the anti-vax community in Figs. 1 and 2. The red
dotted horizontal line in Figs. 3A and 3B gives an indication
of the stage in the simulation that is broadly consistent with
Figs. 2D and 2B for the pro-vax and anti-vax communities
respectively.
The delay in the gelation time observed in Fig. 3B for
heterophily (anti-vax) as compared to homophily (pro-vax)
in Fig. 3A, can be derived analytically using mathematical
analysis from statistical physics (see [27] for full details).
In particular, we have been able to show that the time at
which gelation emerges depends inversely on the average
probability that two randomly picked components join the
same cluster, which is smaller for heterophily than homophily
and hence the gelation time is later for heterophily than
homophily – exactly as observed in Fig. 3. Similarly, it can
be shown mathematically that the gelation sizes (akin to the
sizes of the circles in Fig. 2) will be smaller for heterophily
than homophily, as also observed in Fig 3.
Again, instead of this being good news for the pro-vax
community, the simulation of this mechanistic model shows
that the case of homophily (pro-vax) is less able to absorb an
influx in new users with a range of x values, as compared to
the case of heterophily (anti-vax). This is consistent with the
idea stated earlier, that the anti-vax community appears more
engaging to new users (e.g. parents with children of schoolage who are wary of school vaccine requirements, or who fear
government control) and hence the anti-vax will be more able
to gain new supporters in the long run than the pro-vax.
91890 VOLUME 8, 2020R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
V. LIMITATIONS OF THE STUDY
There are of course many limitations of this study. There
are other social media platforms, apart from Facebook, that
should be explored – but Facebook is the largest. Similar
behaviors should arise in any platform where communities
can form. It will also be interesting, for example, to compare
our findings to other studies focused on Twitter, where messaging is more in the form of short, individual statements [17].
There is also the question of influence of external agents or
entities [16]. However, these social media communities tend
to police themselves for bot-like or troll behavior. Further
analysis is required of the details of the content. This will
require going beyond just text and perhaps beyond LDA,
since memes and images are also shared. Also, the generative
model output needs to be compared in detail to the timeevolution of topics. Further research is also required to formulate the results across all platforms into detailed, actionable
consequences for policy makers. These limitations will be
addressed in future work.
VI. CONCLUSION
These findings suggest that the online anti-vax community is
developing a more diverse and hence more broadly accommodating discussion around COVID-19 than the pro-vax community. As a result, the pro-vax community runs the risk of
making itself less engaging to the heterogeneous ecology of
potential new users who join the online COVID-19 discussion, and who may arrive online with a broad set of concerns,
questions, and possibly preconceived notions, misinformation and even falsehoods.
The analysis in this paper also provides a first step toward
eventually either replacing, or at least supplementing, the
non-scalable efforts of human moderators tasked with identifying online misinformation. In addition, the mechanistic
model (Fig. 3) could be used for what-if scenario testing of
how quickly coherence develops and what the impact would
be of breaking up the coherence around certain topics, e.g.
by counter-messaging against individuals ingesting bleach or
the even newer ‘COVID Organics’ that are circulating as a
cure in Madagscar, Africa and beyond. This can be achieved
by using the empirical analysis in Fig. 2 – repeated over
multiple consecutive time intervals – to identify the growth
of topics around new words which may be gaining popularity as a home cure (e.g. ‘‘bleach’’). Then Facebook, for
example, could post ads that specifically target these specific
new words and topics, rather than blanket vanilla messaging
promoting establishment medical science narratives.
Overall, this approach shows that a machine-learning algorithm, the LDA algorithm, identifies plausible topics within
collections of posts from online communities surrounding
the vaccine and COVID-19 debate. In addition to being
able to handle large quantities of data, its results emerge
quickly using statistical grouping techniques, instead of having to rely on potentially biased, slow and costly human
labeling.
APPENDIX
As mentioned in the main text, the methodology starts with a
seed of manually identified Facebook Pages discussing either
vaccines, public policies about vaccination, or the pro-vs-anti
vaccination debate. Then their connections to other fan pages
are indexed. At each step, new findings are vetted through a
combination of human coding and computer assisted filters.
This snowball process is continued, noting that new links can
often lead back to members already in the list and hence some
form of closure can in principle be achieved. This process
leads to a set containing many hundreds of pages for both the
anti-vax and pro-vax communities. Before training the LDA
models, several steps are employed to clean the content of
these pages in a similar way to other LDA analyses in the
literature:
Step 1: Mentions of URL shorteners are removed, such
as ‘‘bit.ly’’ since these are fragments output by Facebook’s
CrowdTangle API.
Step 2: Many of the posts link to external websites. The fact
that these specific websites were mentioned could itself be an
interesting component of the COVID-19 conversation. Hence
instead of removing them completely, the pieces ‘‘.gov’’,
‘‘.com’’, and ‘‘.org’’ were replaced with ‘‘__gov’’, ‘‘__com’’,
and ‘‘__org’’, respectively. This operation effectively concatenates domains into a form that will not be filtered out by
the later preprocessing steps.
Step 3: The posts are then run through Gensim’s simple_preprocess function, which tokenizes the post on spaces
and removes tokens that are only 1 or 2 characters long. This
step also removes numeric and punctuation characters.
Step 4: Tokens that are in Gensim’s list of stopwords, are
removed. For example, ‘‘the’’ is not a good indication of a
topic.
Step 5: Tokens are lemmatized using the WordNetLemmatizer from the Natural Language Toolkit NLTK, which
converts all words to singular form and/or present tense.
Step 6: Tokens are stemmed using the SnowballStemmer
from NLTK, which removes affixes on words.
Step 7: Any remaining fragments of URLs (other than
domain) that are left over after stemming, such as ‘‘http’’ and
‘‘www’’, are removed.
Steps 5 and 6 help ensure that words are compared fairly
during the training process, and that if a particular word
is a strong indicator of a topic, its signal is not lost just
because it is used in many different forms. These steps rely
on words existing in NLTK’s pretrained vocabulary. Any
word not in this vocabulary is left unchanged. After this
preprocessing, we then train the LDA models on the cleaned
data. Specifically, 10 separate LDA models were trained with
the ‘‘number of topics’’ parameter ranging from 3-20, for a
total of 180 models in each of the two time intervals T1 and
T2. The CV coherence algorithm was then run over each of
these models and the coherence scores were then averaged
for each number of topics. To produce the results, multiple
trials were run for each number of topics to ensure that the
VOLUME 8, 2020 91891R. F. Sear et al.: Quantifying COVID-19 Content in the Online Health Opinion War Using Machine Learning
coherence for a particular number of topics is representative
of what LDA models tend to find (and by extension a better
fit for the data) and is not the result of unaccounted noise
swaying the model to overfit in one way or another. These
trials are independent because the random number generator
for each LDA model was initialized with a different seed,
ensuring that statistical inferences were not be repeated. The
GitHub link is: https://github.com/searri/social-clusteringresearch/wiki/Coronavirus-Vax.
The following illustrates the topic output, focusing on antivax in time interval T2 in Fig. 2B. In this, 9 of the 10 topics
had the word ‘coronavirus’ among the 5 highest weighted
words in the topic; 4 were focused around ‘coronavirus’ and
‘vaccine’ co-occuring together. Others had ‘vitamin’, ‘fear’
and ‘ddt’ in relation to alternative treatments, and ‘weapon’
related to conspiracy theories of COVID-19’s origin. Within
one of the topics, which is focused around alternative health
explanations and cures with words like ‘vitamin’ etc., illustrative posts include the following from Feb 8, 2020 in one
of the ‘Coalition for Vaccine Choice’ pages, with spelling
mistakes left as is: ‘‘The story of this FAKE ‘‘epidemic’’
with the ‘‘corona virus’’ from China is a cover-up story for
the grim reality of the health problems due to 5G technology
exposure coroborated with a lot of other factors: vaccination,
poor alimentation in vitamins, bad water, air pollution, lack of
sleep, etc.... scientists have shown that low level microwave
EMF exposure can result in VGCC activation and elevated
intracellular calcium’’. Meanwhile, for a topic focused on
conspiracy theories with words such as ‘weapon’ and ‘fear’,
an example phrase from a posting is ‘‘..keeping the world
under the thumb of tyrants! You are soldiers, and that means
that you are expendable by your trained nature. You are
being micro-managed by people that give not one caring
thought of you, five thousand miles away, that know little
of the true nature of the battle’’. This illustrates the type of
detailed analyses that we carried out to check our automated
approach, and which underlie our claim that the groupings do
correspond to reasonably distinct conversation topics.
ACKNOWLEDGMENT
CrowdTangle data are made available to the Institute for Data,
Democracy, and Politics.



NEW_PAPER


SPECIAL SECTION ON EMERGING DEEP LEARNING THEORIES AND
METHODS FOR BIOMEDICAL ENGINEERING
Received May 26, 2020, accepted June 25, 2020, date of publication June 29, 2020, date of current version July 8, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3005510
Weakly Supervised Deep Learning for
COVID-19 Infection Detection and
Classification From CT Images
SHAOPING HU1
, YUAN GAO 2,3, (Member, IEEE), ZHANGMING NIU3,4, YINGHUI JIANG4,5
,
LAO LI4,5, XIANGLU XIAO3,5, MINHAO WANG4,5, EVANDRO FEI FANG6
, WADE MENPES-SMITH3
,
JUN XIA7
, HUI YE8
, AND GUANG YANG 9,10, (Member, IEEE)
1Radiology Department, Hospital of Wuhan Red Cross Society, Wuhan 430015, China
2
Institute of Biomedical Engineering, University of Oxford, Oxford OX3 7DQ, U.K.
3Aladdin Healthcare Technologies Ltd., London EC1Y 0UH, U.K.
4Hangzhou Ocean’s Smart Boya Company, Ltd., Hangzhou 310016, China
5Mind Rank Ltd., Admiralty, Hong Kong
6Department of Clinical Molecular Biology, University of Oslo, 0315 Oslo, Norway
7Radiology Department, Shenzhen Second People’s Hospital, Shenzhen 518035, China
8PET-CT Center, Hunan Cancer Hospital, Changsha 410013, China
9NHLI, Imperial College London, London SW3 6LY, U.K.
10Royal Brompton Hospital, London SW3 6NP, U.K.
Corresponding authors: Hui Ye (yuxin75831@163.com) and Guang Yang (g.yang@imperial.ac.uk)
This work was supported in part by the European Research Council Innovative Medicines Initiative on Development of Therapeutics and
Diagnostics Combatting Coronavirus Infections Award ’DRAGON: rapiD and secuRe AI imaging based diaGnosis, stratification,
fOllow-up, and preparedness for coronavirus paNdemics’ under Grant H2020-JTI-IMI2 101005122, and in part by IIAT Hangzhou.
ABSTRACT An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded in Wuhan,
China since late December 2019, which subsequently became pandemic around the world. Although
COVID-19 is an acutely treated disease, it can also be fatal with a risk of fatality of 4.03% in China
and the highest of 13.04% in Algeria and 12.67% Italy (as of 8th April 2020). The onset of serious
illness may result in death as a consequence of substantial alveolar damage and progressive respiratory
failure. Although laboratory testing, e.g., using reverse transcription polymerase chain reaction (RT-PCR),
is the golden standard for clinical diagnosis, the tests may produce false negatives. Moreover, under the
pandemic situation, shortage of RT-PCR testing resources may also delay the following clinical decision
and treatment. Under such circumstances, chest CT imaging has become a valuable tool for both diagnosis
and prognosis of COVID-19 patients. In this study, we propose a weakly supervised deep learning strategy
for detecting and classifying COVID-19 infection from CT images. The proposed method can minimise the
requirements of manual labelling of CT images but still be able to obtain accurate infection detection and
distinguish COVID-19 from non-COVID-19 cases. Based on the promising results obtained qualitatively and
quantitatively, we can envisage a wide deployment of our developed technique in large-scale clinical studies.
INDEX TERMS COVID-19, deep learning, weakly supervision, CT images, classification, convolutional
neural network.
I. INTRODUCTION
Coronavirus disease 2019 (COVID-19) has been widespread
worldwide since December 2019 [1], [2]. It is highly contagious, and severe cases can lead to acute respiratory distress
or multiple organ failure [3]. On 11 March 2020, the WHO
has made the assessment that COVID-19 can be characterised
as a pandemic. As of 8th April 2020, in total, 1,391,890 cases
The associate editor coordinating the review of this manuscript and
approving it for publication was Shuihua Wang .
of COVID-19 have been recorded, and the death toll has
reached 81,478 with a rapid increase of cases in Europe and
North America.
The disease can be confirmed by using the reversetranscription polymerase chain reaction (RT-PCR) test [4].
While being the gold standard for diagnosis, confirming
COVID-19 patients using RT-PCR is time-consuming, and
both high false-negative rates and low sensitivities may put
hurdles for the presumptive patients to be identified and
treated early [3], [5], [6].
VOLUME 8, 2020 
 2020 IEEE. This article is free to access and download, along with rights for full text and data mining, re-use and analysis 118869S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
As a non-invasive imaging technique, computed tomography (CT) can detect those characteristics, e.g., bilateral
patchy shadows or ground glass opacity (GGO), manifested
in the COVID-19 infected lung [7], [8]. Hence CT may serve
as an important tool for COVID-19 patients to be screened
and diagnosed early. Despite its advantages, CT may share
some common imagery characteristics between COVID-19
and other types of pneumonia, making the automated distinction difficult.
Recently, deep learning based artificial intelligence (AI)
technology has demonstrated tremendous success in the field
of medical data analysis due to its capacity of extracting rich
features from multimodal clinical datasets [9]. Previously,
deep learning was developed for diagnosing and distinguishing bacterial and viral pneumonia from thoracic imaging
data [10]. In addition, attempts have been made to detect various chest CT imaging features [11]. In the current COVID-19
pandemic, deep learning based methods have been developed efficiently for the chest CT data analysis and classification [2], [3], [12]. Besides, deep learning algorithms have
been proposed for COVID-19 monitoring [13], screening [14]
and prediction of the hospital stay [15]. A full list of current
AI applications for COVID-19 related research can be found
elsewhere [16]. In this study, we will focus on the chest CT
image based localisation for the infected areas and disease
classification and diagnosis for the COVID-19 patients.
Although initial studies have demonstrated promising
results by using chest CT for the diagnosis of COVID-19 and
detection of the infected regions, most existing methods are
based on commonly used supervised learning scheme. This
requires a considerable amount of work on manual labelling
of the data; however, at such an outbreak situation clinicians
have very limited time to perform the tedious manual drawing, which may fail the implementation of such supervised
deep learning methods. In this study, we propose a weakly
supervised deep learning framework to detect COVID-19
infected regions fully automatically using chest CT data
acquired from multiple centres and multiple scanners. Based
on the detection results, we can also achieve the diagnosis
for the COVID-19 patients. In addition, we also test the
hypothesis that based on the CT radiological features, we can
classify COVID-19 cases from community acquired pneumonia (CAP) and non-pneumonia (NP) scans using the deep
neural networks we developed.
II. MATERIALS AND METHODS
A. PATIENTS AND DATA
This retrospective study was approved by the institutional
review board of the participating hospitals in accordance with
local ethics procedures. Further consent was waived with
approval. This study included 150 3D volumetric chest CT
exams of COVID-19, CAP and NP patients, respectively.
In total, 450 patient scans acquired from two participating
hospitals between September 2016 and March 2020 were
included for further analysis.
TABLE 1. Summary of the patient demographic statistics.
All the COVID-19 patients were confirmed as positive by
the RTPCR testing that were scanned from December 2019
to March 2020. According to the diagnosis and treatment
program of COVID-19 (Trial version sixth) issued by the
National Health Commission in China [17], the clinical classification of COVID-19 patients can be categorised as mild,
moderate, severe, and critical. All our COVID-19 patients
were at severe or critical stage and all the CT scans had been
performed within 3 days of hospitalisation.
CAP and other NP (no lung disease, lung nodules,
chronic inflammation, chronic obstructive pulmonary disease) patients were randomly chosen from the participating
hospitals between September 2016 and January 2020. The
inclusion criteria of CAP patients are in accordance with the
guidelines on the management of community-acquired pneumonia in adults published by the Infectious Diseases Society
of America/American Thoracic Society [18]. CAP diagnosis
is focused on the existence of identified clinical characteristics (e.g., cough, fever, sputum development, and pleuritic
chest pain) and is accompanied by pulmonary examination,
typically by chest X-ray and in our case using CT. In the regular examination of patients that are suspected to have CAP,
a chest radiograph is needed to determine the diagnosis and
to better distinguish CAP from other specific causes of cough
and fever, such as acute bronchitis. Although various CT
manifestations might be observed due to different pathogens,
all our CAP patients were laboratory confirmed bacterial culture positive cases or negative cases, e.g., with mycoplasma
and viral pneumonia. Our assumption is that the proposed
weakly supervised deep learning method can sense subtle
discrepancies in CT images acquired for CAP and COVID-19
patients. NP patients were diagnosed with no lung disease
or lung disease, e.g., lung nodules, chronic inflammation,
chronic obstructive pulmonary disease and others. It is of note
that the criterion for normal CT in the context is that the CT
examinations have shown no obvious lesions in both lungs.
Demographic statistics of the patients are as reported
in Table 1. One-way ANOVA (ANalysis Of VAriance) were
conducted on gender and age distribution over the three
patient groups and the p-values obtained suggest that there
were no significant differences found among three groups in
terms of gender and age distribution (p>0.05).
COVID-19 patients were admitted from two hospitals in China, including 138 patients from Hospital of
Wuhan Red Cross Society (WHRCH) and 12 patients
from Shenzhen Second Hospital (SZSH). Both CAP
and NP patients were recruited from SZSH. COVID-19
118870 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
TABLE 2. Imaging parameters of the CT systems used for COVID-19, CAP and NP patients.
patients were obtained from either Siemens SIEMENS
SOMATOM go.Now16 (WHRCH) or GE Revolution 256
(SZSH) CT systems. For the SIEMENS SOMATOM
go.Now16 CT system, the scanning parameters were as
follows: tube voltage = 130 kVp, automatic tube current modulation = 50 mAs, pitch = 1.5 mm, matrix =
512×512, slice thickness = 0.7 mm, field of view = 350 mm
× 350 mm, and reconstructed slice thickness = 1 mm. For
the GE Revolution 256 CT system, the scanning parameters
were set as tube voltage = 120 kVp, automatic tube current modulation = 150 mAs, pitch = 1.375 mm, matrix =
512 × 512, slice thickness = 0.625 mm, field of
view = 400 mm × 400 mm, and reconstructed slice thickness = 2 mm. All the CAP and NP patients were scanned
using SIEMENS SOMATOM Emotion CT system with the
main imaging parameters of tube voltage = 110 kVp, automatic tube current modulation = 70 mAs, pitch = 1.2 mm,
matrix = 512 × 512, slice thickness = 1.2mm, field of
view = 260 mm × 260 mm, and reconstructed slice thickness = 1.5 mm. Details are shown in Table 2.
B. DATASET FOR LUNG SEGMENTATION
In order to achieve a highly accurate lung segmentation that
can facilitate the following infection detection and classification, we utilised an open dataset (TCIA dataset) [19]
for training a deep neural network for the lung delineation. The data can be accessed from the Cancer Imaging
Archive (TCIA) Public Access.1
In total, 60 3D CT lung
scans were retrieved with manual delineations of the lung
anatomy. These open datasets were made publicly accessible
from the scans obtained by three different institutions: MD
Anderson Cancer Centre, Memorial Sloan-Kettering Cancer
Centre, and the MAASTRO clinic, with 20 cases from each
institution. All the data were scanned with matrix = 512 ×
512, the field of view = 500 mm×500 mm, and reconstructed
slice thickness varies at either 1 mm, 2.5 mm or 3 mm.
C. PRE- AND POST-PROCESSING FOR
LUNG SEGMENTATION
Data pre-processing steps were performed to standardise
data acquired from multiple centres and multiple scanners.
1http://doi.org/10.7937/K9/TCIA.2017.3r3fvz08
Instead of normalising input slices into a pre-defined
Hounsfield unit (HU) window, we designed a more flexible
scheme based on previously proposed image enhancement
methods [20], [21]. Rather than clipping based on HU windows, we proposed to use a fixed-sized sliding window WQ,S
(where Q denotes the size of the window and S denotes
the step length of the sliding procedure) to find the range
where covers most of the pixel values. This can reduce the
bias of data acquired from different centres and different
scanners. Loosely inspired by [22], we proposed a multi-view
U-Net [23] based segmentation network for lung segmentation. Our multi-view U-Net based segmentation network
consisted of a multi-window voting post-processing procedure and a sequential information attention module in order
to utilise the information from each view of the 3D volume
and reinforce the integrity of the 3D lung structure of the
delineation results. Our lung segmentation model was trained,
cross-validated and tested on the TCIA dataset with manual
ground truth. The trained lung segmentation model was then
used for inferencing the delineation of the lung anatomy of
the COVID-19, CAP and NP patients included in this study.
D. DETECTION AND CLASSIFICATION NETWORK
Inspired by the VGG architecture [24], we adopted the configuration that increased CNN depth using small convolution filters stacked with non-linearity injected in between,
as depicted in Figure 1. All convolution layers consisted of 3
× 3 kernels, batch normalisation and Rectified Linear Units.
The proposed CNN was fully convolutional consisting of five
convolutional blocks, i.e., Conv1, Conv2, Conv3, Conv4 and
Conv5 in the backbone architecture. The full architecture,
using shorthand notation, is 2 × C(32, 3, 1) − MP − 2 ×
C(64, 3, 1)−MP−3×C(128, 3, 1)−MP−3×C(256, 3, 1)−
MP − 3 × C(256, 3, 1) − MP, where C(d, f ,s) indicates a
convolution layer with d filters of spatial size f × f , applied
to the input with stride s. MP represents non-overlapping
max-pooling operation with a kernel size of 2 × 2.
E. MULTI-SCALE LEARNING
From the previous findings using CT [25]–[27], it is known
that infections of COVID-19 share the similar and common
radiographic features as CAP, such as GGO and airspace
VOLUME 8, 2020 118871S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 1. Network architecture of our proposed weakly supervised multi-scale learning framework for COVID-19/NP/CAP classification and lesions
detection.
consolidation. They frequently distribute bilaterally, peripherally in lower zone predominant, and the infectious areas
can vary significantly in size depending on the condition of
the patients. For example, in mild cases the lesions appear
to be small, but in severe cases they appear scattered and
spread around over a large area. Therefore, we proposed a
multi-scale learning scheme to cope with variations of the
size and location of the lesions. To implement this, we fed
the intermediate CNN representations, i.e., feature maps,
at Conv3, Conv4 and Conv5, respectively into the weakly
supervised classification layers, in which 1 × 1 convolution
was applied to mapping the feature maps down to the class
score maps (i.e., class activation maps). We then applied
a spatial aggregation with a Global Max Pooling (GMP)
operation to obtain categorical scores. The scores vectors at
Conv3, Conv4 and Conv5 level were aggregated by sum to
make a final prediction with a Softmax function. We then
trained the proposed model end-to-end by minimising the
following objective function
L = −
1
N
X
N
i=1
wi
fi(Sc(xi) − logX
K
k=1
e
Sk (xi)
), (1)
where there are N training images xi and K training classes.
Sk is the kth component in the score vector ∈ <K , and c
is the true class of xi
. As we encountered an imbalanced
classification, we added a class-balanced weighting factor
wi
to the cross-entropy loss, which was set by inverse class
frequency, i.e., wi =
1
freq(c)
. While this emphasised the
importance of a rare class during training, it showed no
difference between easy and hard examples. For instance,
in mild COVID-19 slices, infectious or diseased regions are
often very small and not prominent. Thus, they are prone to be
misclassified as NP examples. To address this, we introduced
another modulating factor, i.e., to down-weight easy examples and therefore focused the training on hard examples [28]
fi = (1−Pc)
γ
, where Pc is the true class posterior probability
of xi
. Intuitively, the modulating factor can reduce the loss
contribution from easy examples. This in turn increases the
importance of correcting misclassified examples. When an
example was misclassified and Pc was small, the factor f was
near 1 and the loss was unaffected. As Pc → 1, the factor
went to 0 and the loss for well-classified examples was downweighted. The parameter γ is a positive integer which can
smoothly adjust the rate at which easy examples are downweighted. As γ is increased the modulating effect of the factor
f is likely to be increased.
F. WEAKLY SUPERVISED LESIONS LOCALISATION
After determining the class score maps and the image category in a forward pass through the network, the discriminative
patterns corresponding to that category can then be localised
118872 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 2. Examples of saliency maps for COVID-19 lesions localisation: (a) shows an example input image, (b) shows the saliency map obtained at
Conv3, (c) shows the saliency map obtained at Conv4, (d) shows the saliency map obtained at Conv5, (e) shows the overlay of the joint saliency map
(pixel-wise multiplication of the Conv3, Conv4 and Conv5 saliency maps) with the input image, and (f) shows the resulting bounding boxes.
in the image. A coarse localisation could already be achieved
by directly relating each of the neurons in the class score maps
to its receptive field in the original image. However, it is also
possible to obtain pixel-wise maps containing information
about the location of class-specific target structures at the
resolution of the original input images. This can be achieved
by calculating how much each pixel influences the activation
of the neurons in the target score map. Such maps can be used
to obtain a much more accurate localisation, like the examples
shown in Figure 2.
In the following, we will show how categorical-specific
saliency maps can be obtained through the integrated gradients. Besides, we will also show how to post-process the
saliency maps from which we can extract bounding boxes
around the detected lesions.
1) CATEGORY-SPECIFIC SALIENCY
Generally, suppose we have a flattened input image denoted
as x = (x1, . . . , xn) ∈ <n
(number of pixels = n), categoryspecific saliency map can be obtained by calculating the
gradient of the predicted class score S(x) at the input x:
g =
∂S(x)
∂x = (g1, . . . , gn) ∈ <n
, where gi represents the contribution of individual pixel xi
to the prediction. In addition,
the gradient can be estimated by back-propagating the final
prediction score through each layer of the network. There
are many state-of-the-art back-propagation approaches,
including Guided-Backpropagation [29], DeepLift [30] and
Layer-wise Relevance Propagation (LRP) [31]. However,
Guided-Backpropagation method may break gradient sensitivity because it back-propagates through a ReLU node only
if the ReLU is turned on at the input. In particular, the lack
of sensitivity causes gradients to focus on irrelevant features
and results in undesired saliency localisation. DeepLift and
LRP methods tackle the sensitivity issue by computing discrete gradients instead of instantaneous gradients at the input.
However, they fail to satisfy the implementation invariance
because the chain rule does not hold for discrete gradients
in general. In doing so, the back-propagated gradients are
potentially sensitive to unimportant features of the models.
To deal with these limitations, we employ a feature attribution
method named ‘‘Integrated Gradients’’ [32] that assigns an
importance score φi(S(x), x) (similar to pixel-wise gradients)
to the ith pixel representing how much the pixel value adds or
subtracts from the network output. A large positive score indicates that pixel strongly increases the prediction score S(x),
while an importance score closes to zero indicates that pixel
does not influence S(x). To compute the importance score,
it needs to introduce a baseline input representing ‘‘absence’’
of the feature input, denoted as x
0 = (x
0
1
, . . . , x
0
n
) ∈ <n
, which
in our study, was a null image (filled with zeros) with the same
shape as input image x. We considered the straight-line path,
i.e., point-to-point from the baseline x
0
to the input x, and
computed the gradients at all points along the path. Integrated
gradients can be defined as
φi(S(x), x, x
0
)= (xi − x
0
i
)×
Z 1
α=0
∂S(x
0 + α(x − x
0
))
∂xi
dα, (2)
where α ∈ [0, 1]. Intuitively, integrated gradients can obtain
importance scores by accumulating gradients on images interpolated between the baseline value and the current input.
The integral in Eq. 2 can be efficiently approximated via a
summation of the gradients as:
φi(S(x), x, x
0
)≈(xi − x
0
i
)×
Xm
n=1
∂S(x
0 +
n
m × (x − x
0
))
∂xi
×
1
m
,
(3)
where m is the number of steps in the Riemann approximation
of the integral. We compute the approximation in a loop over
the set of inputs, i.e., for n = 1, . . . , m. The integrated
gradients are computed at different feature levels, in our
experiments, which are Conv3, Conv4 and Conv5 respectively, as shown in Figure 2(b), Figure 2(c) and Figure 2(d).
Then, a joint saliency can be obtained, as depicted
in Figure 2(e), by pixel-wise multiplication between the
multi-scale integrated gradients.
2) BOUNDING BOX EXTRACTION
Next, we post-processed the joint saliency map from which
a bounding box can be extracted. Firstly, we took the absolute value of the joint saliency map and blurred it with a
5 × 5 Gaussian kernel. Then, we thresholded the blurred
saliency map using the Isodata thresholding method [33]
that it iteratively decided a threshold segmenting the image
VOLUME 8, 2020 118873S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 3. Dice scores of the lung segmentation using different pre-processing and post-processing methods on the TCIA dataset. Left Panel: without any
pre-processing; Middle Panel: normalising using a pre-defined Hounsfield unit (HU) window; Right Panel: normalising using the proposed fixed-sized
sliding window. W/O P: without multi-view learning based post-processing; W P: with multi-view learning based post-processing.
into foreground and background, where the threshold was
midway between the mean intensities of sampled foreground
and background pixels. In doing so, we obtained a binary
mask on which we applied morphological operations (dilation followed by erosion) to close the small holes in the
foreground. Finally, we took the connected components with
areas above a certain threshold and fit the minimum rectangular bounding boxes around them. An example is shown
in Figure 2(f).
G. IMPLEMENTATION DETAILS
1) EXPERIMENTS SETUP
We trained the proposed model for both a three-way classification (i.e., K = 3 for NP, CAP and COVID-19) and three
binary classification tasks (K = 2), i.e., NP vs. COVID-19,
NP vs. CAP and CAP vs. COVID19, respectively. In the
three-way classification settings, we first trained individual
classifiers at different convolution blocks. In our experiment,
we chose Conv3, Conv4 and Conv5, respectively. Then,
we trained a joint classifier on the aggregated prediction
scores (as described in the ‘‘Multi-Scale Learning’’ Section).
All the classifiers were trained with the loss in Eq. 1. Finally,
we conducted a 5-fold cross-validation on all tasks that in
each category, we split the datasets into training, validation and test set. This can ensure that no samples (images)
originating from validation and test patients were used for
training. In each fold, we held out 20% of all samples
for validation and test, and the remaining were used for
training.
2) TRAINING CONFIGURATIONS
We implemented the proposed model (as depicted
in Figure 1) using Tensorflow 1.14.0. All models were trained
from scratch on four Nividia GeForce GTX 1080 Ti GPUs
with an Adam optimiser (learning rate: 10−4
, β1 = 0.5,
β2 = 0.9 and  = 10−8
). We set γ to 1 in the focal
modulator f and the total number of training iterations was set
to 20,000. Early stopping was enabled to terminate training
automatically when validation loss stopped decreasing for
1,000 iterations. We run validation once every 500 iterations
of training, a checkpoint was saved automatically if the current validation accuracy exceeded the previous best validation
accuracy. Once the training was terminated, we generated
a frozen graph on the latest checkpoint and saved it in.pb
format. For testing, we simply loaded the frozen graphs
and retrieved the required nodes. Empirically, we found
that 20 to 30 steps were good enough to approximate the
integral when computing the integrated gradients; thus, we fix
m = 25 in Eq. 3.
3) DATA AUGMENTATION
We applied several random on-the-fly data augmentation
strategies during training, including (1) cropping square
patches at the centre of the input frames with a scaling factor
randomly chosen between 0.7 to 1, and resized the crops to
the size of 224 × 224 (input resolution); (2) rotation with an
angle randomly selected within θ = −25o
to 25o
; (3) Random
horizontal reflection, i.e., flipped the images in the left-right
direction with a probability p = 0.5; and (4) adjust contrast
118874 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 4. Results of the multi-scale COVID-19 class activation mapping.
by randomly darkening or brightening with a factor ranging
between 0.5 and 1.5.
H. EVALUATION METRICS
Using positive results of the RTPCR testing as the ground
truth labelling for the COVID-19 group and diagnosis results
of CAP and NP patients, accuracy, precision, sensitivity and
specificity [34], [35] of our classification framework were
calculated. We also carried out the area under the receiver
operating characteristic curve (AUC) analysis for the quantification of our classification performance. For the lung segmentation, we used Dice score [36] to evaluate the accuracy.
III. EXPERIMENTS AND RESULTS
A. LUNG SEGMENTATION
In order to evaluate the lung segmentation network, we randomly split the 60 TCIA data with ground truth into
40 training, 10 validation and 10 independent testing datasets.
Ablation study results of different pre-processing and postprocessing methods using Dice scores are shown in Figure 3.
B. INFECTION DETECTION
1) CLASS ACTIVATION MAPPING
As a result of multi-scale learning, Figure 4 illustrates
some examples of COVID-19 class activation maps (CAMs)
obtained at the different feature levels, i.e., Conv3, Conv4
and Conv5. The CAMs depict the spatial distribution of classification probability on which the hot areas indicate where
infected areas are. The hotter the areas, the more likely they
are infected. Of note from the multi-scale CAMs, our proposed model learns to capture the distributions of lesions with
different scale: for instance, the large patchy-like lesions,
such as crazy paving sign and consolidation; and also small
nodule-like lesions, such as ground-glass opacities (GGO)
and bronchovascular thickening. Although the CAMs can
indicate where the diseased regions are, they are still too
coarse to localise and estimate the extent of lesions precisely.
The saliency maps shown in Figure 5, on the other hand,
can provide pixel-level information that delineates the exact
extent of the lesions, and therefore can deduce a precise
localisation of the lesions. Notably from the saliency maps,
VOLUME 8, 2020 118875S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 5. Multi-scale detection of COVID-19 lesions with varied size. Green box: small lesions. Yellow box: mix of small and large patchy or strip like
lesions. Red box: large lesions.
the mid-level layer, i.e., Conv3 can learn to detect small
lesions (GGO most frequently), especially those distributed
peripherally and subpleurally. However, Conv3 is not able to
capture larger patchy-like lesions, and this may be because of
the limited receptive field at the mid-layer. On the contrary,
the higher-level layers, e.g., Conv4 and Conv5, having sufficiently large receptive filed to detect the diffuse and patchylike lesions, such as crazy paving sign and consolidation,
which are often distributed centrally and peribronchially.
However, Conv4 and Conv5 tend to overestimate the extent
of small lesions. The multi-scale features complement each
other and result in more precise localisation and estimation of the lesions extent, as shown from the joint saliency
maps.
2) CATEGORICAL-SPECIFIC SALIENCY
Figure 6 shows the examples of categorical-specific joint
saliency computed by integrated gradients. It shows the original inputs on the left and the overlaid saliency on the right.
CAMs showed in Figure 4 only depict the spatial distribution
of infection. However, it can not be used for precise localisation of the lesions. The saliency maps, on the other hand,
can provide pixel-level information that delineates the exact
extent of the lesions so providing a precise localisation of the
lesions.
The saliency maps can also be useful for diagnosis that the
percentage of infection to lung areas can be estimated automatically. These saliency maps highlight the pixels that contribute to increasing categorical-specific scores: the brighter
the pixels, the more significant the contribution. Intuitively,
one can also interpret this as the brighter the pixels are,
the more critical features to the network to make the decision
(prediction). It is of note that in Figure 4 and Figure 6, there
is not only an inter-class contrast variation (due to the data
are collected from multi-institutions) but also an intra-class
contrast variation, especially in COVID-19 group. In our
experiments, we found that histogram matching can suppress lesions, especially on COVID-19 images; for instance,
GGO disappears or become less apparent. Besides, this
leads to inferior performance of detection. Therefore, instead
of directly applying histogram matching, we applied random on-the-fly contrast adjustment for data augmentation at
training time. This turns out to be very effective, as demonstrated in Figure 6, our proposed model learns to be invariant
to image contrast, and precisely capture the lesions.
In particular, in Figure 8, we randomly selected typical
example images to illustrate the variations of the image contrast in COVID-19 cases and compared the saliency maps
obtained from models trained with and without contrast
augmentation (CA vs. NCA). We found that without contrast augmentation, the saliency maps tend to be noisy and
poor in localisation, as mis-detection can be observed often
in the cases such as either only partial instances of infection being captured or the regions without infection being
captured. Whereas, with contrast augmentation, the learned
models generate more discriminative saliency maps and
localisation of infected areas is robust and more accurate
against the contrast variation. As can be seen (enclosed by
green box), our model with contrast augmentation is capable
of capturing all the diseased regions and highlighting their
extent precisely, regardless single or multiple instances of
infection.
118876 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 6. Results of the categorical-specific joint saliency.
In addition, from the COVID-19 and CAP saliency,
we found that the CAP lesions are generally smaller and
more constrained locally compare to COVID-19 cases that
often have multiple infected regions and lesions are massive and scattered. It should also be noted that COVID-19
and CAP lesions do share similar radiographic features,
such as GGO and air space consolidation. Besides, GGOs
appear frequently in subpleural regions as well in CAP cases.
Interestingly, from the saliency map for the NP cases,
we found the network takes the pulmonary arteries as
the salient feature. Finally, Figure 7 shows the bounding boxes extracted from COVID-19 and CAP saliency
maps (corresponding to the examples in Figure 6).
We found the results agree with our primary findings that
CAP cases have less infected areas and often there is
single-instance of infection, in contrast, COVID-19 cases
often have more infected areas (multi-instances of infection),
and the COVID-19 lesions vary a lot in terms of extent.
Overall, CAP infection areas are smaller compare to those of
COVID-19.
C. CLASSIFICATION PERFORMANCE
Performance of our proposed model for each specific task
was evaluated with 5-fold cross-validation, and the results on
the test set are reported and summarised in Table 3. We use
five evaluation metrics, which are accuracy (ACC), precision
(PRC), sensitivity (SEN), specificity (SPE) and the area under
the ROC curve (AUC). We report the mean of 5-fold crossvalidation results in each metric with the 95% confidence
interval. We also compared our proposed method with a
VOLUME 8, 2020 118877S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 7. Bounding boxes extracted from saliency for COVID-19 and CAP examples. (Corresponding to the examples in Figure 6).
FIGURE 8. Effect of applying random contrast augmentation (in data augmentation). Contrast adjustment leads to better saliency quality (less noisy) and
more precise and contrast-invariant detection of infected areas. Cyan arrows: false positives of the saliency maps; Pink arrows: false negatives of the
saliency maps; NCA: No Contrast Adjustment; CA: with Contrast Adjustment.
reimplementation of the Navigator-Teacher-Scrutinizer
Network (NTS-NET) [37].
As described earlier in the experimental settings, basically
we have two groups of tasks: three-way classification tasks
(indicated by ∗
) and binary classification tasks (indicated
by o
), and two learning configurations: single-scale learning (indicated by †
) that assigns an auxiliary classifier to
a specific feature level, and multi-scale learning (indicated
by ‡
) that aggregates the multi-level prediction scores then
trained with a joint classifier. All the binary tasks listed were
trained with the multi-scale learning. In terms of three-way
classification, we found the multi-scale learning with joint
classifier achieves superior overall performance than any of
the single-scale learning tasks. It is of note that among the
single-scale learning tasks, classification with Conv4 and
Conv5 features achieve very similar performance in every
metric, which is significantly better than classification with
mid-level, i.e., Conv3 features. One possible explanation is
the mid-level features are not sufficiently semantic compare
to higher-level features, i.e., Conv4 and Conv5. As we know,
118878 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
TABLE 3. The overall classification performance comparison between different tasks on the test set. Values in brackets are 95% confidence intervals.
AUC: area under the receiver operating characteristic curve, COVID-19: coronovirus disease 2019, CAP: Community Acquired Pneumonia, NP:
Non-Pneumonia. ∗
: three-way classification tasks (i.e., NP/CAP/COVID-19). o
: binary classification tasks. †: single-scale learning. ‡: multi-scale learning.
NCA: No Contrast Adjustment (data augmentation).
TABLE 4. The performance (breakdown into each individual class) of three-way classification on the test set. Values in brackets are 95% confidence
intervals. AUC: area under the receiver operating characteristic curve, COVID-19: coronovirus disease 2019, CAP: Community Acquired Pneumonia, NP:
non-pneumonia. ∗
: no random contrast adjustment. †: with random contrast adjustment.
high-level CNN representations are semantically strong but
poorly at preserving spatial details, whereas mid-lower level
CNN representations preserve well the local features but lack
of semantic information.
Furthermore, it is of note that, overall, binary classification
tasks achieve significantly better performance than three-way
classification, especially in the tasks, such as NP/COVID-19
and NP/CAP. It can be seen our proposed model is reasonably
good at distinguishing COVID-19 cases from NP cases as
suggested by the results, showing that it achieves a mean ACC
of 96.2%, PRC of 97.3%, SEN of 94.5%, SPE of 95.3% and
AUC of 0.970, respectively. One can explain this is because
binary classification is less complicated, and there is also
less uncertainty than three-way classification. This may also
because COVID-19 and CAP image features are intrinsically
discriminative compare to the NP cases. For instance, as the
COVID-19 cases demonstrated earlier, there is often a combination of various diseased patterns and large areas of infection
on the scans.
Last but not least, we found that the performance of
COVID-19/CAP classification is the least superior among
all the binary classification tasks. One possible reason is
COVID-19 shares the similar radiographic features with
CAP, such as GGO and airspace consolidation and the network capacity may not be enough to learn disease-specific
representations. Nevertheless, the results obtained using
our proposed method outperformed the ones obtained by
the NTS-NET.
We also break down the overall performance, i.e., the
joint classifier into classes, and the classification metrics are
reported for each class, as shown in Table 4 and Figure. 9. We
found that the models learned without contrast augmentation
are biased that the classification performance for COVID-19
is significantly better than the other two classes. This may
because models learn to discriminate the classes based on
image style (contrast) rather than the content (normal or
disease patterns) and the COVID-19 class in our data has
the most discriminative contrast style (high variability in
brightness) among all three classes. In comparison, learning
with contrast augmentation results in superior overall classification performance (Table 3) and no class bias (Table 4). In
addition, the ‘‘COVID-19’’ and the ‘‘NP’’ classes achieve the
comparable performance in each metric and the ‘‘NP’’ class
has higher sensitivity (91.3%) than the COVID-19 (87.6%)
and CAP (83.0%). Besides, we found, overall, the ‘‘COVID’’
remains the best performed and the most discriminative class
with a mean AUC of 0.923, compared to the ‘‘CAP’’ (0.864)
and the ‘‘NP’’ (0.901). It can also be noted that the overall
results for the class ‘‘CAP’’ are moderately lower than those
of the ‘‘NP’’ and ‘‘COVID-19’’. This could be correlated
VOLUME 8, 2020 118879S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
FIGURE 9. Receiver operating characteristic (ROC) of individual categories for three-way classification (5-fold cross-validated). (a) NP with AUC
of 0.90±0.03 (mean±standard deviation); (b) CAP with AUC of 0.86±0.03 (c) COVID-19 with AUC of 0.92±0.02. The green region indicates the
95%CI. COVID-19: coronavirus disease 2019, CAP: Community Acquired Pneumonia, NP: Non-Pneumonia, CI: Confidence Interval.
with our finding in the COVID-19/CAP classification that
because of similar appearance, the ‘‘CAP’’ class is likely to be
misclassified as the ‘‘COVID-19’’ sometimes. Also, another
possible reason is that the network could have learned and
be distracted by the few ‘‘NP noises’’, and there might be a
fractional number of non-infected slices in between the CAP
training samples. This is because we sampled all the available
slices from each subject, and there might be a few slices
having no infections.
IV. DISCUSSIONS
In this work, we have presented a novel weakly supervised
deep learning framework that is capable of learning to detect
and localise lesions on COVID-19 and CAP CT scans from
image-level label only. Different from other works, we leverage the representation learning on multiple feature levels and
have explained what features can be learned at each level.
For instance, the high-level representation, i.e., Conv5 captures the patch-like lesions that generally have a large extent.
However, it tends to discard small local lesions. This is well
complemented by the mid-level representations (Figure 4),
i.e., Conv4 and Conv5, from which the lesions detected also
correspond to our clinical findings that the infections usually
located in the peripheral lung (95%), mainly in the inferior
lobe of the lungs (65%), especially in the posterior segment
(51%). We speculate that it is mainly because there are more
well-developed bronchioles, alveoli, rich blood flows and
immune cells such as lymphatic cells in the periphery. These
immune cells played a vital role in the inflammation caused
by the virus. We have also demonstrated that combing multiscale saliency maps, generated by integrated gradients, is the
key to achieve a precise localisation of multi-instance lesions.
Furthermore, from a clinical perspective, the joint saliency
is useful that it provides a reasonable estimation of the
118880 VOLUME 8, 2020S. Hu et al.: Weakly Supervised Deep Learning for COVID-19 Infection Detection and Classification From CT Images
percentage of infected lung areas, which is a crucial factor
that clinicians take account for evaluating the severity of a
COVID-19 patient. Besides, the classification performance
of the proposed network has been studied extensively that
we have not only conducted three-way classification but also
binary classification by combining any two of the classes.
We found one limitation of the proposed network is that
it is not discriminative enough when it comes to separate the
CAP from COVID-19. We suspect this is due to the limited
capacity of the backbone CNN that a straightforward way of
boosting CNN capacity is to increase the number of feature
channels at each level. Another attempt in the future would
be employing more advanced backbone architecture, such as
Resnet and Inception. Another limitation in this work is that
we have trained the networks on individual slices (images)
that we use all available samples for each subject. However,
for the CAP or COVID-19 subjects, there might be fractional
non-infection slices in between which could introduce noises
in training, which have been confirmed by scrutinisation by
our clinicians. In the future, we can address the limitation
by attention-based multiple instances learning that instead
of training on individual slices, we put the patient-specific
slices into a bag and train on bags. The network will learn
to assign weights to individual slices in a COVDI-19 or CAP
positive bag and automatically sample those high weighted
slices for infection detection. Further supervision via labelled
non-infection slices may also boost the performance of our
proposed model, but at a cost of time-consuming manual
labelling procedure.
V. CONCLUSION
In this study, we designed a weakly supervised deep learning framework for fast and fully-automated detection and
classification of COVID-19 infection using retrospectively
extracted CT images from multi-scanners and multi-centres.
Our framework can distinguish COVID-19 cases accurately
from CAP and NP patients. It can also pinpoint the exact position of the lesions or inflammations caused by the COVID19, and therefore can also potentially provide advice on
patient severity in order to guide the following triage and
treatment. Experimental findings have indicated that the proposed model achieves high accuracy, precision and AUC
for the classification, as well as promising qualitative visualisation for the lesion detections. Based on these findings
we can envisage a large-scale deployment of the developed
framework.
ACKNOWLEDGMENT
(Shaoping Hu, Yuan Gao, and Zhangming Niu contributed
equally to this work.)


NEW_PAPER


Received June 14, 2020, accepted July 10, 2020, date of publication July 20, 2020, date of current version July 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3010287
Can AI Help in Screening Viral and COVID-19
Pneumonia?
MUHAMMAD E. H. CHOWDHURY 1
, (Member, IEEE), TAWSIFUR RAHMAN 3
,
AMITH KHANDAKAR 1
, (Senior Member, IEEE), RASHID MAZHAR2
,
MUHAMMAD ABDUL KADIR 3
, ZAID BIN MAHBUB4
, KHANDAKAR REAJUL ISLAM5
,
MUHAMMAD SALMAN KHAN 6,8, (Member, IEEE),
ATIF IQBAL 1
, (Senior Member, IEEE), NASSER AL EMADI1
,
MAMUN BIN IBNE REAZ 7
, (Senior Member, IEEE),
AND MOHAMMAD TARIQUL ISLAM 7
, (Senior Member, IEEE)
1Department of Electrical Engineering, Qatar University, Doha, Qatar
2Thoracic Surgery, Hamad General Hospital, Doha, Qatar
3Department of Biomedical Physics and Technology, University of Dhaka, Dhaka 1000, Bangladesh
4Department of Mathematics and Physics, North South University, Dhaka 1229, Bangladesh
5Department of Orthodontics, Bangabandhu Sheikh Mujib Medical University, Dhaka 1000, Bangladesh
6Department of Electrical Engineering (JC), University of Engineering and Technology, Peshawar 25120, Pakistan
7Department of Electrical, Electronic and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi 43600, Malaysia
8Artificial Intelligence in Healthcare, Intelligent Information Processing Laboratory, National Center for Artificial Intelligence, University of Engineering and
Technology, Peshawar 48550, Pakistan
Corresponding author: Muhammad E. H. Chowdhury (mchowdhury@qu.edu.qa)
This work was supported by the Qatar National Research Fund, a member of Qatar Foundation, Doha, Qatar, under Grant
NPRP12S-0227-190164. The statements made herein are solely the responsibility of the authors.
ABSTRACT Coronavirus disease (COVID-19) is a pandemic disease, which has already caused
thousands of causalities and infected several millions of people worldwide. Any technological tool
enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the
healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the
Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires
specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative
in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI)
in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to
propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray
images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public
database was created by the authors combining several public databases and also by collecting images from
recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and
1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation
to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks
were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral
and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision,
sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%,
97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly
improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic
where disease burden and need for preventive measures are at odds with available resources.
INDEX TERMS Artificial intelligence, COVID-19 pneumonia, machine learning, transfer learning, viral
pneumonia, computer-aided diagnostic tool.
The associate editor coordinating the review of this manuscript and
approving it for publication was Xin Zhang .
I. INTRODUCTION
Coronavirus disease (COVID-19) is an extremely contagious
disease and it has been declared as a pandemic by the World
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 132665M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
Health Organization (WHO) on 11th March 2020 considering the extent of its spread throughout the world [1].
The pandemic declaration also stressed the deep concerns
of the alarming rate of spread and severity of COVID-19.
It is the first recorded pandemic caused by any coronavirus.
It is defined as a global health crisis of its time, which has
spread all over the world. Governments of different countries
have imposed border restrictions, flight restrictions, social
distancing, and increasing awareness of hygiene. However,
the virus is still spreading at very rapid rate. While most of
the people infected with the COVID-19 experienced mild
to moderate respiratory illness, some developed a deadly
pneumonia. There are assumptions that elderly people with
underlying medical problems like cardiovascular disease,
diabetes, chronic respiratory disease, renal or hepatic diseases
and cancer are more likely to develop serious illness [2].
Until now, no specific vaccine or treatment for COVID-19
has been invented. However, there are many ongoing clinical
trials evaluating potential treatments. More than 7.5 million
infected cases were found in more than 200 countries until
11th June 2020, among which around 421 thousand deaths,
3.8 million recovery, 3.2 million mild cases and 54 thousand
critical cases were reported [3], [4].
In order to combat with the spreading of COVID-19,
effective screening and immediate medical response for the
infected patients is a crying need. Reverse Transcription
Polymerase chain reaction (RT-PCR) is the most used clinical
screening method for the COVID-19 patients, which uses
respiratory specimens for testing [5]. RT-PCR is used as a
reference method for the detection of COVID-19 patients,
however, the technique is manual, complicated, laborious
and time-consuming with a positivity rate of only 63% [5].
Moreover, there is a significant shortage of its supply,
which leads to delay in the disease prevention efforts [6].
Many countries are facing difficulties with incorrect number
of COVID-19 positive cases because of not only due to
the lack of test kits but also due to the delay in the
test results [7]. These delays can lead to infected patients
interacting with the healthy patients and infecting them in
the process. It is reported that the RT-PCR kit costs about
USD 120-130 and also requires a specialized biosafety lab
to house the PCR machine, each of which may cost USD
15,000 to USD 90,000 [8]. Such an expensive screening
tool with delayed test results is leading to spread of the
disease, making the scenario worst. This is not an issue
for the low-income countries only but certain developed
countries are also struggling to tackle with this [9]. The
other diagnosis methods of the COVID-19 include clinical
symptoms analysis, epidemiological history and positive
radiographic images (computed tomography (CT) /Chest
radiograph (CXR)) as well as positive pathogenic testing.
The clinical characteristics of severe COVID-19 infection is
that of bronchopneumonia causing fever, cough, dyspnea, and
respiratory failure with acute respiratory distress syndrome
(ARDS) [10]–[13]. Readily available radiological imaging
is an important diagnostic tool for COVID-19. The majority
of COVID-19 cases have similar features on radiographic
images including bilateral, multi-focal, ground-glass opacities with a peripheral or posterior distribution, mainly in the
lower lobes, in the early stage and pulmonary consolidation
in the late stage [13]–[19]. Although typical CXR images
may help early screening of suspected cases, the images of
various viral pneumonias are similar and they overlap with
other infectious and inflammatory lung diseases. Therefore,
it is difficult for radiologists to distinguish COVID-19 from
other viral pneumonias. The symptoms of COVID-19 being
similar to that of viral pneumonia can sometimes lead to
wrong diagnosis in the current situation while hospitals are
overloaded and working round the clock. Such an incorrect
diagnosis can lead to a non-COVID viral Pneumonia being
falsely labelled as highly suspicious of having COVID-19 and
thus delaying in treatment with consequent costs, effort and
risk of exposure to positive COVID-19 patients.
Currently many biomedical health problems and complications (e.g. brain tumor detection, breast cancer detection, etc.) are using Artificial Intelligence (AI) based
solutions [20]–[25]. Deep learning techniques can reveal
image features, which are not apparent in the original
images. Specifically, Convolutional Neural Network (CNN)
has been proven extremely beneficial in feature extraction
and learning and therefore, widely adopted by the research
community [26]. CNN was used to enhance image quality
in low-light images from a high-speed video endoscopy [27]
and was also applied to identify the nature of pulmonary
nodules via CT images, the diagnosis of pediatric pneumonia
via chest X-ray images, automated labelling of polyps
during colonoscopic videos, cystoscopic image analysis
from videos [28]–[31]. Deep learning techniques on chest
X-Rays are getting popularity with the availability of the
deep CNNs and the promising results it has shown in
different applications. Moreover, there is an abundance
of data available for training different machine-learning
models. Transfer learning technique has significantly eased
the process by allowing quickly retrain a very deep CNN
network with a comparatively low number of images.
Concept of transfer learning in deep learning framework
was used by Vikash et al [32] for the detection of
pneumonia using pre-trained ImageNet models [33] and
their ensembles. A customized VGG16 model was used
by Xianghong et al. [34] for lung regions identification and
different types of pneumonia classification. Wang et al [35]
used a large hospital-scale dataset for classification and
localization of common thoracic diseases and Ronneburger
et al [36] used image augmentation on a small set of images
to train deep CNN for image segmentation problem to achieve
better performance. Rajpurkar et al [37] reported a 121-
layer CNN (CheXNet) on chest X-rays to detect 14 different
pathologies, including pneumonia using an ensemble of
different networks. A pre-trained DenseNet-121 and feature
extraction techniques were used in the accurate identification
of 14 thoracic diseases in [38]. Sundaram et al. [39] used
AlexNet and GoogLeNet with image augmentation to obtain
132666 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
an Area Under the Curve (AUC) of 0.95 in pneumonia
detection.
Recently, several groups have reported deep machine
learning techniques using X-ray images for detecting
COVID-19 pneumonia [40]–[56]. However, most of these
groups used rather a small dataset containing only a few
COVID-19 samples. This makes it difficult to generalize
their results reported in these articles and cannot guarantee that the reported performance will retain when these
models will be tested on a larger dataset. Ioannis et al. [39]
reported transfer learning approach for classifying dataset
of 1427 X-ray images containing 224 COVID-19, 700 Bacterial Pneumonia and 504 Normal X-ray images with
accuracy, sensitivity, and specificity of 96.78%, 98.66%,
and 96.46% respectively. Different pre-trained models were
compared however, the reported results were based on a small
dataset. Ashfar et al. [43] proposed a Capsule Networks,
called COVID-CAPS rather than a conventional CNN to deal
with a smaller dataset. COVID-CAPS was reported to achieve
an accuracy of 95.7%, sensitivity of 90%, and specificity
of 95.8%. Abbas et al. [44] have worked on a very small
database of 105 COVID-19, 80 Normal and 11 SARS X-ray
images to detect COVID-19 X-ray images using modified
pre-trained CNN model (DeTraC-Decompose, Transfer and
Compose) to project the high-dimension feature space into
a lower one. This would help to produce more homogenous
classes, lessen the memory requirements and achieved
accuracy, sensitivity and specificity of 95.12%, 97.91% and
91.87% respectively. Wang and Wong in [40] introduced a
deep CNN, called COVID-Net for the detection of COVID-19
cases from around 14k chest X-ray images, however
the achieved accuracy was 83.5%. Ucar et al. [47] has
fine-tuned SqueezeNet pre-trained network with Bayesian
optimization to classify COVID-19 images, which showed
promising result on a small dataset. This approach should
be evaluated on a large COVID and non-COVID dataset.
Khan et al. [51] applied transfer learning approach on
310 normal, 330 bacterial pneumonia, 327 viral pneumonia
and 284 COVID-19 pneumonia images. However, different
machine learning algorithms were not evaluated in this study
and the experimental protocol was not clear in this work.
In summary, several recent works were reported on transfer
learning approach for the detection of COVID-19 X-ray
images from a small dataset with promising results however
these needed to be verified on a large dataset. Some group
have modified or fine-tuned the pre-trained networks to
achieve better performance while some groups use capsule
networks. A rigorous experiment on a large database of
COVID and non-COVID classes are very few and missing
in case of transfer learning approach. The authors in this
paper have prepared a large database of X-ray images
of 1579 normal, 1485 viral pneumonia and 423 COVID-19
positive pneumonia and made this publicly available so that
other researchers can get benefit from it. Moreover, eight
different pre-trained deep learning networks were trained,
validated and tested for two different classification schemes.
One classification model was trained to classify COVID-19
and normal X-ray images while other was trained to classify
normal, viral pneumonia and COVID-19 pneumonia images.
Both of the experiments were evaluated with and without
image augmentation technique to study the effect of image
augmentation in this particular problem.
II. METHODOLOGY
Deep convolutional neural networks typically perform better
with a larger dataset than a smaller one. Transfer learning
can be used in the training of deep CNNs where the dataset
is not large. The concept of transfer learning uses the
trained model from large dataset such as ImageNet [57] and
modify the Softmax and classification layer of the pre-trained
networks. The pre-trained weights are then used for faster
training of the network for an application with comparatively
smaller dataset. This removes the requirement of having
large dataset and also reduces the long training period as is
required by the deep learning algorithm when developed from
scratch [58], [59].
Although there are a large number of COVID-19 patients
infected worldwide, the number of chest X-ray images
publicly available online are small and scattered. Therefore,
in this work, authors have reported a comparatively large
dataset of COVID-19 positive chest X-ray images while
normal and viral pneumonia images are readily available
publicly and used for this study. A Kaggle database was
created by the authors to make the database publicly available
to the researchers worldwide and the trained models were
made available so that others can get benefit of this study [60].
A. DATABASE DESCRIPTION
In this study, posterior-to-anterior (AP)/anterior-to-posterior
(PA) image of chest X-ray was used as this view of radiography is widely used by radiologist in clinical diagnosis.
Six different sub-databases were used to create one database.
Among these databases, COVID-19 database was developed by the authors from collected and publicly available
databases, while normal and viral pneumonia databases were
created from publicly available Kaggle databases. In the
following section, authors have summarized how this dataset
is created.
COVID-19 sub-database, comprising of 423 AP/PA
images, was created from the following four major data
sources.
• Italian Society of Medical and Interventional
Radiology (SIRM) COVID-19 DATABASE :
SIRM COVID-19 database [61] reports 384 COVID-19
positive radiographic images (CXR and CT) with varying
resolution. Out of 384 radiographic images, 94 images are
chest X-ray images and 290 images are lung CT images.
This database is updated in a random manner and until 10th
May 2020, there were 71 confirmed COVID-19 cases were
reported in this database.
• Novel Corona Virus 2019 Dataset :
VOLUME 8, 2020 132667M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
Joseph Paul Cohen and Paul Morrison and Lan Dao
have created a public database in GitHub [62] by collecting 319 radiographic images of COVID-19, Middle
East respiratory syndrome (MERS), Severe acute respiratory syndrome (SARS) and ARDS from the published
articles and online resources. In this database, they have
collected 250 COVID-19 positive chest X-ray images and
25 COVID-19 positive lung CT images with varying image
resolutions. However, in this study, authors have considered
134 COVID-19 positive chest X-ray images, which are
different from the images of the database that the authors
created from different articles.
• COVID-19 positive chest x-ray images from different
articles:
GitHub database has encouraged the authors to look into
the literature and interestingly more than 1200 articles were
published in less than two-months of period. Authors have
observed that the GitHub database has not collected most
of the X-ray and CT images rather a small number of
images were in that database. Moreover, the images in SIRM
and GitHub database are in random size depending on the
X-ray machine resolution and the articles from which it was
taken. Therefore, authors have carried out a tedious task of
collecting and indexing the X-ray and CT images from all the
recently publicly available articles and online sources. These
articles and the radiographic images were then compared with
the GitHub database to avoid duplication. Authors managed
to collect 60 COVID-19 positive chest X-ray images from
43 recently published articles [60], which were not listed
in the GitHub database and 32 positive chest x-ray images
from Radiopaedia [63], which were not listed in the GitHub
database.
• COVID-19 Chest imaging at thread reader:
A physician has shared 103 images for 50 different cases
with varying resolution from his hospital in Spain to the
Chest imaging at thread reader [64]. Images from RSNAPneumonia-Detection-Challenge database along with the
Chest X-ray Images database from Kaggle were used
to create the normal and viral pneumonia sub-databases
of 1579 and 1485 X-ray images respectively.
• RSNA-Pneumonia-Detection-Challenge
In 2018, Radiology Society of North America (RSNA)
organized an artificial intelligence (AI) challenge to detect
pneumonia from the chest X-ray images. In this database,
normal chest X-ray with no lung infection and non-COVID
pneumonia images were available [65].
• Chest X-Ray Images (pneumonia):
Kaggle chest X-ray database is a very popular database,
which has 5247 chest X-ray images of normal, viral and
bacterial pneumonia with resolution varying from 400p to
2000p [66]. Out of 5247 chest X-ray images, 3906 images are
from different subjects affected by pneumonia (2561 images
for bacterial pneumonia and 1345 images for viral pneumonia) and 1341 images are from normal subjects. Chest X-ray
images for normal and viral pneumonia were used from this
FIGURE 1. Sample X-ray image from the dataset: COVID-19 X-ray image
(A), normal X-ray image (B), and viral pneumonia X-ray image (C).
database to create the new database. Figure 1 shows sample
images from the database for normal, COVID-19 pneumonia,
and viral pneumonia chest X-ray images.
B. CNN MODEL SELECTION
Eight different pre-trained CNN models were trained, validated and tested in this study. The experimental evaluation of
MobileNetv2, SqueezeNet [67], ResNet18 [68], ResNet101
and DenseNet201 were performed utilizing MATLAB 2020a
running on a computer with Intel
i7-core @3.6GHz processor and 16GB RAM, with an 8-GB NVIDIA GeForce
GTX 1080 graphics processing unit (GPU) card on 64-bit
Windows 10 operating system. On the other hand, CheXNet,
Inceptionv3 and VGG19 were implemented using PyTorch
library with Python on Intel
R Xeon
R CPU E5-2697 v4 @
2,30GHz and 64 GB RAM, with a 16 GB NVIDIA GeForce
GTX 1080 GPU. Three comparatively shallow networks
(MobileNetv2, SqueezeNet and ResNet18) and five deep
networks (Inceptionv3, ResNet101, CheXNet, VGG19 and
DenseNet201) were evaluated in this study to investigate
whether shallow or deep networks are suitable for this
application. Two different variants of ResNet were used
to compare specifically the impact of shallow and deep
networks with similar structure. Performance difference due
to initially trained on different image classes other than
X-ray images were compared with CheXNet, which is a
121-layer DenseNet variant and the only network pre-trained
on X-ray images. Several researchers showed the reliability of
using this network for COVID-19 classification. Therefore, it
was important to investigate whether CheXNet outperforms
other deep networks or not. Eight pre-trained CNN models
were trained using stochastic Gradient Descent (SGD)
with momentum optimizer with learning rate, α = 10−3
,
momentum update, β = 0.9 and mini-batch size of 16 images
with 20 Back Propagation epochs. Fivefold cross-validation
result was averaged to produce the final receiver operating
characteristic (ROC) curve, confusion matrix, and evaluation
matrices.
Two different experiments were carried out in this study:
i) Two-class image classification using models trained
without and with images augmentation, and ii) Three-class
image classification using models trained without and
with image augmentation. Figure 2 illustrates the overall
system diagram with the three-class image classification
problem.
132668 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 2. Block diagram of the overall system.
TABLE 1. Number of images per class and per fold before and after data augmentation.
C. PREPROCESSING
Chest X-ray images were only resized before applying as
input to the networks. Input requirements for different CNNs
are different. For SqueezeNet, the images were resized
to 227 × 227 pixels whereas for mobilenetv2, ResNet18,
ResNet101, VGG19 and DenseNet201, the images were
resized to 224 × 224 pixels; and for Inceptionv3 the images
were resized to 299×299 pixels. All images were normalized
according to the pre-trained model standards.
In the study1, image augmentation technique was not
applied to the training data. Since COVID-19 positive chest
X-ray images were 423, same number of X-ray images
were randomly selected from normal (out of 1579) and viral
pneumonia (out of 1485) images to match with COVID-19
images to balance the database. In study2, entire database
(i.e., 423 COVID-19, 1579 normal and 1485 viral pneumonia
images) was used. Both the experiments were evaluated using
a stratified 5-fold cross-validation (CV) scheme with a ratio
of 80% for training and 20% for the test (unseen folds) splits,
where 10% of training data is used as a validation set to avoid
overfitting. However, in study2, COVID-19 images are much
smaller in number than that in the other two image classes.
Moreover, overall image number in any class was not several
thousand. Therefore, Image augmentation techniques were
applied to viral pneumonia, normal and COVID-19 X-ray
images for training to create a balanced training set. However,
COVID-19 images were augmented six times while normal
and viral pneumonia images were augmented once only.
FIGURE 3. Original chest X-ray image (A), Image after rotation by
15 degree clockwise (B), Image after rotation by 15 degree counter
clockwise (C), Image after 5% horizontal translation (D), after 5% vertical
translation (E), and after 5% horizontal and vertical translation (F).
D. IMAGE AUGMENTATION
In this study, two different image augmentation techniques (rotation, and translation) were utilized to generate COVID-19 training images, as shown in Figure 3.
The rotation operation used for image augmentation was done
by rotating the images in the clockwise and counter clockwise
direction with an angle of 5, 10 and 15 degrees. Image
translation was done by translating image horizontally and
vertically by −5% to 5%. However, only image translation
was applied to the viral and normal X-ray training images.
Table 1 summarizes the number of images per class used
for training, validation, and testing at each fold. Study1 was
carried out with COVID-19 and normal images while
study2 was carried out with COVID-19, normal and viral
pneumonia images.
E. INVESTIGATION OF THE DEEP LAYER FEATURES
The deep layers features of the image were investigated by
comparing the activated areas of the convolutional layers with
VOLUME 8, 2020 132669M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 4. Activation map for sample network models of (i) first
convolutional layer, (ii) strongest activation channel of first convolutional
layer, (iii) deep layer images set, and (iv) corresponding strongest
activation channel for the deep convolutional layer for a specific X-ray
image input.
the matching regions in the original images. The activation
map can take different range of values and was therefore
normalized between 0 and 1. The strongest activation
channels from the COVID-19, normal and viral pneumonia
X-ray images were identified and compared with the original
images. It was noticed that the strongest channel activates on
edges with positive activation on light left/dark right edges,
and negative activation on dark left/light right edges.
Convolutional neural networks learn to detect features
like color and edges in their first convolutional layer.
In deeper convolutional layers, the network learns to detect
features that are more complicated. Later layers build
up their features by combining features of earlier layers.
Figure 4 shows the activation map in early convolutional
layers, deep convolutional layer and their corresponding
strongest activation channel for each of the models. It might
be difficult to distinguish COVID-19 and viral pneumonia
from the original images as reported by different research
groups. However, the deep layer features explain better the
reason of a deep learning network’s failure or success in a
particular decision. It provides a visual explanation of the
prediction of CNN and it highlights the regions of the images
which are contributing more in classification. This technique
will be used in the result and discussion section to illustrate
how this activation mapping is a distinguishing feature
of COVID-19 X-ray images from the other two class of
images.
F. PERFORMANCE EVALUATION MATRIX
In order to evaluate the performance of different deep
learning algorithms for classifying the X-ray images in
case of two different classification schemes. The trained
algorithms were validated using 5-fold cross-validation.
The performance of different networks was evaluated using
five performances metrics such as- accuracy, sensitivity or
recall, specificity, precision (PPV), and F1 score. Per-class
values were computed over the overall confusion matrix that
accumulates all test fold results of the 5-fold cross-validation.
Accuracyclass_i =
TPclass_i+TNclass_i
TPclass_i+TNclass_i+FPclass_i+FNclass_i
(1)
Precisionclass_i =
TPclass_i
TPclass_i + FPclass_i
(2)
Sensitivityclassi =
TPclassi
TPclassi + FNclassi
(3)
F1_scoreclassi = 2
Precisionclassi × Sensitivityclassi
Precisionclassi + Sensitivityclassi
(4)
Specificityclass_i =
TNclass_i
TNclass_i + FPclass_i
(5)
where classi = COVID-19, and Normal for two class
problem; COVID-19, Normal and Viral Pneumonia for three
class problem.
III. RESULTS AND DISCUSSION
Two different schemes were studied in this study. Classification of COVID-19 and Normal images using eight
different pre-trained CNN models while training was done
with and without image augmentation. COVID-19, normal
and viral pneumonia images were classified using same eight
pre-trained models and training was carried out with and
without image augmentation.
A. EXPERIMENTAL RESULTS-TWO CLASS PROBLEM
The comparative performance for different CNNs for twoclass classification problem with and without augmentation
is shown in Table 2 and comparative AUC curves are
shown in Figure 5.It is apparent from Table 2 that all the
evaluated pre-trained models perform very well in classifying
COVID-19 and normal images in two-class problem. The
weighted average performance matrix for eight different
networks are very similar whereas small gain can be observed
when training was done using image augmentation. Among
the networks trained with 338 X-ray images for two-class
problem, ResNet18 and CheXNet are equally performing
for classifying images while CheXNet and DenseNet201 are
performing better than others in case of training with augmented images, although the difference is marginal. CheXNet
is producing the highest accuracy of 99.4% and 99.7% for
two-class classification without and with image augmentation
respectively. Interestingly, CheXNet is performing well in
both the cases, with and without augmentation and this can
be explained from the fact that CheXNet is the only network
which is pre-trained on a large.
X-ray image database and the network supposed to
perform better for X-ray image classification without the
requirement of training again on a larger dataset. However,
in this classification problem as the COVID-19 images are
significantly different from normal images all the tested
networks are performing well. This is apparent from the ROC
curves of Figure 5 as well. In both the cases (without and
with augmentation) for two-class problem, ROC curves are
showing comparable performance from all the networks.
132670 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 5. Comparison of the ROC curve for normal, and COVID-19 Pneumonia classification using CNN based models without (A) and with
(B) image augmentation.
TABLE 2. Weighted average performance metrics for different deep learning networks for two-class classification problem with and without image
augmentation.
B. EXPERIMENTAL RESULTS-THREE CLASS PROBLEM
Table 3 summarizes the performance matrix for different
pre-trained CNN algorithms tested for the two different
classification schemes without and with image augmentation.
It can be noticed that all the pre-trained networks (shallow
or deep) are showing very similar performance apart from
CheXNet in case of training without image augmentation.
If the pre-trained networks are trained on a small image
dataset as reported by the most of the research groups in
the literature, the performance difference is very marginal
and overall performance is reduced for three-class problem
in comparison to two-class problem. This is expected as
networks are now confused between COVID-19 and viral
pneumonia. However, CheXNet is still performing well while
trained on a small dataset as CheXNet was originally trained
one a very large X-ray image dataset. On the other hand,
while the image augmentation was applied to the training
image set, all the pre-trained networks are now performing
based on their capability to distinguish the three-class
images. Typically, the deeper the network the better is the
performance in distinguishing the image classes.
However, it is important to note that Resnet18 and
ResNet101 do not support this statement rather ResNet18
being a much shallow network than ResNet101, ResNet18 is
still outperforming ResNet101.
Interestingly, CheXNet which is a 121-layer variant of
DenseNet trained on X-ray images, is not outperforming a
deeper variant of DenseNet with 201-layers. Therefore, it can
be summarized that even though CheXNet was trained originally on X-ray images but training an even deeper network
with a larger image set can give better chance of training from
the new image sets on which the training is done, i.e., deep
network can learn better and perform better if the training
is carried out on a larger dataset. DenseNet201 outperforms
VOLUME 8, 2020 132671M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
TABLE 3. Weighted average performance metrics for different deep learning networks for three-class classification problem with and without image
augmentation.
other models in three-class classification scheme in terms of
different performance indices when the image augmentation
was employed and the performance matrix was significantly
improved with image augmentation. It is obvious from
Figure 6 that DenseNet201with image augmentation can
significantly increase overall network performance.
Figure 7 shows the confusion matrix for DenseNet201 for
two-class and three-class problems with image augmentation.
It is clear from Figure 7(A) that only three COVID-19 images
out of 423 images were miss-classified to normal (false
negative) and only three images out of 1579 images were
miss-classified to COVID-19 (false positive). This reflects
that this deep learning technique is extremely robust in
distinguishing COVID-19 images from normal X-ray images.
In the three-class problem, only one COVID-19 image
was miss-classified to normal, which is one of the three
images miss-classified by the two-class classifier. Two other
COVID-19 images were miss-classified as viral pneumonia
images. None of normal images were miss-classified to
COVID-19 by the three-class classifier although several
normal images were miss-classified to viral pneumonia.
COVID-19 image miss-classified to normal has bad consequences than miss-classified to other disease category (i.e.,
viral pneumonia). Similarly, normal images miss-classified
to viral pneumonia has less severe consequence than to be
miss-classified to COVID-19 pneumonia. Only four viral
pneumonia images were miss-classified to COVID-19 out
of 1485 images while 33 images miss-classified to normal.
It can be noted that network is not confusing between
COVID-19, and other two image classes rather network is
more confused between viral pneumonia and normal images.
However, the high precision and F1 score show that the
network is still performing excellent in classifying most of the
images reliably. This is very important, as the computer-aided
system (CAD) should not classify any COVID-19 patients to
normal or vice versa; however, it is important to see the reason
of the classifier being failed for three COVID-19 patients’
X-ray images and miss-classified them to normal.
The difference between normal and COVID-19 X-ray
images can be observed in the deep convolutional layer of
pre-trained CNN model. It is notable from Figure 8 that the
14th layer of the DenseNet201 can detect features that can
distinguish normal, COVID-19 and Viral Pneumonia images.
This shows the reason of the success of the network in
detecting COVID-19 X-ray images and distinguishing it from
normal and viral pneumonia images, which several groups
of researchers reported earlier are not reliably possible by
plain X-ray images [69]–[72]. It is really difficult for the
practicing radiologist to find abnormality in the early stage of
COVID-19. However, with the help of artificial intelligence,
the X-ray images can be used to identify the deep layer
features which are not visible to the human eyes [73]. The
deep layers enhance the distinctive features of COVID-19,
viral pneumonia and normal patients’ X-ray images, thereby
enhancing the chance of identifying the abnormality in the
lungs of the patients.
Figure 9 shows the three images of COVID-19
miss-classified to normal. Image 01-03 are miss-classified
by two-class classifier and Image-03 is miss-classified by
three-class classifier. The main reason behind the missing
of these COVID-19 images is a less opacity in the left
and right upper lobe and suprahilar on posterior-to-anterior
132672 VOLUME 8, 2020M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
FIGURE 6. Comparison of the ROC curve for normal, COVID-19 and viral pneumonia classification using CNN based models without (A) and
with (B) image augmentation.
FIGURE 7. Confusion matrix for classification of (A) Normal and COVID-19, and (B) Normal, COVID-19 and viral pneumonia using DenseNet201.
FIGURE 8. Images of 23rd channel of first convolutional layer (i), 14th
convolutional layer (ii) and 29th convolutional layer images (iii) from
DenseNet201 for different subject groups: Normal, COVID-19, and viral
pneumonia. Red arrows in COVID-19 image shows the regions of light
focus edge, a distinctive feature in COVID-19 patients’ X-ray images which
are not present in viral pneumonia and normal patients.
x-ray images, which is very similar to normal X-ray images
(see Figure 8). The algorithm fails if no evident light focus
edge feature is appeared in the deep layer and this type of
FIGURE 9. Three COVID-19 X-ray images which are miss-classified to
normal images by two- and three-class classifier. Note: Image 01-03 are
miss-classified by two-class classifier and Image-03 is miss-classified by
three-class classifier.
COVID-19 cases have to be confirmed by other techniques.
These three images were evaluated by three practicing
radiologists to identify what is their evaluations for these
three images. First and third images were identified as no
sign or very little sign of COVID-19 by the radiologists while
image-02 was identified as very mild stage of lung infections.
It can be summarized that the proposed technique can classify
most of the COVID-19 X-ray images very reliably.
VOLUME 8, 2020 132673M. E. H. Chowdhury et al.: Can AI Help in Screening Viral and COVID-19 Pneumonia?
IV. CONCLUSION
This work presents deep CNN based transfer learning
approach for automatic detection of COVID-19 pneumonia.
Eight different popular and previously reported efficient CNN
based deep learning algorithms were trained, validated and
tested for classifying normal and pneumonia patients using
chest X-ray images. It was observed that DenseNet201 outperforms other different deep CNN networks while image
augmentation was used for training the CNN models.
CheXNet which is a variant of DenseNet was outperforming
other networks while image augmentation was not used.
This is obvious as the CheXNet was pre-trained on a large
X-ray database and it is showing better performance on this
study while trained on a small non-augmented image dataset.
However, a deeper version of DenseNet, when trained on a
large augmented dataset, Dense201 outperforms CheXNet.
This clearly reveals the fact that the performance reported
on smaller database in the literature should be evaluated on a
large dataset otherwise, the findings of these studies cannot be
generalized for real applications. In this work, authors have
reported the findings from a large database along with the
image augmentation to train shallow and deep networks and
it was observed that deep networks perform better than the
shallow networks particularly in classifying normal and viral
images as most of the networks can identify COVID-19 with
very high sensitivity. The classification accuracy, precision,
sensitivity, and specificity of normal and COVID-19 images,
and normal, COVID-19 and viral pneumonia were (99.7%,
99.7%, 99.7% and 99.55%), and (97.9%, 97.95%, 97.9%,
and 98.8%) respectively. COVID-19 has already become
a threat to the world’s healthcare system and economy
and thousands of people have already died. Deaths were
initiated by respiratory failure, which leads to the failure
of other organs. Since a large number of patients attending
out-door or emergency, doctor’s time is limited and computeraided-diagnosis can save lives by early screening and propercare. Moreover, there is a large degree of variability in the
input images from the X-ray machines due to the variations of
expertise of the radiologist. Artificial intelligence exhibits an
excellent performance in classifying COVID-19 pneumonia
provided that the network is effectively trained from a large
dataset. We believe that this computer aided diagnostic tool
can significantly improve the speed and accuracy in the
screening of COVID-19 positive cases. The method would be
highly useful in this pandemic where disease burden and need
for preventive measures are at odds with available resources.
AUTHORS CONTRIBUTION
Muhammad E. H. Chowdhury: Conceptualization, Writing -
Review & Editing, Supervision, and Project administration.
Tawsifur Rahman: Data Curation, Methodology, Software,
Validation, Formal analysis, Writing - Review & Editing.
Amith Khandakar: Data Curation, Investigation, Resources,
Writing - Original Draft, Writing - Review & Editing. Rashid
Mazhar: Writing - Original Draft, Writing - Review & Editing. Muhammad Abdul Kadir: Methodology, Visualization,
Editing. Zaid Bin Mahbub: Methodology, Visualization.
Khandakar R. Islam: Data Curation, Writing - Original Draft.
Muhammad Salman Khan: Visualization, Writing - Original
Draft. Atif Iqbal: Writing - Review & Editing, Nasser
Al-Emadi: Writing - Review & Editing, Supervision, Mamun
Bin Ibne Reaz: Writing - Review & Editing, Supervision,
Conceptualization. M. T. Islam: Writing - Review & Editing,
Supervision.
ACKNOWLEDGMENTS
This work was made possible by NPRP12S-0227-190164
from the Qatar National Research Fund, a member of Qatar
Foundation, Doha, Qatar. The statements made herein are
solely the responsibility of the authors. The publication of this
article was funded by the Qatar National Library. The authors
would like to thank Italian Society of Medical Radiology and
Interventional for sharing the X-ray images of COVID-19
patients publicly and would like to thank J. P. Cohen for
taking the initiative to gather images from articles and online
resources. Last but not the least, authors would like to
acknowledge the Chest X-Ray Images (pneumonia) database
and RSNA Pneumonia Detection Challenge in Kaggle which
helped significantly to make this work possible. Otherwise,
normal and viral pneumonia images were not accessible to
the team.
CONFLICTS OF INTEREST
The authors declare no conflict of interest.



NEW_PAPER


Received April 27, 2021, accepted May 22, 2021, date of publication June 3, 2021, date of current version June 18, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3085682
COVID-Scraper: An Open-Source Toolset for
Automatically Scraping and Processing Global
Multi-Scale Spatiotemporal COVID-19 Records
HAI LAN 1
, DEXUAN SHA 1,2, ANUSHA SRIRENGANATHAN MALARVIZHI1,2, YI LIU 3
,
YUN LI1,2, NADINE MEISTER4
, QIAN LIU 1,2, ZIFU WANG1,2, JINGCHAO YANG1,2
,
AND CHAOWEI PHIL YANG 1,2, (Member, IEEE)
1NSF Spatiotemporal Innovation Center, George Mason University, Fairfax, VA 22030, USA
2Department of Geography and Geoinformation Science, George Mason University, Fairfax, VA 22030, USA
3Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN 46556, USA
4Department of Physics, Harvard University, Cambridge, MA 02138, USA
Corresponding author: Chaowei Phil Yang (cyang3@gmu.edu)
This work was supported by the National Science Foundation under Award 2027521 and Award 1841520.
ABSTRACT In 2019, COVID-19 quickly spread across the world, infecting billions of people and disrupting
the normal lives of citizens in every country. Governments, organizations, and research institutions all over
the world are dedicating vast resources to research effective strategies to fight this rapidly propagating
virus. With virus testing, most countries publish the number of confirmed cases, dead cases, recovered
cases, and locations routinely through various channels and forms. This important data source has enabled
researchers worldwide to perform different COVID-19 scientific studies, such as modeling this virus’s
spreading patterns, developing prevention strategies, and studying the impact of COVID-19 on other aspects
of society. However, one major challenge is that there is no standardized, updated, and high-quality data
product that covers COVID-19 cases data internationally. This is because different countries may publish
their data in unique channels, formats, and time intervals, which hinders researchers from fetching necessary
COVID-19 datasets effectively, especially for fine-scale studies. Although existing solutions such as John’s
Hopkins COVID-19 Dashboard and 1point3acres COVID-19 tracker are widely used, it is difficult for users
to access their original dataset and customize those data to meet specific requirements in categories, data
structure, and data source selection. To address this challenge, we developed a toolset using cloud-based web
scraping to extract, refine, unify, and store COVID-19 cases data at multiple scales for all available countries
around the world automatically. The toolset then publishes the data for public access in an effective manner,
which could offer users a real time COVID-19 dynamic dataset with a global view. Two case studies are
presented about how to utilize the datasets. This toolset can also be easily extended to fulfill other purposes
with its open-source nature.
INDEX TERMS Web scraper, COVID-19, spatiotemporal data, multiple scale.
I. INTRODUCTION
The worldwide COVID-19 pandemic has infected billions
of people in the past year [1]. This global crisis triggered
lockdowns in most countries around the world for months in
hopes to slow the spread of this novel virus and save lives [2].
Inevitably, the normal lives of citizens have been heavily disturbed and impacted. Scientists all over the world are studying
this pandemic to analyze the spreading dynamics, design
The associate editor coordinating the review of this manuscript and
approving it for publication was Ahmed Farouk .
effective control policies, predict the next possible outbreak
centers, develop vaccines, and optimize vaccination strategies. COVID-19 virus samples, statistics of positive cases,
existing policies, and environmental factors have become
important data for COVID-19 related research [3]. Another
example is spatiotemporal COVID-19 records, which most
countries have gradually published through virus testing
since early 2020. Collecting, organizing, and distributing
spatiotemporal COVID-19 records provide avenues and data
sources to support COVID-19 studies in different fields
such as public health, economics, and environmental science.
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 84783H. Lan et al.: COVID-Scraper: Open-Source Toolset
Governments and organizations of each country recognize the
need for public records. For example, most of the COVID-19
cases data comes from international agencies (i.e. the World
Health Organization (WHO) and the Global Health Council
(GHC)), or individual national organizations (i.e. the Centers
for Disease Control and Prevention (CDC) and the National
Health Commission of the People’s Republic of China).
These organizations have subcommittees that collect and
produce datasets published to the public [4]. However, for
researchers, one difficulty in obtaining these datasets is that
information is published in various sources, formats, types,
scales, channels, and time intervals by different countries.
This makes it time-consuming to acquire the latest fused
structured data for each country routinely, thus hindering the
response progress to fight COVID-19. To address this problem, we developed the COVID-Scraper, a toolset for automatically aggregating the multiple sources of spatiotemporal
COVID-19 dataset from different scales into one spatiotemporal framework with tailored data structures that benefit
related studies.
For some actors, like large institutions, this task has
been undertaken since the COVID-19 outbreak. John’s Hopkins is a prime example that provides a daily updated
COVID-19 Dashboard by pulling data from eight different
non-governmental sources, including the WHO, the CDC,
the European Centre for Disease Prevention and Control
(ECDC), and numerous countries’ data repositories and
organizes the data into one dataset for public sharing [5].
However, the process of data collecting, organizing, and
structuring for their ‘‘COVID-19 Dashboard by the Center
for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU)’’ is not transparent, which leads to
another challenge that some users cannot use it as a tool
to acquire datasets from preferred data sources with customized data structures and setup user-defined acquisition
frequency. Another widely known system is the 1Point3Acres
COVID-19 dashboard, which has gained over 2.8 billion
visits [6]. Similar to the COVID-19 Dashboard by JHU, users
cannot customize the data sources for countries. Another
issue is for a display dashboard, the raw data is difficult
to access by the public (even it claims the data could be
distributed with permission). Hence, it is impossible for users
to define the granularity of data, filter the content of data
and select the categories of data for customized scholar
research. In other words, existing solutions are not flexible enough for users, especially those which have specific
requirements to obtain targeted datasets.
We developed the COVID-Scraper as an open-sourced
COVID-19 scraping toolset by adopting the technology of
web crawlers to collect, filter, organize, pre-process, and
store multi-scale spatiotemporal COVID-19 records for each
nation over the world to generate a comprehensive data product in a single run. It is highly flexible and allows users
to customize the data sources, data structures, filter criteria,
database setup, and visualization formats with only minor
adjustments. Once those parameters are set up, this toolset
can be easily deployed on any cloud platform to fetch required
COVID-19 spatiotemporal datasets automatically. In addition, the COVID-Scraper is easy to use and process data
effectively. For example, it can finish acquiring the available
COVID-19 datasets from all countries over the world within
about six minutes. Furthermore, the COVID-Scraper works
exceptionally well for countries that do not provide good,
well-structured data from their official reports about their
current situation of COVID-19 other than portable document
format (PDF), or pictures in their reports. It can also be used
as a powerful toolset for building historical spatiotemporal
COVID-19 data records for some countries that only provide
the latest COVID-19 data reports.
In this paper, the different types of spatiotemporal
COVID-19 data sources from different countries consumed
by the COVID-Scraper are discussed in section III. Then the
components, mechanism, and implementation of this toolset
are detailed in section IV and include: 1) a workflow of
how the COVID-Scraper functions, 2) how it is designed to
cater to different types of data sources, and 3) the processing
of automation configurations. Section V details two case
studies of how the scraper functioned and produced data for
countries especially those that did not have well-documented
information for easy access. Performance tests are conducted
to demonstrate the overall performance of a single complete scraping process and processing time for different data
types. We also introduce two cases that utilized the final
data product generated by the COVID-Scraper to monitor
the medical resource deficiency dynamics and the impact of
social distancing measures on COVID-19 cases and mortality.
The paper is concluded with discussions of the implications
of the scraper and the future directions of the COVID-Scraper.
The major contributions of this work are:
1) an open-sourced COVID-19 scraping toolset with
web crawlers to collect, filter, organize, pre-process, and
store multi-scale spatiotemporal COVID-19 records for each
nation over the world.
2) a list of data scraping scripts to accommodate
COVID-19 spatiotemporal data scraping tasks for various
types of source data published by various countries.
3) a workflow that could automatically drive this scraping toolset and generate a comprehensive data product in a
single run
4) an up-to-date multi-scale COVID-19 records data product is provided in GitHub repository and a cloud-based
database for the public.
5) an operational dashboard is maintained to visualize the
data product for quick query and access.
II. LITERATURE REVIEW
Web scraping is a data mining technology that is commonly
used for extracting unstructured data from different online
sources and restructuring and converting acquired data into
a structured form that can be further stored and analyzed in
a database [7]. The benefit of a well-designed web scraper
is that it automatically sifts through targeted data sources
84784 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
and form valuable information into a comprehensive dataset.
There are different forms of web scraping including copy and
pasting, text grabbing, HTML parsing, and others [7]. A benefit of web scraping is that it simulates human interaction
with a web page and can obtain attribute data from the web
page itself [8]–[10]. This is beneficial because it brings in
pertinent information that is relevant to the topic assigned
to look for and not scraping for erroneous information. For
example, Weng and his colleagues applied web scraper techniques to collect large-scale datasets of horticultural products information to predict the trend of price fluctuation
with Auto Regressive Integrated Moving Average (ARIMA)
and integrated recurrent neural network (RNN) model [11].
Pawar and colleagues implemented a web scraper to search
medicinal plants and relevant diseases in the India Ayurvedic
system [12].
Web scraping is widely used by epidemiological research
and public health studies. By scraping and analyzing
text-based data from the Internet, researchers can successfully detect diseases and food hazards, as well as predict
potential pandemics. For example, Pollett and colleagues
used a web scraper as a tool to scrape unstructured Internet newswire data to timely detect outbreaks and epidemics
from vector-borne diseases [13]. Walid and his team scraped
worldwide Twitter data for 2 years [14]. By applying sentiment analysis and natural language processing on Walid’s
data, they built a model to detect and predict cancer. In addition to diseases detection, web scraping has been adopted in
food hazards detection and dissemination. By scraping the
events related to food hazards from news and social media,
Ihm and colleagues built a system to prevent and control
food hazards in Korea [15]. In addition, Majumder et al.
utilized web scraped data collected by HealthMap coupled
with Google Trend time series data to calculate the R0 and
predict the outbreak level of Zika virus in 2015 [16]. Beyond
scraping text-based data from Internet resources, images have
been scraped as a valuable dataset to support public health
research. For example, Li et al. scraped illicit drug dealerrelated photos and posts from Instagram. With 3 different
deep learning models applied, they detected 1129 drug dealers successfully [17].
This same technique can be applied to COVID-19 related
data collection. Chen et al. adopted a web crawler to collect
emotion and experience data of online education platforms
for users to assess the satisfaction and quality of online education under the pandemic [18]. La et al. scanned and collected
official media news related to COVID-19 in Vietnam to evaluate the response from policymaking, social media, and science journalism regarding the outbreak [19]. Xu et al scraped
Weibo posts from Wuhan, China at the early stage of the
COVID-19 outbreak to analyze public reaction, knowledge,
and attitude [20]. Their findings potentially support future
policy making and possible future outbreak responses.
However, it is worthwhile to point out that an expressed
concern in the field of web scraping due to the fact that
scrapers can obtain personal information and publish it to an
open database [21]–[23]. This becomes even more sensitive
when medical records are retrieved by the scraper. In our
study, the COVID-19 web scraper is aimed at collecting fine
scale spatiotemporal COVID-19 records for countries that are
releasing numerical data globally and aggregating them into
a central database without directly working with the personal
medical records.
III. DATA TYPES AND AVAILABILITY FOR THE
COVID-SCRAPER
The COVID-Scraper was developed to automatically and
routinely collect spatiotemporal COVID-19 records released
by countries all over the world. However, there are varying
degrees to which these records are available from different countries (Figure 1). Some countries such as the U.S.
and China provide trustable, comprehensive, fully processed,
ready to use datasets through official portals. These datasets
are usually in Comma-Separated Values (CSV) tabular or
JavaScript Object Notation (JSON) structured format that
stored in a standalone file or cloud shared documents such as
Google Spreadsheet [24]. Some other countries like Turkey
and Chile also provide information on COVID-19, but it is
not well organized. For example, the data may be published
on a dynamic website inside a PDF file or embedded in an
image-based file. In these contexts, the datasets cannot be
read and parsed by text-based processing algorithms directly
and automatically. Hence, advanced technologies should be
developed and integrated to mine the expected dataset, extract
required information from those unstructured data sources,
and convert them into user-defined data structures for storage
and sharing. Currently, the COVID-Scraper scans and scrapes
all countries with available data sources daily (Figure 1).
It will skip those countries without any available data source.
Countries listed in Table 1 are the major focus of
the COVID-Scraper, which provides COVID-19 records in
unstructured and not well-organized formats (Table 1). Our
toolset checks the data sources to confirm availability before
every run and reports exceptions if the data source is no longer
valid or the data type/format has been changed.
From a computing perspective, data types of COVID-19
records published by different countries are in structured or
unstructured formats. CSV is one of the most commonly used
formats for structured data. However, other formats are also
adopted by official sources for releasing tabular cases data.
For example, cases data from Brazil [32] are in the Microsoft
Excel format (.xlsx), which will be required to be converted
into CSV before further processing. JSON is another format
for structured data, typically provided as standalone JSON
files or via API by the data sources. In addition to structured data formats, unstructured data formats include original
HTML, PDF, or images (jpg, png, bmp, etc.).
The COVID-Scraper is developed to accommodate various types of COVID-19 case datasets in structured or
unstructured formats. In our study, open-sourced packages
and browser rendering tools [83] have been applied to
support scraping, parsing, and analyzing data in different
VOLUME 9, 2021 84785H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 1. Global scale data availability and the COVID-Scraper coverage.
FIGURE 2. Overall workflow.
formats. Once required spatiotemporal COVID-19 records
are extracted from the data sources, the COVID-Scraper will
filter, organize, and store the data into a single database
under the same data framework. In section VI, the COVIDScraper’s automation methodologies, structures, and detailed
implementation will be discussed for each type of data from
different countries.
IV. METHOD
The overall workflow of the COVID-Scraper toolset contains
seven steps (Figure 2):
1. Detecting the official, trust-worthy websites for
COVID-19 spatiotemporal records data from each individual
country. Choose a preferred data source for each target
country.
2. Scanning all the targeted data sources and analyzing
what type of data should be collected and extracted.
3. Adjusting template crawler unit to accommodate specific needs of each unique data source. Testing it and verifying that only the expected data are collected from the target
data source.
4. Assembling all crawlers into a toolset and hosting
it on a platform for automation. In our operational version, GitHub actions have been adopted for this purpose.
By utilizing GitHub actions, a workflow was developed
and configured, including managing scraping tasks, handling
84786 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
TABLE 1. Major countries and DATA sources scraped by the COVID-Scraper.
VOLUME 9, 2021 84787H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 3. Methodology flow of COVID-Scraper.
exceptions, and processing frequency to automatically run the
COVID-Scraper on demand.
5. Fetching collected results from the configured temporary data store paths. Merging and matching those data based
on unique geographical IDs. Unifying data structure based on
user settings.
6. Verifying data quality and pushing them into a database
as a data product.
7. Visualizing generated data product and publishing it as a
web service for sharing, interactively viewing, and querying.
From the perspective of algorithm implementation, HTTP
requests will be sent at the initialization stage of the
COVID-Scraper to all selected data sources (Figure 3).
By parsing the acquired dataset in different formats via
open-source packages, the spatiotemporal COVID-19 records
from each country can be extracted. After all required datasets
are collected, parsed, matched, and merged automatically,
the whole dataset will be pushed into the database as a final
data product.
To successfully accommodate various types of data
sources, our toolset is designed to handle both structured
datasets and unstructured datasets with only minor parameters adjustments.
A. STRUCTURED DATA SCRAPING
It is straightforward to handle most structured datasets
because they are usually stored in wide or long formats.
Long format tables contain columns corresponding to date,
location, and numbers of confirmed/death/recovered cases.
Since the long format is consistent with that of the daily report
used in our database, the data are expeditiously processed
by identifying the columns and matching the location names
with ISO3, Hierarchical Administrative Subdivision Code
(HASC), or local geographical IDs. Conversely, wide-format
tables usually include multiple columns corresponding to
different locations or dates, which must be converted to a long
format before processing.
CSV, Microsoft Excel, and JSON are three major structured data types from COVID-19 cases data sources. If the
records are provided in CSV format, they can be directly
downloaded and sent for further processing. However, if these
datasets are in Microsoft Excel or JSON, they have to be
converted into CSV first before entering the next processing
stage. Microsoft Excel format can be easily converted to
CSV using the pandas package in Python. The JSON dataset,
which is typically provided as standalone JSON files or via
API by the sources, will require identifying the keys corresponding to date, locations, and case numbers from the JSON
objects to convert them into tabular data format.
Occasionally, although the data is in a structured format,
the link to the data file cannot be directly obtained. For example, one needs to click a button to download the data file from
Brazil’s dashboard, where the link is not hardcoded in the
source code but dynamically generated. For such cases, techniques to handle dynamic web pages will be adopted to obtain
the download URL and acquire the expected dataset. The
detailed implementation for handling dynamic web pages
will be elaborated in the following section.
B. UNSTRUCTURED DATA SCRAPING
Although structured data formats such as CSV and JSON
are preferred, such data sources are not always available.
Sometimes data must be scraped from web pages in addition
to provided data links or APIs. Web pages can be developed
in static and dynamic mode depends on the frameworks of
websites, technology selection, and security concerns. In our
toolset, both static and dynamic web pages can be scraped
automatically.
1) STATIC WEB PAGES SCRAPING
Static web pages are web pages with fixed content. When
HTML data is loaded on the client’s web browser, it directly
displays the same contents that are stored on the web server
side. For static pages, an HTTP request is performed to
retrieve HTML data from the web page. However, how to get
required data out from web pages content effectively should
be carefully considered. A challenge here is it will be very
time consuming to design a parser and acquire valuable data
when it encounters multiple layer nested web data structure
in some web pages. Hence, it is recommended to apply an
optimized approach to design parsers. Subsequently, various
tools can be used to harvest the data from HTML content.
For example, in our toolset, python packages ‘‘requests’’ and
‘‘BeautifulSoup’’ are used. The get() method in the requests
84788 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
package is used to send a GET request to the selected data
source. After that, ‘‘BeautifulSoup’’ [84] is adopted to parse
HTML, filter relevant HTML elements, and extract information from those elements. BeautifulSoup provides an object
that represents web documents as a nested data structure.
By searching and filtering required tags from this object,
users can parse required information in straightforward ways,
which saves significant amounts of time. Hence, the desired
tag in the HTML page could be extracted using the select
method in the BeautifulSoup package. Afterwards, the relevant information is stored as CSV files with proper settings.
2) DYNAMIC WEB PAGES SCRAPING
Unlike static web pages with fixed data structure and web
contents, some data on web pages are dynamically loaded
with JavaScript and therefore they are not accessible in the
requested HTML of the target web page. This results in
a problem that by simply sending an HTTP request, web
content cannot be fetched as expected. One way to scrape
data from dynamic pages is to apply reverse engineering
(i.e., identifying and manually analyzing JavaScript codes
responsible for retrieving data). If relevant APIs can be identified, data could then be directly fetched through the APIs.
For instance, ArcGIS is a commonly used technology to
create many online COVID-19 dashboards. COVID-19 data
published by those channels are normally hosted through
ArcGIS’s feature server and can be queried through APIs.
Those APIs share the same format, and once relevant information such as catalog instance ID and service name are
pinpointed by inspecting the web page’s network activity,
the corresponding ArcGIS query APIs can be obtained.
In general, reverse engineering based on monitoring network
activity can be used to find various other APIs.
However, this technique does not work smoothly sometimes especially when the relevant webpage code is minified
and/or generated using a higher-level framework such as
React.js, which makes the codes less readable. In those cases,
HTML and Javascript codes need to be manually inspected
to reverse engineer relevant information. To conquer this
problem, headless browser rendering tools are adopted in
our toolset to generate static HTML content for dynamic
web pages. In the COVID-Scraper, Selenium web drivers are
exploited to obtain rendered HTML content from dynamic
pages. Selenium is a python package which is used to launch
web driver from a remote machine. The driver.get method
from selenium package is utilized to navigate to the selected
data source. The drivers (such as ChromeDriver, FirefoxDriver) send direct commands to the corresponding web
browser and retrieve the response. Occasionally, user input
such as clicking on buttons and selecting relevant options
from dropdown menus is necessary to obtain correct information, which is nicely supported by Selenium. To better
integrate with the GitHub Actions workflows as mentioned
before, remote web drivers are utilized by creating Selenium servers through Docker containers. Docker containers
connecting to web services are natively supported by GitHub
Actions, making the workflows much smoother. The generated HTML content can then be scraped as static web pages
by using the methods described in section IV part B(1). The
desired HTML tag in the page source is located by using the
find element by id and find element by css selector methods
in the selenium package.
3) PDF DATA PROCESSING
In addition, it is common that some official COVID-19 daily
reports are distributed as PDF documents by governments,
which typically contains tables of case records. A challenge
is to parse data directly from online PDF documents. After
getting the required PDF documents back to a local server,
extracting text-based information from the PDF file is also
necessary.
In order to retrieve data from the PDF documents, two steps
are applied in the COVID-Scraper.
1. The COVID-Scraper first gets links of the daily situation
reports. Usually, there is an official web page containing
links to all the reports. In such a case, the technique
used for scraping from static web pages can be used to
acquire the links. On occasion, documents of different
dates share the same file name except for the date string.
Thus, we can easily substitute the target date into the file
name to obtain the link for the corresponding date.
2. After retrieving the links for PDF documents, several
tools could be utilized to scrape data from the documents. Here we use tabula-py, a Python wrapper for
tabula-java, which is a PDF table extraction engine.
Normally, the relevant table contents are located at the
same locations inside the PDF documents for different
dates. Thus, coordinates of the areas containing those
tables can be specified in tabula-py to obtain better
results. The extracted data are then converted into CSV
files for further processing. However, extra care needs
to be taken to check the format and verify the data
since sometimes the extraction output format may not
be consistent.
4) IMAGE DATA PROCESSING
Another common format for distributing covid case records
is as a picture, usually for easy understanding and easy share
through social media. However, this will be a challenge for
automatic web scrapers to get data directly. For this kind
of data, we also use the python BeautifulSoup package to
scrape those pictures with the specific ID or group name to
fit users’ needs from static or dynamic websites. First, a GET
request will be sent to the data source using get() method
in the requests package. Then, the response of the request
will be parsed by BeautifulSoup. Lastly, select method is
applied to extract all image URLs from the data source to
setup download tasks. After collecting pictures every day,
our volunteers will manually record all the picture data to
a CSV file.
Regardless of the format, typically data can be accessed via
directly HTTP request or by reverse engineering. However,
VOLUME 9, 2021 84789H. Lan et al.: COVID-Scraper: Open-Source Toolset
occasionally the data may be distributed in a platform that
requires authenticated requests. For instance, the Philippines’
daily data are released on Google Drive. To access the data,
client credentials need to be created for connecting to the
Google Drive API before access to those specific resources.
In addition, source websites may have additional protection built to avoid DDOS attacks, which can also break
the scrapers. For instance, the Croatia official COVID-19
website [37] utilizes the Cloudflare DDOS protection, and
therefore requesting the source JSON file directly or via
Selenium from a script will be denied. We use FlareSolverr
to bypass the protection, which starts a proxy server and
opens the requested URL via Chrome browser, and sends the
requested file back after the Cloudflare challenge is solved.
C. DATA COLLECTION AUTOMATION
Once all crawler units are tuned properly, they can be
assembled and processed automatically. Automation of the
COVID-Scraper can be implemented in many different
ways such as a simple script hosted on a server, automation toolkits, or workflows supported by cloud platforms.
In our operational version, GitHub actions are applied to
set up automated scraping processes in the COVID-Scraper.
By hosting our toolset on GitHub actions and using the
workflow files (.yml,.yaml) with a customized virtual environment, the COVID-Scraper can be built, deployed, and
performed under manual control or operation by scheduled
time and period (Figure 4).
FIGURE 4. YML workflow to collect data automatically and routinely.
The event-driven GitHub Action uses YAML file to define
the parameters including 1) the event that triggers the workflow (parameter on is set to push event), 2) when to run
the workflow (parameter schedule, which is set to run daily
at 5:00 pm UTC in current operation), 3) the list of all the
jobs that run in the workflow (parameter job, which is used
to group together runs-on and steps parameters), 4) specify
the configuration environment (parameters runs-on is set to
Ubuntu Linux Runner in our case), 5) a group of all steps
that needs to be run in the workflow (parameters steps is
set to run the python environment in the runner and run
the list of country-wise crawler scripts), and 6) the jobs to
execute the command on the runner (parameter run is set to
GitHub configuration settings to push the latest data). The
steps parameter can be expanded to nest additional crawler
scripts which in turn increases the total crawling time.
However, to ensure high quality dataset can be collected
and saved locally before pushing them into a database, preconfiguration and post-processing will be performed to solve
three possible issues:
• inconsistent location names in data sources
• inconsistent spatial scale
• temporal data gap
Those issues are nearly inevitable in practical operations.
The mismatches of inconsistent names of administrative divisions, regions, or locations need to be fixed before collecting
data. For instance, the Bogra District in Bangladesh officially
changed its English spelling to Bogura District in 2018, but
data scraped from Bangladesh’s COVID-19 dashboard [85]
contains both spellings. Ignoring this issue may result in
missing data or inaccurate cases count for some regions in
those countries.
The inconsistent spatial scale and temporal data gap problem can be handled by post-processing. The truth is daily
cases data for some countries may be reported for administrative divisions, health boards, or other statistical regions.
In other words, after obtaining those datasets, the region
names in those data are needed to match with HASC or
local geographical IDs at consistent scales. For example,
sometimes the data is reported at admin 2 (county/city) level
while the required data scale is admin 1 (province/state)
level [3], [86]. In such cases, a mapping table will be created to convert the admin 2 level dataset to admin 1 level.
In the meantime, the cases records based on the admin 2
level will be aggregated and matched based on admin 1
regions. In addition, data may be missing for certain dates
in some cases. For example, Denmark does not report daily
cases on weekends. To make sure that the output reports
are in consistent format, missing data are filled using data
of the closest previous date when data are available. After
the global dataset has been cleaned and formatted following
each scraping, the cases dataset is exported as a CSV file.
For each region, the corresponding record includes region
name, country name, ISO3, HASC or local ID, and numbers
of confirmed cases, deaths cases, and recovered cases when
available. However, a data quality verification and validation
will be done before pushing them into the database for effective inquires.
D. DATA QUALITY CONTROL
Because the various data formats from the datasets collected
globally, dealing with the instability of raw data quality is a
84790 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
FIGURE 5. An operational dashboard of global COVID-19 records.
challenge for automatically processed crawlers. For example,
the structure of content from many sources is updated frequently which usually results in unexpected scraping errors.
Therefore, detecting errors and anomalies is essential for this
toolset. In addition, to quickly respond to errors during the
toolset running, it is important to validate the collected data
after the scraping process to make sure all datasets are correct
and accurate. Three dimensions of data quality were evaluated in the automatic detection script, including data integrity;
consistency; and validity. The completion check of continuous time-series data availability is required by data integrity.
For consistency, the scraped data should be consistent with
the sources. And several numeric rules were made for data
validity evaluation. For example, 1) the accumulated viral
case value should be unabated by time change; 2) the summarized cases value of a certain region should change among
continuous time step; 3) a surge increase of new cases will be
identified as abnormal growth; and 4) the accumulated case
value of confirmed cases should be much larger than cases
of death/recovered. To implement data quality evaluation in
this toolset, validation scripts were developed as a component of the COVID-Scraper to compare each record from
scraped data sources with corresponding data in validation
data sources automatically. This process will be started after
the crawling process. A data quality report will be produced
to help verify if there is any inconstancies or mistakes in
the collected dataset. For instance, the data of Nigeria is
scraped from a public dataset [62] that provides admin1 level
records. In the meantime, another dataset provided by Nigeria
Centre for Disease Control is applied as a validation data
source to ensure the accuracy of scraped dataset. By daily
comparison of each pair of records in both datasets with the
COVID-Scraper validation process, all mismatching and data
gaps can be found before data finalization. The crawler for
this specific country may need to be adjusted or the scraped
data source may be replaced if any problems were detected
during validation.
The current validation approach can accurately support
data that has been formatted as CSV tabular format. However,
for datasets extracted from PDF types, even if text recognition tool is applied, the recognition accuracy cannot be fully
guaranteed. In those cases, a group of volunteers is helping
manually check all the image type data daily, to make sure
the data that has been published is in a high-quality standard.
E. FINAL DATA PRODUCT GENERATED BY DATA SCRAPER
TOOLSET
Once all scraped datasets pass the daily data quality check
process, they will be converted into a standard table format
joint with a basemap which serves as the spatial supplement
attribute. The datasets are organized by region areas scaling
from country level globally to admin 1 level of each country.
Underneath each region area, daily reports, and time-series
summary tables of confirmed, death, and recovered cases
are produced and presented. After that, the COVID-19 data
collection is pushed and shared via the GitHub repository [87]
as the final data product with daily updates. In addition,
the obtained data is also being loaded into a pre-designed
relational database for backup and public representation purposes. An operational dashboard [88] has been developed
and published online to represent and share the real-time
global scale COVID-19 records in a visual manner with five
minutes updating intervals by using the dataset from the
database (Figure 5).
VOLUME 9, 2021 84791H. Lan et al.: COVID-Scraper: Open-Source Toolset
V. EXPERIMENTS AND DISCUSSION
To verify if the COVID-Scraper can work as designed to
scrape COVID-19 dataset from different countries with various data formats, two study cases are selected in this section
to represent the capability of our toolset to collect both structured data and unstructured dataset from static and dynamic
web-based sources. Furthermore, performance is tested to
check if the COVID-Scraper can be applied to scrape global
datasets in a reasonable time thus support near real-time
updating of the data product. After that, two study cases using
the data product are introduced.
A. COLLECTING FROM CHILE OFFCIAL COVID-19 WEBSITE
The COVID-19 dashboard of Chile [36] is an example of a
static website (Figure 6). This website updates daily with the
newest information about COVID-19 in Chile, all of which is
shown as a table on the webpage.
FIGURE 6. An operational dashboard of global COVID-19 records.
To accommodate static websites, the key task is to parse
the web elements and get required data from nested web
structures. Three steps were applied:
1. Utilize the BeautifulSoup package in python to find the
required data which are in the table or in <tr> or <td>
html elements.
2. Apply pandas package to extract the required information from each parsed web element.
3. Concatenate all the data to a single CSV file as a
result.
Once this file is created, it will be saved as a temporary
result file and passed to a folder which is named by the time
of the crawling process started. This experiment demonstrates
successful functionality of COVID-Scraper, namely locating and scraping the datasets published by static websites.
Scraped data has been stored in both database and the GitHub
repository after the scraping process finished.
B. COLLECTING FROM PAKISTAN COVID-19 DASHBOARD
Pakistan’s COVID-19 dashboard [65] is an example of
dynamic web page (Figure 7). In this website, daily cases data
from seven top-level regions in Pakistan are displayed in a
table located at bottom left of this dashboard page. However,
the table is generated dynamically using Google Data Studio,
hence the data cannot be scraped directly from the page’s
HTML source code.
FIGURE 7. Pakistan COVID-19 Dashboard.
To solve this problem, four steps are needed before scraping data.
1. Analyze the network activity. The direct link of the
dashboard in Google Data Studio (https://datastudio
.google.com/embed/reporting/1PLVi5amcc_R5Gh928g
TE8-8r8-fLXJQF/page/R24IB) should be detected by
using browser tools such as Google Chrome’s developer
tools.
2. Render the dashboard using Selenium web driver, which
connects to and retrieves data from a web browser as
discussed in section IV part B.
3. Start a standalone Selenium service on port 4444 to
listen to incoming requests by adopting Github Actions’
service container capability.
4. Connect to the web driver at http://localhost:4444/
wd/hub once the service in step 3 is established.
Until now, the web page is rendered and returned from the
Selenium web driver. HTML elements in the rendered HTML
document can be located using various methods provided by
the web driver. By using those methods, such as identifying
elements by CSS selectors, cell elements in the table that
contain region names and cases data can then be identified.
Each day, daily cases data is scraped and saved in a new file
in CSV format. Data update time can also be extracted from
rendered HTML as highlighted in Figure 7, as the temporal information. This experiment shows that COVID-Scraper
can successfully scrape data from dynamic website. Different from static websites, web drive technologies have been
adopted here to make sure targeted data can be recognized,
accessed, and scraped.
C. PERFORMANCE TEST
To test if the COVID-Scraper can process the scraping
tasks in a reasonable time for supporting COVID-19 related
research, comprehensive performance tests are conducted.
84792 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
For the overall performance of the automatic scraping all
available countries over the world, the average time spent
for the whole GitHub action job is around six minutes fiftyfive seconds by averaging 15 times tests (Figure 8). For
each test, the processing time varies, mainly because the
internet speed is unstable. When COVID-Scraper is starting,
the process of setup job, setup Python, commit, and push
result takes around 3 to 10 seconds to finish, which is quick.
The major time-consuming steps are processing checkout
repositories, installing Python dependencies, and generating
new data, which are heavily impacted by the Internet speed
during the processes. In addition, we noticed that after the
source websites add more content or change the layout of
their websites, the time spent crawling this website takes
longer, or in the worst case, stops working. Once the scraper
detects those abnormal statuses, a notification will be alarmed
automatically to operators that support them to take action in
real time. We continue to maintain and support this project
in the long run to make sure it is working normally and
effectively.
FIGURE 8. Overall performance of the COVID-Scraper.
To understand the detailed performance of the COVIDScraper to get data from different countries, 10 countries have
been selected including Austria, Chile, Jamaica, Panama,
Bosnia, Hungary, Sri Lanka, Turkey, Slovenia, and Switzerland. Every two of those countries share the same data type,
hence the five types of data scraping performance could
be tested. Every country was run 15 times and the average
time is calculated to reduce randomness. Austria and Chile
publish data in table format. The average processing time
is 2.0 and 2.9 seconds, respectively. Though they are in the
same format, the reason for the difference in processing time
is primarily due to the difference in size of crawling data.
For Austria, the data size is 1. 1 KB whereas for Chile
the data size is 1.46 KB. This may be the reason it takes
more time to process Chile’s data in comparison to Austria’s
data. In addition, the downloading speed during processing
time also contributes to the difference. The Jamaica’s and
Panama’s data are in JSON and show an average time of
2.4 and 0.6 seconds, respectively. Similar to Austria and
Chile, the JSON file size of those two countries is the major
reason for the time difference. The file size of Jamaica and
Panama are 584 KB and 245 KB, respectively. Bosnia and
Hungary publish data in image format and take an average
time of 2.8 and 4 seconds. The file size of Hungary is greater
than Bosnia which contributes to more processing time for
Hungary. The data source of Sri Lanka and Turkey are in
PDF format. The difference in processing time between those
two countries is primarily due to two reasons. First, for Sri
Lanka, the crawling script directly scrapes the data from the
current data PDF file. But for Turkey, the script first crawls
the HTML page to retrieve the latest PDF file link which
then scraps the desired data from the PDF, which takes more
time to process. Second, the required data of Sri Lanka is on
the first page of the published PDF file whereas for Turkey,
the desired data is on the third page during our performance
testing which results in need of crawling more pages than
Sri Lanka. The Slovenia and Switzerland data source are in
XLSX format with a file size of 47.7 and 35 KB, respectively.
The processing time for Slovenia is more than Switzerland
because the file size is larger. Hence, the downloading time
increases, causing an increase of processing time. To sum
up, the processing time for countries mainly depends on the
complexity of published website or data files, size of the data
sources and, Internet speed.
FIGURE 9. Performance tests on single countries with different data
types.
D. USE CASES WITH SCRAPED DATA PRODUCT
The data generated by the COVID-Scraper has been used to
support much scientific research within the academic community. Two studies are introduced here by applying the
data generated by COVID-Scraper as one of the major data
sources.
1) MEDICAL RESOURCE DEFICIENCY DYNAMICS
Since late March 2021, over 61 million of the U.S. population has been tested for a positive result for COVID-19.
Whether medical resources were enough to handle the worst
scenario amid the crisis is discussed and evaluated for public
good. Three elements including ventilators, ICU beds, and
critical medical care staff were reported as the fundamental
VOLUME 9, 2021 84793H. Lan et al.: COVID-Scraper: Open-Source Toolset
medical resources to support critically ill patients. In this
study, authors have created a medical resource deficiency
index (MRDI) by using the COVID-Scraper data product and
related COVID-19 medical data to measure the reality of
the medical burden by using the crawled confirmed, death,
recovered, and hospitalized viral cases at the county level
in U.S [89].
MRDI is defined as the division of daily active cases and
medical resources at the county scale, while the daily active
cases refer to the difference of accumulated number of confirmed (positive tested) patients with accumulated number
of deaths. And the medical resources were calculated by the
number of licensed beds multiplied by the total number of
critical care staff, specifically for COVID-19 response. The
higher the value of MRDI, the medical source for a certain
area is pressed harder. The accumulated viral case numbers
of positive confirmed and deaths were extracted from USA
Facts and cross-validated with sources from John Hopkins
University. Hospital licensed bed number and critical medical care staff with comprehensive specialty were accessed
from Definitive Healthcare consulting services and National
Provider Identifier Registry (NPI) database respectively. All
data collected in this study was converted into county scale
with a unique identifier of county code by Census standard.
To monitor and share the dynamic heterogeneity information of medical resource distribution, a medical resource
deficiency dashboard is created based on the ArcGIS dashboard for analyzing and visualizing the generated results
(Figure 10). A bubble map in the center of the dashboard
represents the spatial distribution MDRI, where the area of
circle refers to the index value. Two lists of counties are
displayed on the right to show the statistics rank of MRDI and
Infection Risk/Rate, which is interactively generated based
on the selected extend of the map. An indicator and two
pie charts (fraction of hospital bed types and medical care
staff) are applied to display for each county on the left of the
dashboard. To track the temporal pattern of the index, a line
chart is built in the bottom to demonstrate the time-series
analysis result for the selected area(s).
FIGURE 10. Use scraped data product to monitor medical resource
deficiency dynamics of COVID-19.
2) THE IMPACT OF SOCIAL DISTANCING MEASURES ON
COVID-19 CASES AND MORTALITY
Another study was on the impact of control policies by using
the COVID-Scraper data and corresponding policies dataset.
In this study, authors analyzed a series of social distancing
policies including school closure, workplace closure, cancellation of public events, public information campaigns, cancel
public transport, internal movement restriction, and travel
control that have been implemented to combat the worldwide pandemic. Previous studies have found social distancing
policies are effective in mitigating COVID-19 [90], [91],
however, these policies have negative impacts on economic
development and normal life [92]. Limited understanding of
the effectiveness of each individual policy has posed grand
challenges on the reopening process in which the stringency
of social distancing is reduced to balance health and development. A study investigating the effectiveness of seven major
social distancing policies in the US on COVID-19 case and
mortality growth rate [93] was conducted using the case data
collected and policy data shared by the oxford policy tracker
project [94]. To estimate the temporal dynamic impact of
policies on the COVID-19 cases, policy data was transformed
to 0-1 variables, which represent the policy’s implementation
periods including one week, two weeks, three weeks, one
month, two months, and more than two months. The scraped
daily cumulative case data were converted to daily case
growth rate, which is the difference between the logarithms
of cumulative case numbers in two successive days. These six
implementation indicators were regressed to case growth rate
using panel regression analysis. Panel regression is widely
used to analyze two-dimensional panel data which typically
cross sectional (e.g., states, countries) and longitudinal (e.g.,
year, month) dimensions [95]. Specifically, a fixed effects
panel regression model was adopted in our study, it could
model unobserved heterogeneity through state-specific fixed
effects [96]. In addition, the growth rate was multiplied by
100 in the regression, thus the regression coefficient of policy
could be interpreted as percentage point changes of growth
rate (Figure 11).
FIGURE 11. Use scraped data product to support COVID-19 policy
analysis.
The study demonstrated that the stay-at-home orders,
workplace closures, and public information campaigns can
drastically decrease the confirmed case growth rate. Stay-athome orders and workplace closure decrease case growth rate
through changes in mobility while public information campaign impact confirmed case growth rate through channels
other than mobility. In addition, regarding death case growth
rate, stay-at-home orders and international travel controls
had limited mitigation effect. The relation between policies
84794 VOLUME 9, 2021H. Lan et al.: COVID-Scraper: Open-Source Toolset
and case growth rates learned by the study could provide
policymakers a better understanding of the effectiveness of
each policy to support decision-making.
VI. CONCLUSION
The COVID-19 outbreak has impacted billions of people over
the world. Governments, organizations, and research institutions are conducting rapid research on COVID-19 related
problems that aim to bring people of every country back to
normalcy. Detailed spatiotemporal COVID-19 records data
is proved to be important evidence to support COVID-19
related research. However, how to collect, aggregate, store
and share the data published by each country in the world to
the community effectively is a challenge. To solve this problem, the COVID-Scraper was developed as an open-sourced
toolset that can automatically scan, extract, collect, filter,
refine, unify and store the public spatiotemporal COVID-19
records of fifty-eight countries around the world, which
provide available COVID-19 data sources [97]. With minor
code adjustments, this toolset can accommodate various types
of data published by each country in various data formats,
scales, channels, and publish frequencies. More importantly,
for the countries that do not provide access to historical
COVID-19 data, it can automatically build historical data collections to support research repeatedly on a certain frequency.
The COVID-Scraper processes in a high effective manner by
collecting data from countries over the world within a single
run in about six minutes. After post-processing and data
cleaning, the fetched data is unified and saved into a database
for sharing. With daily data quality checking and data product
production, a global COVID-19 data Github repository has
been maintained since March 2020. In addition, a visualization component is developed in the COVID-Scraper to
publish the data product as a web service for public view and
access.
The COVID-Scraper utilized the web scraping technologies that are used in data science and GIS-related fields.
By integrating open-source packages and tools for data
extracting, network simulation, file, image parsing, and workflow automation, the COVID-Scraper is a highly flexible and
automatic toolset that can process tasks unsupervised under
users’ settings. With the nature of open source, users can
easily customize the data sources, the data structure of the
output data product, execution logic, processing frequency,
and exception handling. In addition, users can modify the
source code to extend it for collecting datasets for other
purposes to support wider studies and tasks such as emergency response and natural disaster detection for saving
lives.
Currently, a limitation is that the data quality control and
validation cannot be fully automated because the accuracy
of parsing and text extracting cannot be always guaranteed
by using current packages. Hence, users need to intervene
in the data quality control process for PDF and image type
data to make sure the data product is of high quality. With the
rapid development of text parsing from images, we will keep
updating this component to minimize the human intervention
in the automation process.

NEW_PAPER



Received December 17, 2020, accepted January 5, 2021, date of publication January 11, 2021, date of current version January 20, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3050852
A Novel Bayesian Optimization-Based Machine
Learning Framework for COVID-19 Detection
From Inpatient Facility Data
MD. ABDUL AWAL 1
, MEHEDI MASUD 2
, (Senior Member, IEEE),
MD. SHAHADAT HOSSAIN 3
, ABDULLAH AL-MAMUN BULBUL 1
,
S. M. HASAN MAHMUD 4
, AND ANUPAM KUMAR BAIRAGI 5
, (Member, IEEE)
1Electronics and Communication Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
2Department of Computer Science, College of Computers and Information Technology, Taif University, Taif 21944, Saudi Arabia
3Department of Quantitative Sciences, International University of Business Agriculture and Technology, Dhaka 1230, Bangladesh
4School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China
5Computer Science and Engineering Discipline, Khulna University, Khulna 9208, Bangladesh
Corresponding author: Md. Abdul Awal (m.awal@ece.ku.ac.bd)
This work was supported by Taif University Researchers Supporting Project number (TURSP-2020/10), Taif University,
Taif, Saudi Arabia.
ABSTRACT The whole world faces a pandemic situation due to the deadly virus, namely COVID-19. It takes
considerable time to get the virus well-matured to be traced, and during this time, it may be transmitted
among other people. To get rid of this unexpected situation, quick identification of COVID-19 patients is
required. We have designed and optimized a machine learning-based framework using inpatient’s facility
data that will give a user-friendly, cost-effective, and time-efficient solution to this pandemic. The proposed
framework uses Bayesian optimization to optimize the hyperparameters of the classifier and ADAptive
SYNthetic (ADASYN) algorithm to balance the COVID and non-COVID classes of the dataset. Although
the proposed technique has been applied to nine state-of-the-art classifiers to show the efficacy, it can be
used to many classifiers and classification problems. It is evident from this study that eXtreme Gradient
Boosting (XGB) provides the highest Kappa index of 97.00%. Compared to without ADASYN, our proposed
approach yields an improvement in the kappa index of 96.94%. Besides, Bayesian optimization has been
compared to grid search, random search to show efficiency. Furthermore, the most dominating features have
been identified using SHapely Adaptive exPlanations (SHAP) analysis. A comparison has also been made
among other related works. The proposed method is capable enough of tracing COVID patients spending
less time than that of the conventional techniques. Finally, two potential applications, namely, clinically
operable decision tree and decision support system, have been demonstrated to support clinical staff and
build a recommender system.
INDEX TERMS COVID-19, ADASYN, Bayesian optimization, classification, inpatient’s facility data.
I. INTRODUCTION
The world is currently experiencing a pandemic situation
due to the extensive spreading of the novel coronavirus
disease namely, COVID-19. It is an acute respiratory syndrome triggered by the Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2), which was primarily detected
in Wuhan under the Hubei province of China in late 2019.
The associate editor coordinating the review of this manuscript and
approving it for publication was Bilal Alatas .
Considering the alarming rate of infection and death from the
COVID-19, World Health Organization (WHO) announced
the COVID-19 as a pandemic disease in March 2020 [1]–[3].
As per the WHO report on the COVID-19 on
August 04, 2020, about 18,142,718 people have been infected
due to COVID-19 [4]. Among them, about 691,013 people
died so far. Due to its high contagious nature, both the
COVID-19 infection and death toll are rapidly increasing.
In most cases, this disease spreads from man to man
via respiratory droplets, transmitted from individual to
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10263M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
individual via air or any other surfaces. This virus lives
multiple hours to multiple days on a suitable surface at
room temperature [5], [6]. As suggested by WHO, the
COVID-patient should get himself isolated from others as
early as possible to resist its transmission. The COVID-19
should be detected as early as possible, reducing life, livelihood, and the economy. But a critical issue is the broad
maturation period of the COVID-19 that varies from 3 to
14 days. The usual symptoms of this disease include fever,
cough, dyspnea, loss of smell, loss of taste, diarrhoea,
etc. [7], [8]. People affected by COVID-19 should go through
a fruitful, real-time, fast, and accurate screening scheme to
ensure timely treatment, isolation, and safety for the patient.
Many pieces of research are going on to find out efficient
and speedy COVID-19 detection schemes in different dimensions. The Reverse Transcription Polymerase Chain Reaction
(RT-PCR) is a COVID-19 detection scheme that has shown its
efficiency and has been practised worldwide. Using samples
like the nasal or oral pharyngeal swab, this method can competently detect coronavirus and has attained the gold-standard
banner. However, these testing kits fail to meet the mounting
demand due to its limited supply, especially in developing
countries [9]. Another drawback of this method is that it
requires an extended period, ranging from one to two days.
Moreover, the situation is even worse in rural areas, because
people from remote areas get the results after two or more
days, even after a week [10]. This extended period increases
the vulnerability of the spreading of COVID-19 as the patient
does not usually keep himself isolated from others before
getting his result.
To optimize these limitations, the potentiality of Artificial
Intelligence (AI) and Machine Learning (ML) algorithms
in the analysis, characterization, and classification of different diseases have motivated the researchers to introduce
AI and ML in COVID-19 detection. Numerous researches
have already been carried out to design a COVID-19 detection model based on AI and ML [7]–[20]. Furthermore,
Rajaraman and Antani [10] proposed a COVID-19 detection model based on deep learning (DL) algorithms. Using
convolutional neural networks (CNNs), chest X-ray (CXR)
data from patients are analyzed in this model to evaluate the
presence of the SARS-CoV-2 virus. The model showed about
93% accuracy employing the VGG16 classifier. Another
DL and CNNs based automatic COVID-19 detection model
was proposed by Makris et al. [8]. Diagnosing the CXR
data, the model exhibited about 95.9% and 95.00% accuracy engaging VGG16 and the VGG19 classifiers, respectively. A transfer learning-based model was presented by
Abbas et al. [12] to trace COVID-19. This CNN based
model diagnosed the CXR images of patients to check the
COVID-19 presence, and the model attained about 97.5%
accuracy. He et al. [7] presented a DL model for the automatic
detection of COVID-19. This model employed the chest
computed tomography (CT) images from patients to detect
COVID-19. The anticipated 3D CNN model, MNas3DNet41,
revealed about 87% accuracy. Jim et al. [11] presented an
automatic COVID-19 detection model based on sequential CNN. This model took the CT images in its input to detect
COVID-19. The model attained almost 92.5% accuracy along
with 94.2% sensitivity and 95.6% specificity. A lot of more
automatic COVID-19 detection models have been proposed
so far based on the computer-based diagnosis of the CT and
CXR images.
Hence, all the anticipated models require CT or CXR
data of patients as the key input parameter, only available
from diagnostic centres. So, each patient or suspected patient
has to visit the diagnostic centre in person to check the
presence of COVID-19 in his body. Most of the families in
developing countries do not have private transport. Besides,
patients from rural areas have to travel a long distance to
reach a diagnostic centre. Therefore, they have to use public
transport to visit the diagnostic centre to check COVID-19.
This will create high vulnerability to COVID-19 spreading,
among others. From another point of view, a low percentage
of people tested for COVID-19 gets COVID-positive results
in most of the countries; as an example, as of July 30, 2020,
the positive rate is about 1.30% in France, 22.20% in
Bangladesh, 9.90% in Iran, 0.90% in Italy, 7.90% in
the USA, 11.10% in India, 2.10% in Russia, and 0.40% in the
UK [21]. Visiting the diagnostic or test centre, a large percentage of COVID-19 negative people may meet with COVID-19
positive patients, which will enhance the risk of getting contaminated by COVID-19 disease. So, an inpatient data-based
COVID detection will be the best option to avoid these types
of risks. Besides, this type of detection will be very user
friendly, cost-effective, and time-efficient.
Considering all the above issues, we have proposed a fast
and user-friendly model to detect the COVID-19 based on
machine learning. A large volume of data on COVID-19 is
available in different laboratories and test centres. The dataset
comprises other features like age, temperature, pulse rate,
systolic and diastolic pressure, fever, cough, loss of smell,
runny nose, diabetics, loss of taste, asthma, etc., which are
analyzed to design the automatic COVID-19 detection model.
The most promising advantage of this model is that it is
capable of detecting the COVID-19 within a few minutes as
well as help the doctors take adequate precautionary measures while treating the COVID patients. Different classification algorithms such as Linear Discriminant Analysis
(LDA), Quadratic-DA (QDA), Naive Bayes (NB), k-Nearest
Neighbors (KNN), Decision Tree (DT), Random Forest (RF),
eXtreme Gradient Boosting (XGB), Gradient Boosting (GB),
Support Vector Machine (SVM), etc. are used to characterize
the model. These classifiers have some hyper-parameters, and
proper tuning of these hyper-parameter improves the performance of the classification using state-of-the-art global optimizers such as Bayesian optimization [22], Gradient-Based
Optimizer (GBO) [23], Slime mould algorithm (SMA) [24],
and Harris hawks optimization (HHO) [25] etc. The evaluation of different performance metrics such as accuracy, specificity, sensitivity, etc. for the anticipated model
demonstrates higher efficiency in detecting COVID-19.
10264 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
The contribution and key topics covered by this study are as
follows:
• The proposed model can be easily tested on inpatients
or inhouse facilities discussed in Section II. Therefore,
the patient needs not to visit the clinic to test the
COVID-19.
• We have designed a machine learning framework
using Bayesian optimization adapted by the ADASYN
algorithm to detect COVID-19 which is presented in
Section II.D and II.E.
• The state-of-the-art machine learning technique is optimized using our method and compared with other commonly used Grid-search and random search techniques;
see Section III.H.
• The proposed method uses the ADASYN algorithm to
balance the model, and the effect of ADASYN has also
been demonstrated in III.A.
• Using SHapely Adaptive exPlanations (SHAP) analysis,
important features are calculated, and the SHAP values
are explained to interpret the model in Section III.F.
• A clinically operable decision tree is built that will
be helpful for the clinical staff stated in Section IV.A.
A decision support system has also been developed to assist the recommender system illustrated
in Section IV.B.
The remainder of the paper is organized as follows.
In Section II, we discuss the materials and methods used in
this work. We present the experimental results in Section III.
In Section IV, we present a systematic discussion and comparison of the work with other approaches. Finally, we draw
some conclusions in Section V.
II. MATERIALS AND METHODS
A. DATA SOURCE
The clinically-driven information on individuals who have
undergone through RT-PCR test was collected from the [26].
The dataset, containing 11169 person’s data with 2.82% of
patients’ COVID positive and 97.18% COVID negative tests
from the United States, was prepared by Carbon Health (CH)
and Braid Health (BH). The CH started RT-PCR testing of
a coronavirus in early April 2020. The dataset is compliant with the Health Insurance Portability and Accountability
Act (HIPAA) privacy rule’s de-identification standard. Five
clinical teams worked under the CH. The dataset prepared by
the CH covered multiple physiognomies on patients, including Epidemiological (Epi) Factors, comorbidity, vital signs,
lab technician-assessed symptoms, patient-stated symptoms.
Whereas, two clinical teams gathered the dataset under
the BH, which assembled the radiological information containing verdicts, CXR impressions, CXR labels, and CXR
link. We haven’t used radiological information as most of the
patient doesn’t have radiological details. The integration of
radiological information is beyond the scope of this study,
hence excluded from the analysis. The dataset consisted of
both positive and negative test results for patients having both
one or more symptoms and zero symptoms. In addition to
COVID-19 test results, the complete dataset, available on
the GitHub website, contains multiple features of patients
such as pulse rate, temperature, age, higher danger introducer
occupation, higher danger contacts, diabetics, cancer, asthma,
smoker, systole, diastole, diarrhoea, fatigue, fever, losing
smell, losing taste, runny nose, headache, muscle pain, pain
in the throat, cough, shortness of breath, etc. The vignette of
the entire data set has been illustrated through a tabular sketch
shown in Figure 1.
From the pictorial depiction (Figure 1), it is much clearer
that there are two types of data (numeric and boolean),
where the boolean variables are more than three times that of
the numeric data. Moreover, the highest age of the patients
in this data set is 90 years old, and the extreme values
of both systolic and diastolic pressures were dramatically
higher than the natural ones. It can be further added that
days_since_symptom_onset has about 68% missing data,
while the percentage of missing data in the entire data set is
around 17. Besides the tabular display, as shown in Figure 1,
the graphical example the green bars in Figure 2 efficiently
reveals that the variables cough, diabetes, chd, htn, cancer,
asthma, COPD, autoimmune_dis, and smoker have no missing data. In contrast, the variable days_since_symptom_onset
has the highest missing values compared to others.
B. DATA PRE-PROCESSING
The overall workflow of our study is presented in Figure 3.
For data pre-processing, the dataset has been imputed using
Multivariate Imputation by Chained Equations (MICE) algorithm [27]. After completing scaling, we used the ADASYN
algorithm to balance out COVID and non-COVID datasets.
ADAptive SYNthetic (ADASYN) algorithm [28] is an oversampling method where COVID positive is a rare instance.
It helped us generate synthetic data, solving the over-fitting
problem. In contrast, the under-sampling process is not
the right choice in COVID classification. The majority
class (i.e. COVID-no class) is downsampled to the amount
minority class (i.e., COVID-yes). This process will reduce
the amount of data that drastically cause data inefficiency,
and it loses the vital information of COVID-no class. Our
COVID data set is not a big dataset, and downsampling
could mislead the diagnosis and detection. Compared to
other correlated over-sampling methods such as AdaBoost
in conjunction with Over/Under-Sampling and Jittering of
the data (JOUS-Boost), Synthetic Minority Over-sampling
TEchnique (SMOTE), SMOTE-Boost and, DataBoost-IM
(DataBoost IMbalanced) algorithm, ADASYN can balance
the imbalanced dataset, for example, COVID-19 dataset by
reducing the bias introduced by the imbalanced data distribution [28]. Besides, ADASYN shifts the decision boundary
to harder to learn examples which ultimately improves the
classification accuracy. These two objectives, i.e. (i) bias
reduction and (ii) introducing harder to learn neighbourhoods
examples, are accomplished through the dynamic weight
adjustment and adaptive learning procedure [28].
VOLUME 9, 2021 10265M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 1. Characteristics of the Sample.
The Mathematical explanation behind the ADASYN algorithm is given below:
For illustration, if ml and ms represent the majority and
minority classes, respectively, then the Degree of imbalance
of the two classes can be figured as follows:
d =
ms
ml
. (1)
If d < dx (where dx is the preset threshold for the maximum
tolerated imbalance) then the total number of the synthetic
minority can be estimated as follows:
G = (ml − ms)d. (2)
Here d = 1 means there is a total balance between two
classes. If ri =
ml
k
, where k is the number of neighbours of
each minority, and rˆ = Pri
ri
such that Prˆ = 1, then the
amount of synthetic data to generate for each neighbourhood
can be calculated as:
Gi = Grˆ. (3)
If xi and xu are two minority examples within the same
neighbourhood, where xu is randomly selected, then the new
synthetic example,si can be enumerated using the followings:
si = xi + (xu − xi)λ, (4)
10266 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 2. Fill rate for all Variables.
where xu−xi
is the difference vector in n-dimensional spaces,
and λ is a random number over [0, 1].
C. CLASSIFICATION MODELS
These nine classifiers such as Linear Discriminant Analysis
(LDA), Quadratic Linear Discriminant Analysis (QLDA),
Naive Bayes (NB), KNN, DT, RF, XGB, GB, and SVM,
have been utilized in the proposed machine learning framework. Among nine classifiers LDA, QLDA, NB, KNN,
DT and, SVM are common classifiers and also used in
COVID-19 classification. RF, XGB and GBC are recent
state-of-the-art classifiers. For example, XGB is recently
applied to interpret the mortality prediction in COVID-19
patient and proposed a clinically operable simple tree-based
tool which can be suitable to take the right decision from an
expert point of view [56]. Considering the above rationale,
we have used both commonly used classifiers as well as
recently updated classifiers in this study. This will allow
us to compare the classification performance in different
classifiers. Moreover, RF, XGB and GBC classifiers can be
explained through SHAP analysis which is very useful to
clinical engineers. Finally, it can be seen from the results
that the XGB performed better in most of the classification
metrics, and we used SHAP to explain the XGB to interpret
the COVID-19 detection.
1) LINEAR DISCRIMINANT ANALYSIS (LDA)
The LDA, introduced by Ronald Aylmer Fisher in 1936 [29],
is a productive classification technique. It sorts-out
n-dimensional spaces into 2-dimensional spaces that split-up
by hyper-plane. The core objective of LDA is to trace the
mean function for each class, and the function is projected
on the directions that optimize between-groups variance and
reduces within-group variance. The LDA is generated from
the conditional distribution of the data P(X|Y = k) for
each class k, and it optimizes by taking the class k when
the measurements are made on standalone variables for each
observation are continuous quantities [30], [31].
2) QUADRATIC LINEAR DISCRIMINANT ANALYSIS (QLDA)
QLDA, an extension of LDA is exploited in machine learning and statistical analysis to classify two or more groups
by quadratic discernible using distance-based classification
techniques. There is no hypothesis like LDA that the covariance matrix for every class is identical. When the regularity
hypothesis is true, the best prospective test for the hypothesis
that an assumed measurement is from a given class is the
likelihood ratio test. QLDA can be found from the conditional
distribution like LDA of the data P(X|Y = k) like LDA, and it
maximizes by selecting the class k [30], [31]. More precisely,
for LDA and QLDA, P(X|Y = k) is resulting as a multivariate
Gaussian distribution with the following equation:
(Y = k) =

(2π)
d/2




X
k




1/2−1
exp
− 0.5(X − µk )
t X−1
k
(X − µk )

, (5)
where d is the number of features [32]. It needs to estimate
the class priors P(y = k) for using LDA and QDA model as
classifiers, e.g. the proportion of instances of class k from the
training data, the means µk and the covariance matrix.
3) NAIVE BAYES (NB)
NB classifier is authoritative and mainly useful in the large
dataset. It is used in both machine learning and medical
science, especially the diagnosis of different diseases like
COVID-19. It is a Bayes’ theorem, based on probabilistic
classifier objects with the strong independent supposition
between the features. It generates conditional probability
models that allocate class labels to a given problem [33]. Say,
P(Patient|Covid Positive)
=
P(Covid Positive|Patient) × P(Patient)
P(Covid Positive)
,
where, P(Patient|Covid Positive), a conditional probability is
the likelihood of the patient occurring that s/he is affected
VOLUME 9, 2021 10267M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 3. The overall workflow of the classification of COVID-19. The first phase is collecting raw data followed by pre-processing,
where the raw data is imputed, scaled, and most importantly, the imbalanced data is balanced using ADASYN algorithm. Secondly,
the pre-processed data are split into the train and test set used by different classifiers to measure the classification performance. In the
next step, Bayesian optimization has been implemented to tune the hyperparameters of the classifiers. This optimized classification
model is then tested, and different performance metrics (accuracy, precision, Confusion matrix, ROC, 10-fold cross-validation, ANOVA, and
multi-comparison test) have been used for evaluation. Finally, the important features have been efficiently traced using SHAP analysis.
with Covid; P(Covid Positive|Patient) is also a conditional
probability: the likelihood of the positive COVID occurring
that is truly a patient; P(Patient) is the prior probability of a
patient; P(Covid Positive) is the overall probability of observing COVID positive.
4) K-NEAREST NEIGHBOURS (KNN)
KNN is straightforward simplest algorithms in supervised
machine learning technique [34] uses data and classify new
data points based on similarity measures with the distance
function, be able to apply to solve both classification and
regression difficulty. It uses an integer number as 1, −1, or 0
for symbolizing the productivity (labels) of a classification
algorithm outputs. KNN is a memory-based classifier; for
example, it remembers all the training data-points to predict test data by computing the similarity between an input
sample and each training instance. For a given new data
point x0, it finds the k training points xr
,r = 1, . . . , k
closest in distance to x0 and then classify using majority vote
among the k neighbors [32]. For selecting k, it conducts the
KNN algorithm respective times with various values of k and
opts for the k that reduces the number of errors accurately.
5) DECISION TREE (DT)
DT is a hierarchical flow chart like structure that generate
some decision rules. The DT creates a model that predicts
the target variable by learning the decision rule from the data
feature [35]. The main hyper-parameters of DT are criterion,
max_depth, max_features. In DT, ‘‘Gini’’ or ‘‘entropy’’ is
used as a criterion. In contrast, the max_depth is utilized to
limit the number of nodes in the tree, and the max_features
represents the number of features to consider while searching
for the optimal split. By properly tuning the hyper-parameters
of DT (i.e., criterion, max_depth, max_features) applied on
the COVID training dataset, the classification performance
will be efficiently magnified.
6) RANDOM FOREST (RF)
RF is an ensemble learning technique for classification
that uses several DTs on different sub-samples of the
dataset to improve the classification performance and to
control over-fitting [36]. The main hyper-parameters of
RF are criterion, max_depth, max_features, n_estimators.
The criterion, max_depth, and max_features have already
been discussed in DT. Besides, n_estimators represent the
number of DTs in the forest. The performance of RF can
be increased by properly tuning the hyper-parameters of
RF through optimization.
7) GRADIENT BOOSTING CLASSIFIER (GBC)
GBC is also an ensemble classifier that combines different weak learners (typically DT) into a single strong
learner in a forward stage-wise fashion by optimizing the
differentiable loss function [37]. Generally, ‘deviance’ or
‘exponential’ is used as a loss function where ‘deviance’
refers to deviance (logistic regression) for classification with
probabilistic outputs. For thrashing, ‘exponential’ gradient
boosting recaptures the AdaBoost algorithm. Other controlling parameters of GBC contained different parameters
such as n estimators, learning rate, and max depth where
n estimators indicate individual boosting stages to accomplish; learning rate reduces the performance of each tree [32].
10268 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 1. Classifiers and their controlling parameters or hyperparameters.
8) eXtreme GRADIENT BOOSTING (XGB)
XGB is designed based on the principles gradient boosting
framework. It can be used for supervised learning tasks such
as regression, classification, and ranking; similarly, it generates a prediction model in the form of an ensemble of
weak prediction models. The model in a stage-wise approach
is compassed with it as other boosting methods do, and it
generalizes them by approving optimization of a random
differentiable loss function. The gradient descent is used
by ‘Gradient Boosting’ to generate new trees based on all
previous trees. It supervises the objective function toward
the minimum direction [38]. An objective function has a
form, and it divides into training loss and regularization. The
mathematical equation has been added as follows:
obj(θ) = L(θ) + (θ), (6)
where θ denotes the parameters,  symbolizes the regularization term, and L is the training loss. The main
hyper-parameters of XGB are N_estimators, learning_
rate, n_jobs, max_depth, Gamma, min_child_weight,
colsample_by_tree. The hyper-parameters such as
N_estimators, learning_rate, max_depth have already been
discussed. Besides, n_jobs are relevant to the number of
parallel threads used to run XGB; Gamma represents the
loss required to make a further partition on a leaf of the
tree. The min_child_weight denotes the minimum sum of
feature example, i.e., instance weight needed in a child, and
colsample_by_tree is used for the subsampling of columns.
9) SUPPORT VECTOR MACHINE CLASSIFIER (SVC)
SVC is one of the most powerful supervised classifiers and used mostly for data classification in medical
diagnosis [39], [40]. It aims to build a decision boundary
in such a way that it is as far as possible from the closest data points from each of the classes, which are known
as support vectors. For non-linear problems like COVID
detection, a Radial Basis function (RBF) kernel is used.
For RBF-SVC, the controlling hyper-parameters are Cost(C)
and Gamma(γ ). The Cost(C) represents the regularization
parameter that controls the misclassification of the training
instances. Gamma(γ ) controls the ‘‘spread’’ of RBF kernel and, therefore, the decision region. The lower value of
Gamma(γ ) will broaden the decision region and vice versa.
The proper value of C and γ will increase the classification
performance, which can be achieved by optimization.
D. REQUIREMENT OF OPTIMIZATION
Most of the classifiers used in our entire study have some
hyperparameters. The classifier itself is the function of hyperparameters, and these parameters control the hyper-plane.
As an exemplification, XGB requires 7 Hyperparameters,
while KNN and DT have one parameter each [Table 1].
Classifier performance indices, e.g., classification accuracy,
error, specificity, sensitivity, etc. depend on the proper choice
of these parameters. This is an optimization problem, whose
general framework can be written as:
lim
z∈Z
J(Clf (z); Z), (7)
where z ∈ Z denotes the hyper-parameters z1,z2,z3, . . . ..,zn
belongs to Z. Clf denotes the classifiers, e.g. RF, SVM,
DT, NB, etc. and J(.) represents the objective function. This
objective function is the user-defined function where users
can use different classifier metrics such as classification
error or accuracy or other metrics described in the following
section of statistical evaluation of classification measures.
The general framework of the optimization problem can be
interpreted as minimizing the classification objective J(.) as
a function of classifier’s hyperparameters z ∈ Z. In this
study; mean of the the 10-fold cross-validation error is used
as an objective function. We chose one of the state-of-the-art
optimization algorithms named Bayesian optimization. This
algorithm used a stochastic process, namely, as a Bayesian
process, and it tried to find the optimal parameters in a smaller
number of iterations saving both memory and time [41].
Although various meta-heuristic algorithms such as GWO,
GBO, SMA, and HHO etc. successfully integrated into
many applications [42]–[44], hyper-parameter optimization
in expensive-to-evaluate objective function e.g., 10-fold
cross-validation loss, used in this study, makes it more
complicated [45]. Besides, meta-heuristic algorithms require
a set of input parameters that need to be found out to
obtain an improved performance as the performance of
the meta-heuristic algorithms are very sensitive to the
VOLUME 9, 2021 10269M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
input parameters. Furthermore, comparison among various meta-heuristic algorithms is only valid if the proper
input parameters have been set, which requires domain
knowledge [46]. Bayesian optimization is used to set the
parameters of the meta-heuristic algorithm [45], [46].
The Bayesian optimization algorithm is a global optimization method that is specially designed to deal with
such expensive-to-evaluate objective function, which is the
population and genetic operator (mutation, cross-over, and
selection) free algorithm. Bayesian optimization utilizes a
Gaussian process to compute an acquisition function that
evaluates the objective function. Besides, Bayesian optimization memorizes its previous evolution and utilize these statistics towards good solutions. It has been recently used in
COVID-19 detection using x-ray images [22]. Considering
the above rationale, Bayesian optimization has been applied
in this study.
To justify further, the proposed Bayesian optimization is
compared with the recently proposed Harris Hawk Optimisation algorithm [25]. This popular swarm-based and
gradient-free optimization algorithm is based on the cooperative behaviour and chasing styles of Harris’ hawks in nature
called ‘‘surprise pounce’’ [25]. We have chosen this algorithm
for comparison as it is very recent and outperformed by many
popular meta-heuristic algorithms such as GWO, Multi-Verse
Optimizer, Moth-Flame Optimization, Whale Optimization Algorithm, Bat Algorithm, Cuckoo Search, Firefly
Algorithm.
E. BAYESIAN OPTIMIZATION
Bayesian optimization (BO) is superior to grid search, random search, and manual tuning and therefore used in this
study [47]. This algorithm keeps track of the past evaluation results and uses them to form a probabilistic Gaussian model of BO of the objective function and use it to
find out the most optimal hyper-parameters; as an exemplar, in the case of RBF-SVM, the hyper-parameters are
C and γ . The BO algorithm selects C and γ for which
objective function J(RBFSVM;(C, γ )) provides the minimum value. Note that, the classification error is used
as an objective function. The BO algorithm is given
below:
Step 1: Build a Gaussian probability model of the objective function. In this study, classification error is the
objective function.
Step 2: Find the controlling parameters or hyperparameters that perform best on the Gaussian process.
Step 3: Apply these hyper-parameters to the true objective function.
Step 4: Update the Gaussian model incorporating the
new results.
Step 5: Repeat Step 2-4 until maximum iteration is
reached.
The Mathematics behind the Bayesian Optimization for X =
(x1, x2, x3, . . . , xn) independent features and y target variable
is given below:
P(y|X) =
P(X|y)P(y)
P(X)
(8a)
=
P(x1|y)P(x2|y) . . . P(xn|y)P(y)
P(x1)P(x2) . . . P(xn)
(8b)
=
P(y)
Qn
i=1 P(xi
|y)
P(x1)P(x2) . . . P(xn)
(8c)
=

1
P(x1)P(x2) . . . P(xn)

× P(y)
Yn
i=1
P(xi
|y), (8d)
Since all the variables except the target variable are independent, P(x1)P(x2) . . . P(xn) = Constant, Then Eq. (8d) can
be simplified as:
P(y|x1x2 . . . xn) ∝ P(y)
Yn
i=1
P(xi
|y), (9)
Now, from Eq. (9), we find the probability of a given set of
inputs for all possible values of the target variable y and pick
up the output with maximum probability:
y = argmax
y
P(y)
Yn
i=1
P(xi
|y), (10)
F. STATISTICAL EVALUATION OF CLASSIFICATION METRICS
We have used several performance evaluation metrics to evaluate the performance of the proposed framework. The accuracy (ACC), error, false-positive rate (FPR), sensitivity (SE),
specificity (SP), positive predictive value (PPV), Matthew’s
correlation coefficient (MCC), F1_score, and Kappa index
can be calculated from confusion matrix [48], [49]. A lower
value of error and FPR, and a higher value of ACC, SE,
SP, PPV, MCC, F1_score, and Kappa index indicate a better
model. Besides, 10-fold cross-validation has been used [52]
on the overall dataset. The most significant point should
be mentioned here that the box-plot and Analysis of Variance (ANOVA) test are typically executed, relying on the
10-fold cross-validation result. The statistical significance
is determined by the p-value derived from the ANOVA
test [50], [51]. Furthermore, the receiver operating characteristic (ROC) curve and the area under the ROC curve (AUC)
has also been used to evaluate the performance of the classifier. The recall rate vs the decision boundary curve has been
used to examine the performance. In this study, we have used
the value of 0.5 as the decision boundary threshold to provide
the same importance to COVID-yes and COVID-no classes.
G. FEATURE IMPORTANCE USING SHAP VALUES
The SHapely Adaptive exPlanations (shortly known as
SHAP), proposed in recent papers by Lundberg and Lee [53],
are calculated for any tree-based model. The SHAP values from Game Theory to attribute φi value to each feature can be mathematically ascertained using the following
10270 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
formula [54]:
φi =
X
S∈N\i
|S|!(M − |S| − 1)!
M!
[fx (S ∪ {i}) − fx (S)], (11)
where M is the total input features, N is the set of all input
features, and S is a subset of the input features.
• In this plot, all the variables are ranked in descending
order.
• The horizontal line (x-axis) quantifies how much the
value is associated with a higher or lower prediction. All
the left-sided points represent the observations shifting
the predicted value in a negative direction. In contrast,
the points on the right contribute to shifting the prediction in a positive direction. All the features are on the
left y-axis.
• The color shows whether that variable is high (in red) or
low (in blue) for that observation.
III. EXPERIMENTAL RESULTS
In this paper, the Bayesian optimization has been used along
with and without the ADASYN algorithm. In the case of
ADASYN, sufficient adaptive synthetic data has been created to eliminate the imbalanced nature among the majority
and the minority classes. Firstly, the effect of ADASYN has
been evaluated along with ROC, shown in section III.A. The
balanced model has also been tested on the original test
data in section III.B. Box-plot and ANOVA are presented in
section III.C using cross-validation accuracy to evaluate the
statistical significance. The Recall rate vs. decision boundary
curve and Bootstrap ROC with ADASYN are discussed in
sections III.D and III.E, respectively. Then, the evaluation of
feature importance using SHAP and the analysis of SHAP
values have been presented in sections III.F and III.G, respectively. Finally, the performance of Bayesian optimization
has been compared with the Grid search and random search
in section III.H.
A. BAYESIAN OPTIMIZATION WITH AND WITHOUT
ADASYN
The newly obtained balanced dataset has been utilized; 67%
of the total dataset is used for training and validation, and
33% is used for testing. After that, multiple classifiers are
used, and various statistical measurements are presented. The
effect of ADASYN has been experimented and validated in
this subsection.
To begin, in the upper portion of Table 2, the performance analysis for the COVID Dataset with the utilization
of the ADASYN algorithm has been demonstrated. It can
be seen that; RF provides the highest classification performance. However, the performance of XGB and GBC is very
close to RF. LDA and QLD show the worst classification
performance among various classifiers presented in Table 2.
The same AUC value of 99.70% is observed among these
three classifiers, as shown in Figure 4. To demonstrate the
effect of the ADASYN algorithm, the original unbalanced
dataset is used. The dataset is also divided in the same manner,
FIGURE 4. ROC Curve with ADASYN.
i.e., 67% of the total dataset is used for training and validation,
and 33% is used for testing. We rerun the optimized code
on this dataset, and the results on the test dataset without
ADASYN is presented in the lower portion of Table 2. It can
be observed that the highest accuracy of 97.17% is obtained
by RF, which is close to the classification accuracy using RF
with ADASYN. This could happen in the imbalance dataset.
Therefore, accuracy is not a good performance indicator. The
Kappa index, MCC, and AUC are more robust and reliable
indicators in this case.
It can be seen that the highest Kappa, MCC, and AUC
values of 8.96%, 9.36% using NB, and 75.80% using XGB
(Figure 5), respectively, are obtained. Compared to the upper
portion of Table 2, i.e., results with ADASYN, the Kappa,
FIGURE 5. ROC curve without ADASYN. Note that the optimized model
has not been created by using a balanced dataset.
VOLUME 9, 2021 10271M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 2. Classification performance (in %) on the COVID dataset with and without ADASYN.
TABLE 3. Classification performance (in %) on the original test data of COVID.
MCC, and AUC values are 88.23%, 87.84%, and 23.90%
times lower ADASYN algorithm is not applied, respectively.
This can be happened due to an imbalanced model. This
significant improvement using ADASYN concludes that classification performance can significantly be improved through
directly applying the ADASYN algorithm.
B. RESULTS USING ORIGINAL TEST DATA ONLY
So far, we have seen the effect of ADASYN on classification
performance. The ADASYN is an oversampling method, and
the synthetic data is mixed with original test data during data
balancing. Therefore, it could be argued that what are the
results of the balanced model on the original test data only
where synthetic data is not mixed?
To answer this question, balanced and Bayesian-optimized
models have been applied to the original test data. Different performance measures, such as accuracy, sensitivity, specificity, and ROC, are presented in Table 3 and
Figure 6. It can be seen that XGB provides the highest
accuracy, error, F1_score, FPR, Kappa, MCC and sensitivity of 98.63%, 1.37%, 99.29%,24.21%,75.08%,75.08%, and
99.29%, respectively. In contrast, SVC provides the highest
PPV, specificity, and AUC of 99.94%, 97.89% and, 98.90%,
respectively. It can also be seen that XGB performs the best
in most of the classification metrics presented in Table 3.
10272 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 4. The accuracy score (in %) of the different optimized classifiers using 10-fold cross-validation.
FIGURE 6. ROC Curve for COVID on original test data only using each
model. The optimized model has been created by using a balanced
dataset and then applied to the original test dataset.
Furthermore, these results are mostly inclined with
ADASYN results (upper portion of Table 2), and results are
significantly better than without ADASYN in all classification measures. The ROC curve shown in Figure 6 is also
visually very close to Figure 4. Note that the same test dataset
has been used without ADASYN (i.e., in the lower portion of
Table 2) and in Table 3 for a fair comparison. Finally, it can
be concluded that a balanced model can significantly improve
the performance of the COVID dataset and XGB shows the
best classifiers. The confusion matrix of the best performing
balanced model with ADASYN and with original test data
have been presented in Figure 7 to show how much COVID
and Non-COVID patients are correctly classified.
C. K-FOLD CROSS-VALIDATION
In the standard train-test-split method, generally, a small portion of the data is taken as the test set, and the total dataset is
not tested. To overcome this issue, the k-fold cross-validation
(CV) is one of the helpful techniques exploited to test
the effectiveness of machine learning models. It is also a
re-sampling procedure to evaluate, and k = 10 is used in
this study. The first fold is used for testing, and the remaining
folds are used for training and repeated ten times to test the
total dataset fold-by-fold basis. The 10-fold cross-validation
result is presented in Table 4, where the classification result of
each fold is shown. The final row provides the average classification accuracy of the 10-fold results. From the Table 4, it is
observed that the least score has been obtained using QLDA,
whereas the XGB touched the mountain point, grabbing a
score of 96.70% and RF has attained an average accuracy
of 96.46%. On the other side, the classification performance
using Decision Tree, SVC, and GBC was less than XGB
and RF but above 90%. Note that, the data processed by
ADASYN is used only to train the classifier, but the original
test is used during testing and performance comparison.
Figure 8(a) showed the accuracy of different classifiers
using the COVID original dataset using a box-plot. Here
one-way ANOVA provided a p-value of 3.32 × 10−107 for
the original COVID test dataset, which is statistically significant (p < 0.005). It also provided an interactive plot of
multiple comparisons of means in Figure 8(b) that showed
the highest mean accuracy from XGB that is statistically
significant from seven classifiers (GBC, DT, SVC, NB, KNN,
QLDA, and LDA). In contrast, it is statistically not significant
from RF, because the mean of RF is almost identical. Note
that, Figure 8(b) is an interactive plot where the significance
of different classifiers can be visualized by clicking on the
specific classifier level. For instance, RF is blurred (shown
in grey) defining its insignificance as XGB is selected. Similarly, GBC and DT will also exhibit statistical insignificance
if one of them is selected.
D. RECALL RATE VS. DECISION BOUNDARY CURVE
The recall rate, in general, depends on the decision boundary
using a certain threshold. To exemplify, the recall rate vs.
decision boundary curve displayed in Figure 9(a), where
VOLUME 9, 2021 10273M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 7. Confusion matrix of the balanced model applied in (a) COVID
test Dataset with ADASYN, (b) original COVID test Dataset only. Figure 7(a)
depicts the percentage of the correct classification in with the first two
diagonal cells generated by the trained network. The numbers of patients
who are correctly classified as a COVID and non-COVID were 3150 and
3233, corresponding to 48.7% and 49.9% in each group’s patients,
respectively. Likewise, the numbers of patients who are incorrectly
classified as a COVID and non-COVID were 24 and 67, with 0.4% and 1.0%
correspondingly among all patients in each group. Similarly, the overall
99.2% were correctly, and 0.8% were incorrectly classified COVID, and
non-COVID were overall, 98.0% and 2.0% correctly and incorrectly
classified accordingly. In the case of prediction, the correct overall
predictions for COVID and non-COVID were 97.9% and 99.3%, respectively.
On the other hand, the incorrect results for COVID and non-COVID were
2.1% and 0.7%. Similarly, we can also interpret Figure 7(b).
0.5 decision boundary threshold (T ) has been used for the
‘‘COVID-19-yes’’ class. The recall rate of QLDA is about
0.98 at default threshold T = 0.5, meaning that about
98% times this optimized classifier can truly classify the
FIGURE 8. Box-plot for (a) COVID Dataset and (b) multi-comparison test.
Note that (b) is a graphical user interface tool by which one can test the
statistical significance of any classifiers. Here we only show the effect
of XGB. The effect of other classifiers can also be interpreted in the same
way.
‘‘COVID-19-yes’’. The XGB and RF provided a moderate performance of around 0.75 at default threshold
T = 0.5 defining the ‘‘COVID-19-yes’’ class. The SVC shows
the third highest performance of around 0.90. In contrast,
the recall rate of NB at this threshold is 0.25, meaning
that only 25% times NB can truly classify the ‘‘COVID19-yes’’ class. A similar scenario is observed for the
LDA classifier.
On the other hand, looking at Figure 9(b), the recall rate of
QLDA is drastically falling to a value of 0.1 at T = 0.5,
revealing that only 10% times QLDA can classify the
‘‘COVID19-no’’ class. The recall rate of XGB, GBC, and
RF is about 0.99 at this threshold whereas the recall rate
of SVC is 0.90. Finally, considering both ‘‘COVID19-yes’’
and ‘‘COVID-19-no’’ classification using recall rate vs.
decision threshold measure, it can be concluded that
SVC, XGB, and, RF provide the satisfactory recall
rate among different optimized classifiers predicting both
classes.
10274 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
FIGURE 9. Recall rate vs. decision boundary curve for (a) COVID positive and (b) COVID negative.
E. BOOTSTRAP ROC WITH ADASYN
To determine whether the optimized model is highly sensitive
to training data or not, bootstrapping is performed on the
XGB model as it is the best performing model. This gives
Nboot XGB having slightly different discriminative abilities.
To show the error, three ROC curves are plotted in Figure 10;
the middle one represents the average ROC where upper
and lower curves represent the 95% confidence interval (CI).
To obtain this bootstrap ROC, Nboot = 100 XGB models are trained and mean AUC of 0.98 with an upper and
lower confidence interval of 0.97 and 0.99, respectively, are
obtained. This indicates that training is not highly sensitive to
the training dataset.
F. FEATURE IMPORTANCE USING SHAP
In a variable importance plot, the most significant variables are sorted in descending order. The top variables
contribute more to the model than the bottom ones
and thus have high predictive power. By way of example, ‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’,
‘‘high_risk_interactions’’, ‘‘wheezes’’ are the most important
features, where ‘‘fever’’ touched the mountain point in this
case [shown in Figure 11]. Simultaneously, ‘‘pulse’’ and
‘‘sore_throat’’ received the least importance in classifying
the COVID-19 contaminated patients.
G. SHAP VALUE ANALYSIS
From the pictorial example of SHAP analysis [Figure 12] for
training data, it can be summarized that the three features,
‘‘fever’’, ‘‘cough’’, ‘‘high_risk_exposure_occupation’’ and
‘‘loss_of _smell’’ have a massive positive impact is on the
target variable. The ‘‘high’’ comes from the red colour, and
the ‘‘positive’’ impact is shown on the X-axis. Whereas,
we conclude by mentioning that the features ‘‘ctab’’ and
‘‘wheeze’’ are highly negatively correlated with the target
variable. In this way, all the variables can be efficiently
explained. It should be mentioned that the behaviour of the
FIGURE 10. Bootstrap ROC curve of the COVID dataset using XGB
with 95% CI.
XGB model is defined by the SHAP and are not necessarily
causal in the real world. In other word, SHAP values do not
provide the causality; it only describes the model behaviour
and the behaviour of the data used to build the model [55].
As the model does not predict all the COVID patients accurately, it is plausible to get some false positives and false
negatives. However, the SHAP value can able to explain such
results, and the summary plot will be helpful to explain those
results.
H. PERFORMANCE ON THE GRID SEARCH, RANDOM
SEARCH, BAYESIAN OPTIMIZATION AND HARRIS
HAWKS OPTIMIZATION
We propose to use Bayesian optimization techniques in
our framework, and therefore, it is logical to compare
VOLUME 9, 2021 10275M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 5. Comparative search techniques.
FIGURE 11. Feature importance plot using SHAP for XGB.
FIGURE 12. The SHAP variable importance plot of training data using XGB.
the Bayesian optimization algorithm with commonly used
parameter search algorithms. Two popular and widely used
algorithms, namely, grid search and random search, compare
with our proposed techniques. Table 5 presents the comparison of different search algorithms in terms of several
parameters evaluated; the overall time is taken (in sec.) to
complete the program, cross-validation accuracy score, test
score. All the simulations were run on Intel core i9 computer
having 64GB RAM and used the XGB model. It can be seen
that it takes 10473.740 Sec. to complete the simulation using
grid search, whereas random search and proposed Bayesian
optimization take only 162.794 Sec. and 675.389 Sec, respectively. Furthermore, the random search and Bayesian algorithm take 30 parameters each, while the grid search requires
more parameters, which is 218 times than that of others. The
test score using Bayesian optimization is 98.20%, which is
better than grid search, random search.
The pictorial depiction of the comparative search methods has also been given in Figure 13, from where it can
be added that at the initial stage, the accuracy of Random
Search was nearly 97.50%, which was almost stable up to
12 iterations. Then, with a single iteration, it takes a
sharp change in its accuracy, touching closely the score
of 98%, which was followed by an unchanged condition until
30 iterations. In contrast, the score of our proposed Bayesian
Optimization technique commenced before 97%, which was
almost steep up to 2 iterations, touching the accuracy
FIGURE 13. Comparative optimization techniques applied to the XGB
model.
10276 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
above 98%. The most exciting information should be mentioned here that the score of our proposed method remains
unchanged, except for a slight change after 15 iterations.
Before finishing 30 iterations, its accuracy touched the mountain point.
The proposed Bayesian Optimisation Framework has
also been applied to the most recent Harris Hawks optimization algorithm calculated over 200 evolutions with
20 populations on the same train-test settings. It provides
98.39% cross-validation accuracy, whereas the testing accuracy is 98%. The result is very similar to the Bayesian Optimisation framework. However, it takes 6204.80 Sec. which is
9.4 times slower than our proposed framework as it requires
more evaluations and optimization calculations; see Table 5.
To further justify, a statistical significance test between
Bayesian optimization and Harris Hawks optimization algorithm is performed on 10-fold cross-validation using t-test.
After that, the p-value is calculated, and the box-plot is
plotted. A p-value of 0.47 is found, which suggests that
there is no statistically significant difference between these
two optimizations. The box-plot illustrated in Figure 14 also
justifies the same statements.
FIGURE 14. Box-plot of Bayesian optimization and Harris Hawks
optimization.
IV. DISCUSSION AND COMPARISON
In this research, a Bayesian optimization-based machine
learning framework with a class balancing strategy using
the ADASYN algorithm is proposed to identify COVID
patients from their inpatient facility data. Nine state-of-theart classifiers such as LDA, QLDA, NB, KNN, DT, RF,
XGB, GB, and SVC are utilized in this proposed framework to identify COVID patients. Different classification
measures such as accuracy, sensitivity, specificity, Kappa
index, Matthews correlation coefficient are used to show the
efficacy of different classifiers. This study also performed
10-fold cross-validation accuracy to achieve statistical significance using ANOVA, recall rate vs. decision boundary
threshold analysis, ROC, and bootstrap ROC. Finally, SHAP
analysis is performed to interpret the feature importance and
interpret the model. These different classification indicators
describe model performance from another point of view.
The primary intention to use these indicators is to describe
the classification performance from a different perspective.
It can be seen from Table 2 that RF yielded the highest
classification performance in terms of accuracy, kappa index,
and MCC, etc. However, the classification performance of
XGB and GBC is very close to RF. The ANOVA and
multi-comparison tests show that the average accuracy of
RF, XGB, and GBC are very close and are not statistically
significant. However, the 10-fold cross-validation accuracy
of XGB provides the highest value (see Table 4). Moreover, the balanced XGB model offers the highest classification performance when applied to the original test data (see
Table 3). Also, the recall rate vs. decision threshold boundary indicates the superior performance of XGB and SVC
(see Figure 9). This concludes that the balanced and optimized XGB model would be the best choice for detecting
COVID patients using their inpatient facility data. Therefore,
further analyses such as bootstrap ROC and SHAP analysis
and features importance analysis are done on a balanced and
optimized XGB model.
Regarding the ADASYN algorithm, it should be mentioned
that ADASYN adaptively generates synthetic data samples
for the COVID-yes class since it is a minority class to reduce
bias introduced by imbalanced data distribution. ADASYN
moves the classifier’s decision boundary towards harder-tolearn examples, improving the learning performance [28].
Therefore, applying the ADASYN algorithm enhances the
learning process and eventually improves our COVID classification performance; see Table 2 to understand the effect of
ADASYN in detail. Regarding Bayesian optimization (BO),
unlike grid search and random search, it can be mentioned
that BO takes the previous objective function evaluation
into account, and the function goes to the optimal solution.
Therefore, the hyperparameter using BO provides fine-tuning
parameters, which ultimately builds an optimized model and
consequently increases the classification performance. SHAP
is used to determine feature importance and model interpretation; it can be mentioned that SHAP uses a game-theoretic
approach, which has an excellent mathematical background
and current state-of-the-art approach.
Due to the salient features mentioned above, it can be
noted that the proposed framework can not only be applied to
COVID-19 detection but also applied to other classification
problems such as diabetic prediction, asthma prediction, etc.
While describing the significance and strength of this study,
it is also logical to explain the weaknesses of this study. The
database used in this study is a moderately large dataset.
It will be useful to apply the proposed framework on a larger
dataset and validate the proposed approach on a completely
independent dataset before clinical use. Clinical blood sample
data and integration to X-ray and CT-scan will enhance the
detection rate and validity. This is beyond the scope of this
study.
VOLUME 9, 2021 10277M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 6. Description of the clinically operable decision tree algorithm.
FIGURE 15. A decision rule using four key features and their thresholds
in absolute value.
A. DEVELOPMENT OF A CLINICALLY OPERABLE
DECISION TREE
A clinically operable decision tree would benefit clinical staff
as it is straightforward to understand the underlying process. As DT are simple classifiers consisting of sequences of
binary decisions organized hierarchically [56], we have built
a simple tree by using four important features, x1 = cough;
x2 = loss of smell; x3 = high-risk exposure occupation;
x4 = sats; Note that, the continuous value of oxygen saturation feature, i.e., x4 feature is discretized into three different
levels of 1, 2 and 3 to denote severe, moderate and normal
level, respectively. x4 feature value lies between 75 and 90
mm-Hg is treated as severe, 91 and 95 mm-Hg as moderate,
and 96 and 100 mm-Hg as a normal level. Figure 15 represents the corresponding DT, and the description of the tree
algorithm is given in Table 6.
B. DEVELOPMENT OF A DECISION SUPPORT
SYSTEM (DSS)
A DSS could be beneficial to support clinical staff for screening COVID-19 patients from their inpatient facility data.
A DSS is usually a graphical representation of decision,
FIGURE 16. Probabilistic output for the DSS. In the upper figure, the 0 has
represented a subject with COVID negative, whereas 1 represented a
subject with COVID positive. The lower figure represents a probabilistic
outcome of the subject affected by COVID, where the red dotted line
defines the threshold level. When the patient data level exceeds this
threshold level, then the subject will be considered as COVID positive.
Whereas the subject with the probability of less than 0.5, i.e., the
threshold value, will be regarded as COVID negative. In either way, we can
say that this the chance that a person is affected by COVID.
COVID-19, in this case, to visualize the probable state of the
patient. A possible outcome of COVID suspected patient’s
inhouse facility data is presented in Figure 16, in terms of the
posterior probability. A probabilistic result is more intuitive
to the clinical staff and, therefore, used in this DSS. Note
that 100 patients are used from the test database for illustration purposes. The patient is sorted in ascending order so
that patients with ‘‘COVID-no’’ labelled appears first, and
patients with ‘‘COVID-yes’’ appear.
C. COMPARISONS WITH OTHER METHODS/STUDIES
To delineate the superiority of our proposed research,
an illustrative comparison of our work has been accomplished to other COVID studies. From the tabular illustration
[Table 7], it can be mentioned that both Jim et al. [11] and
Ozturk et al. [57] used CNN to obtain the accuracy respectively 92.50% and 98.08%. Furthermore, multiples research
works have been carried out by [7], [63], [64] with the direct
10278 VOLUME 9, 2021M. A. Awal et al.: Novel Bayesian Optimization-Based Machine Learning Framework for COVID-19 Detection
TABLE 7. Comparison of performance with other methods.
implementation of XGB using mostly clinical data, where
the average of the accuracy obtained from [7], [63] was
less than 90%. On top of that, Wu et al. [58] used RF to
get a classification accuracy of approximately 96%, which
outperformed Brinati et al. [59], who utilized both DT and
RF. In addition, the lowest performance was obtained by Sun
et al. [60], who used the SVM classifier for clinical and
Demographic data. Most importantly, although the accuracy
of Wu et al. [58] is slightly higher than that of our proposed
method, the AUC and Specificity of our work far outweigh
the other methodologies mentioned here.
V. CONCLUSION
This paper presents the optimal use of different machine
learning techniques, including state-of-the-art classifiers,
to predict COVID. The proposed approach is aimed to handle
the real-time in-home dataset in detecting the COVID effectively. Thus, the proposed technique provides a user-friendly
and low-cost tool for COVID detection. In designing the
method, the COVID dataset, collected from CH-BH, has
been used to assess the performance using different classification metrics such as accuracy, sensitivity, specificity,
kappa index, etc. The hyper-parameters of different classifiers
have been optimized using Bayesian optimization, and the
ADASYN has been used to balance the dataset. Compared
to the studies presented in this study, it is evidenced that
both the classification accuracy and AUC for our proposed
framework has attained the highest values of 98.50% and
99.40% using XGB, respectively. As the proposed approach
has been applied to a moderately large dataset, it should be
used on a big dataset before clinical trials. However, our
primary intention is to test the feasibility of such settings.
A similar approach can be applied to design other classification problems. Finally, two potential applications of our
proposed technique, namely clinically operable decision tree
and decision support system, would be beneficial for clinical
staff and building an efficient recommender system. It could
easily be integrated into mobile devices which would be very
useful for the end-users.
DATA AVAILABILITY
The raw dataset can be accessed through Github:
https://github.com/mdcollab/covidclinicaldata. The processed data can be obtained from the first author (Md Abdul


NEW_PAPER



A Proactive and Practical COVID-19
Testing Strategy
—KUAN SONG
Gago Ltd., Beijing 100870, China
—SHIQI JIAO
Gago Ltd., Beijing 100870, China
—QIANG ZHU
Gago Ltd., Beijing 100870, China
—HUITAO WU
Zhejiang Lab, Hangzhou 311122, China
(Corresponding author: Kuan Song.)
IEEE DOI 10.1109/EMR.2020.3017648
Abstract—To reopen the economy safely during the COVID-19 pandemic,
governments need the capability to proactively identify new and often
asymptomatic infections, as well as contact tracing. Policymakers and public
health professionals need a sampling-testing method that can achieve broad
population coverage without overwhelming medical workers. We observe that
COVID-19 high-risk groups are located in the hubs and cliques of our geosocial network, formed by the close encounters of people during daily life.
These individuals are the de facto “canary in a coal mine”. We propose that
nations offer free and anonymous testing service to them. With open-source
computer algorithms and datasets, only a small fraction of the population
selected for COVID-19 testing can cover the majority of high-exposure-risk
individuals. A 0.3% sampled testing for a megacity covers 3/4 of its entire
population. A 3% sampled testing for a rural town covers 3/4 of its entire
population. With government oversight and public consent, this approach can
serve each province/state or city/township for decentralized daily testing
planning. However, to protect privacy, we recommend constructing the geosocial network of anonymized cellphones, not named individuals. This
infrastructure should be dismantled once the pandemic is largely over. This
can be achieved by policymakers, health workers, and engineers together in
solidarity.
Key words: COVID-19, decisions under risk and uncertainty, geo-social
networks, network theory, sampling strategy
PROBLEM FORMULATION
THE COVID-19 pandemic puts
global governments in a dilemma.
Before social distancing and stay-athome orders, rapid chain infection
happened. Strict stay-at-home orders
save lives but risk economic
recession. Public opinions are
growing increasingly polarized and
led to armed protesting [1]. If the
economy collapses in any nation, the
ensuing mass unemployment and
social unrest can expose the most
fragile families to the pandemic.
Reopening the economy safely is,
thus, a necessary public health policy.
However, recklessly loosening
stay-at-home policies and reopening
the economy in hard-hit nations can
be risky. Asymptomatic COVID-19
patients can infect others in offices or
onboard public transportation.
Droplets and aerosols from people
talking can carry the virus [2]. If the
chain of community infection goes
undetected, it can grow like wildfire.
Hospitals will again be overwhelmed
and the pandemic can become
endemic. Thus, a prerequisite to
reopening the economy is the ability
to rapidly identify new cases among
the asymptomatic population [3]. That
enables contact tracing of community
infection, and subsequent containing
local outbreaks. There are other
prerequisites such as a declining
number of patients, universal
availability of PPEs, which are as
important but will not be discussed in
this study.
To that end, Mr. B. Gates prescribed a
drastically increase of nucleic testing
capability for COVID-19 [4].
IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020 63
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/Meanwhile, a Harvard panel report
proposed daily proactive testing of 5–
20 million people in the United States
alone or 2–6% of the total population
[5]. The study did not specify how
they come to that estimation nor how
good that estimation is. The
challenge to that testing capability lies
not only in the production and
distribution of test kits but more
crucially in the logistics of the actual
tests. There might not be enough
medical workers and lab technicians
in the US to conduct 20 million tests a
day. Peto et al. [3] advocate universal
weekly random testing of 13% of the
U.K. population to reach 90%
coverage. That translates to 2%
daily testing of the entire population.
This is a huge logistic challenge for
the U.K. as well. Similar random
sampling schemes are being
developed for India [6]. However,
none of these testing schemes
materialized since their conception.
This probably is because
governments deem them impractical.
This logistical challenge can be
readily solved, if only a selected
0.1–0.3% sample of the total
population is needed to tested
daily or weekly. As of now, megacities
in the United States, Europe, and
China already have that testing
capacity.
We propose the daily testing of only a
small subset of the asymptomatic
population, specifically targeting the
hubs and cliques in a geo-social
network of anonymous cellphones. If
any result comes back positive, then
the people around them need further
testing as contact tracing. The geosocial network of anonymous
cellphones in a given area during a
given time period consists of vertices
and links. The vertices are the
cellphones, carried by their owners
active in the economy. The links
among them indicate significant close
encounter, such as working in the
same office, living in the same house,
and sharing the same ride.
The following graph illustrates a
simple geo-social network of three
young working professionals. Mary,
Giuseppe, and Lee work in a small
consulting firm. Mary shares her
house with a partner and jogs with a
group of X (5 to 20) people to the
office daily. Giuseppe shares a house
with his parents and 2 siblings and
drives alone to the office daily. Lee
lives alone in his condo and takes a
40-min metro ride to the office daily
with Y (10 to 50) people in a train car.
In the geo-social network graph, we
use F to denote family members, and
C to denote commuters they meet
daily. For simplicity we assume that
other family members stay strictly at
home, the commuters interact with no
one else, and all the people in this
graph are asymptomatic.
Given such a geo-social network,
who should we administer COVID-19
tests to if we only have three test kits
available every day? What about two
test kits? Or even just a meager one
test kit per day? We might want to
reserve testing to the people who are
most exposed to the virus, and who
have the highest potential to infect
others. Very often the same people
meet both criteria. Naturally, we
would choose to first test Mary,
Giuseppe, and Lee because they
connect to more people than others.
Lee has the highest exposure risk
because of the packed subway ride
with dozens of commuters, and thus,
he should get the test if only one test
kit is available. In our opinion, each
municipality and/or CDC office should
have the tools to automatically
analyze such geo-social networks
and provide testing service to the
individuals with the highest exposure
risks.
There exists no full-scale study on
COVID-19 exposure on individuals.
Patients of old age or with preexisting medical conditions have the
highest death rate once infected, but
not necessarily the highest exposure
chances before getting ill. We
observed that two types of people
might be the most exposed to
COVID-19 due to their distinctive geosocial network niches. We could
focus our limited testing capabilities
on them.
Around the world, senior government
officials have been disproportionately
hit by COVID-19. The list includes
prime ministers of Britain and Russia,
the first Ladies of Spain and Canada,
the first family of Brazil, and countless
ministers around the world. Likely this
situation resulted from their busy daily
schedule to meet with a large number
of people, often internationally. In
other words, the “hubs” in our geosocial network are most exposed to
infection risks. In a sense, they are
the canary in a coal mine. Timely
testing for them could buy time for
their local communities.
People spending long hours in
close quarters have seen horrendous
local outbreaks of COVID-19.
Well-known cases include the
Diamond Princess, USS Theodore
Roosevelt, USS Kidd, and many
hospital wards, retirement homes,
factories [7], and prisons [8] around
the world. In a geo-social network,
these communities are known as
clique’s because each member is
within close vicinity of all other
members and, therefore, geo-socially
interconnected. Such cliques are
often exposed to airborne droplets
carrying the virus, which leads to
unusually high percentages of local
infection.
Thus, our goal is to identify, in each
geo-social network of a workforce
embracing economic reopening, the
hub’s and clique’s people for daily
COVID-19 testing even though they
are asymptomatic. If any hub’s or
clique’s individual turns up positive
for COVID-19, the geo-social network
of his/her immediate daily interaction
circle needs to be tested, and the
patients quarantined. We argue that
this is an efficient sampling strategy
64 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020for COVID-19 testing in a reopened
economy.
Each city has its own logistical
constraints on testing. Some cities
can afford to test daily 1% of its
workforce, others may afford to test
0.1%, which testing percentage is
sufficient? How to measure
sufficiency? How can each city
perform its own rapid assessment on
a daily basis?
METHODOLOGY AND
EXPERIMENT
To address the abovementioned
questions, we conducted a pilot study
using existing social network tools on
two real-world social network
datasets. The simplest approach is to
single out individuals with the most
links in the geo-social network for
testing. But the problem with that
approach is that those individuals are
often in the same local community
and, thus, have highly overlapped
geo-social networks [9]. For example,
doctors and nurses working in the
same ER room, or the congress
members of the same nation. If we
concentrate our testing resources on
them, we will miss out on the big
picture in the population and have a
social inequality issue.
Thus, we aim to find the individuals
with the most links in the geo-social
network, while the individuals directly
linked to them cover the maximum
percentage of the population. This
can be achieved by dividing the geosocial network of mega-cities like
Wuhan or NYC into small
communities or cliques. We can then
identify the hub’s in each community.
Unfortunately, in mathematics and
computer science, this problem is
NP-hard. To find the exact optimal
solution takes exponentially
computation time as the size of the
population grows. There exist
heuristic solutions that can produce
imperfect yet useable solutions with a
limited time budget. These solutions
were developed over the past two
decades not just to analyze social
networks and internet traffic [9].
These algorithms are also the
workhorses behind Internet search
engines such as Google [10] and
Microsoft Bing [11].
The heuristic algorithms examined
here are developed in academia and
open-source. We also share crude
yet simple Python snippets [12], [13]
to make use of these models with
real-world datasets. We hope that the
public health sector can integrate
these methods without hiccups. In our
pilot study, both algorithms can
analyze geo-social networks with
millions of vertices (people) in several
minutes on a Linux workstation. This
indicates the feasibility of
decentralized day-to-day operations
in each municipality without additional
charges.
The Louvain algorithm was created
by Blondel et al. [14] from the
University of Louvain, Belgium. It is a
bottom-up clustering algorithm to find
communities large or small, often very
different in size. The METIS algorithm
[15],[16] was created by G. Karypis
and V. Kumar from the University of
Minnesota, USA. It enables parallelprocessing to partition social
networks into communities of similar
Figure 2. Selecting the hubs from a sample geo-social network. sizes.
Figure 1. Sample geo-social network of a small consulting company.
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 65The first dataset we tested on is a
Googleþ social network dataset [17],
including 107 614 people, and 13 673
453 links among them. On average
each person is connected to 127
others. This number is comparable to
the number of people a working
professional meets daily in a busy
metropolis using public
transportation. It is a densely
connected network.
The second dataset we tested on is
an Internet server topology dataset
[18] originally assembled to study the
transmission of computer viruses. It
has 1 696 415 vertices (machines)
and 11 095 298 links among them. On
average each machine is connected
to 6.5 others. This number is
comparable to the number of people
a working professional meets daily in
a small town without using public
transportation. It is a sparsely
connected network.
To be clear, we do not assume that
COVID-19 transmits along with cybersocial networks. We consider the two
datasets previously because they
have network structures similar to
geo-social networks of the workforce,
which has close-range physical
interactions daily in a reopened
economy.
Our study is designed in the following
four steps. First, we partition the
network datasets into U clusters
using the METIS algorithm and the
Louvain algorithm. Then in each
cluster, we single out K individuals
who have the most connections
within the cluster. In total, we have
U
K individuals chosen for COVID-19
testing. As a simpler baseline choice,
we single out the top U
K individuals
with the most connection links in the
complete geo-social network. We
adopted the value of parameter U as
the total number of individuals S
divided by 100 or 1000. In this way,
the total amount of individuals chosen
[U
K] will be a percentage of the total
population. The evaluation metric is
the coverage of the tested individuals,
defined as the number of individuals
immediately linked to the tested
individuals divided by the total
number of individuals. The four steps
are illustrated in Figure 2 using the
sample described in Figure 1.
FINDINGS
The following two tables list the
coverage rates from three different
algorithms on two real-world
datasets. They can tell us to an extent
how well the geo-social network
sampling and testing cover the
population in a reopened economy.
The “Coverage” percentages are
calculated as the percentage of
people who had close contacts with
the COVID-19 test subjects, out of the
general population.
On both datasets and all sampling
percentages, the METIS algorithm
steadily outperforms other algorithms
in terms of coverage rate. This does
not indicate that the Louvain
algorithm is inferior. It was designed
to identify natural-looking
subcommunities large and small. Its
most suitable use would be to
visualize and trace local community
transmission.
On the densely connected Googleþ
dataset, we are indeed running a
simulation of busy urban life such as
that in NYC, or Wuhan. Results listed
in Table 1 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
Table 2. Coverage Percentage out of Geo-Social Network Sampling
Test on Skitter Dataset.
Table 1. Coverage Percentage out of Geo-Social Network Sampling
Test on Googleþ Dataset.
66 IEEE ENGINEERING MANAGEMENT REVIEW, VOL. 48, NO. 3, THIRD QUARTER, SEPTEMBER 2020an immediate-connection coverage of
74.1% of the population. By sampling
2% of the population, we can
effectively represent an immediateconnection coverage of 92.3% of the
population. Beyond 2% sampling,
extra sampling and testing work offer
marginal benefit.
On the sparsely connected Skitter
dataset, we are indeed running a
simulation of quiet small-town life
such as that in Ithaca upstate NY, or
Suifenhe China. Results listed in
Table 2 indicates that, the METIS
algorithm used to sample 0.3% of the
population can effectively represent
an immediate-connection coverage of
51.4% of the population. By sampling
3% of the population, we can
effectively represent an immediateconnection coverage of 77.7% of the
population. Beyond 3% sampling,
extra sampling and testing work offer
marginal benefit.
DISCUSSIONS
In summary, our study shows that a
highly efficient sampling, testing, and
tracing scheme can be achieved by
constructing the geo-social network of
a city or township, safeguarding the
economy reopening. The busier the
city is, the smaller percentage we
need to test for COVID-19. We
estimate that 0.3% to 3% can monitor
COVID-19 transmission covering the
majority of the population. This is not
to say that our sampling can keep
COVID-19 from happening, but rather
a realistic managed low-occurrence
live-with-COVID approach. Also
arguably this is also not as important
as the universal wearing of masks as
PPE.
This pilot study assumes that a geosocial network dataset for each city/
township can be constructed every
day. Indeed it can, only if with public
consensus and government
oversight. Our cellphones currently
produce multiple location-tracking
data streams, including
telecommunication tracking,
operating system tracking, and map
API-based tracking. In each nation,
the cellphone service providers
acquire coarse-resolution tracking
data streams via the triangulation of
3G/4G base stations. Operating
system tracking data stream exists in
each Android phone and IPhone as
an essential service by integrating
GPS and WiFi signals. In addition,
most of the cellphone apps on the
market call various precision map/
location service APIs from Google
Map, Amap, Bing Maps, Baidu maps,
HERE maps, or Tencent maps for
location upon App use. That tracking
computes the 3G/4G signal along
with GPS and WiFi. The current data
records link location to each unique
cellphone, but not to individual
persons. These data records are
highly confidential and literally
guarded by laws like the European
GDPR against wanton usage.
Societies already embraced some of
their usages in real time, such as
Google traffic alert [33]. Hence, a
geo-social network of anonymous
cellphones can be quickly computed
out of existing data streams, with the
right permission clearance. This
study does not advocate collecting
cellphone location data with personal
IDs.
Geo-social network could be
constructed through another
process, arguably less intrusive.
Google and Apple are developing a
Bluetooth contact-alert service [19].
It can tell the user whether his/her
phone was within Bluetooth
distance of a COVID-19 patient’s
phone recently. However, this
feature is only valid if everyone
turns Bluetooth on and, thus, may
not eventually work out. By now,
this effort has largely died OFF.
With location data sitting idle with the
telecommunication service providers
and tech giants, the general public,
and national governments may want
to discuss and decide whether or not
to make use of it during the pandemic
[20], [21]. People have valid reasons
to worry about privacy,[22] but these
are not normal times [23]. Safe and
moral usages of this data flow require
mandatory erasure of any and all
personal details from the dataset and
render it anonymous except to
oneself. For example, only the citizen
him/herself can know that he/she is a
hub of the geo-social network. If he/
she wants to show up for work without
endangering coworkers, he/she
needs to have a free COVID-19 test.
When a patient’s test comes back
positive, then the people who had a
recent interaction with him/her have
the right to be notified via their
phones. Automatic contact tracing
can be done with technology instead
of spreading thin our medical
workforce in the field. When the
pandemic is about to be fully
eliminated, this “war-time”
infrastructure should be dismantled
so as not to be abused in peacetime.
We find it is logistically feasible for
local facilities to operate a daily
routine. First, every night, the local
locational data flows from either
telecommunication providers or tech
giants are used to construct the geosocial network of the previous day.
Residents who are the identified
0.3%–3% hubs in that network wake
up the next morning with a text
message notification for a quick test
before showing up for work. Testing
capacities vary from region to region.
Some developed nations might afford
to test them every day. Developing
nations might afford to test once a
week. Either way helps.
To further alleviate the pressure on
logistics, nations can consider a
recent practice [30] in Wuhan,
China during May 13–22, 2020.
Nasal swabs from multiple persons
from the same neighborhood are
mixed into one testing. This is
known as pooled testing. It reduces
logistics pressure of testing to 1/5
or even 1/10, compared to
PROACTIVE AND PRACTICAL COVID-19 TESTING STRATEGY 67conducting 1 test for each
individual. In the United States, the
importance of pooled testing is just
gaining recognition [31], but not yet
implemented en masse.
Pooled testing and geo-social
network sampling can boost each
other in many ways. First, each batch
in pooled testing can consist of
individuals from the same “clique” of
the geo-social network because they
share similar risks of infection.
Second, when testing resources are
very scarce, pooled testing of
selected “hubs” in the geo-social
network can be highly efficient. Third,
tracing of infection chains can be
achieved with geo-social networks
after pooled testing.
Another possibility to improve this
approach is to integrate the infection
rate of population groups into the geosocial network. A vanilla geo-social
network can measure the chance of
exposure to infection. When
multiplied by the infection rate of age
groups, it can measure the chance of
infection.
Around the world, pilot experiments
on locational tracking to fight the
pandemic are sprouting, for example
in Israel [24], South Korea [21], and
China [25]. In China, Alibaba and
Tencent scrambled to work with
government oversight creating
location-based health-checkup Apps
starting in late January 2020. The
initial version went online on February
11 after 2 weeks of intensive
development [26]. It can only trace
location down to city blocks and tell
the user whether they have been to
COVID-19 hot zones in the past 14
days. The majority of the Chinese
public chose to adopt this
infrastructure. Along with other
measures such as universal maskwearing and quarantines, it
contributed significantly to the
Chinese effort of containing and
almost total elimination of COVID-19.
This effort released openly its
technical whitepapers [25] on May 1,
2020. However, at the time being
there is yet no reported effort to use
that infrastructure for proactive
nucleic or antibody testing for the
general public.
On April 27, Science Magazine
recently called for the utilization of
mobile phone data for modeling and
contact tracing [27]. Gradually,
policymakers, scientists, and
engineers globally are coming to
realize that data from mobile phones
can help them combat COVID-19. It is
important that peoples are aware of
this option, can debate about it, and
make a decision for their own nation.
We do not yet know how long this
pandemic lasts and how bad it can
go. Therefore, all options should stay
on the table. For epicenters of the
pandemic, government might want to
integrate all possible measures
together to turn the tide against the
pandemic.
This pilot study is a baby step to
introduce to the field of public health
the importance of social network
analyses. We have already seen the
use of traditional S-I-R modeling for
infectious diseases since the onset of
the pandemic. The S-I-R models
assume equal infection risk for all
individuals and, thus, is insufficient
alone. Social network analyses
provide insights into exposure risks of
each individual and, thus, can be
integrated into S-I-R models for
S-E-I-R modeling. We assume that
everyone has equal immunity in our
model because of limited data. If
possible to collect more detailed
information about individuals, we
hope to improve our model
considering the covariates affecting
personal immunity. To battle the
pandemic and potentially endemic
COVID-19 as a planetary challenge,
interdisciplinary teamwork among
epidemiologists, computer scientists
and data scientists, and lawmakers is
needed. We hope to see our model
revised and applied in policies and
day-to-day operations [28]. Modeling
can only tell us so much. Politics does
the rest [29]. The bottom line against
dystopian use of location data is to
construct a geo-social network of
anonymous cellphones, not of people
without privacy. Make this a service
instead of surveillance. And this
service should only be temporary
during the pandemic. Our planet after
the pandemic does not need
Geoslavery [22].
CONTRIBUTORS
Conceptualization: KS/HW;
Programming and Analysis: ZQ/SJ/
KS; Writing: KS/HW.
ACKNOWLEDGMENT
The authors would like to thank L. Yu,
C. Deng, C. Pei, W. Jiang, L. Xu, and
K. Dong for many rounds of fruitful
discussions. The open access fee for
this article was provided by Gago
Inc,. Beijing, China.




NEW_PAPER

Received November 25, 2020, accepted December 8, 2020, date of publication December 14, 2020,
date of current version December 31, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3044858
Artificial Intelligence Applied to Chest X-Ray
Images for the Automatic Detection of COVID-19.
A Thoughtful Evaluation Approach
JULIÁN D. ARIAS-LONDOÑO 1
, (Senior Member, IEEE), JORGE A. GÓMEZ-GARCÍA 2
,
LAUREANO MORO-VELÁZQUEZ3
, (Member, IEEE), AND
JUAN I. GODINO-LLORENTE 2
, (Senior Member, IEEE)
1Department of Systems Engineering, Universidad de Antioquia, Medellín 050010, Colombia
2Bioengineering and Optoelectronics Laboratory (ByO), Universidad Politécnica de Madrid, 28031 Madrid, Spain
3Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD 21218, USA
Corresponding author: Juan I. Godino-Llorente (ignacio.godino@upm.es)
This work was supported in part by the Ministry of Economy and Competitiveness of Spain under Grant DPI2017-83405-R1, and in part
by the Universidad de Antioquia, Medellín, Colombia.
ABSTRACT Current standard protocols used in the clinic for diagnosing COVID-19 include molecular or
antigen tests, generally complemented by a plain chest X-Ray. The combined analysis aims to reduce the
significant number of false negatives of these tests and provide complementary evidence about the presence
and severity of the disease. However, the procedure is not free of errors, and the interpretation of the chest
X-Ray is only restricted to radiologists due to its complexity. With the long term goal to provide new evidence
for the diagnosis, this paper presents an evaluation of different methods based on a deep neural network.
These are the first steps to develop an automatic COVID-19 diagnosis tool using chest X-Ray images to
differentiate between controls, pneumonia, or COVID-19 groups. The paper describes the process followed
to train a Convolutional Neural Network with a dataset of more than 79, 500 X-Ray images compiled from
different sources, including more than 8, 500 COVID-19 examples. Three different experiments following
three preprocessing schemes are carried out to evaluate and compare the developed models. The aim is to
evaluate how preprocessing the data affects the results and improves its explainability. Likewise, a critical
analysis of different variability issues that might compromise the system and its effects is performed. With
the employed methodology, a 91.5% classification accuracy is obtained, with an 87.4% average recall for
the worst but most explainable experiment, which requires a previous automatic segmentation of the lung
region.
INDEX TERMS COVID-19, deep learning, pneumonia, radiological imaging, chest X-ray.
I. INTRODUCTION
COVID-19 pandemic has rapidly become one of the biggest
health world challenges in recent years. The disease spreads
at a fast pace: the reproduction number of COVID-19 ranged
from 2.24 to 3.58 during the first months of the pandemic
[1], meaning that, on average, an infected person transmitted
the disease to 2 or more people. As a result, the number
of COVID-19 infections dramatically increased from just
a hundred cases in January –most of them concentrated in
The associate editor coordinating the review of this manuscript and
approving it for publication was Wenming Cao .
China– to more than 43 million in November spread all
around the world [2].
COVID-19 is caused by the coronavirus SARS-COV2, a
virus that belongs to the same family of other respiratory
disorders such as the Severe Acute Respiratory Syndrome
(SARS) and Middle East Respiratory Syndrome (MERS).
The symptomatology of COVID-19 is diverse and arises
after incubation of around 5.2 days. The symptoms might
include fever, dry cough, and fatigue; although, headache,
hemoptysis, diarrhea, dyspnoea, and lymphopenia are also
reported [3], [4]. In severe cases, an Acute Respiratory Distress Syndrome (ARDS) might be developed by underlying
pneumonia associated with COVID-19. For the most severe
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 226811J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
cases, the estimated period from the onset of the disease to
death ranges from 6 to 41 days (with a median of 14 days),
being dependent on the patient’s age and the patient’s immune
system status [3].
Once the SARS-COV2 reaches the host’s lung, it gets
into the cells through a protein called ACE2, which serves
as the ‘‘opening’’ of the cell lock. After the virus’s genetic
material has multiplied, the infected cell produces proteins
that complement the viral structure to produce new viruses.
Then, the virus destroys the infected cell, leaves it, and
infects new cells. The destroyed cells produce radiological
lesions [5]–[7] such as consolidations and nodules in the
lungs, that are observable in the form of ground-glass opacity
regions in the X-Ray (XR) images (Fig. 1c). These lesions
are more noticeable in patients assessed 5 or more days after
the onset of the disease, and especially in those older than
50 [8]. Findings also suggest that patients recovered from
COVID-19 have developed pulmonary fibrosis [9], in which
the connective tissue of the lung gets inflamed, leading to a
pathological proliferation of the connective tissue between
the alveoli and the surrounding blood vessels. Given these
signs, radiological imaging techniques –using plain chest
XR and thorax Computer Tomography (CT)– have become
crucial diagnosis and evaluation tools to identify and assess
the severity of the infection.
Since the declaration of the COVID-19 pandemic, the
World Health Organization identified four major key areas
to reduce the impact of the disease in the world: to prepare
and be ready; detect, protect, and treat; reduce transmission;
and/or innovate and learn [10]. Concerning the area of detection, significant efforts have been undertaken to improve the
diagnostic procedures of COVID-19. To date, the gold standard in the clinic is still a molecular diagnostic test based on a
polymerase chain reaction (PCR), which is precise but timeconsuming, requires specialized personnel and laboratories,
and is in general limited by the capacities and resources
of the health systems. An alternative to PCR is the rapid
tests such as those based on real-time reverse transcriptasepolymerase chain reaction (RT-PCR), as they can be more
rapidly deployed, decrease the load of the specialized laboratories and personnel, and provide faster diagnosis compared
to traditional PCR.
Other tests, such as those based on antigens, are now
available but are mainly used for massive testings (i.e. for
non-clinical applications) due to a higher chance of missing
an active infection. In contrast with RT-PCR, which detects
the virus’s genetic material, antigen tests identify specific
proteins on the virus’s surface, requiring a higher viral load,
which significantly shortens the sensitivity period.
In clinical practice, the RT-PCR test is usually complemented with a chest XR, in such a manner that the combined analysis reduces the significant number of false negatives and, at the same time, brings additional information
about the extent and severity of the disease. In addition to
that, thorax CT is also used as a second-row method for
evaluation. Although the evaluation with CT provides more
accurate results in the early stages and have been shown to
have greater sensitivity and specificity [11], XR imaging has
become the standard in the screening protocols since it is fast,
minimally-invasive, low-cost, and requires simpler logistics
for its implementation.
In the search for rapid, more objective, accurate and sensitive procedures, which could complement the diagnosis and
assessment of the disorder, a trend of research has emerged
to employ clinical features extracted from thorax CT or chest
XR with automatic detection purposes. A potential benefit of
studying the radiological images is that these can characterize pneumonic states even in asymptomatic population [12].
However, more research is needed in this field as the lack
of findings in infected patients is also reported [13]. The
consolidation of such technology will permit a speedy and
accurate diagnosis of COVID-19, decreasing the pressure
on microbiological laboratories in charge of the PCR tests
and providing more objective means of assessing the disease’s severity. To this end, techniques based on deep learning have been employed to leverage XR information with
promising results. Although it would be desirable to employ
CT for detection purposes, some significant drawbacks are
often present, including higher costs, a more time-consuming
procedure, thorough hygienic protocols to avoid infection
spread, and the requirement of specialized equipment that
might not be readily available in hospitals or health centers.
By contrast, XR imaging procedures are available as first
screening tests in many hospitals or health centers, at lower
expenses.
Several approaches for COVID-19 detection based on
chest XR images and different deep learning architectures
have been published in the last few months, reporting classification accuracies around 90% or higher. However, the central
analysis in most of those works is focused on the variations
of network architectures, whereas there is less attention to
the variability factors that a real solution should tackle before
it can be deployed in the medical setting. In this sense, no
analysis has been provided to demonstrate the reliability of
the networks’ predictions, which in the context of medical
solutions acquires particular relevance. Moreover, most of
the works in state of the art have validated their results with
data sets containing dozens or a few hundreds of COVID-19
samples, limiting the proposed solutions’ impact.
With these antecedents in mind, this paper uses a deep
learning algorithm based on CNN, data augmentation, and
regularization techniques to handle data imbalance for the
discrimination between COVID-19, controls, and other types
of pneumonia. The methods are tested with the most extensive
corpus to date, to the authors’ knowledge. Three different
sets of experiments were carried out in the search for the
most suitable and coherent approach. To this end, the paper
also uses explainability techniques to gain insight about the
manners on how the neural network learns, and interpretability in terms of the overlapping among the regions of interest
selected by the network and those that are more likely affected
by COVID-19. A critical analysis of factors that affect the
226812 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 1. Experiments considered in the paper. First row: raw chest XR images belonging to the control, pneumonia, and
COVID-19 classes. Second row: Grad-CAM activation mapping for the XR images. Despite the high accuracy, the model
focuses its attention on areas different from the lungs in some cases. Third row: Grad-CAM activation mapping after
zooming in, cropping to a squared region of interest and resizing. Zooming to the region of interest forces the model to
focus its attention to the lungs, but errors are still present. Fourth row: Grad-CAM activation mapping after a zooming and
segmentation procedure. Zooming in and segmenting force the model to focus attention in the lungs. The black background
represents the mask introduced by the segmentation procedure.
VOLUME 8, 2020 226813J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
performance of automatic systems based on deep learning is
also carried out.
This paper is organized as follows: section II presents some
background and antecedents on the use of deep learning for
COVID-19 detection. section III presents the methodology,
section IV presents the results obtained, whereas V presents
the discussions and main conclusions of this paper.
II. BACKGROUND
A large body of research has emerged on the use of Artificial
Intelligence (AI) to detect different respiratory diseases using
plain XR images. For instance, in [14] authors developed
a 121-layer Convolutional Neural Network (CNN) architecture, called Chexnet, which was trained with a dataset of
100, 000 XR images for the detection of different types of
pneumonia. The study reports an area under the Receiving
Operating Characteristic (ROC) curve of 0.76 in a multiclass
scenario composed of 14 classes.
Directly related to the COVID-19 detection, three CNN
architectures (ResNet50, InceptionV3 and InceptionResNetV2) were considered in [15], using a database of just
50 controls and 50 COVID-19 patients. The best accuracy
(98%) was obtained with ResNet50. In [16], seven different
deep CNN models were tested using a corpus of 50 controls
and 25 COVID-19 patients. The best results were attained
with the VGG19 and DenseNet models, obtaining F1-scores
of 0.89 and 0.91 for controls and patients. The COVID-Net
architecture was proposed in [17]. The net was trained with
an open repository, called COVIDx, composed of 13, 975 XR
images, although only 358 -from 266 patients– belonged to
the COVID-19 class. The attained accuracy was of 93.3%. In
[18] a deep anomaly detection algorithm was employed for
the detection of COVID-19, in a corpus of 100 COVID-19
images (taken from 70 patients), and 1, 431 control images
(taken from 1008 patients). 96% of sensitivity and 70% of
specificity was obtained. In [19], a combination of a CNN for
feature extraction and a Long Short Term Memory Network
(LSTM) for classification were used for automatic detection
purposes. The model was trained with a corpus gathered from
different sources, consisting of 4, 575 XR images: 1, 525 of
COVID-19 (although 912 come from a repository applying
data augmentation), 1, 525 of pneumonia, and 1, 525 of controls. In a 5-folds cross-validation scheme, a 99% accuracy
was reported. In [20], the VGG16 network was used for
classification, employing a database of 132 COVID-19, 132
controls and 132 pneumonia images. Following a hold-out
validation, about 100% accuracy was obtained identifying
COVID-19, being lower on the other classes.
Authors in [21] adapted a model for the classification of
COVID-19 by using transfer-learning based on the Xception
network. Experiments were carried out in a database of 127
COVID-19, 500 controls, and 500 patients with pneumonia gathered from different sources, attaining about 97%
accuracy. A similar approach, followed in [22], used the
same corpus for the binary classification of COVID-19 and
controls; and for the multiclass classification of COVID-19,
controls, and pneumonia. With a modification of the Darknet
model for transfer-learning and 5-folds cross-validation, 98%
accuracy in binary classification and 87% in multiclass classification was obtained. Another Xception transfer-learningbased approach was presented in [23], but considering two
multi-class classification tasks: i) controls vs. COVID-19
vs. viral pneumonia and bacterial pneumonia; ii) controls
vs. COVID-19 vs. pneumonia. To deal with the imbalance
of the corpus, an undersampling technique was used to
randomly discard registers from the larger classes, obtaining 290 COVID-19, 310 controls, 330 bacterial pneumonia,
and 327 viral pneumonia chest XR images. The reported
accuracy was 89% in the 4-class problem and 94% in the
3-class scenario. Moreover, in a 3-class cross-database experiment, the accuracy was 90%. In [24], four CNN networks
(ResNet18, ResNet50, SqueezeNet, and DenseNet-121) were
used for transfer learning. Experiments were performed on
a database of 184 COVID-19 and 5, 000 no-finding and
pneumonia images. Reported results indicate a sensitivity of
about 98% and a specificity of 93%. In [25], five state-of-theart CNN systems –VGG19, MobileNetV2, Inception, Xception, InceptionResNetV2– were tested on a transfer-learning
setting to identify COVID-19 from control and pneumonia
images. Experiments were carried out in two partitions: one
of 224 COVID-19, 700 bacterial pneumonia, and 504 control
images; and another that considered the previous normal and
COVID-19 data but included 714 cases of bacterial and viral
pneumonia. The MobileNetV2 net attained the best results
with 96% and 94% accuracy in the 2 and 3-classes classification. In [26], the MobileNetV2 net was trained from
scratch and compared to one net based on transfer-learning
and to another based on hybrid feature extraction with finetuning. Experiments performed in a dataset of 3905 XR
images of 6 diseases indicated that training from scratch
outperforms the other approaches, attaining 87% accuracy
in the multiclass classification and 99% in the detection
of COVID-19. A system, also grounded on the InceptionNet and transfer-learning, was presented in [27]. Experiments were performed on 6 partitions of XR images with
COVID-19, pneumonia, tuberculosis, and controls. Reported
results indicate 99% accuracy, in a 10-folds cross-validation
scheme, in the classification of COVID-19 from other classes.
In [28], fuzzy color techniques were used as a preprocessing stage to remove noise and enhance XR images
in a 3-class classification setting (COVID-19, pneumonia,
and controls). The pre-processed images and the original
ones were stacked. Then, two CNN models were used to
extract features: MobileNetV2 and SqueezeNet. A feature
selection technique based on social mimic optimization and a
Support Vector Machine (SVM) was used. Experiments were
performed on a corpus of 295 COVID-19, 65 controls and 98
pneumonia XR images, attaining about 99% accuracy.
Given the limited amount of COVID-19 images, some
approaches have focused on generating artificial data to train
better models. In [29], an auxiliary Generative Adversarial
Network (GAN) was used to produce artificial COVID-19
226814 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
XR images from a database of 403 COVID-19 and 1, 124
controls. Results indicated that data augmentation increased
accuracy from 85% to 95% on the VGG16 net. Similarly,
in [30], GAN was used to augment a database of 307
images belonging to four classes: controls, COVID-19, bacterial and viral pneumonia. Different CNN models were
tested in a transfer-learning-based setting, including Alexnet,
Googlenet, and Restnet18. The best results were obtained
with Googlenet, achieving 99% in a multiclass classification approach. In [31], a CNN based on capsule networks
(CapsNet), was used for binary (COVID-19 vs. controls)
and multi-class classification (COVID-19 vs. pneumonia
vs. controls). Experiments were performed on a dataset of
231 COVID-19, 1, 050 pneumonia and 1, 050 controls XR
images. Data augmentation was used to increase the number of COVID-19 images to 1, 050. On a 10-folds crossvalidation scheme, 97% accuracy for binary classification,
and 84% multi-class classification were achieved. The CovXNet architecture, based on depth-wise dilated convolution
networks, was proposed in [32]. In the first stage, pneumonia (viral and bacterial) and control images were employed
for pretraining. Then, a a refined model of COVID-19 is
obtained using transfer learning. In experiments using twodatabases, 97% accuracy was achieved for COVID-19 vs.
controls, and of 90% for COVID-19 vs. controls vs. bacterial and viral cases of pneumonia. In [33], an easy-to-train
neural network with a limited number of training parameters was presented. To this end, patch phenomena found on
XR images were studied (bilateral involvement, peripheral
distribution, and ground-glass opacification) to develop a
lung segmentation and a patch-based neural network that
distinguished COVID-19 from controls. The basis of the
system was the ResNet18 network. Saliency maps were also
used to produce interpretable results. In experiments performed on a database of controls (191), bacterial pneumonia
(54), tuberculosis (57) and viral pneumonia (20), about 89%
accuracy was obtained. Likewise, interpretable results were
reported in terms of large correlations between the saliency
maps’ activation zones and the radiological findings found
in the XR images. The authors also indicate that when the
lung segmentation approach was not considered, the system’s
accuracy decreased to about 80%. In [34], 2D curvelets transformations were used to extract features from XR images. A
feature selection algorithm based on meta-heuristic was used
to find the most relevant characteristics, while a CNN model
based on EfficientNet-B0 was used for classification. Experiments were carried out in a database of 1, 341 controls, 219
COVID-19, and 1, 345 viral pneumonia images, and 99%
classification accuracy was achieved with the proposed
approach. Multiclass and hierarchical classification of different types of diseases producing pneumonia (with 7 labels and
14 label paths), including COVID-19, were explored in [35].
Since the database of 1, 144 XR images was heavily imbalanced, different resampling techniques were considered. By
following a transfer-learning approach based on a CNN architecture to extract features, and a hold-out validation with
5 different classification techniques, a macro-avg F1-Score of
0.65 and an F1-Score of 0.89 were obtained for the multiclass
and hierarchical classification scenarios, respectively. In [36],
a three-phases approach is presented: i) to detect the presence
of pneumonia; ii) to classify between COVID-19 and pneumonia; and, iii) to highlight regions of interest of XR images.
The proposed system utilized a database of 250 images of
COVID-19 patients, 2, 753 with other pulmonary diseases,
and 3, 520 controls. By using a transfer-learning system
based on VGG16, about 0.97 accuracy was reported. A
CNN-hierarchical approach using decision trees (based on
ResNet18) was presented in [37], on which a first tree classified XR images into the normal or pathological classes;
the second identified tuberculosis; and the third COVID-19.
Experiments were carried out on 3 partitions obtained after
having gathered images from different sources and data augmentation. The accuracy for each decision tree –starting from
the first– was about 98%, 80%, and 95%, respectively.
A. ISSUES AFFECTING RESULTS IN THE LITERATURE
Table 1 presents a summary of state of the art in the automatic detection of COVID-19 based on XR images and deep
learning. Despite the excellent results reported, the review
reveals that some of the proposed systems suffer from certain
shortcomings that affect the conclusions extracted in their
respective studies, limiting the translational possibilities to
the clinical environment. Likewise, variability factors have
not been deeply studied in these papers and their study can
be regarded as necessary.
For instance, one of the issues that affect most of the
reviewed systems to detect COVID-19 from plain chest XR
images is the use of very limited datasets, which compromises
their generalization capabilities.
Indeed, to date and from the authors’ knowledge, the
paper employing the largest database of COVID-19 considers
1, 525 XR images gathered from different sources. However,
912 images belong to a data augmented repository, which
does not include additional information about the initial number of files or the number of augmented images. In general
terms, most of the works employ less than 300 COVID-19
XR images, having systems that use as few as 50 images.
However, this is understandable given that some of these
works were published during the onset of the pandemics when
the number of available registers was limited.
On the other hand, a good balance in the patients’ age is
considered essential to avoid the model to learn age-specific
features. However, several previous works have used XR
images from children to populate the pneumonia class.1 This
might be biasing the results given the age differences of
COVID-19 patients.
Despite many works in the literature report a good performance in detecting COVID-19, most of the approaches follow
1First efforts used the RSNA Pneumonia Detection Challenge dataset,
which is focused on the detection of pneumonia cases in children.
https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview
VOLUME 8, 2020 226815J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 1. Summary of the literature in the field.
a brute force approach exploiting deep learning’s potentiality
to correlate with the outputs (i.e., the class labels) but provide
low interpretability and explainability of the process. It is
unclear if the good results are due to the system’s actual
capability to extract information related to the pathology or
because it leart other aspects during training that are biasing
and compromising the results. As a matter of example, just
one of the studies reported in the literature follows a strategy that forces the network to focus on the most significant
areas of interest for COVID-19 detection [33]. It does so by
proposing a methodology based on semantic segmentation of
the lungs. In the remaining cases, it is unclear if the models
are analyzing the lungs or if they are categorizing given
any other information available, which might be interesting
for classification purposes but might lack diagnostic interest. This is relevant, as in all the analyzed works in literature, pneumonia and controls classes come from a certain
repository, whereas others such as COVID-19 comes from
a combination of sources and repositories. Having classes
generated in different conditions might undoubtedly affect
the results, and as such, a critical study about this aspect is
needed. In the same line, other variability issues such as the
sensor technology employed, the type of projection used, the
sex of the patients, and even age, require a thorough study.
Finally, the literature review revealed that most of the
published papers showed excellent correlation with the disease but low interpretability and explainability (see Table 1).
Indeed, it is often more desirable in clinical practice to
obtain interpretable results that correlate with pathological
conditions or a particular demographic or physiological variable than a black box system that yields a binary or a multiclass decision. From the revision of literature, only [33] and
[32] partially addressed this aspect. Thus, further research on
this topic is needed.
With these ideas in mind, this paper addresses these aspects
by training and testing with a wide corpus of RX images,
proposing and comparing two strategies to preprocess the
images, analyze the effect of some variability factors, and
provide some insights to more explainable and interpretable
results. The primary goal is to present a critical overview
of these aspects since they might be affecting the modeling
capabilities of the deep learning systems for the detection of
COVID-19.
III. METHODOLOGY
The design methodology is presented in the following
section. The procedure followed to train the neural network
is described first, along with the process that was followed to
create the dataset. The network and the source code to train
it are available at https://github.com/jdariasl/COVIDNET, so
results can be readily reproduced by other researchers.
A. THE NETWORK
The core of the system is a deep CNN based on the
COVID-Net2 proposed in [17]. Some modifications were
2Following the PyTorch implementation available at
https://github.com/IliasPap/COVIDNet
226816 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
made to include regularization components in the last two
dense layers and a weighted categorical cross-entropy loss
function to compensate the class imbalance. The network
structure was also refactored to allow gradient-based localization estimations [38], which are used after training in the
search for an explainable model.
The network was trained with the corpus described in III-B
using the Adam optimizer with a learning rate policy: the
learning rate decreases when learning stagnates for some time
(i.e., ’patience’). The following hyperparameters were used
for training: learning rate = 2
-5, number of epochs = 24,
batch size = 32, factor = 0.5, patience = 3. Furthermore,
data augmentation for pneumonia and COVID-19 classes was
leveraged with the following augmentation types: horizontal
flip, Gaussian noise with a variance of 0.015, rotation, elastic
deformation, and scaling. The variant of the COVID-Net
was built and evaluated using the PyTorch library [39]. The
CNN features from each image are concatenated by a flatten
operation, and the resulting feature map is fed to three fully
connected layers to generate a probability score for each
class. The first two fully connected layers include dropout
regularization of 0.3 and ReLU activation functions. Dropout
was necessary because the original network tended to overfit
since the very beginning of the training phase.
The network’s input layer rescales the images keeping the
aspect ratio, with the shortest dimension scaled to 224 pixels.
Then, the input image is cropped to a square of 224 × 224
pixels located in the center of the image. Images are normalized using a z-score function with parameters mean =
[0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225], for
each of the three RGB channels respectively. Even though we
are working with grayscale images, the network architecture
was designed to be pre-trained on a general-purpose database
including colored images; this characteristic was kept in case
it would be necessary to use some transfer learning strategy
in the future.
The network’s output layer provides a score for each of
the three classes (i.e. control, pneumonia, or COVID-19),
which is converted into three probability estimates –in the
range [0, 1]– using a softmax activation function. The class
membership’s final decision is made according to the highest
of the three probability estimates obtained.
B. THE CORPUS
The corpora used in the paper have been compiled from a set
of Posterior-Anterior (PA) and Anterior-Posterior (AP) XR
images from different public sources. The compilation contains images from participants without any observable pathology (controls or no findings), pneumonia, and COVID-19
cases. After the compilation, two subsets of images were
generated, i.e., training and testing. Table 2 contains the
number of images per subset and class. Overall, the corpus
contains more than 70, 000 XR images, including more than
8, 500 images belonging to COVID-19 patients.
The repositories of XR images employed to create the corpus used in this paper are presented next. Most of these conTABLE 2. Number of images per class for training and testing subsets.
tain solely registers of controls and pneumonia patients. Only
the most recent repositories include samples of COVID-19
XR images. In all cases, the annotations were made by a
specialist as indicated by the authors of the repositories.
The COVID-19 class is modelled compiling images coming from three open data collection initiatives: HM Hospitales COVID [40], BIMCV-COVID19 [41] and Actualmed
COVID-19 [42] chest XR datasets. The final result of the
compilation process is a subset of 8, 573 images from more
than 3, 600 patients at different stages of the disease.3
Table 3 summarizes the most significant characteristics of
the datasets used to create the corpus, which is presented next:
1) HM HOSPITALES COVID-19 DATASET
This dataset was compiled by HM Hospitals [40]. It contains all the available clinical information about anonymous
patients with the SARS-CoV-2 virus treated in different centers belonging to this company since the beginning of the
pandemic in Madrid, Spain.
The corpus contains the anonymized records of 2, 310
patients and includes several radiological studies for each
patient corresponding to different stages of the disease. A
total of 5, 560 RX images are available in the dataset, with
an average of 2.4 image studies per subject, often taken in
intervals of two or more days. The histogram of the patients’
age is highly coherent with the demographics of COVID-19
in Spain (see Table 3 for more details).
Only patients with at least one positive PCR test or positive
immunological tests for SARS-CoV-2 were included in the
study. The Data Science Commission and the Research Ethics
Committee of HM Hospitales approved the current research
study and the data for this purpose.
2) BIMCV COVID19 DATASET
BIMCV COVID19 dataset [41] is a large dataset with chest
radiological studies (XR and CT) of COVID-19 patients
along with their pathologies, results of PCR and immunological tests, and radiological reports. It was recorded by the
Valencian Region Medical Image Bank (BIMCV) in Spain.
The dataset contains the anonymized studies of patients with
at least one positive PCR test or positive immunological tests
for SARS-CoV-2 between February 26th and April 18th,
2020. The corpus is composed of 3, 013 XR images, with an
average of 1.9 image studies per subject, taken in intervals
of approximately two or more days. The histogram of the
patients’ age is highly coherent with the demographics of
3Figures at the time the datasets were downloaded. The datasets are still
open, and more data might be available in the next future.
VOLUME 8, 2020 226817J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 3. Demographic data of the datasets used. Only those labels confirmed are reported.
COVID-19 in Spain (Table 3). Only patients with at least
one positive PCR test or positive immunological tests for
SARS-Cov-2 were included in the study.
3) ACTUALMED SET (ACT)
The actualmed COVID-19 Chest XR dataset initiative [42]
contains a series of XR images compiled by Actualmed and
Universitat Jaume I (Spain). The dataset contains COVID-19
and control XR images, but no information is given about the
place or date of recording and/or demographics. However, a
metadata file is included. It contains an anonymized descriptor to distinguish among patients and information about the
XR modality, type of view, and the class to which the image
belongs.
4) CHINA SET - THE SHENZHEN SET
The set was created by the National Library of Medicine,
Maryland, USA, in collaboration with the Shenzhen No.3
People’s Hospital at Guangdong Medical College in Shenzhen, China [43].
The dataset contains normal and abnormal chest XR with
manifestations of tuberculosis and includes associated radiologist readings.
5) THE MONTGOMERY SET
The National Library of Medicine created this dataset in
collaboration with the Department of Health and Human
Services, Montgomery County, Maryland, USA. It contains
data from XR images collected under Montgomery County’s
tuberculosis screening program [43], [44].
6) ChestX-ray8 DATASET (CRX8)
The ChestX-ray8 dataset [45] contains 12, 120 images from
14 common thorax disease categories from 30, 805 unique
patients, compiled by the National Institute of Health (NIH).
For this study, the images labeled with ’no radiological findings’ were used to be part of the control class, whereas the
images annotated as ’pneumonia’ were used for the pneumonia class.
7) CheXpert DATASET
CheXpert [46] is a dataset of XR images created for an
automated evaluation of medical imaging competitions and
contains chest XR examinations carried out in Stanford Hospital during 15 years. For this study, we selected 4, 623 pneumonia images using those annotated as ’pneumonia’ with
and without additional comorbidity. COVID-19 never caused
these comorbidities. The motivation to include pneumonia
with comorbidities was to increase the number of pneumonia
examples in the final compilation for this study, increasing
this cluster’s variability.
8) MIMIC-CXR DATABASE
MIMIC-CXR [47] is an open dataset complied from 2011 to
2016, and comprising de-identified chest RX from patients
admitted to the Beth Israel Deaconess Medical Center. In
our study, we employed the images for the pneumonia class.
The labels were obtained from the agreement of the two
methods indicated in [47]. The dataset reports no information
about gender or age; thus, we assume that the demographics are similar to those of CheXpert dataset and those of
pneumonia [48].
C. IMAGE PRE-PROCESSING
XR images were converted to uncompressed grayscale ’.png’
files, encoded with 16 bits, and preprocessed using the
DICOM WindowCenter and WindowWidth details (when
needed). All images were converted to a Monochrome 2
photometric interpretation. Initially, the images were not rescaled to avoid loss of resolution in later processing stages.
Only AP and PA views were selected. No differentiation
was made between erect, either standing or sitting, or decubitus. This information was inferred by a careful analysis of
the DICOM tags and required manual checking due to certain
labeling errors.
D. EXPERIMENTS
The corpus collected from the aforementioned databases was
processed to compile three different datasets of equal size
to the initial one. Each of these datasets was used to run a
different set of experiments.
1) EXPERIMENT 1. RAW DATA
The first experiment was run using the raw data extracted
from the different datasets. Each image is kept with the original aspect ratio. Only a histogram equalization was applied.
226818 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
2) EXPERIMENT 2. CROPPED IMAGE
The second experiment consists of preprocessing the images
by zooming in, cropping to a squared region of interest, and
resizing to a squared image (aspect ratio 1 : 1). The process
is summarized in the following steps:
1) Lungs are segmented from the original image using
a U-Net semantic segmentation algorithm.4 The algorithm used reports Intersection-Over-Union (IoU) and
Dice similarity coefficient scores of 0.971 and 0.985
respectively.
2) A black mask is extracted to identify the external
boundaries of the lungs.
3) The mask is used to create two sequences, adding
the grey levels of the rows and columns respectively.
These two sequences provide four boundary points,
which define two segments of different lengths in the
horizontal and vertical dimensions.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated with the lungs,
taking advantage of the higher added values outside the
lungs (Fig. 2). The process to obtain the squared region
requires identifying the middle point of each of the
identified segments and cropping in both dimensions
using the length of the longest of these two segments.
5) The original image is cropped with a squared template
placed in the centre of the matrix using the information
obtained in the previous step. No mask is placed over
the image.
6) Histogram equalization of the image obtained.
This process is carried out to decrease the variability of the
data, to make the training process of the network simpler, and
to ensure that the region of significant interest is in the centre
of the image with no areas cut.
3) EXPERIMENT 3. LUNG SEGMENTATION
The third experiment consists of preprocessing the images by
masking, zooming in, cropping to a squared region of interest,
and resizing to a squared image (aspect ratio 1 : 1). The
process is summarized in the following steps:
1) Lungs are segmented from the original image using
the same semantic segmentation algorithm used in
experiment 2.
2) An external black mask is extracted to identify the
external boundaries of the lungs.
3) The mask is used to create two sequences, adding the
grey levels of the rows and columns respectively.
4) The sequences of added grey levels in the vertical and
horizontal dimensions of the mask are used to identify
a squared region of interest associated to the lungs,
taking advantage of the higher added values outside
them (Fig. 2).
4Following the Keras implementation available at https://github.com
/imlab-uiip/lung-segmentation-2d
FIGURE 2. Identification of the squared region of interest. Plots in the top
and left represent the normalized accumulated gray level in the vertical
and horizontal dimension respectively.
5) The original image is cropped with a squared template
placed in the center of the image.
6) The mask is dilated with a 5 × 5 pixels kernel, and it is
superimposed to the image.
7) Histogram equalization is applied only to the segmented area (i.e. the area corresponding to the lungs).
This preprocessing makes the training of the network much
simpler and forces the network to focus the attention on
the lungs region, removing external characteristics –like the
sternum– that might influence the obtained results.
E. IDENTIFICATION OF THE AREAS OF SIGNIFICANT
INTEREST FOR THE CLASSIFICATION
The areas of significant interest used by the CNN for
discrimination purposes are identified using a qualitative
analysis based on a Gradient-weighted Class Activation
Mapping (Grad-CAM) [38]. This is an explainability method
that serves to provide insights about the manners on how
deep neural networks learn, pointing to the most significant
areas of interest for decision-making purposes. The method
uses the gradients of any target class to flow until the final
convolutional layer, and to produce a coarse localization map
which highlights the most important regions in the image
identifying the class. The result of this method is a heat map
like those presented in Fig. 1, in which the colour encodes the
importance of each pixel in differentiating among classes.
IV. RESULTS
The model has been quantitatively evaluated computing
the test Positive Predictive Value (PPV), Recall, F1-score
(F1), Accuracy (Acc), Balanced Accuracy (BAcc), Geometric
Mean Recall (GMR) and Area Under the ROC Curve (AUC)
for each of the three classes in the corpus previously described
in section III-B. The performance of the models is assessed
using an independent testing set, which has not been used
VOLUME 8, 2020 226819J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 4. Performance measures for the three experiments considered in the paper.
FIGURE 3. ROC curves and confusion matrices for each one of the experiments, considering each one of the classes separately. Top: ROC curves. Bottom:
Normalized confusion matrices. Left: Original images (experiment 1). Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
during development. A 5-folds cross-validation procedure
has been used to evaluate the obtained results (Training/Test
balance: 90/10 %). The performance of the CNN network on
the three experiments considered in this paper is summarized
in Table 4. Likewise, the ROC curves per class for each of the
experiments, and the corresponding confusion matrices are
presented in Fig. 3. The global ROC curve displayed in Fig. 4
for each experiment summarizes the global performance of
the experiments.
Considering experiment 1, and although slightly higher for
controls, the detection performance remains almost similar
for all classes (the PPV ranges from 91-93%) (Table 4). The
remaining measures per class follow the same trend, with
similar figures but better numbers for the controls. ROC
curves and confusion matrices of Fig. 3a and Fig. 3d point out
that the largest source of confusion for COVID-19 is the pneumonia class. The ROC curves for each one of the classes reach
in all cases AUC values larger than 0.99, which, in principle
is considered excellent. In terms of global performance, the
system achieves an Acc of 91% and a BAcc of 94% (Table 4).
This is also supported by the average ROC curve of Fig. 4,
which reveals the excellent performance of the network and
226820 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 4. Average ROC curves for each experiment, including AUC values.
the almost perfect behaviour of the ROC curve. Deviations
are small for the three classes.
When experiment 2 is considered, a decrease in the performance per class is observed in comparison to experiment 1.
In this case, the PPV ranges from 81-93% (Table 4), with a
similar trend for the remaining figures of merit. ROC curves
and confusion matrices in Fig. 3a and Fig. 3d report AUC
values in the range 0.96-0.99, and an overlapping of the
COVID-19 class mostly with pneumonia. The global performance of the system -presented in the ROC curve of Fig. 4
and Table 4- yields an AUC of 0.98, an Acc of 87% and a
BAcc of 81%.
Finally, for experiment 3, PPV ranges from 78% − 96%
(Table 4). In this case, the results are slightly worse than those
of experiment 2, with the COVID-19 class presenting the
worse performance among all the tests. According to Fig. 3c,
AUCs range from 0.94 to 0.98. Confusion matrix in Fig. 3f
reports a large level of confusion in the COVID-19 class
being labelled as pneumonia 18% of the times. In terms of
global performance, the system reaches an Acc of 91% and a
BAcc of 87% (Table 4). These results are consistent with the
average AUC of 0.97 shown in Fig. 4.
A. EXPLAINABILITY AND INTERPRETABILITY OF THE
MODELS
The regions of interest identified by the network were analyzed qualitatively using Grad-CAM activation maps [38].
Results shown by the activation maps, permit the identification of the most significant areas in the image, highlighting
the zones of interest that the network is using to discriminate.
In this regard, Fig. 1, presents examples of the Grad-CAM
of a control, a pneumonia, and a COVID-19 patient, for each
of the three experiments considered in the paper. It is important to note that the activation maps are providing overall
information about the behaviour of the network, pointing to
the most significant areas of interest, but the whole image is
supposed to be contributing to the classification process to a
certain extent.
The second row in Fig. 1 shows several prototypical results
applying the Grad-CAM techniques to experiment 1. The
examples show the areas of significant interest for a control,
pneumonia and COVID-19 patient.
The results suggest that the detection of pneumonia or
COVID-19 is often carried out based on information that is
outside the expected area of interest, i.e. the lung area. In the
examples provided, the network focuses on the corners of the
XR image or in areas around the diaphragm. In part, this is
likely due to the metadata which is frequently stamped on
the corners of the XR images. The Grad-CAM plots corresponding to the experiment 2 (third row of Fig. 1), indicates
that the model still points towards areas which are different
from the lungs, but to a lesser extent. Finally, the Grad-CAM
of experiment 3 (fourth row of Fig. 1) presents the areas of
interest where the segmentation procedure is carried out. In
this case, the network is forced to look at the lungs, and
therefore this scenario is supposed to be more realistic and
more prone to generalizing as artifacts that might bias the
results are somehow discarded.
On the other hand, for visualization purposes, and in order
to interpret the separability capabilities of the system, a t-SNE
embedding is used to project the high dimensional data of the
layer adjacent to the output of the network, to a 2-dimensional
space. Results are presented in Fig. 5 for each of the three
experiments considered in the paper.
Fig. 5 indicates that a good separability exists for all
the classes in both training and testing data, and for all
experiments. The boundaries of the normal cluster are very
well defined in the three experiments, whereas pneumonia
and COVID-19 are more spread, overlapping with adjacent
classes.
In general terms, the t-SNE plots demonstrate the ability
of the network to learn a mapping from the input data to the
desired labels. However, despite the shape differences found
for the three experiments, no additional conclusions can be
extracted.
B. POTENTIAL VARIABILITY FACTORS AFFECTING THE
SYSTEM
There are several variability factors which might be biasing
the results, namely: the projection (PA vs. AP); the technology of the detector (Computed Radiography (CR) vs.
Digital Radiography (DX)); the gender of the patients; the
age; potential specificities of the dataset; or having trained
with several images per patient.
The use of several images per patient represents a certain
risk of data leak in the COVID-19 class due to its underlying
imbalance. However, our initial hypothesis is that using several images per COVID-19 patient but obtained at different
instants in time (with days of difference), would increase the
variability of the dataset, and thus that source of bias would
be disregarded. Indeed, the evolution of the associated lesions
often found in COVID-19 is considered fast, in such a manner
that very different images are obtained in a time interval
as short as one or two days of the evolution. Also, since
VOLUME 8, 2020 226821J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 5. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3).
TABLE 5. Performance measures considering the XR projection (PA/AP).
every single exploration is framed differently, or sometimes
even taken with different machines and/or projections, the
potential bias is expected to be minimized.
Concerning the type of projection, and to evaluate its
effectiveness, the system has been studied taking into
account this potential variability factor, which is considered to be one of the most significant. In particular,
Table 5, presents the outcomes after accounting for the
influence of the XR projection (PA/AP) in the performance of the system. In general terms, the system demonstrates consistency with respect to the projection used,
and differences are mainly attributable to smaller training and testing sets. However, significant differences are
shown for projection PA in class COVID-19/experiment 3,
decreasing the F1 up to 65.61%. The reason for the
unexpected drop in performance is unknown, but likely
226822 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
FIGURE 6. Mapping of the high-dimensional data of the layer adjacent to the output into a two dimensional plot. Top: Output network embedding
using t-SNE for the training data. Bottom: Output network embedding using t-SNE for the testing data. Left: Original images (experiment 1).
Center: Cropped Images (experiment 2). Right: Segmented images (experiment 3). Labels correspond to data sets and classes.
attributable to an underrepresented class in the corpus (see
Table 3).
Besides, Table 6 shows –for the three experiments under
evaluation and for the COVID-19 class– the error distribution with respect to the sex of the patient, technology of
the detector, dataset and projection. For the four variability
factors enumerated, results show that the error distribution
committed by the system follows –with minor deviations– the
existing proportion of the samples in the corpus. These results
suggest that there is no clear bias with respect to these potential variability factors, at least for the COVID-19 class which
is considered the worst-case due to its underrepresentation.
Similar results would be expected for control and pneumonia
classes, but these results are not provided due to the lack of
certain labels in some of the datasets used (see Table 3).
Concerning age, the datasets used are reasonably well
balanced (Table 3), but with a certain bias in the normal class:
COVID-19 and pneumonia classes have very similar average
ages, but controls have a lower mean age. Our assumption
has been that age differences are not significantly affecting
the results, but the mentioned difference might explain why
the normal cluster in Fig. 5 is less spread than the other two.
In any case, no specific age biases have been found in the
errors committed by the system.
An additional study was also carried out to evaluate the
influence of potential specificities of the different datasets
used to compile the corpus (i.e. the variability of the results
with respect to the datasets merged to build the corpus). This
variability factor is evaluated in Fig. 6 using different t-SNE
plots (one for each experiment in a similar way than in Fig. 5)
but differentiating the corresponding cluster for each dataset
and class.
Results for the different datasets and classes are clearly
merged or are adjacent in the same cluster. However, several datasets report a lower variability for certain classes
(i.e. variability in terms of scattering). This is especially
clear in Chexpert and NIH pneumonia sets, which are successfully merged with the corresponding class but appear
VOLUME 8, 2020 226823J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
TABLE 6. Percentage of testing samples and error distribution with
respect to several potential variability factors for the COVID-19 class.
(% in hits represents the percentage of samples of every factor under
analysis in the correctly predicted set).
clearly clustered, suggesting that these datasets have certain
unknown specific characteristics different to those of the
complementary datasets. The model has been able to manage
this aspect but is a factor to be analyzed in further studies.
V. DISCUSSION AND CONCLUSION
This study evaluates a deep learning model for the detection
of COVID-19 from RX images. The paper provides additional evidence to the state of the art, supporting the potential of deep learning techniques to accurately categorize XR
images corresponding to control, pneumonia, and COVID-19
patients (Fig. 1). These three classes were chosen under the
assumption that they can support clinicians in making better
decisions, establishing potential differential strategies to handle patients depending on their cause of infection [17]. However, the main goal of the paper was not to demonstrate the
suitability of deep learning for categorizing XR images but to
make a thoughtful evaluation of the results and the different
preprocessing approaches, searching for better explainability
and interpretability of the results while providing evidence of
potential effects that might bias results.
The model relies on the COVID-Net network, which has
served as a basis for the developing a more refined architecture. This network has been chosen due to its tailored
characteristics and given the previous good results reported
by other researchers. The COVID-Net was trained with a
corpus compiled using data gathered from different sources:
the control and pneumonia classes –with 49, 983 and 24, 114
samples respectively– were collected from the ACT, Chinaset, Montgomery, CRX8, CheXpert, and MIMIC datasets;
and the COVID-19 class was collected from the information
available at the BIMCV, ACT, and HM Hospitales datasets.
Although the COVID-19 class only contains 8, 573 chest
RX images, the developers of the data sources are continuously adding new cases to the respective repositories, so the
number of samples is expected to grow in the future. Despite
the unbalance of the COVID-19 class, up to date, and to the
authors’ knowledge, this is the most extensive compilation of
COVID-19, images based on open repositories. Despite that,
the number of COVID-19 RX images is still considered small
compared to the other two classes. Therefore, it was necessary
to compensate for the class imbalance by modifying the
network architecture, including regularization components in
the last two dense layers. To this end, a weighted categorical
cross-entropy loss function was used to compensate for this
effect. Likewise, data augmentation techniques were used for
pneumonia and COVID-19 classes to generate more samples
for these two underrepresented classes automatically.
We stand that automatic diagnosis is much more than a
classification exercise, meaning that many factors have to be
considered to bring these techniques to clinical practice. In
this respect, there is a classic assumption in the literature
that the associated heat maps –calculated with Grad-CAM
techniques- provide a clinical interpretation of the results,
which is unclear in practice. In light of the results shown in
the heat maps depicted in Fig. 1, we show that experiment 1
must be carefully interpreted. Despite the high-performance
metrics obtained in experiment 1, the significant areas identified by the network are pointing towards certain areas with
no clear interest for the diagnosis, such as corners of the
images, the sternum, clavicles, etc. From a clinical point of
view, this is biasing the results. It means that other approaches
are necessary to force the network to focus on the lung
area. In this respect, we have developed and compared the
results with two preprocessing approaches based on cropping
the images and segmenting the lung area (experiment 2 and
experiment 3). Again, given the heat maps corresponding
to experiment 2, we also see similar explainability problems to those enumerated for experiment 1. The image area
reduction proposed in experiment 2 significantly decreases
the system’s performance by removing the metadata that
usually appears in the top left or right corner. This technique
removes areas that can help categorize the images but have
no interest from the diagnosis point of view. However, while
comparing experiments 2 and 3, performance results improve
in the third approach, which focuses on the same region
of interest but with a mask that forces the network to see
only the lungs. Thus, results obtained in experiments 2 and
3 suggest that eliminating the needless features extracted
from the background or non-related regions improves the
results. Besides, the third approach (experiment 3) provides
more explainable and interpretative results, with the network
focusing its attention only on the area of interest for the
disease. The gain in explainability of the last method is still
at the cost of a lower accuracy with respect to experiment
1, but the improvement in explainability and interpretability
is considered critical in translating these techniques to the
clinical setting. Despite the decrease in performance, the
proposed method in experiment 3 has provided promising
results, with an 91.53% Acc, 87.6 BAcc, 87.37% GMR,
and 0.97 AUC.
Performance results obtained are in line with those presented in [17], which reports sensitivities of 95, 94, and 91
for control, pneumonia, and COVID-19 classes respectively
–also modeling with the COVID-Net in similar conditions as
our experiment 1–, but training with a much smaller corpus
of 358 RX images from 266 COVID-19 patients, 8, 066
226824 VOLUME 8, 2020J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
controls, and 5, 538 RX images belonging to patients with
different types of pneumonia.
The paper also critically evaluates the effect of several
variability factors that might compromise the network’s performance. For instance, the projection (PA/AP) effect was
evaluated by retraining the network and checking the outcomes. This effect is important, given that PA projections are
often practiced in erect positions to observe pulmonary ways
better and are expected to be examined in healthy or slightly
affected patients. In contrast, AP projections are often preferred for patients confined in bed, and as such are expected
to be practised in the most severe cases. Since AP projections
are common in COVID-19 patients, in these cases, more
blood will flow to the lungs’ apices than when standing;
thus, not considering this variability factor may result in
a misdiagnosis of pulmonary congestion [49]. Indeed, the
obtained results have highlighted the importance of taking
into account this factor when designing the training corpus,
as PPV decreases for PA projections in our experiments with
COVID-19 images. This issue is probably due to an underrepresentation of this class (Table 5), which would require a
further specific analysis when designing future corpora.
On the other hand, results have shown that the error distribution for the COVID-19 class follows a similar proportion to
the percentage of images available in the corpus while categorizing by gender, the detector’s technology, the projection,
and the dataset. These results suggest no significant bias with
respect to these potential variability factors, at least for the
COVID-19 class, which is the less represented one.
An analysis of how the clusters of classes were distributed
is also presented in Fig. 5, demonstrating how each class
is differentiated. These plots help identify existing overlap
among classes (especially that present between pneumonia
and COVID-19, and to a lesser extent between controls and
pneumonia). Similarly, since the corpus used to train the
network was built around several datasets, a new set of t-SNE
plots was produced, but differentiating according to each
of the subsets used for training (Fig. 6). This test served
to evaluate the influence of each dataset’s potential specific
characteristics in the training procedure and, hence, possible
sources of confusion that arise due to particularities of the
corpora that are tested. The plots suggest that the different
datasets are correctly merged in general terms, but with some
exceptions. These exceptions suggest that there might be
certain unknown characteristics in the datasets used, which
cluster the images belonging to the same dataset together.
The COVID-Net has also demonstrated being a good starting point for the characterization of the disease employing XR
images. Indeed, the paper’s outcomes suggest the possibility
to automatically identify the lung lesions associated with
a COVID-19 infection (see Fig.1) by analyzing the GradCAM mappings of experiment 3, providing an explainable
justification about the way the network works. However,
the interpretation of the heat maps obtained for the control
class must be carried out carefully. Whereas the areas of
significant interest for pneumonia and COVID-19 classes are
supposed to point to potential lesions (i.e. with higher density
or with different textures in contrast to controls), the areas of
significant interest for the classification in the control group
are supposed to correspond to something complementary,
potentially highlighting less dense areas. Thus, in the control
class, these areas do not point towards any kind of lesion in
the lungs.
Likewise, the system developed in experiment 3 attains
comparable results to those achieved by a human evaluator
differentiating pneumonia from COVID-19. In this respect,
the ability of seven radiologists to correctly differentiate
pneumonia and COVID-19 from XR images was tested in
[50]. The results indicated that the radiologists achieved sensitivities ranging from 97% to 70% (mean 80%), and specificities ranging from 7% to 100% (mean 70%). These results
suggest that AI systems have a potential use in a supervised
clinical environment.
COVID-19 is still a new disease, and much remains
to be studied. The use of deep learning techniques
would potentially help understand the mechanisms on
how the SARS-CoV2 attacks the lungs and alveoli and
how it evolves during the different stages of the disease. Despite there is some empirical evidence on the
evolution of COVID-19 –based on observations made by
radiologists [6]–, the employment of automatic techniques
based on machine learning would help analyze data massively, guide research onto certain paths, or extract conclusions faster. Nevertheless more interpretable and explainable
methods are required to go one step forward.
Inline with the previous comment, and based on the empirical evidence respecting the evolution of the disease, it has
been stated that during the early stages of the disease, groundglass shadows, pulmonary consolidation and nodules, and
local consolidation in the centre with peripheral groundglass density are often observed. However, once the disease
evolves, the consolidations reduce their density resembling
a ground-glass opacity that can derive in a ‘‘white lung’’ if
the disease worsens or in a minimization of the opacities
if the course of the disease improves [6]. In this manner,
if any of these characteristic behaviours are automatically
identified, it would be possible to stratify the disorder’s stage
according to its severity. Computing the extent of the groundglass opacities or densities would also be useful to assess the
severity of the infection or to evaluate the evolution of the
disease. In this regard, the infection extent assessment has
been previously tested in other CT studies of COVID-19 [51]
using manual procedures based on observation of the images.
Solutions like the one discussed in this paper are intended
to support a much faster diagnosis and alleviate radiologists and specialists’ workload, but not to substitute their
assessment. A rigorous validation would open the door to
integrating these algorithms in desktop applications or cloud
servers for its use in the clinic environment. Thus, its use,
maintenance, and update would be cost-effective and straightforward and would reduce healthcare costs and improve
diagnosis response time and accuracy. [52]. In any case,
VOLUME 8, 2020 226825J. D. Arias-Londoño et al.: Artificial Intelligence Applied to Chest X-Ray Images for the Automatic Detection of COVID-19
the deployment of these algorithms is not exempt from
controversies: hosting the AI models in a cloud service
would entail uploading the images that might be subject
to national and international regulations and constraints to
ensure privacy [53].




NEW_PAPER



Received August 21, 2020, accepted August 26, 2020, date of publication September 18, 2020,
date of current version September 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3025010
DL-CRC: Deep Learning-Based Chest Radiograph
Classification for COVID-19 Detection: A Novel
Approach
SADMAN SAKIB 1
, TAHRAT TAZRIN 1
, MOSTAFA M. FOUDA 2,3, (Senior Member, IEEE),
ZUBAIR MD. FADLULLAH 1,4, (Senior Member, IEEE),
AND MOHSEN GUIZANI 5
, (Fellow, IEEE)
1Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada
2Department of Electrical and Computer Engineering, College of Science and Engineering, Idaho State University, Pocatello, ID 83209, USA
3Department of Electrical Engineering, Faculty of Engineering at Shoubra, Benha University, Cairo 11629, Egypt
4Thunder Bay Regional Health Research Institute (TBRHRI), Thunder Bay, ON P7B 7A5, Canada
5Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar
Corresponding author: Sadman Sakib (ssak2921@lakeheadu.ca)
This work was supported in part by the MITACS Accelerate under Grant IT18879, and in part by the Natural Sciences and Engineering
Research Council of Canada (NSERC) under Discovery Grant RGPIN-2020-06260.
ABSTRACT With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians
continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities.
Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely
available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be
used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the
COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph
classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other
abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available
sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal
cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI)
algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and
generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train
a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our
customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection
accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few
actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify
our customized CNN model by extensively comparing it with widely adopted CNN architectures in the
literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based,
and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it
can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence
of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.
INDEX TERMS COVID-19, convolutional neural network (CNN), deep learning, generative adversarial
network (GAN), pneumonia.
I. INTRODUCTION
The severe acute respiratory syndrome coronavirus 2 (SARSCoV-2), first observed in Wuhan, China, turned into a global
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
pandemic of COVID-19 (coronavirus disease 2019) [1].
COVID-19 has a destructive impact on the well-being of people, particularly senior citizens and patients with underlying
health conditions and compromised immunity levels. By midJuly 2020, the COVID-19 pandemic already contributed to
over 570,000 mortalities and more than 13 million cases
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 171575S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
of COVID-19 infection [2]. A critical step to combat the
pandemic is to effectively detect COVID-19 infected patients
as early as possible so that they may receive appropriate
attention and treatment. Early detection of COVID-19 is
also important to identify which patients should isolate to
prevent the community spread of the disease. However,
considering the recent spreading trend of the COVID-19,
an effective detection remains a challenging task, particularly
in communities with limited medical resources. While the
reverse transcription polymerase chain reaction (RT-PCR)
test-kits emerged as the main technique for COVID-19 diagnosis, chest X-ray (chest X-ray), computed tomography (CT)
scans, and biomarkers (i.e. high C-reactive protein (CRP),
low procalcitonin (PCT), low lymphocyte counts, elevated
Interleukin-6 (IL6), and Interleukin-10 (IL10)) are also being
increasingly considered by many nations to aid diagnosis
and/or provide evidence of more severe disease progression [3]–[5].
As depicted in Fig. 1, the existing system for detecting
COVID-19 using the aforementioned virus and antibody testing modalities is time-consuming and requires additional
resources and approval, which can be a luxury in many developing communities. Hence, at many medical centers, the test
kits are often unavailable. Due to the shortage of kits and
false-negative rate of virus and antibody tests, the authorities
in Hubei Province, China momentarily employed radiological scans as a clinical investigation for COVID-19 [6].
FIGURE 1. Challenges of existing system and our research focus for
COVID-19 screening in rural areas.
Motivated by this, several researchers and sources
recommend the use of chest radiograph for suspected
COVID-19 detection [7]–[9]. Therefore, radiologists can
observe COVID-19 infected lung characteristics (e.g., ground
glass opacities and consolidation) by harnessing non-invasive
techniques such as CT scan or chest X-ray. However, it is
difficult to differentiate the COVID-19-inflicted features
from those of community acquired bacterial pneumonia [10].
Therefore, for many patients, manual inspection of the radiograph data and accurate decision making can be overwhelming for the radiologists, and an automated classification technique needs to be developed. In addition, radiologists may get
infected and need to isolate that may impact rural communities with a limited number of hospitals, radiologists, and
caregivers. Moreover, as the second wave of COVID-19 is
anticipated in the fall of 2020, preparedness to combat such
scenarios will involve increasing use of portable chest X-ray
devices due to widespread availability and reduced infection
control issues that currently limit CT utilization [10]. Therefore, as depicted in Fig. 1, in this paper, to automate the
COVID-19 detection using X-ray images, we aim to develop
an artificial intelligence (AI)-based smart chest radiograph
classification framework to distinguish the COVID-19 cases
with high accuracy from other abnormal (e.g., pneumonia)
and normal cases. In this vein, the main contributions of the
paper can be summarized as follows:
• A deep learning-based predictive analytics approach is
employed to propose a smart and automated classification framework for predicting COVID-19, pneumonia,
and normal cases. Our proposed deep learning-based
chest radiograph classification (DL-CRC) framework
consists of a data augmentation of radiograph images
(DARI) algorithm and a customized convolutional neural network model.
• A uniquely compiled dataset from multiple publicly
available sources is prepared with radiographs of healthy
(normal), COVID-19, and pneumonia cases reported to
date. The limited number of COVID-19 instances in
the dataset is identified as the prime reason for training bottleneck of deep learning algorithms. As a solution, our proposed DARI algorithm essentially combines
a customized generative adversarial network (GAN)
model with several generic augmentation techniques
to generate synthetic radiograph data to overcome the
COVID-19 class imbalance problem due to limited
dataset availability.
• We train a customized CNN model based on combined
real and synthetic radiograph images that contributes to
significantly improved accuracy of 93.94% in contrast
with 54.55% when only actual COVID-19 instances in
public datasets are used for training. While chest X-ray
is regarded as a less sensitive modality in detecting
COVID-19 infection in lungs compared to CT scans
in the literature [10], we demonstrate the good performance of our custom CNN model in identifying
COVID-19 cases in the real dataset with high accuracy implying that our approach nullifies the need
for using expensive CT scan machines because the
COVID-19 detection accuracy using our custom CNN
model is much higher compared to the reported baseline [10].
• We rigorously analyze the computational complexity
of the DARI, training, and running/inference steps of
our proposed DL-CRC framework. The analyses, further corroborated by experimental results, reveal that
our proposed methodology leads to significantly lower
training time, and particularly much improved inference time, which is crucial for deploying the trained
model into portable X-ray devices for fast and reliable
COVID-19 feature detection in lung radiographs.
171576 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
• The performance of our customized CNN model is
extensively compared with the state-of-the-art CNN
architectures in the literature (i.e., depth-based CNNs,
multi-path-based CNNs, and so forth) [11]. Our proposal
is demonstrated to substantially outperform the contemporary models in terms of classification efficiency.
The remainder of the paper is organized as follows.
Section II surveys the relevant research work regarding
COVID-19 and the relevant use of AI. The problem of traditional COVID-19 detection and challenges associated with it
to apply in developing communities is discussed in section III.
Our proposed input representation and deep learning model
are presented in section IV. The performance of our proposal
is evaluated in section V and extensively compared with those
of well-known CNN architectures. Some of the limitations of
the study is briefly explored in section VI. Finally, section VII
concludes the paper.
II. RELATED WORK
This section explores the relevant research work in the literature from two perspectives, i.e., imaging modalities for
COVID-19 detection, and AI-based analysis of radiograph
samples.
A. IMAGING MODALITIES FOR COVID-19 DETECTION
Most nations had to take measures to react to the sudden
and rapid outbreak of COVID-19 within a relatively short
period of time. According to [12], radiology departments
have started to focus more on preparedness rather than diagnostic capability, after sufficient knowledge was gathered
regarding COVID-19. The study in [5] stated the resemblance
of COVID-19 with other diseases caused by other coronavirus variants such as the severe acute respiratory syndrome
(SARS) and the middle east respiratory syndrome (MERS).
The importance of a tracking the lung condition of a recovering coronavirus patient using CT scans was also mentioned
in the study. Chest imaging techniques were highlighted to be
a crucial technique for detecting COVID-19 by capturing the
bilateral nodular and peripheral ground glass opacities in the
lung radiograph images [13].
B. AI-BASED RADIOGRAPH ANALYSIS
The application of AI, for early detection, diagnosis, monitoring, and developing vaccines for COVID-19, were elaborately discussed in [14]. Several research work exist in the
literature that exploited various deep learning techniques on
X-ray data to demonstrate reasonable performance [15]–[18].
In [19], a model, referred to as DarkCovidNet, for early
detection of COVID-19 was proposed which utilized 17 convolutional layers to perform binary and multi-class classification involving normal, COVID, and pneumonia cases.
While the model reported an overall accuracy of 98.08%
for the binary classification and 87.02% for multi-class classification, our reconstruction of the DarkCovidNet using
multiple datasets indicated overtraining and much lower
accuracy when non-biased test data are presented to the
model. Several other papers applied deep learning models on
CT scan images to detect and monitor COVID-19 features
in the radiograph data [20], [21]. Ardakani et al. in [22]
employed implemented the state-of-the-art CNN architectures such as AlexNet, ResNet-18, ResNet-50, ResNet-101,
SqueezeNet, VGG-16, VGG-19, MobileNet-V2, GoogleNet,
and XceptionCT to differentiate between COVID-19 and
non-COVID-19 cases. Their experiments showed that deep
learning could be considered as a feasible technique for identifying COVID-19 from radiograph images. To avoid poor
generalization and overfitting due to lack of COVID-19 samples in available datasets, a GAN model was used in [23]
to generate synthetic data, which achieved a dice coefficient
of 0.837. The applicability of GAN for COVID-19 radiograph
data synthesis can be confirmed from the broader spectrum of
GAN applications on various medical data according to the
survey in [24]. The survey identified various unique properties of GAN such as domain adaptation, data augmentation,
and image-to-image translation that encouraged researchers
to adopt it for image reconstruction, segmentation, detection,
classification, and cross-modality synthesis for various medical applications.
III. PROBLEM STATEMENT
With the rapidly surging pandemic, the demand for efficient
COVID-19 detection has dramatically increased. The lack of
availability of COVID-19 viral and antibody test-kits, and the
time required to obtain the test results (in the order of days
to weeks) in many countries are posing a great challenge in
developing/rural areas with less equipped hospitals or clinics.
For instance, in many developing countries, hospitals do
not have sufficient COVID-19 test-kits, and therefore, they
require the assistance of more advanced medical centers to
collect, transport, and test the samples. This creates a bottleneck in mass testing for COVID-19. Therefore, to meet
the daily demand for an enormous amount of new test cases,
an automated and reliable complementary COVID-19 detection modality is necessary, particularly to confront the second wave of the pandemic. Radiograph image utilization for
initial COVID-19 screening may play a pivotal role in areas
with inadequate access to a viral/antibody testing. In several
studies, CT scans were used for analyzing and detecting features of COVID-19 [25] due to higher resolution of features
of ground glass opacities and lung consolidation compared
to chest X-ray images. However, due to infection control
matters associated with patient transport to CT suites, relatively high cost (for procurement, operation and maintenance
of CT equipment), and the limited number of CT machines
in developing/rural areas, CT scan is not a practical solution for detecting COVID-19 [10]. On the other hand, chest
X-ray can be employed to identify COVID-19 or other pneumonia cases as a more practical and cost-effective solution
because X-ray imaging equipment are pervasive at hospital
ERs, public healthcare facilities, and even rural clinics. Even
for trained radiologists, detecting chest X-ray images pose
VOLUME 8, 2020 171577S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
challenges to distinguish between features of COVID-19 and
community acquired bacterial pneumonia [10]. Moreover,
the influx of patients into hospital ERs during pandemic,
manual inspection of radiograph data and accurate decision
making can lead to a formidable tradeoff between detection
time and accuracy that can overwhelm the radiologist department. Therefore, an automated classification technique needs
to be designed. As the second wave of COVID-19 is expected
in many countries, preparedness to combat the pandemic
will involve increasing use of portable chest X-ray devices
due to widespread availability and reduced infection control
issues that currently limit CT utilization [10]. In the following
section, we address the aforementioned problem and present
a deep learning-based approach to effectively solve the problem.
FIGURE 2. Our customized generative adversarial network (GAN) model
for data augmentation.
IV. PROPOSED DEEP LEARNING-BASED CHEST
RADIOGRAPH CLASSIFICATION (DL-CRC) FRAMEWORK
Deep learning in smart health analytics is a prominent interdisciplinary field that merges computer science, biomedical engineering, health sciences, and bioinformatics. Various
medical imaging devices have a dedicated image and signal
analysis and processing module, on which deep learningbased models can be implemented to provide accurate, realtime inferences. Motivated by this, we conceptualize a deep
learning-based chest radiograph classification (DL-CRC)
framework, which can used for automating COVID-19 detection from radiograph images.
Our proposed DL-CRC framework consists of two components: (i) the data augmentation of radiology images (DARI)
algorithm, and (ii) a deep learning model. Our proposed
DARI algorithm generates synthetic X-ray images by adaptively switching between a customized GAN architecture
and generic data augmentation techniques such as zoom and
rotation. The synthetic X-ray images are combined with the
actual radiograph data to build a robust dataset for efficiently
training the deep learning model, i.e., the second component
of our DL-CRC framework. A custom CNN architecture is
designed to construct the deep learning model to carry out
automated feature extraction and classification of the radiograph images.
Next, the details of the proposed DARI algorithm and
custom CNN model of our envisioned DL-CRC framework
are presented, followed by a rigorous complexity analysis of
the proposed methodology in training and inference phases.
A. PROPOSED DARI ALGORITHM
Here, we propose an adaptive data augmentation of radiograph images algorithm, referred to as DARI. Our proposed
DARI algorithm performs an on-demand generation of synthetic X-ray images, triggered by class imbalance in the original dataset. The generated synthetic images are combined
with actual radiograph images to construct a robust training
dataset. This is essential, in the COVID-19 context, where
enough representative samples of COVID-19 chest X-ray
images are not sufficient in the currently available datasets.
DARI leverages a custom GAN model, as depicted in Fig. 2,
along with generic data augmentation techniques such as
zoom and rotation. The GAN model is invoked if the number
of samples in a class is less than a certain pre-defined threshold (δ). In the GAN model, a generator (G) and a discriminator (D) are trained simultaneously until the discriminator
is unable to separate the generated data samples from the
original ones. The generator receives random noise as input
and produces chest X-ray images, which are, in turn, received
by the discriminator. Thus, the GAN can be regarded as a
two-player minimax game between a discriminative model
(D) and a generative model (G) [26]. By exerting a noisy
sample nx with the data distribution of p(nx ) as the input,
the generative network G outputs new data X
0
, distribution
of which, denoted by p(X
0
), is supposed to be identical to that
of the distribution of original data, p(X). The discriminative
network, D, is employed to distinguish the true data sample X
with the distribution of p(X) and the generated sample X
0 with
a distribution of p(X
0
). Then, this adversarial training process
can be formulated as follows,
minG maxDV(D, G) = EX∼p(X)
log(D(X))
+ Enx∼p(nx )
log(1 − D(nx )). (1)
We customize the GAN model for chest X-ray image
augmentation as follows. The generator is constructed with
a stack of ng hidden layers. Each layer comprises a dense
layer, followed by Leaky Rectified Linear Unit (LeakyReLU)
as the activation function. In each successive layer (i
th) of the
generator, the number of neuron units (i.e., nodes) is twice
the number of nodes in the preceding layer. On the other
hand, in the discriminator model, it receives collections of
original (X) and generated (X
0
) X-ray radiograph data with
COVID-19 infected lung images. Here, the inputs to the discriminator are X = [x1, x2, . . . xn] and X
0 = [x
0
1
, x
0
2
, . . . x
0
n
],
where each xi represents an original image while each x
0
i
denotes an augmented chest X-ray image. Similar to the
171578 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
generator, the discriminator’s structure also consists of nd
hidden layers, and each i
th layer contains a sequence of a
dense layer with LeakyReLU as the activation function [27].
A dropout layer is then included. Let pi denote the dropout
rate. The number of nodes in each i
th layer is denoted by Di
.
Note that Di =
1
2
· Di−1. The discriminator aims to optimize
the loss function by distinguishing generated images from the
original ones. Our custom GAN model is trained for ξmax
number of iterations, where ξmax ∈ Z
+. The detailed steps of
our proposed DARI algorithm are presented in Algorithm 1.
Here, we either invoke the GAN or a more generic type of
data augmentation, based upon a given condition as illustrated
in Algorithm 1. This procedure takes two inputs: (i) type
of augmentation, and (ii) data for augmentation. For one
condition, the proposed GAN model gets executed from steps
2 to 22. When the other condition is fulfilled, the generic data
augmentation is performed as described in steps 23 to 25,
which includes enlarging the image by Z quantity and rotating
by θ amount.
B. PROPOSED CUSTOM CNN MODEL FOR
COVID-19 DETECTION IN X-ray IMAGES
Next, we need to train a deep learning model which can take
advantage of the robust dataset obtained from our proposed
DARI algorithm in section IV-A. Since the problem can
be regarded as a classification task of normal, COVID-19,
and other abnormal cases (e.g., pneumonia), we investigate
the contemporary deep learning architectures suited for classification. In contrast with other variants of deep learning
architectures (i.e., long-short term memory (LSTM), deep
belief networks, and so forth) and extreme learning machines,
CNNs are regarded as the most powerful deep learning
architecture for image classification. Therefore, we explore
the robust CNN models recently employed to gain reasonable classification accuracy with chest X-ray data [19].
By applying the contemporary CNN models on the latest
dataset compiled from four public repositories, we realize that
their reported performances are constrained by overfitting
and influenced by biased test data. To address this issue,
we propose a two-dimensional (2-D), custom CNN model
for classifying X-ray images to predict COVID-19 cases as
depicted in Fig. 3. The 2-D CNN structure is utilized to learn
the discriminating patterns automatically from the radiograph
images.
The proposed CNN model consists of three components.
The first component is a stack of nc convolution layers while
the second segment consists of nd fully connected layers.
The final component is responsible for generating the output
probability. At first, the convolution layers (i.e., the first component of the model) receive radiograph images (X) as input,
identify discriminative features from the input examples, and
pass them to the next component for the classification task.
Each i
th layer among the nc convolution layers consists of a
filter size of z
i
. Initially, the filter size is set to xir
in the 1st
layer, and it is decreased by λ in each successive layer. In the
Algorithm 1 Data Augmentation of Radiograph Images
(DARI)
Input: type (type of data augmentation,
possible values ‘generic’,
‘GAN’), D (collection of data
for augmentation)
Output: γ (augmented sample data)
1 γ ← ∅
2 if (type=‘GAN’) then
3 Initialize ξmax (maximum number of
epochs), B (mini-batch size), and
naug (number of data to augment)
4 mg ← construct generator model as
depicted in Fig. 2
5 md ← construct discriminator model
as depicted in Fig. 2
6 foreach e ∈ ξmax do
7 for (i=1 to B) do
8 nx ← generate naug samples of
random noise to initialize
the generator
9 gi ← generate image by
passing nx to the generator mg
10 ri ← select random set of
samples from D
11 X
∗ ← construct collection
from generated (gi) and
original samples (ri)
12 md ← update the discriminator
model by batch training using
X
∗
13 end
14 nx ← generate naug samples of
random noise
15 mg ← update the generator model
parameters
16 if e=ξmax then
17 γ ← generate collection of
augmented images by using nx
18 foreach img ∈ γ do
19 save img to corresponding
directory
20 end
21 end
22 end
23 else
24 γ ← augment data by applying
zooming rate of Z and rotation of θ
on each item from data collection D
25 end
26 return γ
forward pass, the convolution operation is performed between
the input image and the filter coefficients using Eq. 2. Here,
VOLUME 8, 2020 171579S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 3. Proposed DL-CRC framework consisting of our envisioned
DARI algorithm and custom CNN model. (1) The test data is obtained by
splitting the original images that are not used for training. (2) DARI
algorithm adaptively uses GAN and generic data augmentation
techniques to generate synthetic chest X-ray images which are combined
with the remaining original radiograph images to construct a robust
training dataset. (3) The training input is passed to our customized CNN
model, which performs automated feature extraction and classification.
x
l
ij and w
l
ij denote the output and the filter weights of the l
th
layer, respectively.
x
l
ij =
X
i∈xir
,j∈xic
(x
l−1
ij × w
l
ij). (2)
Hyper-parameter tuning is conducted to select the optimal
activation function, , as shown in in Eq. 2. The activation
function considers a constant, denoted by α > 0.
Next, we apply a dropout of rate pi as the regularization
technique that will assist the network in evading overfitting and achieve better model generalization by randomly
disregarding randomly selected neurons in the hidden layers [28]. To reduce the feature size and computational power
need, we introduce the max-pooling layer with a pool size
of ki = (k
i
r
, k
i
c
) in the hidden layers where ki
is set to a
fraction µ of the initial dimension of the input xi
. The maxpooling layers assist the model in capturing abstract spatial
information more robustly and enhancing the model’s generalization ability of the model [29]. The output features of
the convolution layers are converted into a one-dimensional
(1-D) vector by flattening the layer, and then forwarded to the
stack of nd fully-connected or dense layers for the automated
classification stage. The number of nodes in the first dense
layer is equal to xir
, and it is decreased by a factor of λ in each
successive i
th layer with respect to the number of nodes in the
previous layer. The output of the n
th dense layer is propagated
through a dropout layer of rate pi
.
Finally, the output layer computes the probability of the
input xi belonging to each class. The learning is set to a
constant ηc throughout the training of the model. The classification task receives radiograph samples as input X =
[x1, x2, . . . xn], and outputs a sequence of labels Y =
[y1, y2, . . . yn]. Here, each xi corresponds to the pixel values
of the input images. On the other hand, each yi denotes a
distinct class. Each xi has the dimension of (xir
, xic
, ϑi). In this
case, xir
, xic
, and ϑi denote the image height, width, and the
number of channels for the i
th sample. The augmented and
real samples are passed to the training data during the training
phase, and some part of the real samples are considered as the
test dataset during the testing phase.
C. TRAINING AND RUNNING PHASES OF PROPOSED
DL-CRC
From hereon, we discuss the steps of the training and running
phases of our proposed DL-CRC algorithm.
The steps of the training phase of our proposed DL-CRC
framework is presented in Algorithm 2. The training stage of
DL-CRC commences from Algorithm 2, which takes C, k, B,
λ, and δ as inputs to our custom CNN model. The description
of each input parameter is provided in the input section of the
algorithm. Steps 1 to 3 of Algorithm 2 initialize the required
parameters. In steps 4 to 10, all data are loaded from location,
and the test data are split by the ratio of λ to be utilized in the
running phase for evaluating the model. Initially, all data are
171580 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
Algorithm 2 Training Phase (DL-CRC)
Input: C (collection for training,
testing, and validation data
location), k (number of fold
in cross-validation), ξ
(number of epoch), B
(mini-batch size), λ (test
ratio), δ (threshold value for
class imbalance ratio), N
(total number of samples
across all classes)
Output: Mt (Trained model)
1 Mt ← ∅
2 X ← []
3 Y ← []
4 X
∗ ← read all data from C[train]
5 if (len(X
∗
)> 0) then
6 I
∗ ← generate random values in
range[0, λ × len(X
∗
)]
7 foreach index i ∈ I
∗ do
8 move C[train] + X
∗
[i] to C[test] + X
∗
[i]
9 end
10 end
11 foreach class ci ∈ C[train] do
12 x
∗
i ← read all data from ci
13 if (len(x
∗
i
)/N < δ) then
14 x
∗
i
+= DARI(‘gan’, x
∗
i
)
15 end
16 foreach class data ∈ x
∗
i
do
17 X+=data
18 Y+=ci
19 end
20 end
21 for (fold no. j=1 to k) do
22 Xtrain, ytrain, Xval, yval ← set data and
labels of j
th fold from X, Y
23 Xtrain += DARI(‘generic’, Xtrain)
24 Xval += DARI(‘generic’, Xval)
25 Mt ← update the CNN model depicted
in Fig. 3 by training it using Xtrain
for ξ and B
26 evaluate Mt by using Xval, yval
27 end
28 save the model parameters of Mt
29 return Mt
stored in the training directory. Hence, they are loaded from
the location of training data. Steps 11 to 20 are responsible for
checking whether any data augmentation is required or not,
and accordingly preparing all the training and validation data
from the dataset. Specifically, steps 13 to 15 check whether
the training data in any class is less than a predefined threshold δ or not, based on the condition if it can exploit the
Algorithm 3 Running Phase (DL-CRC)
Input: testPath (location of test
images)
Output: ypred (prediction of testing
samples)
1 Xtest ← read all data from testPath
2 Mt ← load the saved pre-trained model
3 yprob ← predict the probabilities of
each data from Xtest
4 ypred ← argmax(yprob)
5 return ypred
proposed data augmentation of radiograph images (DARI)
algorithm described in Algorithm 1. Our customized CNN
model is trained in steps 21-27, utilizing the model structure
illustrated in Fig. 3. At the penultimate step, the trained
model (Mt) is stored for further testing and validation. Finally,
in step 29, the algorithm returns the trained model.
Next, in the running phase, the CNN model of our proposed
DL-CRC framework follows Algorithm 3. It receives the
location of sample data for inference and returns the predicted
class labels (ypred) for the corresponding data. After reading
the data from step 1, the pre-trained model (Mt) is loaded in
the following step. In step 4, the model Mt
is employed to
predict the probabilities for a sample test data to be in each of
the possible classes. Finally, in the last step, the class with the
maximum probability is identified for each sample data, and
then returned as a collection of predictions for all the data.
D. COMPUTATION OVERHEAD ANALYSIS
In the remainder of the section, we rigorously analyze the
computational overhead of our proposed model in terms of
time-complexity. The analyses are divided into training and
running phases.
1) TRAINING PHASE
The training phase includes both our proposed DARI (Algorithm 1) for data augmentation and training our customized
CNN model (Algorithm 2). Particularly for the analysis
of Algorithm 2, we consider that the appropriate hyperparameters of our CNN model are already selected after
hyperparameter tuning. We partition the analysis of the training phase into three main segments, i.e., DP (required data
preparation), DA (data augmentation), and CNN (the execution of the CNN model). Therefore, the total computational
complexity can be expressed as follows.
C(T ) = O(DP) + O(DA) + O(CNN). (3)
In the first three steps (1-3) of Algorithm 2, where initialization is conducted, the time complexity can be denoted as
constant time, O(1). In the 4th step, all the data from the train
path are read. So, if there are fn number of data available to
train, the time complexity will be O(fn). Steps 5-9 split the test
data by the λ ratio. Therefore, the complexity associated with
VOLUME 8, 2020 171581S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
these steps is O(λ). Hence, the computational complexity of
the data preparation phase can be denoted as:
O(DP) = O(3) + O(fn) + O(λ) ≈ O(fn) + O(λ). (4)
The data augmentation part of the complexity analysis mainly consists of our proposed DARI (Algorithm 1),
invoked in steps 13-15 of Algorithm 2. This requires loading
data from each class in step 12 that results in the computational complexity of O(cl × f
i
n
). Here, cl denotes the number
of classes while f
i
n
refers to the number of data read from
i
th class. Then, through steps 13-15, the DARI algorithm is
invoked and its complexity is denoted as ODARI. Suppose
that ng and nd denote the numbers of layers in the generator and discriminator, respectively. Then, the computations
required by the generator and the discriminator models can
be denoted as Gc (Eq. 5) and Dc (Eq. 6), respectively:
Gc = 2(Xng
i=1
x
i
g × w
i
g + b
i
g
), (5)
Dc = 2(Xnd
i=1
x
i
d × w
i
d + b
i
d
). (6)
Combining the previous two expressions of Gc and Dc,
the overall overhead of DARI (Algorithm 1) is evaluated as
follows.
O(DARI) = O(cl×ξmax×B×(Gc+Dc))+O(cl × naug),
(7)
where naug, ξmax, and B denote the number of data to augment,
maximum number of epochs, and mini-batch size, respectively.
In steps 16-19 of the training algorithm, assuming the
length of each x
∗
i
as lx∗
i
, the computational overhead is O(lx∗
i
).
Therefore, the overall complexity of the data augmentation
stage can be expressed as:
O(DA) = O(cl × f
i
n
) + O(DARI) + O(lx∗
i
). (8)
From steps 21 to 27, the training algorithm invokes the
adopted 2-D CNN structure. The computational overhead for
this part can be derived from Eq. 9:
O(CNN) = O(CNNcl) + O(CNNdl), (9)
where O(CNNcl) and O(CNNdl) denote the computational
overheads in the convolutional layers and dense layers,
respectively. If we consider for a layer i, the number of filters
in the i
th layer z
i
, input image x
i with the dimension of
(x
i
r
, x
i
c
) and kernel k
i with the dimension of (k
i
r
, k
i
c
), then the
computational complexity of the convolutional layers can be
expressed as:
O(CNNcl) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
))). (10)
After the convolutional layers, for n layers, assuming w
i
and b
i
are the weight vector and the bias of i
th layer, the complexity of the fully connected layers is given by:
O(CNNdl) = O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (11)
Hence, combining the aforementioned equations, to finalize the computational complexity of the proposed CNN,
we can re-write Eq. 9 as follows:
O(CNN) = O(z
i × (
Xnc
i=1
(x
i
r × x
i
c × k
i
r × k
i
c
)))
+ O(
Xnd
i=1
(x
i
r × x
i
c × w
i + b
i
)). (12)
Finally, to determine the total time complexity of the training phase of the DL-CRC algorithm, we can substitute the
corresponding values from Eqs. 4, 8, and 12 into Eq. 3.
2) RUNNING PHASE
The running phase is conducted to infer classes of each test
data using the pre-trained model and then evaluate the model.
As shown in Algorithm 3, if we consider the number of test
data to be ntest, the computational overhead in the testing
phase can be given by:
C(R) = O(ntest). (13)
Eq. 13 demonstrates that the model is able to produce results in linear time. This implies that our proposed
DL-CRC framework comprising DARI algorithm and the
customized CNN model can be deployed on clinical-grade
X-ray machines with image processing capability, computing
resources having access to digitized radiograph images from
analog X-ray machines, and even portable X-ray machines
in movable booths and trucks with adequate shielding and
power supply. Thus, our model is viable for automating the
radiograph image classification with fast turn-around time for
COVID-19 detection.
V. PERFORMANCE EVALUATION
To evaluate the performance of our proposed DL-CRC framework, in this section, we describe the collected datasets used
to train our customized CNN model, followed by extensive
experimental results and discussion.
A. DATASET PREPARATION
The dataset employed for the supervised radiograph image
classification using our proposed DL-CRC framework consists of three classes: COVID-19, pneumonia, and normal
chest X-ray images. We collected the dataset using four different existing datasets of Posteroanterior (PA) chest X-rays,
and combined those into a single dataset to utilize it for the
classification purpose. We developed the dataset from GitHub
for COVID-19 X-rays [30], X-ray data collected in this study
for cases of pneumonia, and normal images [31], CheXpert
171582 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 1. Brief description of the used dataset for X-ray image
classification.
dataset collected by Stanford ML group [32], and the rest of
the normal and pneumonia chest X-ray images were collected
from the dataset in [33]. Table 1 lists the initial class distribution of the collected chest X-ray dataset. The number of
samples collected for COVID-19 is significantly lower than
the other two classes because this is a novel disease, and at this
moment, data regarding COVID-19 is challenging to obtain.
In other words, the number of COVID-19 class samples in
the merged dataset is lower than the threshold value for class
imbalance ratio, δ. Therefore, to overcome the effect of the
low amount of COVID-19 data, we employed our proposed
DARI algorithm to increase the number of samples. We then
applied our proposal along with contemporary CNN models
to verify which one yields the best COVID-19 detection
performance.
B. PERFORMANCE INDICATORS
To evaluate the classification results, we primarily adopted
the combination of three measurement indicators, accuracy,
weighted precision, and weighted F1 score. The accuracy of
a test is its ability to correctly differentiate the three cases.
Assume that C denotes the number of classes in the considered classification task, |yi
| refers to the number of samples
in the i
th class, and |Y | indicates the total number of samples
in all the classes. Then, the accuracy can be represented as
follows.
Accuracy =
PC
i=1
(TPi)
|Y |
. (14)
Next, we define the weighted precision. Our aim is to
measure how precise the model is in terms of the number of
samples actually present in the i
th class out of those predicted
to be in that class. This number is multiplied by the weight of
the i
th class to obtain the weight precision as follows.
Weighted precision =
X
C
i=1
(
|yi
|
|Y |
×
TPi
TPi + FPi
). (15)
Next, the weighted F1 score is defined as the weighted
average of precision and recall. Although we did not use
recall directly as a performance measure, because of using
the F1 score, it is implicitly used. The weighted F1 score can
be obtained as follows,
Weighted F1 score =
X
C
i=1
(
|yi
|
|Y |
× 2
Pi × Ri
Pi + Ri
). (16)
Here, Pi and Ri are the precision and recall of i
th class,
respectively. Pi can be expressed as TPi/(TPi + FPi) and
Pi can be denoted as TPi/(TPi + FNi). TPi
, FPi
, and FNi
denotes True Positive, False Positive, and False Negative
for i
th class respectively. TPi
indicates the number of cases
correctly identified to be in the i
th class; FPi represents the
number of cases incorrectly identified to be in the i
th class,
and FNi denotes the number of cases incorrectly identified
as a class other than the i
th class. In addition, for evaluating
our results more comprehensively we also employed class
specific classification accuracy (i.e., normal, COVID-19, and
pneumonia detection accuracy) for all three classes.
C. RESULTS AND DISCUSSION
We have followed a systematic approach by applying different techniques to find the optimal model for the classification
task. All the experiments were conducted on a workstation
with Intel Core i7, 3.00GHz CPU, 16 GB RAM, powered
by Nvidia RTX 2060 Graphics Processing Unit (GPU). The
simulations were implemented employing Python’s Keras
and TensorFlow library. The visualization of the experimental
results was achieved by utilizing Python’s Matplotlib library.
During the simulations, we have resized the image samples by
setting both xir
and xic
to 100 to keep the images consistent in
terms of size. The number of channels of the samples (ϑi) was
set to 1 as the input images were grayscale in nature. The values of xir
and xic were selected based on manual tuning. Using
our proposed DARI algorithm, on-demand data augmentation
is performed by adaptively employing GAN, rotation (θ) of 5
degrees, and zooming (Z) rate of 0.50. The value of δ was
set to 0.1. We systematically constructed three experimental
scenarios to conduct a comprehensive performance comparison of our proposed DL-CRC framework consisting of DARI
algorithm and our customized CNN models with the stateof-the-art CNN models which have been recently reported to
provide reasonable accuracies for COVID-19 detection. The
three scenarios, constructed in an incremental fashion, are
described below.
1) In our first scenario, we designed our customized deep
CNN model architecture depicted in Fig. 3. The parameters of the model were selected based on the results of
the grid search technique.
2) In the second scenario, we implemented the proposed
DARI algorithm to analyze the effect of the generic and
GAN-based data augmentation to train the CNN-based
model in a robust fashion to significantly improve the
COVID-19 detection accuracy.
3) In the third and final scenario, we trained several stateof-the-art CNN models using different deep learning
paradigms on our compiled dataset. The same test data
(unknown chest X-ray original images with normal,
COVID-19, and pneumonia cases) were presented to
the customized CNN model of our proposed DL-CRC
framework as well as the contemporary CNN models.
The results were used to compare the performances of
our proposal and these contemporary models in terms
of COVID-19 and pneumonia detection efficiency.
VOLUME 8, 2020 171583S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 4. Performance in terms of accuracy for different combinations of
activation functions and optimizers.
FIGURE 5. Performance in terms of precision for different combinations
of activation functions and optimizers.
FIGURE 6. Performance in terms of F1 score for different combinations of
activation functions and optimizers.
In the first scenario, we implemented the customized CNN
model of our proposed DL-CRC framework and carried out
a grid search to achieve the optimal model parameters (i.e.,
FIGURE 7. Performance comparison for diverse ratios of the
COVID-19 X-ray images generated by the GAN with respect to the existing
number of samples in the dataset.
the best activation functions and optimizer). It is worth noting that other customized CNN models revealed a performance bottleneck in terms of validation accuracy and we
found the model in Fig. 3 to be the most lightweight yet
efficient for automating the chest X-ray classification task.
Figs. 4, 5, and 6 demonstrate the results obtained from the
hyper-parameter tuning in terms of accuracy, precision, and
F1 score, respectively. These performances were extensively
evaluated across six optimizers (Stochastic Gradient Descent
(SGD), Adaptive Moment Estimation (Adam), Root Mean
Square Propagation (RMSProp), Adaptive Delta (AdaDelta),
Nesterov and Adam (Nadam), and Adaptive Gradient Algorithm (Adagrad)) and five activation functions (tanh, sigmoid, Scaled Exponential Linear Unit (SELU), Rectified
Linear Unit (ReLU), and Exponential Linear Unit (ELU)). As
depicted by the results in these figures, SELU demonstrated
better performances on average when compared with the
other activation functions. However, the best performance
was exhibited when ELU is adopted as the activation function
with the value of constant α = 1.0 and the optimizer set to
Adagrad with the learning rate of 0.001. For this first experimental setting for selecting the optimal hyper-parameters
of the deep learning-based model, the mini-batch size (B)
was set to 8, and the number of epochs (ξ ) was set to 20.
With this configuration, the validation accuracy, precision,
and F1 score were found to be 97.25%, 97.24%, and 97.21%,
respectively. Therefore, for further analysis, we applied this
configuration in the customized CNN model of our DL-CRC
framework. Furthermore, in the max-pooling layer of our
proposed CNN architecture, we conducted manual parameter
tuning, and the pool size ki was assigned as µ, where µ = 2%
of the initial size of the input xi
.
In the second experimental scenario, as the number of
COVID-19 samples in the collected dataset was lower than
the pre-defined threshold δ, we applied our proposed DARI
algorithm to increase the number of COVID-19 samples so
that the model can be trained with a robust training data
171584 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
FIGURE 8. Confusion matrix of testing phase employing 5-fold stratified cross-validation.
and eventually predict positive COVID-19 cases with high
accuracy. In Fig. 7, we altered the proportions for our customized GAN model in the DARI algorithm with respect to
the original sample size of the COVID-19 class. The ratios
of GAN-generated samples of the proposed approach were
varied from 50% to 200% with respect to the number of
COVID-19 examples in the original dataset. The number of
iterations for producing the augmented samples using the
GAN-based method was set to 200. Among the proportions
mentioned earlier, the COVID-19 detection performance of
our customized CNN model was found to be the highest
(with an accuracy of 93.94%) when the number of newly
generated samples was 100% of the size of the original
COVID-19 samples. Therefore, we picked this configuration to be used in our conducted experiments in the next
scenario.
After producing the augmented samples for the COVID-19
class, we analyzed the effect of combining the adaptive
generic data augmentation and GAN-based DARI algorithm
with the CNN architecture to fully implement and fine-tune
the DL-CRC framework, and compared the performance with
the base CNN model only (i.e., without adopting DARI
algorithm). The experiment was conducted utilizing a fivefold stratified cross-validation. Using the stratification technique, the samples are rearranged so that each fold has a
stable representation of the whole dataset by maintaining
the percentage of samples for each class [34]. In our third
experimental setup, the number of epochs (ξ ) was set to
100, and the mini-batch size (B) was set to 8. The number of convolutional layers, nc, was set to five. The number of fully-connected/dense layers, nd , was also fixed to
five. Note that these hyperparameter values were manually
tuned. To analyze the results more critically in terms of
COVID-19 detection efficiency, in this experimental setting,
we also investigated the normalized and non-normalized values of the confusion matrices of our customized CNN model
TABLE 2. Performance comparison of the proposed DL-CRC and CNN
with generic and GAN-based data augmentation.
without (i.e., CNN-only model) and with the proposed DARI
algorithm (i.e., the complete DL-CRC framework). Fig. 8
represents the normalized confusion matrix where the proposed CNN model is implemented without applying the data
augmentation, and Fig. 8 depicts the same for the combined
CNN and DARI algorithm. Despite similar performances of
both approaches, the normalized confusion matrix demonstrates that our proposed DL-CRC framework is much more
robust for classifying positive COVID-19 and pneumonia
cases. The proposed DL-CRC exhibited 93.94% and 88.52%
accuracies while detecting positive COVID-19 and pneumonia cases, respectively. The encouraging classification
performance indicates that our proposed deep learningbased DL-CRC framework is able to classify the radiograph images with high efficiency, specifically for COVID-19
detection.
Furthermore, we analyzed the impact of generic and GANbased data augmentation separately combined with our customized CNN model and compared the COVID-19 detection
accuracy with the proposed DL-CRC framework. Table 2
exhibits the simulation results, which proves that both the
generic and GAN-based data augmentation had significant
influence in enhancing the COVID-19 detection efficiency.
The simulation results in the table show that our CNNonly base model achieved 54.5%, CNN with generic data
augmentation obtained 63.4%, and CNN with the proposed
VOLUME 8, 2020 171585S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 3. Performance comparison of our proposed DL-CRC architecture
with the existing CNN architectures for all three classes.
GAN-based data augmentation delivered 84.5% COVID-19
detection accuracy. On the other hand, the proposed DL-CRC
framework demonstrated the highest COVID-19 detection
accuracy (93.94%). This good performance is attributed to
the combination of our customized CNN model with the proposed DARI algorithm where both generic and GAN-based
data augmentation are adaptively performed, Therefore, it is
evident from these results that our proposed DL-CRC framework made the customized CNN model much more robust
with DARI algorithm.
In the third experimental scenario, we compared the performance of our customized CNN model with the performances
of the state-of-the-art CNN models such as Inception-Resnet
V2, Resnet, and DenseNet. The reason behind choosing these
contemporary models is their good performances reported
in the recent literature for COVID-19 detection. It is worth
noting that Inception-ResNet v2 and DenseNet belong to the
depth-based and multi-path-based CNN paradigms, respectively. On the other hand, ResNet combines both depthbased and multi-path-based CNN architectures. Table 3
demonstrates the comparative analysis, which indicates
the efficiency of our proposed DL-CRC framework in
terms of COVID-19 and pneumonia detection using chest
X-ray images. Our proposed model, outperformed ResNet,
Inception-ResNet v2, and DenseNet. Although Densenet
achieves 98.01% prediction performance for normal test
cases, its accuracy is only 72.42% for pneumonia detection
while it exhibits the poorest performance of 60.61% for
identifying COVID-19 cases. This implies that multi-pathbased structure, although reported in recent work, is not suitable for COVID-19 detection. On the other hand, Inception
ResNet v2, using the depth-based CNN modeling paradigm,
achieves improved COVID-19 detection accuracy (69.70%).
The combination of these two modeling paradigms is incorporated in ResNet, which is able to predict test cases having
COVID-19 samples slightly elevated accuracy of 72.72%.
On the other hand, our proposed DL-CRC framework, combining our envisioned DARI algorithm and customized CNN
model, is able to detect the COVID-19 cases with a significantly high accuracy of 93.94%. Note that the pneumonia (the other abnormal case) present in the test dataset is
also detected with much higher accuracy (88.52%) compared
to the contemporary models. Even though the performance
slightly drops for normal case identification, the accuracy
is still close to 96% in case of our proposal. Furthermore,
in the final column of Table 3, the AUC (area under the ROC
(receiver operating characteristic) curve) values are also listed
for the proposed DL-CRC and contemporary models. The
AUC score of our proposed DL-CRC is 0.9525 which demonstrates the reasonable accuracy of identification across all
samples in the test data. Thus, the encouraging performance
of the proposed DL-CRC algorithm over prominent CNN
models clearly demonstrates that the proposed technique can
be useful for detecting COVID-19 and pneumonia cases with
a significantly high (i.e., reliable) accuracy.
Furthermore, we compare the performance of our proposal
with a recent custom model, referred to as DarkCovidNet
[19]. For multi-class classification, the accuracy of DarkCovidNet was reported to be 87.02%, which is considerably
lower than that of our proposed model’s performance
(93.94%), which we believe ensures the effectiveness of our
proposed model. In addition, we have conducted two-fold
experiments to validate and compare our proposed technique (DL-CRC) with DarkCovidNet. Table 4 demonstrates
the results obtained when our proposed model is tested on
both datasets, and the DarkCovidNet model is tested on
both datasets. Both models were trained by employing the
respective dataset used by the work in [19] and our current work. These experimental results presented in Table 4
were produced after training the models for 25 epochs for
each case, and then the trained models were tested on both
datasets. Our proposed technique outperformed DarkCovidNet for detection accuracies for both normal and COVID-19
cases. In addition to the classification efficiency, our proposed DL-CRC framework is more lightweight than that of
used in DarkCovidNet. Our customized CNN model of DLCRC consists of 5 convolutional layers while the DarkCovidNet model comprises 17 convolutional layers, making our
model’s training phase more lightweight and computationally
less expensive than the DarkCovidNet model.
Moreover, while some researches reported overall accuracy, they did not mention the COVID-19 detection accuracy.
On the other hand, most researches applying deep learning
techniques did not report the AUC score, which is a robust
representative performance metric for practically evaluating
the COVID-19 detection ability of the model. In summary,
by applying various contemporary CNN models (Inception
with Resenet V2, Resnet, Densenet) and a recent customized
model (DarkCovidNet) for COVID-19 detection on the latest
dataset compiled from four public repositories, we realized
that their reported performances are constrained by overfitting and influenced by biased test data. Thus, the accuracy
bottleneck of those existing models justifies why we required
to build a customized CNN model in this research and combine it with the DARI algorithm to perform robust training
and avoid overfitting to ensure high COVID-19 detection
accuracy and a significantly high AUC score.
VI. LIMITATIONS OF THE STUDY
In this section, we briefly discuss some limitations and possible future work that can be conducted to extend the study.
171586 VOLUME 8, 2020S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
TABLE 4. Comparison of the performance our proposed model with that of DarkCovidNet [19] on both datasets.
• Our study and experiments have been conducted at a
very critical stage and time-sensitive manner to combat the COVID-19 pandemic with a proof-of-concept
COVID-19 using radiograph images. Despite compiling
datasets from multiple sources with X-ray images containing COVID-19 samples, the used data was considerably small in size. Therefore, synthetic images were
generated using our customized GAN-assisted data augmentation technique that were used to train a robust
CNN model to perform binary (normal and COVID-19)
and three-way classification (normal, pneumonia, and
COVID-19) with significantly high accuracy. Due to
the lack of real datasets consisting of other diseases
(e.g., SARS, MERS, and so forth) which exhibit acute
respiratory distress syndrome (ARDS) and pneumonialike conditions in the lungs, more class labels were not
considered in our work.
• From a physician’s perspective, it is important to diagnose the severity of COVID-19. However, due to the lack
of labeled data, in this work, our model could not be
used to classify the various stages of COVID-19 such
as asymptomatic, mild, high and severe.
• The proposed technique performed efficiently when we
utilized it to analyze X-ray samples. However, the study
can be extended to evaluate the system’s performance
in COVID-19 detection while using other radiograph
techniques such as CT scan, lung ultrasound, and lung
PET (positron emission tomography) scan.
• The dataset used in this study is limited by only
one modality type, i.e., X-ray images containing
COVID-19 features. Further customization in our CNN
model will be required if we want to combine multiple
imaging modalities (e.g., lung CT scan, ultrasound, PET
along with X-ray images), other modalities (e.g., body
temperature, ECG, MCG, diabetes level, renal function,
and so forth), and patient parameters (e.g., age, gender, ethnicity, travel history, and contact history) to perform an in-depth COVID-19 classification. Therefore,
a multi-modal input characterization and corresponding
AI model customization will be needed in the future for
interpreting and explaining the classification results.
VII. CONCLUSION
In this paper, we addressed the emerging challenges of
detecting COVID-19. Due to the shortage of efficient diagnosis equipment and personnel in many areas, particularly
in developing and/or rural zones, numerous people remain
non-diagnosed. This results in a substantial gap between the
number of confirmed and actual cases. Radiographs such as
chest X-ray images and CT scans have been demonstrated
to have the potential for detecting COVID-19 infection in
the lungs that can complement the time-consuming viral
and antibody testing. While CT scans have higher resolution or fine-grained details compared to X-ray images, X-ray
machines are pervasive in hospital emergency rooms, public
health facilities, and even rural health centers or clinics.
In addition, because X-ray is a much cheaper alternative
and an appealing solution for portability in mobile trucks
and COVID-19 screening booths with adequate shielding
and power supply, how to identify COVID-19 infection of
the lung by recognizing patterns such as glass opacities and
lung consolidations raised a formidable research problem,
that we addressed in this paper. Also, we discussed why
it is necessary to automate the X-ray image classification
to be well prepared for the next wave of COVID-19 pandemic, when radiologists and caregivers are expected to be
overwhelmed by patient influx as well as the need to selfisolate in case they themselves become infected. This means
there is a pressing need to automate the classification of
radiographs, particularly X-ray images, to minimize the turnaround time for COVID-19 detection. Therefore, to leverage
the availability and cost-efficiency of chest X-ray imaging,
in this paper, we proposed a framework called DL-CRC
(Deep learning-based chest radiograph classification) to automate COVID-19 detection that can complement existing viral
and antibody testing methods.
Our proposed DL-CRC framework consists of two parts:
the DARI algorithm (which adaptively employs a customized
generative adversarial network and generic data augmentation techniques such as zoom and rotation) and a twodimensional convolutional neural network (CNN) model. We
employed a unique dataset for multiple publicly available
sources, containing radiograph images of COVID-19 and
pneumonia infected lungs, along with normal lung imaging.
The classification accuracy significantly increased to 94.61%
by adopting our proposed DL-CRC framework. Our proposal was compared with existing deep learning models from
diverse categories such as depth-based CNN (e.g., InceptionResNet v2), multi-path-based CNN (DenseNet), and hybrid
CNN (ResNet) architectures. Extensive experimental results
demonstrated that our proposed combination of DARI and
custom CNN-based DL-CRC framework significantly outperformed the existing architectures. Thus, incorporating our
proposed model with significantly high accuracy into the
VOLUME 8, 2020 171587S. Sakib et al.: DL-CRC for COVID-19 Detection: A Novel Approach
clinical-grade as well as portable X-ray equipment can allow
an automated and accurate detection of COVID-19 in the
scrutinized patients.




NEW_PAPER


Received October 28, 2020, accepted November 10, 2020, date of publication November 16, 2020,
date of current version November 30, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3038279
Drr4covid: Learning Automated
COVID-19 Infection Segmentation From
Digitally Reconstructed Radiographs
PENGYI ZHANG , YUNXIN ZHONG , YULIN DENG , XIAOYING TANG , AND XIAOQIONG LI
1School of Life Science, Beijing Institute of Technology, Beijing 100081, China
2Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, Ministry of Industry and Information
Technology, Beijing 100081, China
Corresponding author: Xiaoqiong Li (aeople@126.com)
This work was supported by the Science and Technology Innovation Program, Beijing Institute of Technology, under
Grant 1870011162001.
ABSTRACT Automated infection measurement and COVID-19 diagnosis based on Chest X-ray (CXR)
imaging is important for faster examination, where infection segmentation is an essential step for assessment
and quantification. However, due to the heterogeneity of X-ray imaging and the difficulty of annotating
infected regions precisely, learning automated infection segmentation on CXRs remains a challenging
task. We propose a novel approach, called DRR4Covid, to learn COVID-19 infection segmentation on
CXRs from digitally reconstructed radiographs (DRRs). DRR4Covid consists of an infection-aware DRR
generator, a segmentation network, and a domain adaptation module. Given a labeled Computed Tomography
scan, the infection-aware DRR generator can produce infection-aware DRRs with pixel-level annotations
of infected regions for training the segmentation network. The domain adaptation module is designed to
enable the segmentation network trained on DRRs to generalize to CXRs. The statistical analyses made
on experiment results have indicated that our infection-aware DRRs are significantly better than standard
DRRs in learning COVID-19 infection segmentation (p < 0.05) and the domain adaptation module can
improve the infection segmentation performance on CXRs significantly (p < 0.05). Without using any
annotations of CXRs, our network has achieved a classification score of (Accuracy: 0.949, AUC: 0.987,
F1-score: 0.947) and a segmentation score of (Accuracy: 0.956, AUC: 0.980, F1-score: 0.955) on a test
set with 558 normal cases and 558 positive cases. Besides, by adjusting the strength of radiological signs of
COVID-19 infection in infection-aware DRRs, we estimate the detection limit of X-ray imaging in detecting
COVID-19 infection. The estimated detection limit, measured by the percent volume of the lung that is
infected by COVID-19, is 19.43% ± 16.29%, and the estimated lower bound of infected voxel contribution
rate for significant radiological signs of COVID-19 infection is 20.0%. Our codes are made publicly available
at https://github.com/PengyiZhang/DRR4Covid.
INDEX TERMS COVID-19 diagnosis, infection segmentation, DRRs, X-ray imaging, deep learning.
I. INTRODUCTION
The highly contagious Coronavirus Disease 2019
(COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) virus [1]–[3], has spread
rapidly to most countries in the world. Globally, as of 2:34pm
CEST, 7 July 2020, there have been 11,500,302 confirmed
cases of COVID-19, including 535,759 deaths, reported to
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
World Health Organization (WHO) [4]. Rapid detection and
confirmation of COVID-19 infection is critical to prevent the
spread of this epidemic.
Radiological imaging, such as Computed Tomography (CT) and Chest X-ray (CXR), is currently used to provide
visual evidence for confirming COVID-19 positive patients
in clinical practice. CT scan provides accurate 3D images of
the lungs that are able to detect very small lesions effectively
such as lung nodule and tumor. However, the workflow of CT
imaging, involving several pre-scan events [5], is relatively
207736 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
complex, and meanwhile, CT examinations are costly. As the
number of infected patients rapidly increases, the routine use
of CT brings heavy burden to the radiology department [6].
In contrast, CXR examination is much easier, faster and less
costly, and provides high-resolution 2D images of the lungs
that can detect a variety of lung conditions such as pneumonia, emphysema and cancer. CXRs are the typical firstline imaging modality used for patients under investigation
of COVID-19 [7]. Therefore, automated infection measurement and COVID-19 diagnosis based on CXRs is important
for faster examination, where infection segmentation is an
essential step for assessment and quantification.
Many approaches have been proposed for automated
COVID-19 diagnosis based on CXRs, and have claimed
notable detection accuracy of COVID-19 infection. However,
due to the lack of sufficient CXRs with pixel-level annotations of infected regions, the majority of these approaches
are designed by using classification models rather than segmentation models. The projective nature of X-ray imaging
causes large overlapping of anatomies, fuzzy object boundaries and complex texture patterns, thus making it extremely
difficult to delineate infected regions precisely on CXRs
even for experienced clinicians [8]. As an alternative, some
researchers have leveraged the interpretability of classification model (e.g., saliency map or attention map) to locate the
infected regions roughly. However, such methods are unable
to produce accurate COVID-19 infection segmentation for
further assessment and quantification. Currently, to our best
knowledge, no effective approaches have been developed for
automated COVID-19 infection segmentation on CXRs as
reviewed by Shen et al. [7].
Digitally reconstructed radiograph (DRR) [9]–[12] is a
synthetic X-ray image that is generated by simulating the
passage of X-rays through a 3D CT volume in specific poses
(position and orientation) within a virtual imaging system.
CXR findings of COVID-19 infection reflect those described
by CT [13] such as bilateral, peripheral consolidation and/or
ground glass opacities (GGOs) [7], [14], [15]. Besides, delineating infected regions in 3D CT scans is much easier than
in heterogeneous 2D CXRs because CT scans can provide
accurate 3D images of the lungs rather than heterogeneous
2D images. Thus, we propose to learn automated COVID-19
infection segmentation on CXRs from labeled DRRs by
leveraging the publicly available CT scans with voxel-level
annotations of infected regions and the correlation between
DRRs and CXRs.
To this end, we propose a novel approach, called
DRR4Covid, which can learn automated COVID-19 infection segmentation on CXRs from labeled DRRs. We design
DRR4Covid with a modular framework, which consists of
an infection-aware DRR generator, a deep segmentation network, and a domain adaptation module. Given a CT volume
with voxel-level infection annotations, our infection-aware
DRR generator can produce DRRs with adjustable radiological signs of COVID-19 infection, and generate pixellevel annotations of infected regions that match the DRRs
accurately. Although such synthetic DRRs are photo-realistic,
there is still a gap between synthetic DRRs and real CXRs,
which may lead to a poor segmentation performance on real
CXRs. Therefore, we introduce a domain adaptation module
to train networks on labeled DRRs and unlabeled CXRs
together. In this article, we provide a simple but effective
implementation of DRR4Covid by using a domain adaptation
module based on Maximum Mean Discrepancy (MMD), and
a FCN-based [16] network with a classification header and
a segmentation header. Extensive experiment results have
confirmed the efficacy of our method; specifically, without
using any annotations of CXRs, our network has achieved
a classification score of (Accuracy: 0.949, AUC: 0.987,
F1-score: 0.947) and a segmentation score of (Accuracy:
0.956, AUC: 0.980, F1-score: 0.955) on a test set with
558 normal cases and 558 positive cases. Besides, by adjusting the strength of radiological sign of COVID-19 infection
in synthetic DRRs, we estimate the detection limit of X-ray
imaging in detecting COVID-19 infection. The estimated
detection limit, measured by the percent volume of the lung
that is infected by COVID-19, is 19.43% ± 16.29%, and the
estimated lower bound of the contribution rate of infected
voxels for significant radiological signs of COVID-19 infection is 20.0%.
The novelties and contributions of our study mainly come
from four major aspects:
1) We propose a novel approach, i.e., DRR4Covid,
to learn automated COVID-19 infection segmentation
on CXRs. To our best knowledge, this is the first
attempt to learn automated COVID-19 infection segmentation on CXRs by using the labeled DRRs that are
generated from Chest CT scans. Owing to the modular
framework, our DRR4Covid can be implemented flexibly with the off-the-shelf segmentation networks and
domain adaptation algorithms. Moreover, DRR4Covid
is a unified approach that can be applied to other lesion
segmentation (e.g., lung nodule and tumor) on X-ray
images;
2) We design an infection-aware DRR generator to synthesize infection-aware DRRs with pixel-level annotations of infected regions for training segmentation
network. The statistical analyses made on experiment
results have confirmed that our infection-aware DRRs
are significantly better than standard DRRs in learning
COVID-19 infection segmentation (p < 0.05);
3) We provide a simple but effective implementation of
DRR4Covid by using a domain adaptation module
based on Maximum Mean Discrepancy (MMD), and
a FCN-based network with a classification header and
a segmentation header. The statistical analyses made
on experiment results have confirmed that the domain
adaptation module can improve the infection segmentation performance on CXRs significantly (p < 0.05);
4) We estimate the detection limit of X-ray imaging in
detecting COVID-19 infection for the first time, which
VOLUME 8, 2020 207737P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
is of great significance for the severity assessment of
COVID-19 infection based on X-ray imaging.
II. RELATED WORK
In this section, we review the related work from three aspects,
including DRR, domain adaptation and CXR based screening
of COVID-19 in light of infection segmentation.
A. DRR
A digitally reconstructed radiograph (DRR) [9]–[12] is a synthetic X-ray image that is generated by simulating the passage
of X-rays through a 3D CT volume in specific poses (position
and orientation) within a virtual imaging system. DRRs are
generally used as reference images by the intensity based
2D to 3D image registration algorithms to verify the correct
setup position of a patient for many radiotherapy treatments
[17]–[19]. Each pixel value of DRR is obtained by calculating
the radiological path length (RPL) [20], i.e., the summation
of the length travelled by the ray in each voxel, multiplied
by the relative CT intensity of the voxel that is measured in
Hounsfield units (HUs). Thus, with a high complexity level
of O(n
3
), the synthesis of DRRs is computationally intensive
by nature [21]. Meanwhile, in the iterative optimization of
2D–3D image registration algorithms, the synthesis of DRRs
is usually performed many times to calculate the similarity
measure [19], which greatly limits the running speed of
2D-3D image registration algorithms [12]. Therefore,
the majority of previous studies have focused on this problem and have proposed plenty of improved approaches
to accelerate the synthesis of DRRs [11], [12], [19]–[23].
In contrast, we are more concerned with the consistency
between DRRs and the infection annotation masks. Thus,
we directly design our infection-aware DRR generator based
on SiddonGpuPy [24], which combines the serial algorithm
proposed by Jacob [11] to improve the original Siddon’s
algorithm [9], and the parallel implementation proposed by
Greef et al. [20].
The most closely related work is TD-GAN [8] and DeepDRR [25], [26]. TD-GAN aims to learn automatic parsing
of anatomical objects in X-ray images from labeled 3D CT
scans by using synthetic labeled DRRs. The pixel-level annotations of anatomical objects are obtained by projecting 3D
CT labels along the same trajectories used in the synthesis
of DRRs. TD-GAN adopts the CycleGAN architecture to
perform unpaired image-to-image translation and unsupervised domain adaptation to enable the segmentation models
trained on DRRs to generalize to real X-ray images. Similar strategy is also used by X2CT-GAN [27] to reduce the
gap between synthetic DRRs and real X-ray images. Unlike
TD-GAN and X2CT-GAN, DeepDRR attempts to produce
more realistic radiographs and fluoroscopy from 3D CT scans
to enable machine learning models trained directly on DeepDRRs to generalize to clinical data without the need for
domain adaptation. DeepDRR has been used in anatomical
landmark detection in pelvic X-ray and to simulate X-rays
of the femur during insertion of dexterous manipulators in
orthopedic surgery. Both TD-GAN and DeepDRR care more
about the anatomical structures than the lesion regions. Given
a CT with COVID-19 infection, the existing DRR generators
may produce a DRR with no findings due to the heterogeneity of DRRs. It is tough to keep the consistency between
standard DRRs and annotation masks of lesion regions by
using existing DRR generators. Therefore, we design a new
infection-aware DRR generator to solve this problem through
a category-weighted projection and RPL threshold method.
B. DOMAIN ADAPTATION
Domain adaptation aims at rectifying the distribution discrepancy between the training samples (source domain) and test
samples (target domain) [28] and tuning the model toward
better generalization onto the target domain in a supervised or
unsupervised manner. Numerous domain adaptation methods
have been proposed based on deep models recently as deep
networks can learn more transferable features for domain
adaptation and achieve better performance [29]–[31]. The
main insight behind these approaches is to extract domaininvariant representations by embedding domain adaptation
modules in the pipeline of deep learning [28], [32]–[38].
Existing deep domain adaptation methods align the distributions of source domain and target domain mainly from
three perspectives. The first stream is image alignment,
and image-to-image translation models are typically used
to reduce the gap between source domain images and
target domain images [8]. The second stream is feature
alignment [32]–[37], which is the mainstream approach
and aims to learn domain-invariant deep features. The
last stream is output alignment, which is often used to
learn semantic segmentation of urban scenes from synthetic data [28], [38]. Moreover, we recognize that there
are two main approaches to perform feature alignment,
including adversarial approach [34], [35], [39]–[41] and
non-adversarial approach [31], [33], [36], [42]–[44]. The
adversarial approach motivates deep models to extract
domain-invariant features through adversarial training. It is
done by training task-specific deep models to minimize the
task-specific loss and the adversarial loss simultaneously,
thereby fooling the domain discriminator to maximize the
probability of deep features from source domain being classified as target domain. The non-adversarial approach is statistic moment matching-based approach, involving maximum
mean discrepancy (MMD) [33], [42], [43], central moment
discrepancy (CMD) [44] and second-order statistics matching [36]. The statistic moment matching-based approach
encourages deep models to extract domain-invariant deep
features by minimizing the distance between the statistic
moments of deep features from source domain and from
target domain. MMD [45] is the most representative method,
and has been widely used to measure the discrepancy between
the source domain and target domain distributions [31].
Compared with the adversarial approaches, MMD-based
methods are simple, stable and are easy to implement, and thus can facilitate to verify the efficacy of
207738 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
DRR4Covid quickly. In our implementation of DRR4Covid,
we directly use an off-the-shelf MMD-based domain adaptation approach, i.e., LMMD proposed by Zhu et al. [31],
to enable the deep models trained on DRRs to generalize to
real CXRs.
C. CXR BASED SCREENING OF COVID-19 IN A VIEW
OF INFECTION SEGMENTATION
Segmentation is an essential step in automated infection
measurement and COVID-19 diagnosis, which can provide the delineation of the regions of interest (ROIs), e.g.,
infected regions, in the CXRs for further assessment and
quantification. Many approaches have been proposed for
automated COVID-19 diagnosis based on CXRs. However,
the majority of these approaches are based on classification models rather than segmentation models as reviewed
by Shen et al. in [7] due to the aforementioned reasons.
Some researchers have leveraged the interpretability of deep
classification models to highlight the infected regions rather
than accurately segmenting the infected regions. Specifically, Oh et al. [6] introduce a probabilistic Grad-CAM
saliency map to indicate the multifocal lesions within CXRs
in their local patch-based deep classification models for
COVID-19 diagnosis. Such method is derived from a famous
explanation technique, i.e., gradient weighted class activation map (Grad-CAM), and can effectively locate the
radiological signs of COVID-19 infection, such as the
multifocal ground-glass opacification and consolidations.
Similarly, Karim et al. [46] use a revised Grad-CAM,
i.e., Grad-CAM++, and layer-wise relevance propagation
(LRP) [47] in classifying CXRs as Normal, Pneumonia and
COVID-19 to indicate the class-discriminating regions in
CXRs. Besides, Tabik et al. [48] adopt multiple explanation
techniques, including occlusion [49], saliency [50], input X
gradient [51], guided backpropagation [52], integrated gradients [53], and DeepLIFT [54], to investigate the interpretability of deep classification models and highlight the relevant
infected regions of pneumonia and COVID-19 separately.
To sum up, these approaches based on explanation techniques
are mainly used for the inspection of deep models’ decision,
and may not be suitable for further assessment and quantification. In comparison, our DRR4Covid is able to train deep segmentation models for precise infection segmentation directly
without the need for the pixel-level infection annotations of
real CXRs.
III. METHODS
In this section, we describe the modular framework of proposed DRR4Covid, and analyze the critical elements in the
design of DRR4Covid, followed by an introduction of our
implementation of DRR4Covid.
A. MODULAR FRAMEWORK OF DRR4Covid
Given CT scans with voxel-level infection annotations and
unlabeled CXRs, we aim to learn deep models to perform automated COVID-19 infection segmentation on CXRs.
FIGURE 1. The modular framework of proposed DRR4Covid.
We design DRR4Covid with a modular framework as shown
in Fig. 1. DRR4Covid consists of three key components,
i.e., an infection-aware DRR generator, a deep classification
and/or segmentation model, and a domain adaptation module. The basic workflow of DRR4Covid involves generating
DRRs with pixel-level infection annotations from CT scans,
and training deep models on synthetic labeled DRRs and
unlabeled CXRs by using the domain adaptation module.
1) GENERATING LABELED DRRs
The DRR generator is responsible for synthesizing photorealistic DRRs that resemble real CXRs as much as possible and producing pixel-level infection annotations that
match the DRRs precisely by projecting 3D CT annotations
along the same trajectories used in synthesizing DRRs. Highquality labeled DRRs in the context of this article can be
defined by two conditions. One is a good consistency between
DRRs and infection annotation masks; the other one is a
good correlation between the radiological signs of COVID-19
infection in DRRs and in real CXRs. As CXRs are typically
considered less sensitive than 3D CT scans [7], it may happen
that CT examination detects an abnormality, whereas the
X-ray screening on the same patient reports no findings.
DRRs also suffer from such problem, which will lead to the
inconsistency between DRRs and infection annotation masks.
This is the first key point for designing a high-quality DRR
generator. The second key point is the correlation between the
radiological signs of COVID-19 infection in real CXRs and in
synthetic DRRs. Note that the synthetic DRRs and infection
annotation masks are used later to train deep segmentation
models. Thus, a large gap between the radiological signs of
COVID-19 infection in real CXRs and in synthetic DRRs will
make deep models trained on DRRs fail to generalize to real
CXRs even if the domain adaptation module is applied.
2) TRAINING DEEP MODELS WITH THE DOMAIN
ADAPTATION MODULE
Although synthetic DRRs are photo-realistic, there is still
a gap between DRRs and real CXRs. Thus, we introduce the domain adaptation module into the framework of
DRR4Covid. According to the quality of synthetic labeled
VOLUME 8, 2020 207739P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 2. Illustration of the synthesis of infection-aware DRRs.
DRRs, the problem of training deep models on labeled DRRs
and unlabeled CXRs for infection segmentation on CXRs by
using the domain adaptation module can be divided into two
categories. One is deep domain adaptation with fully supervised learning in the source domain (i.e., synthetic DRRs)
and unsupervised learning in the target domain (i.e., real
CXRs); the other one is deep domain adaptation with weakly
supervised learning in the source domain and unsupervised
learning in the target domain. The condition of the first
category is a good consistency between DRRs and infection
annotation masks. If such condition is not well satisfied,
the problem will be turned into the second category due to the
inaccurate synthetic infection annotations. Compared with
the second one, the first category of problem is well defined,
and has been extensively studied. In this article, we mainly
focus on solving the first category of problem. Thus, we first
implement a high-quality DRR generator, i.e., the infectionaware DRR generator.
B. INFECTION-AWARE DRR GENERATOR
We design the infection-aware DRR generator to produce
high-quality DRRs as defined in Section III-A. The standard
DRR generator takes a CT volume or an infection annotation
volume in a specific pose (position and orientation) as input
and outputs a DRR or an infection mask. In contrast, our DRR
generator takes both a CT volume and its infection annotation
volume as input and produce a labeled DRR as illustrated
in Fig. 2. A ray is casted from the X-ray source through
labeled CT volumes to the center of each pixel of DRR.
Each pixel value of DRR is obtained by calculating the classweighted RPL [20], i.e., the class-weighted summation of the
length travelled by this ray within each voxel, multiplied by
the relative CT intensity of the voxel that is measured in HUs.
The calculation of the d-th pixel of DRR pd is formulated as
pd =
P
(i,j,k)∈d
l(i,j,k)ρ(i,j,k)w(i,j,k)
P
(i,j,k)∈d
w(i,j,k)/|d |
(1)
where d is the 3D index set of the voxels in the X-ray
direction, |d | is the number of voxels in d , l(i,j,k) represents the normalized length travelled by the ray within the
(i, j, k)-th voxel, ρ(i,j,k) and w(i,j,k) denote the CT value and
the weight of the (i, j, k)-th voxel, respectively. The weight of
the (i, j, k)-th voxel is defined as
w(i,j,k) =



w2, if m(i,j,k) = 2
w1, elif m(i,j,k) = 1
w0, otherwise



m(i,j,k) ∈ {0, 1, 2} (2)
where m(i,j,k) ∈ {0, 1, 2} is the category of the (i, j, k)-th
voxel, 0, 1 and 2 represent the background, lungs and
COVID-19 infection respectively. Note that the infectionaware DRR generator will produce standard DRRs when
the weights of all categories are equal. On the other hand,
207740 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 3. Illustration of the framework of our FCN-based network equipped with a MMD-based domain adaptation
module. GAP denotes global average pooling.
the label of pd , md , is computed as
md =



2, if π
2
d > T
2
1, elif π
2
d ≤ T
2 and π
1
d > T
1
0, otherwise
(3)
where π
c
d
denotes the contribution rate of the voxels of category c in calculating pd , and T
c
represents the contribution
threshold of category c. Specifically, π
c
d
is defined as
π
c
d =
P
(i,j,k)∈c
d
l(i,j,k)w(i,j,k)
P
(i,j,k)∈d
l(i,j,k)w(i,j,k)




c ∈ {0, 1, 2} (4)
where c
d
denotes the 3D index set of the voxels of category
c in the X-ray direction.
The strength of the radiological signs of COVID-19 infection in CXRs and DRRs depends on the contribution rate
of infected voxels (CRIV) due to the projective nature of
X-ray imaging. A higher value of CRIV represents a larger
number of infected voxels appear in the X-ray direction, and
the radiological signs of COVID-19 infection, e.g., GGOs,
will be more significant. Such property of X-ray imaging
can be well modeled in ‘‘1’’ and ‘‘4’’ by our infection-aware
DRR generator. Increasing the weight of infected voxels will
improve the value of CRIV and vice versa. Accordingly, our
infection-aware DRR generator can produce DRRs with different strengths of radiological signs of COVID-19 infection
simply by adjusting the weight of infected voxel. The synthetic pixel-level annotations of COVID-19 infection are
also computed based on the CRIV. Therefore, our infectionaware DRR generator can maintain the consistency between
synthetic DRRs and infection annotation masks easily by
increasing the weight of infected voxels when the value of
CRIV is too small. To sum up, our infection-aware DRR
generator has the following advantages:
1) By setting the weight of infected voxels to a very small
value, our infection-aware DRR generator is able to
produce DRRs with no findings, which are essential
for training deep classification models for COVID-19
diagnosis;
2) By setting the weight of infected voxels to a relatively
large value, our infection-aware DRR generator can
generate high-quality DRRs with pixel-level annotations of infected regions, which are essential for training deep segmentation models for precise COVID-19
infection segmentation;
3) By adjusting the weight of infected voxels from small
values to large values, our infection-aware DRR generator will synthesize a serial of labeled DRRs with different strengths of the radiological signs of COVID-19
infection. Such DRRs might be able to be used to estimate the detection limit of X-ray imaging in detecting
COVID-19 infection.
VOLUME 8, 2020 207741P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
C. FCN-BASED NETWORK EQUIPPED WITH A
MMD-BASED DOMAIN ADAPTATION MODULE
1) NETWORK ARCHITECTURES
We design a FCN-based network as depicted in Fig. 3. It consists of a backbone network, a classification header and a segmentation header. Compared with FCN [16], our model has
an auxiliary classification header. The classification header
is designed for two purposes. One is to enable our model
to perform both classification task and segmentation task for
automated infection measurement and COVID-19 diagnosis.
The other one is to facilitate the use of MMD-based methods
for domain adaptation. The backbone network is responsible
for extracting deep features by performing the convolution
and spatial pooling operations on DRRs and CXRs. The
extracted deep features are then fed into the classification
header and segmentation header separately. In the classification branch, we adopt a very simple structure with a global
average pooling (GAP) layer and a fully convolution (FC)
layer. In the segmentation branch, we use two convolutional
layers followed by an up-sampling layer to generate the segmentation output with the same size as the input DRRs and
CXRs.
2) MMD-BASED DOMAIN ADAPTATION MODULE
As a nonparametric distance estimate between two distributions, MMD [45] has been widely used in domain adaptation
algorithms to measure the discrepancy between the source
and target distributions. In our implementation, we adopt
an off-the-shelf MMD-based domain adaptation approach,
i.e., LMMD loss proposed by Zhu et al. [31]. LMMD can
measure the discrepancy of local distributions by taking the
correlations of the relevant subdomains into consideration.
By minimizing the LMMD loss during the training of deep
models, the distributions of relevant subdomains within the
same category in the source domain and target domain are
drawn close. As the LMMD method is proposed in the context
of object recognition and digit classification tasks, we apply
it to the classification header directly by aligning the deep
features from the GAP layer. The effect of feature alignment
can be propagated to the segmentation branch implicitly
through the input of the GAP layer. The experiment results
have verified the efficacy of our design, which will be detailed
in Section IV-D.
3) OBJECTIVE FUNCTION
The training of our model is performed by minimizing the classification loss lcls, segmentation loss lseg,
and LMMD loss lmmd simultaneously. The total loss is
computed as
ltotal = λcls × lcls + λseg × lseg + λmmd × lmmd (5)
where λcls, λseg, and λmmd denote the weights of the
classification loss, segmentation loss, and LMMD loss,
respectively.
IV. EXPERIMENTS AND RESULTS
A. MATERIALS
1) CHEST CT SCANS
We use the public COVID-19-CT-Seg dataset [55], which
consists of 20 public COVID-19 CT cases with voxel-level
annotations of the left lung, right lung and COVID-19 infection. The annotations, first labeled by junior annotators, are
refined by two radiologists with 5 years of experience, and are
further verified and refined by a senior radiologist with more
than 10 years of experience in chest radiology. In these 20 CT
volumes, the voxel values of 10 volumes have been normalized to [0, 255], and thus we cannot access their CT values
measured in HUs. We discard these ten cases and use the other
10 CT cases for the synthesis of DRRs in our experiments. For
each CT case, we obtain 40 front-view DRRs and 40 lateralview DRRs with pixel-level annotations of infected regions
by using our infection-aware DRR generator, which will be
detailed in Section IV-B. Thus, we build a training set in the
source domain with these 800 DRRs as shown in Table 1.
2) CHEST X-RAY IMAGES
We use two public COVID-19 CXR collections [56], [57],
which are constructed upon Radiopaedia [58], COVID-19
image data collection [59], Chest X-Ray Images (Pneumonia) [60], SIRM [61], Twitter COVID-19 CXR dataset [62],
and Hannover Medical School dataset [63]. The first collection [56] consists of 219 COVID-19 positive images from
96 patients and 1341 normal images from 1211 patients.
The second collection contains 558 COVID-19 positive
images that are different from the 219 positive images in
the first collection. We randomly select 219 normal images
from 219 different patients in the first collection, and combine them with the 219 COVID-19 positive images in the
first collection to build a training-validation set in the target
domain. Besides, we use the 558 COVID-19 positive images
in the second collection and 558 normal images that are
randomly selected from the remaining 992 patients in the first
collection to build an independent test set in the target domain
as shown in Table 1. We perform 4-fold cross validation
(75% patients for training and 25% patients for testing) on
the training-validation set and perform independent testing
on the test set. Note that these CXRs have no pixel-level
expert annotations of infected regions. We can only use the
image tags (i.e., positive or negative) to evaluate the classification and segmentation results. Therefore, we also introduce another CXR dataset, i.e., the BIMCV COVID-19+
dataset [64], where a sub-set of 10 CXRs is annotated with
ROIs of the COVID-19 findings (e.g., consolidation/GGOs)
by a team of eight radiologists from the Hospital Universitario
de San Juan de Alicante for the first iteration. To our best
knowledge, this is the only COVID-19 CXR dataset that
provides pixel-level annotations of infected regions currently.
Although the sub-set is very small, we use it to provide
207742 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 1. The Split of Training, Validation and Test Sets.
preliminary insights into the real infection segmentation performance of our method.
B. INFECTION-AWARE DRRs
1) GENERATING NORMAL DRRs
DRRs with no findings are important for training deep classification and segmentation models for COVID-19 diagnosis.
Our infection-aware generator is able to generate such DRRs
with no findings by setting the weight of infected voxels to a
relatively small value to reduce the CRIV in the ray-casting
process. In our experiment, we empirically set the weights of
background, lung, and COVID-19 infection as w0 = 24.0,
w1 = 24.0, and w2 = 1.0. Several synthetic normal DRRs
are depicted in Fig. 4.
FIGURE 4. Illustration of normal DRRs generated by our infection-aware
DRR generator.
2) GENERATING MULTIPLE DRRs FROM A SINGLE
CT VOLUME
It is easy to generate multiple DRRs from a single CT volume
by adjusting the pose (position and orientation) of the CT
volume within a virtual imaging system. In our experiment,
we randomly shift each CT volume between −100 and 100,
and rotate it between −45◦
and 45◦
in 3D directions. Several
DRRs generated from a single CT volume are illustrated
in Fig. 5.
FIGURE 5. Illustration of multiple DRRs from a single CT volume by
adjusting the pose of this CT volume.
3) GENERATING DRRs WITH DIFFERENT STRENGTHS OF
RADIOLOGICAL SIGNS OF COVID-19 INFECTION
Our infection-aware DRR generator is able to generate DRRs
with different strengths of radiological signs of COVID-19
infection by adjusting the weights of background, lung and
COVID-19 infection (w0,w1,w2). In our experiment, we set
(w0,w1,w2) to (12.0, 12.0, 1.0), (6.0, 6.0, 1.0), (3.0, 3.0, 1.0),
(1.5, 1.5, 1.0), (1.0, 1.0, 1.0), (1.0, 1.0, 1.5), (1.0, 1.0, 3.0),
(1.0, 1.0, 6.0), and (1.0, 1.0, 12.0) separately. Several samples
are shown in the last column of Fig. 6.
4) GENERATING PIXEL-LEVEL ANNOTATIONS OF
COVID-19 INFECTION
We empirically set the contribution threshold of infected
voxels (CTIV) T
2
as 0.00, 0.01, 0.05, 0.10, 0.15, 0.20, and
0.40 respectively to get the corresponding infection annotation masks. The contribution threshold of the lungs is set
to 0.00. Several infection masks are visualized in the first five
columns of Fig. 6.
5) BUILDING TRAINING SETS IN THE SOURCE
DOMAIN (DRRs)
For each CT volume, we first generate 40 normal DRRs,
including 20 front-view DRRs and 20 lateral-view DRRs
by randomly adjusting its pose. Next, in the same way we
generate 40 DRRs and the corresponding pixel-level annotations of infected regions with given (w0,w1,w2) and T
2
.
By this means, we build a training set in the source domain
with 800 DRRs as shown in Table 1. Finally, with given the
63 different combinations of (w0,w1,w2) and T
2
, we totally
obtain 63 training sets in the source domain.
C. EXPERIMENT SETTING
1) EXPERIMENT DESIGN
This article aims at learning automated COVID-19 infection
segmentation on CXRs from DRRs. To this end, we propose DRR4Covid, which consists of an infection-aware DRR
generator, a FCN-based network and a MMD-based domain
adaptation module. To verify the efficacy of our method,
we conduct experiments from four aspects: 1) standard
DRRs versus infection-aware DRRs; 2) using domain adaptation versus not using domain adaptation; 3) estimating the
detection limit of X-ray imaging in detecting COVID-19
infection by searching for the best parameters (w0,w1,w2)
and T
2
; and 4) evaluation of segmentation performance
on 10 CXRs. Accordingly, in each fold, we first train the
FCN-based network on the 63 training sets in the source
domain without using the domain adaptation module respectively. Next, we train the same network on the 63 training
sets in the source domain and the training set in the target
domain by using the MMD-based domain adaptation module
separately. All of the trained models are finally evaluated on
the same validation set and test set. We report the results of
the 4-fold cross validation in the format of Mean ± Standard
Deviation. Note that the annotations of CXRs in the target
domain are always kept unseen in all training tasks and our
infection-aware DRR generator will produce standard DRRs
when (w0,w1,w2) equals to (1.0, 1.0, 1.0).
VOLUME 8, 2020 207743P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 6. Illustration of DRRs with different strengths of radiological signs of COVID-19 infection from a single CT volume and their
corresponding pixel-level annotations of the lungs and infected regions. The weights of background and lungs are set as 1.0, and the
contribution threshold of the lungs T
1 is set as 0.0. The red arrows in the last column highlight the infected regions.
2) TRAINING DETAILS
ResNet-18 is adopted as the backbone of the FCN-based
network in our experiments. We train the network with
100 epochs by using Adam optimizer with the parameters
of β1 = 0.9 and β2 = 0.999. We adopt mini-batch of 16,
and use an initial learning rate of 0.0001 that is linearly
decayed by 2% each epoch after 50 epochs. We initialize
the backbone network with the weights of ResNet-18 that
are pre-trained on ImageNet. Data augmentation, involving
random cropping, horizontal flipping, vertical flipping and
random rotating, are performed. The input image size of our
network is 256 × 256 × 3. Besides, the category-weighted
cross entropy loss is adopted as the segmentation loss to
emphasize the optimization of COVID-19 infection segmentation, where the weights of background, lung and COVID-19
infection are set to 0.1, 1.0 and 5.0. Binary cross entropy
loss is used as the classification loss. The weights of the
classification loss, segmentation loss and LMMD loss are set
as λcls = 1.0, λseg = 1.0, and λmmd = 0.3 respectively.
We use the PyTorch1.4 framework to build the deep models.
The infection-aware DRR generator is designed by using
CUDA10.2, Python3.6, and Cython. All models are trained
and evaluated on a Linux server equipped with four NVIDIA
GTX1080ti GPU cards.
3) EVALUATION METRICS
For the classification output of our model, we adopt the
commonly used classification metrics, including accuracy,
F1-score and area under precision-recall curve (AUC of
PR-curve). As the pixel-level annotations of infected regions
are not available for the validation and test sets in the target
domain (CXRs), we are unable to use the segmentation evaluation metrics directly. To enable evaluate the quality of segmentation output of our model, we convert the segmentation
output into classification output by determining whether there
exists infected regions in the segmentation output, and then
adopt the same three classification metrics. As for the sub-set
of 10 CXRs in the BIMCV COVID-19+ dataset, we directly
207744 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
adopt the commonly used segmentation metric, i.e., Dice
similarity coefficient (DSC), to evaluate the segmentation
results.
4) STATISTICAL ANALYSIS
Statistical tests are conducted to determine the significance in
performance differences of learning infection segmentation
from DRRs between standard DRRs and our infection-aware
DRRs and between using our domain adaptation module and
not using domain adaptation. According to the experiment
design, we perform paired samples t-test to compare the
means of scores. Specifically, we remove the outliers of
the scores and apply Shaprio-Wilk test for normality. If the
variables violate the assumption of normality, we perform
Wilcoxon signed-rank test instead of paired samples t-test.
The SciPy package is used in these analyses.
D. EXPERIMENT RESULTS
We report the evaluation results of our model trained on the
63 training sets with/without MMD-based domain adaptation
module in Table 4-27 of the appendix. We will analyze these
results from the four perspectives as introduced in the experiment design.
FIGURE 7. Comparison of standard DRRs, infection-aware DRRs, and real
CXRs. The first column represents the infection masks that are generated
with the contribution threshold T
1 = T
2 = 0.00. We use such infection
masks to indicate the infected pixels of DRRs whose corresponding X-rays
pass through the infected voxels of CT volume.
1) STANDARD DRRs VERSUS INFECTION-AWARE DRRs
Firstly, we do qualitative comparison in Fig. 7. As can be
seen, many infected pixels in standard DRRs indicated by
infection masks present no-findings due to the low contribution rate of infected voxels in the X-ray casting. This observation is consistent with the heterogeneous nature of X-ray
imaging, and implicates that X-ray imaging has a lower sensitivity than CT imaging. We notice that the radiological signs
of COVID-19 infection in standard DRRs are indistinctive.
The strength of radiological signs of COVID-19 infection
in standard DRRs depends on the severity of COVID-19
infection. Such property makes it hard to leverage the publicly
available CT volumes, because there is no guarantee that a
positive CT scan will yield positive DRRs. In contrast, our
infection-aware DRR generator is able to produce DRRs with
different strengths of radiological signs of COVID-19 infection simply by adjusting the weight of infected voxels w2.
For instance, a CT case with mild COVID-19 infection can
yield DRRs with significant radiological signs of COVID-19
infection; whereas a CT case with severe COVID-19 infection
can yield normal DRRs. Seen from the last column in Fig. 6,
the radiological signs of COVID-19 infection become more
significant gradually as the weight of infected voxels w2
increases. Such ability of our infection-aware DRR generator
promotes to take full advantages of the publicly available
CT volumes and determine the precise infection annotation
masks for training infection segmentation models. Note that
visual findings of COVID-19 infection in DRRs will be unrealistic when the value of w2 is too large, e.g., w2 = 12.0,
which may break the correlation between real CXRs and
synthetic DRRs.
Secondly, we analyze the classification and segmentation
results on the validation and test sets without using domain
adaptation in Table 16-27 of the appendix. To avoid the
influence of the subjective choice of contribution threshold,
we average the performance scores on CTIV, and compare
the average scores of standard DRRs and infection-aware
DRRs visually in Fig. 8 and Fig. 9. Our infection-aware
DRRs achieve significantly higher average scores on both
validation and test sets in the target domain than the standard
DRRs. Such results indicate that the gap between infectionaware DRRs (e.g., w2 = 3.0) and real CXRs is smaller
than the gap between standard DRRs (w2 = 1.0) and real
CXRs, and thus verify the efficacy of our infection-aware
DRR generator without using domain adaptation.
Next, we analyze the classification and segmentation
results on the validation and test sets with using domain
adaptation in Table 4-15 of the appendix. We compare the
average results of standard DRRs and infection-aware DRRs
visually in Fig. 10 and Fig. 11. Similarly, the infection-aware
DRRs surpass the standard DRRs by a large margin on both
validation and test sets in the target domain. Such results
strongly demonstrate the effectiveness of our infection-aware
DRR generator with using the domain adaptation module.
Finally, we perform statistical tests to compare the means
of scores in Fig. 8, Fig. 9, Fig. 10 and Fig. 11 between standard DRRs and infection-aware DRRs. We observe statistical
significant difference (p < 0.05) in all of these 96 comparison
items, which indicates our infection-aware DRRs are significantly better than the standard DRRs in learning automated
COVID-19 infection segmentation on CXRs from DRRs.
2) DOMAIN ADAPTATION VERSUS NO
DOMAIN ADAPTATION
In order to highlight the efficacy of our domain adaptation
module, we compare the average scores of domain adaptation
and no domain adaptation on the validation and test sets
in Fig. 12 and Fig. 13. This intuitive comparison shows that
the using of our domain adaptation module can improve
the classification and segmentation scores of infection-aware
DRRs significantly and consistently, which verifies the efficacy of our domain adaptation module. Besides, seen from
Fig. 8 and Fig. 9, we notice that the average scores of
infection-aware DRRs increase first and then decrease as the
VOLUME 8, 2020 207745P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 8. Comparison of average scores on the validation set in the target domain (no domain adaptation). CLS denotes classification results, SEG
denotes segmentation results, and w represents the weight of infected voxels w2
. The scores are averaged on CTIV
(T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
FIGURE 9. Comparison of average scores on the test set in the target domain (no domain adaptation). CLS denotes classification results, SEG denotes
segmentation results, and w represents the weight of infected voxels w2
. The scores are averaged on CTIV (T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
FIGURE 10. Comparison of average scores on the validation set in the target domain (domain adaptation). CLS denotes classification results, SEG denotes
segmentation results, and w represents the weight of infected voxels w2
. The scores are averaged on CTIV (T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
FIGURE 11. Comparison of average scores on the test set in the target domain (domain adaptation). CLS denotes classification results, SEG denotes
segmentation results, and w represents the weight of infected voxels w2
. The scores are averaged on CTIV (T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
weight of infected voxels w2 increases from 1.0 to 3.0 and
then to 12.0. The peak of average scores of infection-aware
DRRs appears at w2 = 3.0. It suggests that an excessively large weight of infected voxels may make the infected
regions in DRRs unrealistic, thus leading to a decrease in
performance scores without using domain adaptation module.
In contrast, there is no significant decrease in the average
scores of infection-aware DRRs with using our domain adaptation module as shown in Fig. 10 and Fig. 11 when the
weight of infected voxels w2 increases from 3.0 to 6.0 and
207746 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 12. Comparison of average scores on the validation set with domain adaptation and without domain adaptation. The scores are averaged on CTIV
(T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
FIGURE 13. Comparison of average scores on the test set with domain adaptation and without domain adaptation. The scores are averaged on CTIV
(T
2 = 0.40, 0.20, 0.15, 0.10, 0.05, 0.01, 0.00).
then to 12.0. It implies that the domain adaptation module
still works well even when infected regions in DRRs become
slightly unrealistic. On the other hand, we observe that the
segmentation scores are relatively lower than the classification scores when the domain adaptation module is not
applied. For instance, in the case of infection-aware DRRs
with w2 = 3.0, the average segmentation scores on the test
set in the target domain, including the accuracy, AUC and
F1-score, are 0.581, 0.889, and 0.694 respectively, whereas
the corresponding classification scores are 0.869, 0.934, and
0.874. Such results implicate that the segmentation header
is much more sensitive to the domain discrepancy between
VOLUME 8, 2020 207747P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
DRRs and real CXRs than the classification header. By using
the domain adaptation module, both the segmentation scores
and classification scores are greatly improved; specifically,
the improvement in segmentation scores is much more significant than the improvement in classification scores. For
instance, in the case of infection-aware DRRs with w2 = 3.0,
the average segmentation scores on the test set are 0.925
(+0.344↑), 0.969 (+0.080↑), and 0.917 (+0.223↑) respectively, whereas the corresponding classification scores are
0.948 (+0.079↑), 0.987 (+0.053↑), and 0.947 (+0.073↑).
Such results indicate that our domain adaptation module
works well not only for classification task but also for segmentation task, thus confirming our claim that the effect of
feature alignment applied in the classification branch can be
propagated to the segmentation branch implicitly. Finally,
we perform statistical tests to compare the means of scores
in Fig. 12 and Fig. 13 between using our domain adaptation module and not using domain adaptation. We observe
statistical significant difference (p < 0.05) in all of these
60 comparison items except for 4 items, i.e., standard DRR’s
classification AUC on the validation set and standard DRRs’
classification AUC, segmentation accuracy and segmentation
F1-score on the test set. It indicates our domain adaptation
module is able to improve the performance of learning infection segmentation on CXRs from DRRs significantly and thus
confirms the efficacy of our domain adaptation module.
3) VISUALIZING THE COVID-19 INFECTION
SEGMENTATION RESULTS
We specifically use the case of infection-aware DRRs with
w2 = 3.0 and T
2 = 0.20 as an example to show the
COVID-19 infection segmentation results. The segmentation
scores, including accuracy, AUC, and F1-score, on the validation and test sets are (0.919, 0.977, 0.910) and (0.956,
0.980, 0.959) respectively as listed in Table 7, 8, 9, 13, 14,
and 15 of the appendix. Next, we visualize the infection segmentation results from the first fold. The confusion matrices
of the segmentation results on the corresponding validation
and test sets are shown in Fig. 14. We visualize several true
positive and true negative cases in Fig. 15. Compared with
previous studies that highlight the infected regions roughly by
leveraging the interpretability of deep classification models,
our segmentation model trained on the infection-aware DRRs
is able to segment the infected regions in CXRs directly and
accurately. Besides, we present several failure (false positive
and false negative) cases in Fig. 16.
4) ESTIMATING THE DETECTION LIMIT OF X-RAY IMAGING
IN DETECTING COVID-19 INFECTION
As mentioned earlier, CXRs are generally considered less
sensitive than 3D CT scans [7]. It may happen that CT examination detects an abnormality, whereas the X-ray screening
on the same patient reports no findings. The significance
level of radiological signs of COVID-19 infection in Xray images depends on the severity of COVID-19 infection,
which is typically assessed by the percent volume of the
FIGURE 14. Confusion matrices of segmentation results on the validation
and test sets in the case of infection-aware DRRs with w2 = 3.0 and
T
2 = 0.20.
FIGURE 15. COVID-19 infection segmentation results of the
infection-aware DRRs with w2 = 3.0 and T
2 = 0.20 on the validation and
test sets in target domain. The red overlay is used to indicate the infected
regions.
lung that is infected by COVID-19 (PIV for short). Only
when the PIV reaches a certain level (i.e., detection limit),
X-ray imaging can effectively detect COVID-19 infection.
Therefore, we propose to leverage our infection-aware DRR
generator by searching the best parameters (w0,w1,w2) and
T
2
to estimate such detection limit. The insight behind this
207748 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 2. Total average (T-Avg.) Scores (Mean ± Standard Deviation) of our Model Trained on 63 Different Training Sets in the Source Domain. Each Item
in This Table is the Average of the Corresponding Items in Table 4-27 of the Appendix. EAPIV Denotes the Equivalent Average Percent Infection Volume of
the Lungs of the 10 CT Cases That are Used for the Synthesis of Infection-Aware DRRs.
TABLE 3. DSC (Mean ± Standard Deviation) Table of Segmentation Results on the sub-set of 10 CXRs.
TABLE 4. Accuracy (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (Domain Adaptation).
TABLE 5. AUC (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (Domain Adaptation).
TABLE 6. F1-score (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (Domain Adaptation).
estimation method is that the DRRs, generated by using the
best parameters, have the smallest gap with real positive
X-ray images, and thus will achieve the highest classification and segmentation scores no matter whether the domain
adaptation module is appied or not. Accordingly, we average
the corresponding items in Table 4-27 of the appendix to
obtain the total average (T-Avg.) scores of 63 training sets
to search for the best parameters. Meanwhile, we compute
VOLUME 8, 2020 207749P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 7. Accuracy (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (Domain Adaptation).
TABLE 8. AUC (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (Domain Adaptation).
TABLE 9. F1-Score (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (Domain Adaptation).
TABLE 10. Accuracy (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (Domain Adaptation).
TABLE 11. AUC (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (Domain Adaptation).
the equivalent average PIV (EAPIV) of the 10 CT cases that
are used to generate infection-aware DRRs. As can be seen
from Table 2, the peak of T-Avg. scores at each row in Table 2
appears consistently at w2 = 3.0, and the corresponding
EAPIV is 19.43% ± 16.29% (Mean ± Standard Deviation).
When the EAPIV is less than 19.43% (w2 = 3.0), e.g.,
11.77% (w2 = 1.5) and 8.51% (w2 = 1.0), the corresponding
T-Avg. scores drop below 81.0% no matter what the contribution threshold of infected voxels (CTIV) T
2
is. Such
results imply that DRRs generated from a CT case whose
PIV is less than 19.43% cannot be easily distinguished from
normal DRRs. Therefore, we conclude that the detection limit
207750 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 12. F1-Score (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (Domain Adaptation).
TABLE 13. Accuracy (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (Domain Adaptation).
TABLE 14. AUC (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (Domain Adaptation).
TABLE 15. F1-Score (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (Domain Adaptation).
FIGURE 16. Failure cases of the segmentation results of the
infection-aware DRRs with w2 = 3.0 and T
2 = 0.20 on the validation and
test sets. The red overlay is used to indicate the infected regions.
of X-ray imaging, measured by the percent volume of the
lung that is infected by COVID-19, is 19.43% ± 16.29%.
Moreover, to examine the function of CTIV, we plot the histograms of the CRIV of the pixels in infection-aware DRRs
in Fig. 17. Note that only the pixels whose corresponding
X-rays pass through the infected voxels of CT volume are
counted. These histograms show the effectiveness of our
infection-aware DRR generator in changing the distribution
of CRIV of the pixels in infection-aware DRRs. For the best
parameters w0,1 = 1.0 and w3 = 3.0 (the 8-th column
of Table 2 ), the peak of T-Avg. scores (87.9%) appears at
T
2 = 0.20. Increasing the CTIV T
2
from 0.2 to 0.4 makes a
large numberof pixels (more than 600,000) whose CRIVs are
between 0.2 and 0.4 be treated as negative pixels, thus leading
to a significant drop in T-Avg. score (-6.9%↓). Meanwhile,
decreasing the CTIV T
2
from 0.2 to 0.15 makes the pixels
(less than 200,000) whose CRIVs are between 0.15 and 0.2
be treated as positive pixels, thus leading to a minor drop
in T-Avg. score (-0.9%↓). Therefore, we conclude that the
estimated lower bound of CRIV for significant radiological
VOLUME 8, 2020 207751P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
FIGURE 17. Histograms of infected voxel contribution rates of the pixels in infection-aware DRRs.
TABLE 16. Accuracy (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (No Domain Adaptation).
TABLE 17. AUC (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (No Domain Adaptation).
TABLE 18. F1-Score (Mean ± Standard Deviation) Table of Classification Output on Validation Set in the Target Domain (No Domain Adaptation).
signs of COVID-19 infection in DRRs is 20.0%. It means
that the pixels whose CRIVs are lower than 20.0% cannot be easily distinguished from the pixels of the lungs
in CXRs.
5) EVALUATION OF SEGMENTATION PERFORMANCE
ON 10 CXRs
We simply use the 4-fold cross validation models trained by
using our domain adaptation module to segment the 10 CXRs.
207752 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 19. Accuracy (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (No Domain Adaptation).
TABLE 20. AUC (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (No Domain Adaptation).
TABLE 21. F1-Score (Mean ± Standard Deviation) Table of Segmentation Output on Validation Set in the Target Domain (No Domain Adaptation).
TABLE 22. Accuracy (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (No Domain Adaptation).
TABLE 23. AUC (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (No Domain Adaptation).
The average DSC scores of these segmentation results are
reported in Table 3. As can be seen, our infection-aware
DRRs (w2 = 3.0 or w2 = 6.0) have achieved an average DSC score of ∼40%, which are much better (>20%)
than the standard DRRs. Besides, we also observe the same
pattern as in Table 2: the peak of average DSC scores of
our infection-aware DRRs appears at w2 = 3.0. It provides
more evidence for confirming the validity of the estimated
detection limit of X-ray imaging in detecting COVID-19
infection.
VOLUME 8, 2020 207753P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 24. F1-Score (Mean ± Standard Deviation) Table of Classification Output on Test Set in the Target Domain (No Domain Adaptation).
TABLE 25. Accuracy (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (No Domain Adaptation).
TABLE 26. AUC (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (No Domain Adaptation).
V. LIMITATIONS OF THE STUDY
This study still has a variety of limitations. Firstly, the synthetic annotation masks of infected regions for DRRs are
only investigated experimentally, and are not evaluated by
the radiologists. The expert annotations of infected regions
for DRRs may provide evidence to determine more accurate
contribution threshold of infected voxels. Secondly, this study
uses publicly available CT and CXR datasets from various
sources. The variability in expert annotations of CT scans and
CXRs is not assessed, which may introduce implicit biases
to the training and evaluation. Thirdly, the evaluation for
the segmentation performance of our method in this study
is incomprehensive due to the lack of sufficient CXRs with
pixel-level annotations of infected regions. The evaluation
results on ten CXRs may be biased and unable to give guidance to optimize our method. A comparison between learning
infection segmentation from CXRs straightway and learning
from DRRs may provide key insights on how to realize
high-quality automated COVID-19 infection segmentation on
CXRs efficiently. Lastly, this study uses only ten COVID-19
positive CT cases for synthesizing DRRs. The performance
of our DRR4Covid and the validity of the estimated detection
limit of X-ray imaging in detecting COVID-19 infection can
be improved by involving more CT scans from patients in
various stages of COVID-19 infection. Nevertheless, the findings of this article provide promising results that encourage
the use of DRR4Covid for learning automated COVID-19
infection segmentation on CXRs from DRRs without the need
for any expert annotations of CXRs.
VI. CONCLUSION
We propose a novel approach, called DRR4Covid, to learn
automated COVID-19 infection segmentation on CXRs from
DRRs. DRR4Covid consists of three key components, including an infection-aware DRR generator, a classification and
segmentation network, and a domain adaptation module. The
infection-aware DRR generator is able to produce DRRs
with adjustable strength of radiological signs of COVID-19
infection, and generate pixel-level infection annotations that
match the DRRs precisely, thus enabling deep segmentation
networks to be trained directly for automated infection segmentation. The domain adaptation module is introduced to
reduce the domain discrepancy between DRRs and CXRs by
training networks on unlabeled real CXRs and labeled DRRs
together. We provide a simple but effective implementation of
DRR4Covid by using a domain adaptation module based on
Maximum Mean Discrepancy (MMD), and a FCN-based network with a classification header and a segmentation header.
Extensive experiment results have confirmed the efficacy
of our method; specifically, without using any annotations
of real CXRs, our network has achieved a classification
score of (Accuracy: 0.949, AUC: 0.987, F1-score: 0.947)
207754 VOLUME 8, 2020P. Zhang et al.: Drr4covid: Learning Automated COVID-19 Infection Segmentation From Digitally Reconstructed Radiographs
TABLE 27. F1-Score (Mean ± Standard Deviation) Table of Segmentation Output on Test Set in the Target Domain (No Domain Adaptation).
and a segmentation score of (Accuracy: 0.956, AUC: 0.980,
F1-score: 0.955) on a test set with 558 normal cases and
558 positive cases. Besides, we estimate the detection limit of
X-ray imaging in detecting COVID-19 infection by adjusting
the strength of radiological signs of COVID-19 infection in
synthetic DRRs. The estimated detection limit, measured by
the percent volume of the lung that is infected by COVID-19,
is 19.43% ± 16.29%, and the estimated lower bound of the
contribution rate of infected voxels is 20.0% for significant
radiological signs of COVID-19 infection.
To our best knowledge, this is the first attempt to realize the
automated COVID-19 infection segmentation base on CXRs
by using the labeled DRRs that are generated from Chest
CT scans. Future work can be carried out by extending the
DRR4Covid to DRR4Lesion to enable multiple lung lesion
segmentation on CXRs.
APPENDIX
MORE EXPERIMENTAL RESULTS
See Tables 4–27.
ACKNOWLEDGMENT
The authors would like to thank providers of Radiopaedia,
COVID-19 Image Data Collection, Chest X-Ray Images
(pneumonia), SIRM, Twitter COVID- 19 CXR dataset, and
Hannover Medical School dataset.



NEW_PAPER



SPECIAL SECTION ON DEEP LEARNING
ALGORITHMS FOR INTERNET OF MEDICAL THINGS
Received April 21, 2020, accepted April 27, 2020, date of publication May 4, 2020, date of current version May 26, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2992341
A Comprehensive Review of the
COVID-19 Pandemic and the Role of IoT,
Drones, AI, Blockchain, and 5G in
Managing Its Impact
VINAY CHAMOLA 1
, VIKAS HASSIJA 2
, VATSAL GUPTA 2
,
AND MOHSEN GUIZANI 3
, (Fellow, IEEE)
1Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS), Pilani 333031, India
2Department of CSE and IT, Jaypee Institute of Information Technology, Noida 201309, India
3Department of Computer Science and Engineering, Qatar University, Doha, Qatar
Corresponding author: Mohsen Guizani (mguizani@ieee.org)
This work was supported by the Qatar National Research Fund (a member of the Qatar Foundation) under Grant NPRP10-1205-160012.
ABSTRACT The unprecedented outbreak of the 2019 novel coronavirus, termed as COVID-19 by the World
Health Organization (WHO), has placed numerous governments around the world in a precarious position.
The impact of the COVID-19 outbreak, earlier witnessed by the citizens of China alone, has now become
a matter of grave concern for virtually every country in the world. The scarcity of resources to endure the
COVID-19 outbreak combined with the fear of overburdened healthcare systems has forced a majority of
these countries into a state of partial or complete lockdown. The number of laboratory-confirmed coronavirus
cases has been increasing at an alarming rate throughout the world, with reportedly more than 3 million
confirmed cases as of 30 April 2020. Adding to these woes, numerous false reports, misinformation, and
unsolicited fears in regards to coronavirus, are being circulated regularly since the outbreak of the COVID19. In response to such acts, we draw on various reliable sources to present a detailed review of all the major
aspects associated with the COVID-19 pandemic. In addition to the direct health implications associated
with the outbreak of COVID-19, this study highlights its impact on the global economy. In drawing things
to a close, we explore the use of technologies such as the Internet of Things (IoT), Unmanned Aerial
Vehicles (UAVs), blockchain, Artificial Intelligence (AI), and 5G, among others, to help mitigate the impact
of COVID-19 outbreak.
INDEX TERMS Coronavirus, COVID-19, pandemic, transmission stages, global economic impact, UAVs
for disaster management, Blockchain, IoMT applications, IoT, AI, 5G.
I. INTRODUCTION
The COVID-19, an acronym for ‘‘Coronavirus Disease2019’’, is a respiratory illness caused by the severe acute
respiratory syndrome coronavirus-2 (SARS-CoV-2), a contagious virus belonging to a family of single-stranded,
positive-sense RNA viruses known as coronaviridae. Much
like the influenza virus, SARS-CoV-2 attacks the respiratory
system and causes ailments such as cough, fever, fatigue,
and breathlessness. While the exact source of the virus is
unknown, scientists have mapped the genome sequence of the
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque .
SARS-CoV-2 and determined it to be a member of the β-CoV
genera of the coronavirus family, which typically derives its
gene sources from bats and rodents [1]. The COVID-19 was
first reported to affect human life in Wuhan City, in the
Hubei province of China in December 2019. Since then, the
COVID-19 has spread like wildfire throughout the rest of the
world, marking its presence in 213 countries and independent
territories. COVID-19 statistics for the worst affected countries and regions of the world have been presented in Fig. 1.
According to the WHO, the current global tally1 of confirmed
coronavirus cases stands at 3,090,445 while the death toll
1
as of 30 April 2020
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 90225V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 1. Statistics in regards to the COVID-19 (Data Source: WHO Situation Report - 30 April 2020 [3]).
has reached 217,769 [2]. The rapid rise in the number of
COVID-19 incidents worldwide has prompted the need for
immediate countermeasures to curb the catastrophic effects of
the COVID-19 outbreak. To this end, this paper evaluates the
use of varied technologies such as IoT, UAVs, AI, blockchain,
and 5G, which could help mitigate the adverse effects of this
pandemic and expedite the recovery process. However, before
exploring the potential technological solutions for COVID-19
pandemic impact management, we provide a comprehensive
review of the COVID-19, including its clinical features, diagnosis, treatment, and the impact of its outbreak on the global
economy.
A. BACKGROUND
According to the WHO, viral infections, particularly the
ones caused by different coronaviruses, continue to emerge
and pose a severe public health problem [1]. Coronaviruses
are spherical positive-sense RNA viruses ranging from
600Å - 1400Å in diameter [4], with proteins known as spikes
protruding from its surface, which impart a crown-like structure to them under the electron microscope. The past two
decades have witnessed the emergence of several viral outbreaks with different forms of coronavirus at the helm,
such as the 2002-2004 SARS-CoV outbreak [5], and the
more recent middle east respiratory syndrome coronavirus
(MERS-CoV) infection of 2012. The SARS-CoV outbreak
originated in the Guandong province of China and later
spread to more than 37 countries worldwide, causing over
8000 infections and around 774 deaths [6]. The first case of
MERS-CoV infection was detected in Saudi Arabia, which
initiated a large-scale outbreak in the middle eastern countries
that ultimately led to 871 fatalities [7], [8].
The COVID-19 outbreak came to light on 31 December 2019 when 27 cases of pneumonia of unknown etiology
were reported at the WHO’s country office in China. For the
entire timeline of events, kindly refer to Fig. 2 [9]. The epicenter of the outbreak was linked to Wuhan’s wholesale market for seafood and other exotic animals, including snakes,
bats, and marmots [10]. A new strain of a highly contagious
β-coronavirus, SARS-CoV-2, has been deemed responsible
for the rapid outbreak of COVID-19. Distinguishing characteristics of the virus include its extremely contagious nature
and relatively long (1-14 days) incubation period. During
this period, a person can be infected by the virus and not
show any symptoms at all. Therefore, people infected with
the disease may unknowingly serve as silent carriers of
the virus, contributing to a high basic reproductive number2
for the COVID-19 virus. While some studies indicate
that SARS-CoV-2 could be susceptible to heat and ultraviolet (UV) light [1], there is no specific treatment or vaccine
for the infection to date, and the management protocols for
the disease are evolving as of this writing.
2WHO defines basic reproductive number as the number of secondary
infections caused by a single infected individual
90226 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 2. A timeline of the COVID-19 pandemic.
B. CLINICAL FEATURES
COVID-19 manifests with clinical features ranging from
the asymptomatic state (no symptoms) to acute respiratory
distress syndrome (ARDS) and multiple organ dysfunction
syndrome (MODS). According to the results of a recent
study conducted by the WHO in collaboration with China,
of the 55,924 laboratory-confirmed COVID-19 cases that
were examined, a majority exhibited clinical characteristics
such as fever, dry cough, fatigue, and sputum production.
At the same time, only a handful of patients showcased
symptoms such as sore throat, headache, myalgia, and breathlessness, while symptoms such as nausea, nasal congestion, hemoptysis, diarrhea, and conjunctival congestion were
found to be very rare (refer to Table 1). While most of the
COVID-19 patients developed a mild to moderate disease,
a few patients were diagnosed with a severe (13.8%) and a
critical (6.1%) form of the same [11]. Patients with a severe
or a critical form of the disease often develop bluish lips/face
and are prone to a variety of complications, including ARDS,
acute heart injury, and secondary infection. According to
the US Centers for Disease Control and Prevention (CDC),
the individuals at the highest risk for severe illness from the
COVID-19 include older adults (people above the age of 60)
and people with existing medical conditions, such as diabetes,
hypertension, asthma, and cardiovascular disease [12].
C. TRANSMISSION MECHANISM
Although there are several studies in the direction of
COVID-19’s pathophysiological properties, its propagation
mechanism remains somewhat elusive. While the initial
COVID-19 cases were associated with the direct exposure
of individuals to infected animals, the rapid outbreak of the
disease has shifted the focus of the research to human-tohuman transmission. An analysis of around 75,465 cases of
COVID-19 in China has revealed that the COVID-19 virus is
TABLE 1. List of COVID-19 symptoms.
primarily transmitted between people from the spread of respiratory droplets through sneezing and coughing [13]. These
respiratory droplets have the potential to cover a distance
of up to 1.8 meters (6 feet). Therefore, any person in close
contact with an infected person is at risk of being exposed to
the respiratory droplets, and by extension, the virus. Although
symptomatic people have been identified to be the primary
source of SARS-CoV-2 transmission, there is also a possibility of transmission via unsymptomatic people. Direct and
indirect contact with infected surfaces has been identified as
another potential cause of COVID-19 transmission. Evidence
suggests that the virus can survive on plastic and steel surVOLUME 8, 2020 90227V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 3. Organization of this work.
faces for as long as three days, on copper for approximately
4 hours, and up to 24 hours on cardboard [14].
Once the virus enters into a healthy body, it passes through
the nasal passage to the mucus membranes present in the
throat and binds itself to the body’s cellular receptors. With
the help of the spikes present on its surface, the SARS-CoV-2
ruptures the cell membrane and forces the cell into making
multiple copies of itself. These newly generated copies burst
out of the cell and infect other cells in the body. Following
this, the virus moves down the bronchial tubes and reaches
the lungs, where it severely impairs the host’s air sacs [15].
D. ORGANIZATION
The rest of the paper is organized as follows. In section II,
we address the existing works that have reviewed the state
of the COVID-19 pandemic. In Section III, we present a
brief overview of the pandemics that have occurred in the
past century. In Section IV, we discuss the different stages of
the COVID-19 transmission, while in Section V, the global
impact of the outbreak on different sectors of the economy
has been evaluated. Section V also includes some statistics
providing valuable insights into the widescale impact of
the COVID-19 pandemic on these sectors. In Section VI,
we discuss the current methods for COVID-19 diagnosis.
Section VII examines the efforts being made by various
organizations and laboratories in the direction of COVID-19
vaccine & drug development, while Section VIII lists the
preventive measures required to safeguard oneself against the
COVID-19. In the next nine sections, we provide a comprehensive review of the use of technologies such as IoT, UAVs,
robots, smart wearables, AI, blockchain, and 5G as a means
to manage the outbreak effectively. Finally, Section XVIII
concludes the paper. The organization of the paper has also
been depicted pictorially in Fig. 3.
II. RELATED WORKS
The massive outbreak of the COVID-19 has prompted various
scientists, researchers, laboratories, and organizations around
the world to conduct large scale research to help develop vaccines and other treatment strategies. In the months following
the COVID-19 outbreak, several papers examining different
aspects of the COVID-19 have been published [16]–[22].
To determine the clinical characteristics of the COVID-19,
Dawei Wang et al. have studied 138 infected patients in
Wuhan, China [21]. The authors have taken into account
specifics such as demographics, signs & symptoms, and
medical history of all the patients to assess their cases
carefully. The authors have also presented the laboratory
findings of these patients to demonstrate the effects of the
SARS-CoV-2 virus on different vital organs of the body.
Nanshan Chen et al. studied 99 patients with the COVID-19,
49 of whom had a direct link to the Huanan seafood market in
Wuhan, known to be the COVID-19 epicenter. Their findings
of the epidemiological, clinical, and radiological characteristics of the disease have been published in [22]. In their findings, they report that among all the patients that were studied,
17% developed acute respiratory distress syndrome (ARDS),
and among them, 11% died of multiple organ dysfunction
syndrome (MODS).
90228 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 2. Major viral diseases (1915 - present).
Fang Jiang et al. have reviewed six published studies recognizing the clinical characteristics of the COVID-19. In their
work, they have summarized these studies and, in doing so,
provided a brief overview of clinical features and treatments
of the COVID-19 [23]. The authors of [24] have reviewed the
existing literature on computed tomography (CT) characteristics of COVID-19 available on platforms such as PubMed,
Google Scholar, and Elsevier, among others. The primary
issue with both these works is that they review a small subset
of a much broader subject. To this end, the authors of [4]
and [10] provide a brief overview of the COVID-19 outbreak
in terms of its clinical features, prevention, diagnosis, and
treatment. Although these surveys shed some light on the
current scenario of the COVID-19 outbreak, they give a very
brief and limited idea about the exact situation.
Despite the abundance of research in the domain of
COVID-19 characteristic analysis and vaccine development,
to the best of our knowledge, at the time of this writing, there
is no survey that provides a comprehensive review of the
COVID-19 outbreak and its potential implications. Furthermore, no work in the existing literature attempts to review
the role of emerging technologies such as IoT, UAVs, AI,
blockchain, and 5G in managing the COVID-19 pandemic.
This presents the need for a detailed survey that provides
both the horizontal and the vertical view of the COVID-19 in
terms of its clinical features, diagnosis, treatment, prevention
strategies, and the technological solutions being adopted to
alleviate the impact of its outbreak. In this work, we present a
comprehensive review of the COVID-19 pandemic that will
help readers gain a deeper understanding of the current global
situation due to the COVID-19 pandemic. Before divulging
into a thorough analysis of the COVID-19 pandemic, we take
a brief look at some of the past pandemics in the section
below.
III. PANDEMICS IN THE PAST CENTURY
The last century has seen a plethora of outbreaks and
epidemics. While coronaviruses such as SARS-CoV &
MERS-CoV have been responsible for a majority of these
outbreaks (refer to Table 2), different types of influenza
viruses, such as H1N1, H2N2, and H3N2, have been at the
helm of all the four pandemics in the past 105 years. The
H1N1 virus alone has been responsible for two pandemics -
1) the Spanish Flu of 1918-1919 and the 2) Swine flu
in 2009-2010, while the H2N2 and H3N2 influenza viruses
have been responsible for the Asian Flu of 1957-1958, and
the Hong Kong flu of 1968-1969, respectively. In this section,
we provide an overview of all these pandemics.
A. SPANISH FLU PANDEMIC (1918-1919)
The Spanish Flu is known by many to be the deadliest pandemic in the history of humankind, with the total number of
fatalities surpassing the 50 million mark [25]. The disease
was caused by the H1N1 virus, which is believed to have
originated in birds. Unlike most diseases, Spanish Flu had
a peculiar characteristic of being extremely lethal against
the young and healthy populace. This was because the virus
attacked hosts by causing cytokine storms in the patient’s
immune system, which often lead to death [26]. Since young
people had stronger immune systems as compared to older
adults, they were more likely to be affected by the virus.
B. ASIAN FLU PANDEMIC (1957-1958)
The Asian flu pandemic began in February of 1957 in Singapore. It was the second major pandemic of the 20th century
after the Spanish Flu pandemic of 1918. It is believed to have
caused 116,000 deaths in the US and a total of 1.1 million
fatalities worldwide [27]. The virus at the root of this disease
was identified to be the type A H2N2 virus, which, like the
H1N1, is believed to be of avian origin. Eleven years after
the outbreak, the H2N2 virus subsequently mutated to a strain
that is no longer able to affect human hosts.
C. HONG KONG FLU PANDEMIC (1968-1969)
The Hong Kong Flu pandemic was the third major influenza
pandemic of the 20th century. It was caused by the
H3N2 virus, which is believed to have evolved from
the H2N2 virus that caused the Asian flu pandemic. The
H3N2 virus involved a mutated version of the HA antigen
present in H2N2 but retained the same N2 antigen. The
impact of the Hong Kong Flu pandemic across the world has
VOLUME 8, 2020 90229V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 4. Cumulative number of cases of the COVID-19 (data source: WHO situation reports, several media reports).
been described as sporadic, which is believed to have been
due to the prior immunity developed against the N2 antigen on account of the Asian Flu pandemic [26]. Unlike the
H1N1 virus behind the Spanish Flu pandemic, the H3N2 virus
was more aggressive towards people above the age of 65.
D. SWINE FLU PANDEMIC (2009-2010)
In the spring of 2009, a new strain of the type A
H1N1 influenza virus emerged, leading to the swine flu
pandemic. Like the Spanish Flu, which was caused by a
different strain of the same virus, the swine flu pandemic
was more deadly against people below 65 years of age.
Pre-acquired immunity in older people on account of previous
exposure to the H1N1 virus was believed to be one of the
reasons for the same. The US Centers for Disease Control and
Prevention (CDC) estimate that there have been more than
43.3 million cases, 195,086 hospitalizations, and 8868 deaths
in the US alone due to the virus, while the worldwide tally of
fatalities stands above 151,700 [28].
IV. DIFFERENT STAGES OF COVID-19 OUTBREAK
According to the WHO, the COVID-19 pandemic is regarded
as having four main classes of transmission that remain
consistent throughout the world to facilitate better communication and understanding amongst the countries [29].
Such a categorization makes it simpler for other countries to
enforce policies which they think would assist in preventing
the outbreak, for example, imposing travel bans, shutting
down schools & colleges, and enforcing partial or complete
lockdown. For better understanding, we have portrayed the
WHO transmission classes as different stages of the COVID19 outbreak keeping in line with several media reports. The
onset of different stages of the COVID-19 outbreak in four
countries, namely, China, Spain, Italy, and the USA, have
been mapped in Fig. 4.
A. STAGE I - IMPORTED CASES ONLY
The first stage of the COVID-19 outbreak in a particular
nation is characterized by its first reported incident of the disease, in this case, COVID-19. In this stage, the disease does
not spread locally, and the infection is usually limited to the
people with travel history to an already affected region [30].
B. STAGE II - SPORADIC CASES/LOCAL TRANSMISSION
The second stage of the COVID-19 outbreak occurs when
there are a few sporadic cases of the disease in the country.
It happens when people who are already infected with the
disease spread it to people with whom they come into contact,
usually immediate family members, friends, and colleagues.
At this stage, it is possible to perform contact tracing and
limit the spread of the disease by quarantining the infected
people.
90230 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 5. Countries in lockdown as of 19 April 2020 (data source: media reports [31]–[48]).
C. STAGE III - CLUSTERS OF CASES
The third stage of the COVID-19 outbreak in a country is
marked by the presence of several clusters of COVID-19
cases, i.e., when the disease-causing virus starts circulating
within a geographic location and infects individuals who have
neither a history of travel nor contact with someone who does.
At this stage, it becomes hard to trace the source of the virus
transmission, and geographical lockdown becomes highly
necessary to prevent the outbreak from reaching stage IV.
D. STAGE IV - COMMUNITY TRANSMISSION
The fourth stage of the COVID-19 pandemic in a country is associated with community transmission, i.e., larger
outbreaks of local transmission in a country, leading to an
extremely high number of reported incidents and deaths.
At this stage, the outbreak gets out of control, and finding
a cure or vaccine is the only way to mitigate the impact of the
disease. Countries like Iran, Turkey, Canada, and the USA are
currently in the fourth stage of the COVID-19 pandemic [29].
V. IMPACT OF THE COVID-19 PANDEMIC ON THE
GLOBAL ECONOMY
Owing to the lack of any concrete treatment strategy, social
distancing has been identified as the best possible defense
strategy against the COVID-19 pandemic at the time of this
writing. However, the need for social distancing has prompted
governments around the world to impose lockdowns (refer
to Fig. 5), which has marked a huge dent in the global
economy. All non-essential services have been forced to shut
down, causing virtually all the industrial sectors to face significant disruptions in the supply chain (refer to Table 3),
and consequently, putting billions of people at risk of losing
their jobs. Furthermore, the rapid outbreak of COVID-19 has
forced governments to restrict the trade of a majority of goods
across country borders, leaving international trade flows on
the verge of collapse. According to the projections put forth
by JPMorgan Chase & Co., the COVID-19 pandemic has
the potential to paralyze the global economy, with an estimated loss of more than 5.5 trillion US dollars in the next
18-24 months [49]. In this section, we analyze the impact
of the COVID-19 pandemic on the overall economy by thoroughly dissecting its impact on different economic sectors.
A. AUTOMOTIVE INDUSTRY
The automotive industry has seen major disruptions in production due to stringent lockdown measures enforced in several countries worldwide as an effort to contain the pandemic.
As social distancing is enforced and people are required to
stay in their homes, usage of automobiles, including both
public & private transport, has declined across the world. The
only automobiles currently in use are the vehicles associated
with essential services.
1) RELEVANT STATISTICS
• In China, the automobile industry saw an 18% drop in
sales in year-over-year (YoY) sales of January 2020.
Despite containment efforts, this number escalated to
79.1% in February 2020, which is the biggest ever
YoY drop experienced by the Chinese automotive industry [50].
• In March 2020, the YoY sales of passenger vehicles and
commercial vehicles in India saw a decline of 52% and
VOLUME 8, 2020 90231V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 3. Industries hit hardest by the COVID-19 pandemic.
89%, respectively, as dealers were forced to shut down
their showrooms following government stipulations to
limit the spread of COVID-19 [51], [52].
• According to the European Automobile Manufacturers
Association (ACEA), the combined production losses
in the European Union (EU) and the United Kingdom amount to more than 2.1 million vehicles as
of 28 April 2020. Additionally, employment of more
than 1.1 million people has been adversely affected due
to factory shutdowns [53].
• In the USA, the COVID-19 outbreak has forced a majority of automakers, including General Motors, Fiat, Ford,
and many others, to suspend their production activities [54]. According to the estimates published by the
Alliance for Automotive Innovation on 26 March 2020,
93% of all automobile production plants were forced to
close down in the USA following the COVID-19 outbreak [55].
B. AVIATION INDUSTRY
The COVID-19 pandemic has had a massive impact on the
aviation industry. Affected countries, which includes almost
all the nations, have been forced to impose travel bans on both
international and domestic passenger flights. The only active
airways include critical supply routes that support cargo and
freight aircraft.
1) RELEVANT STATISTICS
• As per a recent report published by the International
Air Transport Association (IATA), the global air travel
demand increased by just 2.4% in January 2020,
which is the lowest YoY increase registered in the last
decade [56]. The major disruption in travel demand,
however, was recorded between 24 and 30 March 2020,
when the reported number of operational flights plummeted to 280,000, a sharp decline from 780,000 flights
reported in the same period in 2019 [57].
• According to the most recent IATA estimates, the airline
industry is well on track to lose as much as 314 billion US dollars in revenues globally, following the
COVID-19 crisis [58].
• As airline services are currently stalled, the demand for
the purchase of new aircraft has also dropped. The total
number of aircraft orders has decreased from 1858 in
2018 to 235 in 2020 [59].
C. TOURISM INDUSTRY
The tourism industry has been one of the worst affected
industries following the outbreak of COVID-19. Revenues
generated from the tourism sector account for 10% of the
world’s GDP. Therefore, any adversity faced by the tourism
sector has the potential to dent the global economy severely.
1) RELEVANT STATISTICS
• According to the World Travel & Tourism Council (WTTC) estimations, the COVID-19 pandemic could
lead to a layoff of about 50 million people associated
with the tourism industry worldwide [60].
• As per the figures issued by the United Nations World
Tourism Organisation (UNWTO), international visitor
arrivals could fall by up to 30% in 2020, which corresponds to a loss of 300-450 billion US dollars in
international tourism receipts (ITRs) [61].
D. OIL INDUSTRY
The shutdown of international and domestic passenger aircraft across the world has resulted in a drastic decline in the
consumption of aviation fuel. Similarly, on the ground, all
non-essential traffic remains stalled, causing a sharp decline
in the global oil demand.
1) RELEVANT STATISTICS
• In China, the demand for crude oil has fallen by around
3 million barrels a day (which corresponds to 20% of the
total consumption) [62].
90232 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
• The Brent crude oil benchmark collapsed over 65% in
the first quarter of 2020, while the West Texas Intermediate (WTI) benchmark recorded a drop of more than 66%.
With oil prices plummeting to nearly 25 US dollars, both
these benchmarks have recorded their worst ever quarter
in history [63].
E. CONSTRUCTION INDUSTRY
Construction firms are likely to face severe disruptions and
delays in current projects on account of the COVID-19 pandemic. Due to a majority of the workforce being unable to
work as a result of stringent self-quarantine guidelines, most
construction firms will be required to cease all non-essential
operations until the outbreak is contained. This will likely
result in the large scale re-scheduling of existing projects,
which might lead to severe losses for the industry.
1) RELEVANT STATISTICS
• Within just the first two months of the year, fixed asset
investment in China dropped by 30.3%, while the real
estate development dropped by 16.3% [64].
• The widespread impact of the COVID-19 outbreak
on the construction sector in China and other leading
economies has prompted GlobalData3
to update its estimate for construction growth in 2020 from 3.1% to
0.5% [65].
F. FOOD INDUSTRY
In comparison to other sectors, the impact of the COVID-19
pandemic has not been as severe on the food industry. Recognition of food as an essential commodity has allowed supply
chains associated with food products to remain operational.
In fact, as per the Food and Agriculture Organization (FAO)
of the United Nations (UN), packaged food demand has risen
significantly in the months following the COVID-19 outbreak [66]. However, that does not go as far as to say that
the industry has not been affected at all. While supply chains
for essential food items are kept open, restaurants, cafes, and
other luxury food service providers have been forced to shut
down [67]. Furthermore, several grocery store owners and
supermarkets are often finding themselves unable to meet the
rising demands owing to ‘panic buying’ and stocking up of
food supplies by the masses [68]–[70].
G. HEALTHCARE AND MEDICAL INDUSTRY
The COVID-19 pandemic has had a devastating effect on the
healthcare systems across the world. While most industrial
sectors have been economically affected due to the inactivity caused as a result of lockdown measures & travel
bans, what the healthcare industry is witnessing is far from
stagnation. Hospitals across the world are currently facing
a shortage of ventilators, intensive care units (ICUs), and
personal protective equipment (PPE) required to manage the
COVID-19 patients. The healthcare systems of even the most
3
a data analytics and consulting company
developed countries in the world are on the brink of collapse due to the exponentially increasing number of COVID19 patients [71]–[74].
H. TELECOMMUNICATIONS INDUSTRY
The impact of the COVID-19 pandemic on the telecommunications industry has been sporadic. Various telecommunication service providers (TSPs) and internet service
providers (ISPs) have reported witnessing a massive increase
in traffic [75]. The large scale consumption of network bandwidth has been attributed to the governments’ lockdown
efforts, which have forced the educational institutions to use
online platforms of teaching, and companies to allow their
employees to work from home. However, the COVID-19 pandemic has not left the telecommunications sector unscathed.
Much like other industrial companies, a majority of TSPs &
ISPs have recorded a massive drop in their share prices over
the past few months. In GlobalData’s share price analysis
of some of the top TSPs worldwide, it was revealed that
share prices of telecom behemoths AT&T, China Telecom,
and Telefonica plummeted by more than 20% between 1 January and 25 March 2020 [76].
The large scale implications of the COVID-19 pandemic on
the global economy are attributed to the substandard response
system adopted following its initial outbreak. Although the
response to the COVID-19 pandemic has been more organized than the response to previous epidemics and pandemics,
a few issues in the current epidemic/pandemic response system remain. Table 4 lists all the underlying issues with the
current response, along with the key learning points for future
public health emergency management [10]. These lessons are
very relevant not just for other health crises but also in case
there is a second/third wave of the COVID-19 pandemic in
the future.
VI. DIAGNOSTIC TESTING FOR THE COVID-19
Given the significant spurt in COVID-19 cases across the
world in the past few months, a carefully devised strategy
for reliable diagnosis is the need of the hour. The onset
of stage II and stage III of the COVID-19 outbreak has
prompted a majority of the countries worldwide to extend
their scope of testing beyond individuals with foreign travel
history. However, due to the insufficient number of testing kits, large-scale testing of the COVID-19 is infeasible.
Furthermore, the inability to distinguish the symptoms of
COVID-19 from the symptoms of common flu has made it
difficult for governments across the world to determine fixed
criteria required to carry out a test. To this end, the CDC has
issued priority-based testing criteria to guide the evaluation
of COVID-19 cases. The criteria assign the highest priority
to healthcare workers & hospitalized patients showing symptoms of COVID-19 infection, while symptomatic patients a)
above the age of 65, or b) having existing medical conditions,
have been given the second priority. The entire guidelines for
the testing criteria have been listed on the official website of
the CDC [77].
VOLUME 8, 2020 90233V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 4. Lessons drawn from the current response to the COVID-19 pandemic [10].
A. CONTACT TRACING
Contact tracing refers to the process of identifying people
with a history of exposure to infected individuals. The relatively long incubation period associated with the COVID-19
and the absence of large scale testing has made it extremely
challenging for the authorities to identify the actual number
of infected patients. This leaves the process of contact tracing as the only viable option. According to the WHO [78],
the process of contact tracing involves three steps:
i) Identifying individuals with a history of contact with an
infected person.
ii) Recording the details of those individuals.
iii) Getting those individuals tested as soon as possible.
Adopting the process of contact tracing can be particularly
advantageous for the countries currently in the first and
the second stage of the COVID-19 outbreak.
B. CLINICAL TESTS FOR COVID-19 DETECTION
Developing accurate and reliable tests to diagnose
SARS-CoV-2 infection in individuals is essential to curb its
rapid transmission. The currently available COVID-19 tests
can be broadly classified into two types:
1) MOLECULAR TESTS
The WHO-recommended Nucleic Acid Amplification
Test (NAAT) has emerged as the most popular test for detecting an active SARS-CoV-2 infection [79]. These tests involve
the use of the nasopharyngeal swab technique, wherein a
sample comprising a mixture of mucus and saliva is obtained
from the back of the throat (upper respiratory tract) using
a cotton swab (kindly refer to Table 5 for details on other
types of sample collection techniques). However, in case
the person being tested is suffering from severe respiratory
ailments, the WHO recommends obtaining specimens from
his/her lower respiratory tract as well [80]. These samples
are then brought to a specialized laboratory, where they are
assessed for detecting the presence of viral RNA using a
real-time Reverse-Transcription Polymerase Chain Reaction
(rRT-PCR) test [81]. A diagnosis of the COVID-19 is only
confirmed if the test identifies either:
i) the presence of two discriminatory targets for the
SARS-CoV-2 genome, one of which is preferably
explicit to the SARS-CoV-2, or
ii) the presence of betacoronavirus followed by the identification of SARS-CoV-2 using partial or complete
sequencing of the virus genome (the target sequence
should be larger than the amplicon on which the NAAT
assay is used).
The viral genes being targeted by the Nucleic Acid Amplification Tests (NAATs) are the N, E, S, and RdRp genes.
Identification of just a single gene in the NAAT generates
the need for a repeat test of the patient. In any subsequent
tests, the WHO recommends using a different specimen and
target sequence from the one used in the initial test [80].
90234 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 5. Various techniques for coronavirus sample collection.
TABLE 6. COVID-19 candidate vaccines in clinical evaluations.
While NAATs have high sensitivity (true positive rate) and
specificity (true negative rate), one of their drawbacks is that
they can only diagnose current cases of infection, i.e., they
do not provide any insights as to whether someone had the
infection earlier.
2) SEROLOGICAL TESTS
Unlike molecular tests that detect the presence of the virus
itself, serological tests are used to detect the existence of
antibodies in the bloodstream of the person being tested.
Antibodies are proteins formed by the white blood cells to
combat a specific antigen. By enabling healthcare experts to
identify individuals who have developed an immune response
to the infection, serological tests have the potential to play a
massive role in the fight against COVID-19 [85]. However,
serological tests also have one significant shortcoming. They
do not have the ability to detect a disease during its early
days when the body is still building antibodies against the
infection.
VII. TREATMENT
COVID-19, caused by the novel SARS-CoV-2, has led the
world into an unprecedented state of severe disarray. At the
time of writing, no definitive treatment or preventive vaccine
exists for the coronavirus. As such, the treatment of COVID19 is mostly symptomatic, i.e., the type of treatment administered depends on the specific symptoms exhibited by the
patient.
Most cases of the coronavirus disease have been classified
as mild, with patients recovering on their own without the
need for supportive care. Therefore, it is recommended that
patients with mild COVID-19 symptoms be managed at home
VOLUME 8, 2020 90235V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
to avoid placing additional strain on the already stressed-out
health systems. However, severe and critical cases of COVID19 do tend to require hospitalization. Patients experiencing
hypoxemia4 may require the provision of additional oxygen
via face masks or ventilators. Co-infections that occur as
a result of a weakened immune system, due to the virus,
are treated with necessary antibiotics and antifungals on a
case by case basis. As the SARS-CoV-2 virus may affect the
kidney as well, renal replacement therapy might be required
in some cases [21]. In any case, patients diagnosed with the
disease need to be put under strict isolation, irrespective of
the severity of the symptoms, in order to prevent further
transmission.
While no definitive antiviral medicine or preventive vaccine for SARS-CoV-2 is available to date, various attempts
are being made to make one available for commercial use as
soon as possible. In the following subsections, we address the
efforts being made to produce potent vaccines and drugs for
COVID-19 treatment.
A. VACCINE DEVELOPMENT
Developing vaccines for viral diseases is particularly challenging, owing to their capability to mutate from one person to another. Nevertheless, the development of reliable
& potent vaccinations is the only viable way of bringing
the COVID-19 pandemic to an end. Following the outbreak,
various medical organizations, independent laboratories, and
scientists have been attempting to create a vaccine for the
SARS-CoV-2. According to the WHO, as of 26 April 2020,
around 82 candidate vaccines are in the pre-clinical stage,
while 7 have already entered the clinical evaluations (refer
to Fig. 6) [86]. Some of the most significant efforts being
made in the direction of COVID-19 vaccine development are
as follows:
1) MODERNA’S mRNA-1273
Moderna, a US-based biotech company, has put forth a
vaccine candidate in collaboration with the National Institute of Allergy and Infectious Diseases (NIAID). Moderna’s
approach is based on the injection of mRNA, a genetic form of
the virus’ genome, into human cells to allow them to generate
proteins required to combat the virus. Unlike the methods
adopted in conventional vaccines, this approach does not
require growing large numbers of the virus [87]. Although
this vaccine has entered the first phase of clinical trials on
15 March 2020, its commercial release is expected to be more
than a year away [88].
2) CanSino’s Ad5-nCoV
Another candidate vaccine that is undergoing clinical evaluations is the adenovirus type-5 vector-based recombinant
COVID-19 vaccine (Ad5-nCoV). Developed by CanSino
Biological Inc in association with the Beijing Institute of
Technology (BIT), Ad5-nCoV uses the non-replicating viral
4
a low level of arterial oxygen supply
FIGURE 6. COVID-19 preventive measures.
vector as its platform, the same as the one used in their Ad5-
EBOV vaccine for Ebola. This vaccine relies on the adenovirus type-5 vector to stimulate immune responses that work
against the disease. Given the positive response recorded in
the first phase of clinical trials, CanSino might move for an
expedited phase II clinical trial [89].
3) PittCoVacc (PITTSBURGH CORONAVIRUS VACCINE)
The researchers at the University of Pittsburgh School of
Medicine have recently developed a vaccine against the
SARS-CoV-2 named PittCoVacc [90]. Unlike the mRNA
vaccine candidate developed by Moderna, PittCoVacc adopts
the more conventional method of building immunity using
laboratory-generated pieces of viral protein. The preliminary
tests conducted on mice revealed that PittCoVacc triggered
the development of a large number of antibodies against
SARS-CoV-2 within two weeks of it being administered.
Pending FDA’s approval, phase I of the clinical trials for this
vaccine are slated to commence soon [91].
4) JOHNSON & JOHNSON’S COVID-19 LEAD VACCINE
Healthcare conglomerate Johnson & Johnson, and the
Biomedical Advanced Research and Development Authority
(BARDA), a subdivision of the US Department of Health and
Human Services (HSS), have pledged to collectively invest
more than 1 billion US dollars in the R&D of COVID-19 vaccines. On 30 March 2020, Johnson & Johnson declared that
it had identified its lead candidate vaccine after three months
of comprehensive research on several vaccine candidates in
collaboration with the Beth Israel Deaconess Medical Center,
90236 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 7. Promising candidate drugs for the treatment of COVID-19.
a division of the Harvard Medical School. Johnson & Johnson
plans to launch the clinical trials of its lead candidate vaccine
by September 2020 at the latest [92].
5) MULTIPLE EFFORTS MADE BY THE CEPI
The Coalition for Epidemic Preparedness Innovations
(CEPI), a Norway-based foundation established to expedite
the development of vaccines against emerging infectious
diseases, has initiated collaborations with several organizations & institutes across the world to aid in the development
of effective vaccines against the SARS-CoV-2. CEPI and
GlaxoSmithKline (GSK) announced a new partnership on
3 February 2020, which will see GSK make its existing
adjuvant technology available to the CEPI [93]. On 11 February 2020, CEPI struck a partnership with the International
Vaccine Institute (IVI), an international organization based in
the Republic of Korea, which shares its vision of a COVID-19
free world. Under the terms of this partnership, the IVI
will render its technical expertise in the CEPI-sponsored
projects in exchange for which it will receive funding from
the CEPI [94]. In addition to the partnership efforts, the CEPI
has pledged initial funding to various institutes, including the
University of Queensland, University of Hong Kong (HKU),
University of Oxford, and the Pasteur Institute, to accelerate
the development of effective vaccines against SARS-CoV-2.
To date, the CEPI has invested a sum of 29.2 million US
dollars in the R&D of various COVID-19 vaccines [95].
Although researchers around the world are making determined attempts to come up with a vaccine for the extirpation
of the COVID-19, the imminent arrival of an effective vaccine seems implausible. Two main reasons for the same are
mentioned below:
i) In the last two coronavirus outbreaks, namely SARS
and MERS, it was observed that once the vaccine was
administered to an individual, there was a sudden
increase in his/her immune response (cytokine bursts).
Cytokine bursts often lead to acute respiratory distress
syndrome (ARDS), which is considered to be the leading
cause of death in COVID-19 patients. To avoid such
complications and to ensure that the vaccines currently
in development do not prove to be counter-effective later,
it is necessary to certify that these vaccines have a good
safety profile.
ii) Sometimes, a single dose of vaccine is not sufficient to
develop sufficient antibodies. For example, the Hepatitis
B vaccine is given in 3 doses, each of them months apart.
Once identified, the need for wide-scale production of
the COVID-19 vaccine to meet world requirements is
anticipated to take much time. Adding to that, if multiple
doses across several months are required, it will take
an even longer time before we can rely on vaccines for
bringing the COVID-19 pandemic to an end.
B. POTENTIAL DRUGS FOR TREATMENT
Many pharmaceutical companies have come up with potential
drugs as solutions to treat the coronavirus disease. While no
drug is globally approved as of yet, several of these drugs
are being tried out, with some of them in various phases of
clinical trials (refer to Table 7). As of 29 April 2020, more
than 1800 clinical trials worldwide are listed on the WHO’s
International Clinical Trials Registry Platform (ICTRP) [96].
Among the drugs being tested, Remdesivir, Hydroxychloroquine, and Arbidol have shown immense promise, and are
already undergoing clinical trials at several hospitals across
the world [97], [98]. Earlier in 2008, Arbidol was shown
to have promising results against the pathogens of the
SARS-CoV virus in cellular models [99]. It was also proven
to be effective against influenza type A and B viruses, as well
as the Hepatitis type C virus [100].
VOLUME 8, 2020 90237V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
Another drug that has emerged as a candidate to treat the
COVID-19 is the Shuang-Huang-Lian (SHL), a well known
traditional Chinese drug used to treat various bacterial and
viral infections. Chinese Researchers have reported that SHL
oral liquid may have inhibitory properties against the SARSCoV-2 virus due to the presence of baicalin, chlorogenic acid,
and forsythin, which are known to have inhibitory effects
against multiple pathogenic viruses [101], [102]. It is important to note, however, that currently there is no conclusive
evidence backing the use of SHL oral liquid as a treatment
for the COVID-19.
Although various attempts are being made to develop
efficient treatment strategies against the COVID-19, a commercially viable vaccine might not be possible for at least
another year. Therefore, the best way to keep the disease from
spreading any further is to limit the exposure of non-infected
individuals to infected individuals. In the following section,
we discuss the various preventive measures suggested by the
WHO and the CDC against the COVID-19 [103], [104].
VIII. PREVENTIVE MEASURES
As the world continues to suffer from the COVID-19 health
crisis, it is essential to follow effective preventive measures
(Fig. 6) to minimize the likelihood of becoming another
casualty. If individuals and communities comply with the
practices mentioned below, the world may soon witness a flattened COVID-19 curve. Flattening the curve implies bringing
down the spread of the COVID-19 to the extent where available healthcare facilities can sufficiently handle the impact of
the disease.
i) Clean your hands frequently with an alcohol-based hand
sanitizer or wash them thoroughly with soap and water.
ii) Practice social distancing - Seek to keep yourself at a
distance of at least 1 meter (3 feet) from others.
iii) Stay at home unless absolutely necessary to go out.
Individuals above 60, people with underlying health conditions, and pregnant women are especially advised to
stay away from all social interactions.
iv) Avoid touching your eyes, nose, and mouth without
thoroughly cleansing your hands.
v) Frequently touched surfaces, such as doorknobs, desks,
phones, light switches, and laptops should be routinely
disinfected.
vi) Cover your coughs & sneezes with a cloth, handkerchief,
or a tissue. If none of these are readily available, coughing/sneezing into your elbow pit is advisable.
vii) It is advisable to wear masks around other people. However, care should be taken to ensure their proper disposal [105].
The rapid outbreak of the COVID-19 has placed sincere
emphasis on the need to follow good practices in daily life,
like washing hands, taking regular baths, improving eating
habits, and much more. It is important to note that good
hygiene practices and eating habits should be followed, not
just during the COVID-19 pandemic, but also after it.
IX. EMERGING TECHNOLOGIES FOR MITIGATING THE
IMPACT OF THE COVID-19 PANDEMIC
As the novel coronavirus continues its onslaught across the
globe, the world is reeling under the weight of crashing
economies and piling casualties. Unfortunately, billions of
people are still under a constant threat of infection, with the
situation not likely to get any better in the coming days. However, a multitude of technological approaches are emerging to
deal with the impacts of the COVID-19 pandemic. Among
them, digital technologies, including IoT, AI, blockchain,
and next-generation telecommunication networks like 5G,
have been at the forefront [106]. According to the WHO
and the CDC, digital technologies can play an essential
role in improving public health response to the COVID-19
pandemic [107]. In the following sections, we explore the
efficacy of the aforementioned technologies in allaying the
disastrous impacts of the COVID-19 pandemic.
X. IoT & IoMT
The Internet of Medical Things (IoMT), also referred to as
the healthcare IoT, is an amalgamation of medical devices
and software applications offering extensive healthcare services, that are connected to the healthcare IT systems (refer
to Fig. 7). In recent times, much like the IoT, IoMT has
witnessed a surge in the number of its potential applications [108]. This surge is attributed to the fact that an
increasing number of mobile devices are now equipped with
Near Field Communication (NFC) readers that allow these
devices to interact with IT systems [109]. Applications of
IoMT include 1) monitoring patients from a remote location, 2) tracking medication orders, and 3) using wearables
to transmit health information to the concerned health care
professionals.
Owing to their ability to collect, analyze, and transmit
health data efficiently, the health care sector has realized the
transformative potential of IoMT technologies [110], [111].
Amid the ongoing COVID-19 pandemic, several innovators,
medical organizations, and government bodies are looking
to leverage IoMT tools in order to reduce the burden on the
healthcare systems. In the following few sections, we explore
various IoT & IoMT technologies that have made a sizable
contribution in monitoring, and consequently, managing the
impact of the COVID-19 pandemic.
A. SMART THERMOMETERS
Eight years ago, a US health technology company named
Kinsa had launched internet-connected thermometers to
screen people for high fevers. Although these thermometers
were initially developed to track the common flu, they are,
nevertheless, proving to be highly useful in identifying the
potential COVID-19 clusters throughout the USA. Following
the COVID-19 outbreak, Kinsa Health has deployed more
than a million smart thermometers to households in various
cities of the USA. These thermometers are linked to a mobile
application, which allows them to transmit their readings
to the company immediately. Once received, this data is
90238 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 7. IoMT.
assimilated by Kinsa to generate daily maps showing which
of the US regions are witnessing an increase in high fevers,
thereby allowing the US authorities to identify potential
hotspots. In the past few years, Kinsa’s interactive maps have
proven to be highly accurate in the timely prediction of the
spread of flu around the US, outdoing even the CDC’s official
app in terms of the promptness of prediction [112].
B. IoT BUTTONS
To maintain high cleaning standards and limit the number
of hospital-acquired infections (HAIs), several hospitals in
Vancouver have installed battery-operated IoT buttons [113].
These buttons, named Wanda QuickTouch, were designed for
rapid deployment in any facility, irrespective of their size,
in order to issue prompt alerts to the management, warning
them of any sanitation or maintenance issue that may pose a
risk to public safety. A remarkable feature of these buttons is
their independence on external infrastructure, i.e., their ability
to stick to any given surface [114].
C. TELEMEDICINE
The practice of using IoMT technologies to facilitate remote
patient monitoring is called telemedicine. Also known
as telehealth, this practice allows clinicians to evaluate,
diagnose, and treat patients without needing any physical interaction with them [115]. Following the outbreak
of the highly contagious COVID-19, several IoMT tech
and telemedicine platforms have faced a rapid surge in
traffic. Recently, JD Health, an e-commerce platform for
healthcare solutions, has reported witnessing a considerable
rise in demand for online consultations since the outbreak
of the COVID-19 [116]. In the USA, the Office of Civil
Rights (OCR) and the Centers for Medicare and Medicaid
Services (CMS) have waived certain medicare rules for
allowing doctors to provide their patients with remote medical expertise via telehealth platforms [117]. Following the
relaxations in these regulations, a Texas-based multinational
telemedicine company, Teladoc Health, has reported an enormous increase in demand for its telemedicine solutions. This
surge in demand has prompted its share prices to rise by more
than a 100% in a span of few weeks [118].
The benefits of adopting telehealth techniques have been
twofold: 1) it has lessened the burden on the overworked
hospital staff, 2) it has reduced the risk of emanation of the
virus from the infected individuals to the healthcare personnel. Mentioned below are some ways in which telemedicine
platforms are being used around the world to manage the
impact of COVID-19:
• In the USA, the George Washington University Hospital (GWUH) has adopted the use of several telemedicine
strategies, including video consultations and live facebook webinars to provide remote medical expertise to
several people [119].
• Another university hospital in the USA, the Rush
University Medical Center, has adopted the use of
telemedicine platforms to facilitate on-demand video
consultations. However, the health professionals at the
Rush University Medical Center are using such consultations not only to provide medical expertise to people
but also to screen them for the COVID-19 [120].
• In India, the state governments of Andhra Pradesh and
Assam have rolled out telemedicine facilities to enable
remote interaction of potential COVID-19 patients with
medical experts [121], [122].
• In Israel’s largest hospital, the Sheba Medical Center,
several telehealth technologies were used to monitor
12 Israeli passengers that were on board the cruise
ship quarantined in Japan for several weeks. However, the Sheba Medical Center employed the use of
telemedicine strategies not to treat these passengers
remotely, but to ensure minimal human contact while
treating them within the hospital premises. [123], [124].
In the past few months, several telemedicine tools like
telemedicine carts, teleconsultation software, and portable
tablets have proved their merit in the fight against the
COVID-19 pandemic. However, the true potential of
telemedicine can only be realized when existing telemedicine
platforms are used in conjunction with other technologies
such as drones, robots, smart wearables, and next-generation
5G cellular networks (refer Fig. 8). The consolidation of these
technologies with existing telehealth platforms can allow for
a more dynamic healthcare ecosystem that can enable remote
monitoring and distant clinical care of patients with mild
cases of COVID-19.
The wide range of use cases presented above indicates the
potential of IoT & IoMT in solving the unprecedented challenges posed by the COVID-19. However, the tools discussed
above form a small subset of the much larger domain that is
IoT. In the four sections that follow, we thoroughly dissect
four prominent technologies linked to IoT that have had a
wide-ranging impact in the battle against COVID-19, namely,
drone technology, robots, wearables, and apps.
XI. DRONE TECHNOLOGY
During the times of a public health emergency, such as the
COVID-19 pandemic, UAVs, i.e., drones, can offer many
VOLUME 8, 2020 90239V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 8. Various technologies enabling telemedicine.
advantages. Not only can they ensure minimized human
interaction, but they can also be used to reach otherwise
inaccessible areas. China, the first country to face the wrath
of the COVID-19, has made great use of drone technology to
counter the COVID-19 outbreak. Taking that as inspiration,
several countries around the world have joined forces with
numerous researchers and innovators in an attempt to find
ingenious ways of using drones to fight the COVID-19 (refer
to Fig. 9). In this section, we explore the numerous benefits
that drones can provide in terms of managing the COVID-19
pandemic or any other future outbreak.
A. CROWD SURVEILLANCE
To contain the spread of the COVID-19, governments around
the world are taking all the necessary steps to ensure social
distancing. To this end, many countries around the world,
including China and India, have adopted the drone technology for crowd surveillance.
MicroMultiCopter, a leading industrial drone manufacturer based out of Shenzhen in China, has deployed over
100 drones in several cities of China in an attempt to survey areas and observe crowds efficiently [125]. The drones,
equipped with sky speakers, can also be used to give instructions to people not in compliance with the guidelines issued
by the Chinese government.
In India, a global technology solutions company named
Cyient has provided the Telangana police with unmanned
aerial spectrum monitoring technology to help manage the
COVID-19 lockdown. The drones deployed are equipped
with surveillance cameras that can effectively monitor sensitive areas in the city and allow the police to handle any
unwarranted situation promptly [126].
B. PUBLIC ANNOUNCEMENTS
In addition to crowd surveillance, drones can prove to be
highly useful for broadcasting important information, particularly in areas that lack open channels for communication. The police authority in Madrid, Spain, used a drone
equipped with a loudspeaker to inform people of the guidelines put in place regarding the state of emergency that was
imposed [127]. Additionally, several other European countries have regularly used drones to make public announcements emploring people to practice social distancing norms
and taking other necessary precautions to limit the spread of
the disease [128].
C. SCREENING MASSES
Following the outbreak of the COVID-19, several authorities
in China committed themselves to detect COVID-19 patients
as soon as possible. They employed the use of drones
equipped with infrared cameras to carry out large-scale temperature measurements in several residential areas [128].
In India, the authorities in New Delhi have employed
the use of a multipurpose drone to contain the spread of
the COVID-19. Dubbed the ‘‘corona combat’’ drone, it is
equipped with a thermal camera for screening individuals,
90240 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 9. UAVs for COVID-19 impact management.
a night vision camera for monitoring the crowd, a portable
medical box for carrying essential medical supplies, a loudspeaker for making announcements, and a disinfectant
tank with a capacity of 10 liters for sanitizing public
spaces [129]. Unlike the infrared thermometers that can measure the temperature of one person at a time, this drone
can be used to measure the temperature of multiple people
simultaneously [130].
In addition to these efforts, researchers at the University
of South Australia, in association with the Canada-based
commercial UAV manufacturer DraganFly, are in the process
of developing a ‘‘pandemic drone’’ to remotely observe and
identify people with infectious respiratory infirmities. These
drones are to be installed with a specialized sensor and computer vision system that can monitor people’s temperature
and heart rates [131]. These drones are also expected to
have the ability to detect people sneezing and coughing in
public spaces. If successful, these drones have the potential
to revolutionize COVID-19 diagnostics by early detection of
potential COVID-19 patients.
D. SPRAYING DISINFECTANTS
In the face of the COVID-19 pandemic, drones can be used
to enter contaminated regions and spray disinfectants. This
can minimize the risk of further spread of the disease while
also reducing the exposure of frontline workers to the virus.
While China and India have routinely used drones for this
practice since the onset of the COVID-19 outbreak, Spain
has become the first European country to deploy drones for
pandemic management. The Spanish military has recently
adopted the use of agricultural drones made by DJI, a leading
Chinese drone manufacturer, to spray disinfecting chemicals
over public spaces [132]. As per DJI’s claims, the drones have
a load capacity of 16 liters and can disinfect one-tenth of a
kilometer in an hour [128].
E. DELIVERY OF MEDICAL SUPPLIES AND OTHER
ESSENTIALS
In September 2019, researchers from the National University
of Ireland (NUI) were able to use a UAV to deliver diabetes
medication from Galway to a remote location in the Aran
Islands. This was the first successful Beyond Visual Line
of Sight (BVLOS) diabetes drone mission, and it showed
the world how drones have the capability to carry medical
supplies reliably [133]. In the current state of crisis, this functionality can prove to be particularly valuable to reduce the
burden on the hospitals and health care staff. Drones can be
used for the rapid delivery of medicines and supplies 1) from
VOLUME 8, 2020 90241V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
one medical facility to another or, 2) from medical centers
to the COVID-19 patients being cared for in their homes (in
case of a mild form of the COVID-19) [134]. An example of
the former was seen in China when a drone was used to move
medical supplies from the disease control center in Xinchang
County to the People’s Hospital in Xinchang County without
exposing humans to infection [135].
Marut Drones, a Hyderabad-based startup led by a team
of Indian Institute of Technology (IIT) alumni, recently
launched an entire line of drones to combat the COVID-19
pandemic in India. The company has drones for sanitizing,
medicine delivery, thermal analysis, movement monitoring,
and crowd surveillance in its arsenal of drones to combat
the COVID-19 pandemic. The company claims that their
medical delivery drones, equipped with obstacle avoidance
and advanced navigation technology, can cover a distance
of 12 kilometers in merely 8 minutes, thereby ensuring medical deliveries 80 times faster than the conventional methods [136]. Marut Drones has already offered a few drones
to various authorities in Telangana to monitor crowds and
disinfect public places [137], [138]. As per the company’s
estimates, their disinfectant drones have already disinfected
areas covering more than 1900 km [136]. Pending approval
from the Government of India (GoI), the company also hopes
to deploy its delivery drones soon [137].
In the USA, following the devastating impact of the
COVID-19, various steps are being taken by different US
bodies to introduce drone technology in the country. The
Small UAV Coalition has filed a petition for expedited
Federal Aviation Administration (FAA) approvals to allow
the use of drones for delivering medical supplies. Furthermore, Zipline, a medical product delivery company,
is planning to establish an active medical supply delivery
network. By delivering urgent medication directly to people’s
doorsteps, Zipline hopes to reduce the burden on delivery personnel while also promoting the practice of social distancing
among people [134].
Apart from being a safe way for delivery of medical supplies, drones can facilitate the delivery of groceries, as witnessed in some parts of Australia, China, and the USA [128].
In China, the e-commerce giant JD.com has started using
a few of its drones to make last-mile deliveries of essential goods [139]. Meanwhile, in the USA, Google’s parent
company - Alphabet, has recorded a considerable increase in
the number of deliveries made using its autonomous drone
delivery services known as Wing.
F. CHALLENGES
Despite the numerous benefits that UAVs can provide in
response to health crises like the COVID-19 pandemic,
the use of drone technology is confronted by certain challenges and limitations.
1) The integration of UAVs in the COVID-19 impact
response system in many countries is limited by the lack
of clear government regulatory policies.
2) Vulnerabilities in drone operations, such as GPSjamming and hacking, make drones an attractive
prospect for malicious users to conduct cyberterrorism
and other unlawful activities. In recent times, many
law-enforcement agencies have voiced their concerns
about the security risks posed by drones.
3) Although considerable strides have been made in the
advancement of drone technology in recent years,
Beyond Visible Line of Sight (BVLOS) drone operations remain somewhat unsafe. There is a growing need
for technological and operational guidelines to warrant
the safe operations of UAVs, and consequently, to reap
their comprehensive societal benefits.
4) At present, UAVs face several constraints in terms of battery life and load capacity, which inhibits their capability
to cover long distances and make multiple deliveries at
once.
While a few challenges plague the wide-scale use of drone
technology, the great promise that it holds in regards to
healthcare support cannot be overlooked. Even then, many
countries have not yet adopted the use of UAVs in the fight
against the COVID-19 pandemic. To this end, government
authorities should carefully collect and assess data in regards
to existing UAV projects and put more effort into UAV
research and development.
XII. ROBOTS & AUTONOMOUS VEHICLES
Much like drone technology, other autonomous technologies
like robots and autonomous vehicles (AVs) have made great
strides in the fight against the COVID-19 pandemic. In this
section, we discuss how authorities around the world have
employed the use of these autonomous technologies to mitigate the impact of the COVID-19 pandemic.
A. ROBOTS
As governments and medical organizations around the world
struggle to contain the spread of the COVID-19, robots are
being deployed to assist in the treatment of patients, and
consequently, alleviating the stress levels of the healthcare
workers. Additionally, robot-controlled noncontact ultraviolet (UV) surface disinfection methods are also being
employed to limit the transfer of the disease via contaminated surfaces. Compared to the practice of manual decontamination, which involves the deployment of cleaning staff
and subsequently puts them at risk of contracting the virus,
autonomous disinfection robots ensure rapid and effective
disinfection of the premises, with little to no human contact [140]. Presented below are a few examples of how
robots are being used in hospitals around the world to aid in
COVID-19 impact management.
• In India, a Kerala-based startup named Asimov Robotics
has developed a three-wheeled robot that can be used to
assist patients residing in isolation wards. The robot is
capable of doing tasks like serving food to the patients as
well as giving them medication, thereby reducing some
90242 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
burden on the healthcare workers, and freeing them from
the risk of contracting the infection.
• Xenex Disinfection Services, a company established
by two John Hopkins educated epidemiologists, has
developed an autonomous disinfection robot to help
limit the number of hospital-acquired infections (HAIs).
Xenex asserts that their UV LightStrike Germ-Zapping
robots have the potential to efficiently obliterate all
types of germs, including various types of viruses and
bacteria [141]. Xenex has reported witnessing an enormous surge in demand for its UV Germ-Zapping robot,
especially from countries like Singapore, Japan, South
Korea, and Italy.
• A Danish robotics company, UVD Robots, has developed multiple disinfection robots to be delivered in
hospitals around the world. To date, UVD Robots has
delivered its robots to several provinces in China, several
parts of Asia, and healthcare markets in Europe and the
United States. These robots emit powerful UV light that
can disinfect surfaces by tearing apart strands of virus’
DNA. The Danish company claims that their robots can
operate for about 2.5 hours and disinfect about nine or
ten rooms on a single charge [142].
According to a leading robotics expert from the Carnegie
Mellon University (CMU), in addition to the tasks mentioned
above, robots with the potential to execute tasks like obtaining
nasal samples for testing, and rendering support to isolated
patients, may also be developed soon [143].
B. AUTONOMOUS VEHICLES
Amid the global health crisis that is the COVID-19 pandemic,
AVs could help ease the stress on existing delivery mechanisms while mitigating the risk of virus transmission [144].
China has led the charge in the use of autonomous vehicles (AVs) against the pandemic. In fact, at the time of writing,
it is believed to be the only country in the world to deploy AVs
for COVID-19 impact management. Beijing-headquartered
White Rhino Auto company, in alliance with UNIDO’s
Investment and Technology Promotion Office (ITPO), dispatched two autonomous delivery vehicles from Beijing to
the Guanggu Field Hospital in the Hubei province of China.
These vehicles have proved to be highly useful for a variety
of tasks, such as delivering medical supplies and meals. The
use of AVs not only lessened the workload on the overburdened hospital staff, but it also helped in limiting the risk of
cross-infection [145].
XIII. WEARABLES
Wearables are communication enhancing devices worn on
the body that are connected to an internet source. Wearables
range from smartwatches like Apple Watch, fitness trackers
like Fitbit, smart headbands like Dreem, to personal sensors
& patches. The ability to monitor people’s physical health,
along with their stress levels, has made wearables an ideal
technology for adoption in the healthcare sector. In the midst
of the current health crisis, various organizations have modified their existing offerings or rolled out new wearables to aid
in COVID-19 impact management. Some of these technologies have been discussed below:
A. WHOOP STRAP 3.0
A Boston-based human performance technology start-up,
WHOOP, has collaborated with a team of researchers at the
Central Queensland University (CQUniversity) in Australia
to examine a potential link between alterations in respiratory
rates and the COVID-19 symptoms. The primary objective
of this study is to be able to develop a mechanism that can
identify the COVID-19, well during its incubation period,
by detecting early signs of abnormal respiratory behavior
in COVID-19 patients. With a high reproductive number,
a factor that has made the COVID-19 outbreak so severe,
this sort of an early-warning system can help slow the global
proliferation of the COVID-19.
In association with the Cleveland Clinic, the researchers at
CQUniversity’s Appleton Institute plan to carry out a study
using 24/7 physiological data, gathered via the wrist-mounted
WHOOP Strap 3.0, from hundreds of WHOOP members
who have identified themselves as having the COVID-19 and
volunteered to be a part of the study [146]. By discerning
any deviation in respiratory rates of an individual from their
established baseline, the strap can notify that individual of
any issues that they might experience. This study will also
collect data from the WHOOP Journal, a recently launched
online interface accessible from the members’ smartphones
that enables them to monitor their daily behavior and make
healthier lifestyle choices.
Although a few watches from Garmin and Fitbit also have
the functionality to measure respiratory rates [146], WHOOP
claims to be the only wearable to have its accuracy of measuring cardiorespiratory variables validated by a third-party
study [147].
B. ESTIMOTE WORKPLACE LEVEL CONTACT TRACING
WEARABLE
Estimote, a start-up known for its Bluetooth location beacons, has recently developed a set of wearable devices to
enable contact tracing at the workplace, in an attempt to
provide employees with a safer workplace environment. This
wearable device allows organization leaders to monitor the
health status of their employees remotely and to keep a
record of any case of COVID-19 transmission amongst them.
It empowers an organization’s leaders to curb the disease
spread before it spreads rampantly within the organization
or even outside it [148]. When this device is turned on,
it scans for other wearable devices and records any close
interactions with them. The devices’ hardware includes a passive GPS location-tracker in addition to Bluetooth powered
proximity sensors, ultra-wideband connectivity, built-in LTE,
and a rechargeable battery [149]. Furthermore, every device
has LED indicators and buttons, just like a smartwatch. The
purpose of these buttons is to allow the employees to log
VOLUME 8, 2020 90243V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
their real-time health status. For example, the wearer can
update his/her health status as certified healthy, symptomatic,
or verified infected. When the wearer updates his/her health
status, it is recorded in a central database that stores the
information for up to six weeks. There are three variants of
these devices: a pebble-like device to be worn around the
neck, a wrist-worn version, and a device in the form of a card.
C. LifeSignals BIOSENSOR PATCH
A Silicon Valley start-up named LifeSignals plans to launch a
novel biosensor patch that leverages the cardiovascular monitoring technique to assist early detection of the COVID-19 in
an individual. This single-use, showerproof, and lightweight
wearable named Biosensor Patch1AX, when affixed on the
chest area, can record the temperature of the person along
with his/her respiration rate, ECG trace, and even the heart
rate in real-time. This data is automatically sent from the
user’s patch to an application on the user’s smartphone,
enabling them to view their data in real-time [150]. In case
a person using this patch develops COVID-19 symptoms,
his/her data can also be sent to a centralized and secure
cloud platform, alerting the healthcare workers of a potential
COVID-19 patient [151]. The patches have been designed in
such a way that it can be worn by an individual for five days
in one go, post which they can be safely disposed to ensure
that the disease does not spread from the patch.
LifeSignals also plans to launch the second version of the
patch, Biosensor Patch 2A, in June. By storing and streaming
clinical-grade vital signs of a patient, the patch will enable the
healthcare workers to monitor COVID-19 patients admitted
to the intensive care units (ICUs) [151].
D. SPRY HEALTH’S LOOP SIGNAL
Spry Health is a company that is known for its health
management and telemedicine technologies. This company
has launched a wearable device called Loop Signal to limit
patients from visiting hospitals unnecessarily, especially during such times. Loop Signal helps healthcare personnel to
remotely manage the health of people who have symptoms
of COVID-19. Worn on the wrist, Loop Signal tracks the
heart rate, respiratory rate, and pulse-oximetry of the patient.
All these parameters are critical to assess the severity of
the COVID-19 in a patient, and can, therefore, empower
healthcare professionals to make an in-person visit only if
the patient’s condition warrants it. This easy-to-wear device
helps in collecting hundreds of data points for a patient on a
daily basis. The aggregation of a large number of data points
provides a much-needed certainty about the present condition
of a patient, as opposed to a single data point that may even
be an error, sometimes leading to false alarms [152].
E. SPHCC WITH CASSIA AND VIVALNK
Shanghai Public Health Clinical Centre (SPHCC) has
employed the use of Bluetooth IoT gateways developed
by Cassi Network, and wearable sensors developed by
VivaLNK, to monitor COVID-19 patients with minimal
human contact. China has been successful in reducing the
count of COVID-19 thanks to the advent of such technologies. In the mechanism put in place by the SPHCC,
VivaLNK’s wearable sensors constantly supply real-time data
about the changes in the body temperature of the patient. Cassia’s gateways then collate this data and transmit it wirelessly
to the healthcare staff’s station. This enables first-line healthcare workers to keep track of their patients’ health without
having to visit them personally. The Cassia IoT gateways
allow nearly 40 Bluetooth Low Energy (BLE) devices to
be paired at the same time, thereby facilitating connectivity
between multiple rooms of the SPHCC. The use of these
technologies in the SPHCC has significantly reduced the
healthcare workers’ risk of exposure to the infection while
also ensuring reduced workload [153].
F. CHALLENGES
Although wearables have played a significant role in the
fight against the COVID-19 pandemic, it is essential to note
that certain challenges/limitations hinder the use of wearables
amid the current health crisis.
1) Due to lockdowns and interrupted supply chains, delivery of these wearables is challenging in many parts of
the words.
2) The battery life of smart wearables is usually in question.
The tedious task of charging wearable devices again and
again, often dissuades users from buying these devices
altogether.
3) There are no established guidelines about the use of the
private data accumulated using these wearables, which
gives rise to a multitude of security and privacy concerns. It is necessary to ensure that the development
of such wearables is done while keeping in mind the
security and privacy preservation of the users [154].
XIV. MOBILE APPLICATIONS & OTHER PLATFORMS
The use of mobile applications (commonly referred to as
apps) has emerged as a prominent strategy in the fight
against the COVID-19. Several governments and private
organizations around the world have already developed certain apps and platforms for COVID-19 impact management,
while several others are in the process of doing so. Most of
these modern platforms use a wide variety of technologies,
including Bluetooth, Global Positioning System (GPS), and
Geographic Information System (GIS). Certain apps have
also adopted the use of blockchain, an emerging technology
that helps in storing data in the form of immutable blocks.
Table 10 lists the key technologies being used to develop
contact tracing applications [155]. In this section, we discuss
a few of the numerous applications that have emerged in the
last few months for combating the COVID-19 crisis.
A. BLOCKCHAIN
A blockchain is a continuously expanding record of transactions between two parties [156]. Such records can be used
90244 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 10. Contact tracing applications for COVID-19.
to verify the claims of a party that a transaction has indeed
happened. Blockchain is gaining more and more prominence
each day thanks to its wide applications in various walks
of life [157]. Seeing its utility, numerous companies and
authorities across the globe have started using blockchain to
build apps that can help in countering the COVID-19. These
apps aim to address a crucial problem, which is the lack of
integration of verified data sources. According to experts, one
of the main advantages of using blockchain-enabled apps is
blockchain’s capability of validating continuously changing
data. This feature can prove to be quite valuable in managing the rapidly escalating COVID-19 situation. Discussed
below are two blockchain-based applications, developed in
an attempt to help fight the COVID-19 pandemic:
1) CIVITAS
A Canadian start-up specializing in blockchain solutions has
recently launched a safety system, in the form of an app,
known as Civitas, that may assist local authorities in various
nations of the world to control the impact of the COVID19. This app associates people’s official IDs with blockchain
records to verify whether the person has permission to leave
their homes or not. This app also determines the ideal time
and day for people exhibiting the COVID-19 symptoms to
go out and buy essential items, thereby minimizing the risk
of infecting others. Additionally, Civitas offers a built-in
telemedicine functionality that allows doctors to keep track
of their patients’ symptoms and send them notes in regards
to the medicines to be used and healthcare strategies to be
followed. As per the company’s claims, the app makes sure
that people’s data remains private and secure [158].
2) MiPasa
MiPasa is a data streaming platform built on top of the
Hyperledger Fabric. This platform also draws on the services
provided by the IBM blockchain & the IBM cloud platforms,
to facilitate the sharing of verified health and location information among individuals, authorities, and hospitals. This
application works by collecting the information provided by
various medical organizations, public health officials, and
other individuals. The WHO recently acknowledged this
app to be an effective platform for helping the doctors gain
access to verifiable information. The data available on this
platform can help the hospitals to determine their future
action plans and to efficiently allocate their resources to
alleviate the impact of the COVID-19 outbreak [159].
VOLUME 8, 2020 90245V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
B. GEOGRAPHIC INFORMATION SYSTEM (GIS)
Understanding the geography of the spread of the
COVID-19 is crucial to comprehend the severity of the crisis
in a particular region, and to deploy appropriate measures
to mitigate the impact of the disease in that region. To this
end, the GIS systems use spatial analytics, mapping, and
location intelligence to map the occurrence of the diseases
against multiple parameters such as demographics, environment, and past occurrences. This kind of data will help
1) epidemiologists to understand the origins of the outbreak
and, 2) governments to identify high-risk areas and deploy
healthcare facilities accordingly.
1) ESRI ArcGIS APPLICATION
California-based Environment Systems Research Insitute (Esri) is an international provider of GIS software,
whose product line includes ArcGIS Desktop, ArcGIS Pro,
ArcGIS Enterprise, among others. Following the outbreak
of the COVID-19, the Esri has partnered with several private organizations around the world to launch the ‘‘Esri
COVID-19 Resources and GIS Hub’’, featuring a compilation of datasets, dashboards, applications, and other helpful
resources to facilitate adequate planning against the pandemic. Additionally, Esri has joined forces with various
government agencies around the world to help them exploit
GIS technology for taking proactive measures to manage the
COVID-19 spread [160].
C. BLUETOOTH
Bluetooth is one of the most useful technologies used for
accurate proximity calculation. It is also one of the least
invasive technologies since it does not monitor the exact
location of a cell user but rather the relative distance between
his device and that of another. Bluetooth contact tracing
applications generally monitor the proximity between two
people by calculating the distance between their devices using
the Received Signal Strength Indicator (RSSI) measure. Such
apps store records of all of a device’s prior Bluetooth connections, including the time for which it maintained a Bluetooth
connection with another device. In case a person is diagnosed
with the COVID-19, these apps can leverage the Bluetooth
connection history of that device to trace all the people who
had exposure to the infected individual. These apps can make
it simpler for the authorities to effectively determine potential
COVID-19 patients and use appropriate measures to quarantine them. Some of the apps that use the Bluetooth technology
for contact tracing are mentioned below:
1) TraceTogether
TraceTogether is a contact tracing app launched by the Government of Singapore, which uses Bluetooth technology to
determine the history of exposure of an unaffected individual to an infected one. Whenever two people with this
mobile application come into close contact with each other,
an encrypted code is transferred between their devices and
stored in their apps, provided that Bluetooth is turned on in
both the devices. If a person with this app is later diagnosed
with the COVID-19, the authorities can check the records
stored in his/her app to trace all the people who had come into
close contact with the infected person. This app does not use
GPS to pinpoint a user’s location, thereby allaying the fears
of those people who are worried about their privacy. As on
1 April 2020, nearly 1 million downloads were recorded for
this app, which incidentally is a record for the highest number
of downloads for an application hosted by a government
website in Singapore [161]. However, this number is still not
considered to be enough by the Government of Singapore as
the reliable functioning of this application requires participation from everyone in the country, and 1 million corresponds
to just one-sixth of Singapore’s entire population.
2) APPLE & GOOGLE’S JOINT CONTACT TRACING
TECHNOLOGY
In light of the current health crisis, two Silicon Valley tech
giants, Apple and Google, have teamed up for a rare joint venture to help governments and medical organizations around
the world in their fight against the COVID-19. They plan
to develop a privacy-preserving framework that incorporates
‘‘application programming interfaces (APIs) and operating
system-level technology’’ to assist public contact tracing
applications [162]. In a bid to safeguard user’s privacy,
the framework is set to use only the Bluetooth technology for
tracking the spread of the COVID-19. Furthermore, the two
companies claim that data from the user’s smartphone will
not be made available to anyone without the user’s consent.
Their framework will enable contact tracing applications to
use Bluetooth Low Energy (BLE) technology to log people’s
interactions and keep track of whether a smartphone owner
has come into contact with someone who is later diagnosed
to be COVID-19 positive. If indeed, this scenario takes place,
the user is sent an alert stating that he/she has come into
contact with someone who is now diagnosed with the disease. Once alerted, such users can then self-isolate or get
themselves tested. At present, the framework is still in the
development stages, with the API expected to be launched
in May, while the OS-level technology to be rolled out in
the following months. The draft technical documentation
for the framework can be found in [163], and the overview
of the API’s working can be found in [164].
D. GPS
Global Positioning System (GPS) is a satellite navigation
system owned and maintained by the United States government that provides users with positioning, navigation, and
timing (PNT) services [170]. By leveraging this technology, government authorities around the world can monitor
the real-time location as well as the historical location of
COVID-19 positive patients in their country, which can subsequently enable them to trace other potential COVID-19
patients. Mentioned below are official contact-tracing apps
of two countries that make use of the GPS technology:
90246 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
TABLE 8. Challenges associated with the implementation of various technologies in mobile applications.
1) AAROGYA SETU APP
The National Informatics Centre, a subdivision of India’s
Ministry of Electronics and IT (MeitY), has recently developed a contact tracing app called Aarogya Setu to help curb
the spread of the COVID-19 in India. Any Indian citizen can
download this application for free and register using their
mobile number to use this app’s services. On launching this
application, it asks the user if they are facing any symptoms
of the COVID-19, or, if they have an international travel
history; if not, the user is classified as belonging to the
green zone. This application currently supports 11 Indian languages and is available for both iOS and Android users [171].
Unlike TraceTogether, this app uses the GPS location of the
cellphone user in addition to the Bluetooth technology to
determine if an individual has been exposed to any potential
COVID-19 patient listed in its database [172]. In a scenario
that an individual belonging to the green zone comes in
contact with someone who is later marked as belonging to the
red zone, this app immediately sends an alert to the former,
notifying him/her of the guidelines that he/she should follow.
Additionally, this app provides its users with easy access to
relevant information [172]. On its release, the Aarogya Setu
app became instantly popular among the Indian public. The
app garnered over 10 million downloads in just five days of
its launch. In response to the privacy concerns surrounding
the app’s use of GPS technology [173], the Government of
India (GoI) has assured its citizens that the data which the
app collects is encrypted and will not be used for any purpose
besides contact tracing.
2) HAMAGEN APP
A contact-tracing app called HaMagen launched recently by
Israel’s Health Ministry, has sparked massive interest from
the governments of Italy, Australia, and Germany, among
others. HaMagen makes use of the GPS technology to determine if any app user has come in contact with someone
VOLUME 8, 2020 90247V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
who has been tested positive for the disease. Quashing
the rumors surrounding the application’s privacy pitfalls,
the Health Ministry has issued a statement maintaining that
any user’s private data does not leave the phone without
his/her consent. The app’s functioning relies heavily on the
user’s self-reported information regarding their exposure to
the COVID-19. Within the first week of the app launch,
around 50,000 app users claimed that they had adopted the
measure of self-isolation [174].
E. VOICE DETECTION
Following the COVID-19 outbreak, several voice-detection
apps have been developed for COVID-19 screening. Voice
detection applications require users to voluntarily provide a
sample of their voice, based on which the app decides whether
or not a person has symptoms of the COVID-19. Two prominent attempts at developing such voice detection platforms
for COVID-19 screening have been discussed below:
• An automated AI system has been designed by a team of
researchers from Carnegie Mellon University to detect
the presence of the COVID-19 in an individual based
on his/her voice. After logging in to the app, a user is
asked for his height and weight, followed by a request
to cough three times. Post this, he/she is asked to recite
an alphabet and a vowel loudly, which finally helps
the app in measuring the lung capacity of the user
by comparing it with thousand’s of other users’ data,
including those who are infected [169]. By the end of
this brief process, the user is given a score out of 10.
A higher score indicates that a user’s features are highly
similar to the features exhibited by COVID-19 patients.
The researchers, however, have added a word of caution
stating that this is not a diagnostic process and can never
be substituted for tests conducted in the hospitals and the
laboratories [175].
• A similar mobile application for voice-based
COVID-19 diagnosis has also been developed by students of the DY Patil Institute of Bio-Technology and
Bio Informatics, Mumbai, India [176]. This app is
currently being tested at the University of Tor Vergata
in Rome, Italy. To use the app, one has to speak into
the microphone of his/her device, following which the
app breaks the sound into multiple parameters, including
frequency and noise distortion. The values of these
parameters are then compared to an average person’s
parameter values to determine if an individual is potentially infected with the COVID-19 [177].
F. CHALLENGES
Although many people have hailed the efforts made by
various governments and organizations in building contact
tracing apps [178], a school of thought exists that believes
that contact tracing applications, even the ones that claim
to respect user’s privacy, are not secure and can blatantly
abuse the privacy of people [179]–[182]. In addition to the
privacy concerns associated with the use of contact tracing
apps, several issues in terms of accuracy and reliability also
impede their performance (refer to Table 8).
It has become quite evident that the COVID-19 is here to
stay unless adequate measures are taken to fight it effectively.
Governments and health officials alone cannot vanquish the
current health crisis. People around the world need to work
collectively with their governments to expedite the end of
this pandemic and get things back to normalcy. For example,
most of the tools mentioned above require the support of
the masses to yield fruitful results. The mere presence of
technologies such as smart thermometers and smart wearables is meaningless unless people are willing to use them
to fight COVID-19. The use of telemedicine platforms is
inconsequential unless patients are willing to trust their health
experts. Even the most straightforward contact-tracing apps
are worthless unless people are willing to use them when they
venture out of their homes. In the coming times, the actions
taken not just by the governments, but also by the people,
would influence the extent of the havoc wreaked by the
COVID-19 pandemic.
XV. ARTIFICIAL INTELLIGENCE
Since its inception, AI has proved to be a landmark technological advancement. If used properly, it stands to be a
highly effective tool against the COVID-19 pandemic [183].
Mentioned below are some of the actual and potential ways
in which AI can aid the authorities in effectively combating
the COVID-19 pandemic:
• Disease Surveillance
• Risk Prediction
• Medical Diagnosis and Screening
• Curative Research
• Virus Modeling and Analysis
• Host Identification
• Busting Fake News
• Enforcing the Lockdown Measures
In the subsections that follow, we review all of the aforementioned applications in detail.
A. DISEASE SURVEILLANCE
The timely surveillance and forecast of diseases, especially
the ones with the ability to lead the world into a state
of disarray, is crucial. To this end, a Toronto-based health
surveillance company, BlueDot, was successful in reporting
an impending outbreak of coronavirus on 31 December 2019,
nine days before the WHO [184]. BlueDot’s AI model leverages several machine learning (ML) and natural language
processing (NLP) tools to look for evidence of emerging
diseases. This model has allowed BlueDot to track the spread
of the SARS-CoV-2 and forecast its outbreak well before
epidemiologists. However, that does not go as far as saying
that no human effort was required to do the same. While
their AI model was able to give predictions in regards to the
90248 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 11. Applications of AI for COVID-19 pandemic impact mangement.
outbreak of the disease, human interpretation of the model’s
output remained central to its working [185].
Besides BlueDot, several other organizations have adopted
the use of AI to estimate the risks associated with emerging
infections. For example, a risk analytics company founded
in 2008, Metabiota, has developed an epidemic monitoring
platform that allows it to forecast the spread of diseases.
Metabiota bases its predictions on factors like the infection’s
clinal features, fatality rate, and the availability of treatment. Other functionalities of Metabiota’s Epidemic Tracker
include providing detailed information and up-to-date statistics on over 120 novel pathogens [186].
In addition to these efforts, a few scientists have also proposed the use of such technologies in identifying potentially
fatal zoonotic viruses well before they cause damage to the
human population. The Global Virome Project (GVP) is an
example of one such endeavor. The GVP aims to establish a
genetic and ecological database of viruses in various animal
species that are capable of infecting humans. The large volume of data that they collect on viruses could also be used to
shape AI technologies to predict which zoonotic viruses have
the potential to cause the most harm to the human species.
Such mechanisms can allow for the proactive development
of vaccines, drugs, and preventive measures [187].
B. RISK PREDICTION
One of the possible avenues of application of AI against
COVID-19 is risk prediction (refer to Fig. 11). Broadly,
risk prediction can be classified into the following
categories [188]:
• Predicting the risk of getting infected.
• Predicting the risk of developing severe symptoms once
infected.
• Predicting the risk of using a specific line of treatment
on an infected person.
Typically, the risk of getting infected is a function of a
myriad of factors. These include age, travel history, hygiene
habits, current health status, pre-existing health conditions,
and family medical history. Direct mathematical modeling
of such factors would not yield fruitful results. However,
a comprehensive analysis of these factors integrated with AI
techniques, can offer a more precise and reliable prevision
of individual risk profiles. For example, authors in [189]
describe an ML-based stratagem to build a vulnerability index
for individuals susceptible to the novel coronavirus.
Once a person is infected, AI capabilities can also be
used to determine the probability of survival and the requirement of ICU treatment for COVID-19 patients. To this end,
physicians at universities like Stanford and the University of
Chicago are making attempts at augmenting their existing AI
systems to accurately identify the COVID-19 patients whose
condition might worsen. Earlier, these systems have proved
their mettle in predicting whether or not heart disease patients
will require a transfer to the ICU. In another effort, Bayesian
Health, a start-up tracing its roots to the John Hopkins University, has started working on an early warning system for acute
respiratory distress syndrome (ARDS), one of the severe
symptoms associated with the COVID-19 [190]. The authors
of [191] have also proposed an AI framework that leverages
predictive analysis performed on real COVID-19 patients
to support clinical decision-making. Their AI-powered
VOLUME 8, 2020 90249V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
predictive model is capable of identifying people with a
higher likelihood of developing severe symptoms like ARDS
based on initial presentation. According to their results, their
model achieved an accuracy of 70-80 % in predicting severe
cases of the COVID-19.
In addition to the use-cases mentioned above, AI techniques, particularly machine learning algorithms, can also be
used to correlate the patient’s data parameters with a specific
drug’s usage. Such correlations can be used to predict the
effect of the drug on a specific group of patients. Pre-emptive
knowledge of these factors can enable the doctors and medical suppliers to be better prepared for the consequences.
C. MEDICAL DIAGNOSIS AND SCREENING
Rapid diagnosis of the COVID-19 can allow governments to
take effective response measures to limit the disease’s further
spread. The shortage of testing kits worldwide, however, has
made it hard for the authorities to carry out large-scale diagnostic testing. Many existing AI tools are being repurposed,
while some new ones are also being built to solve this problem. In this subsection, we examine the various ways in which
AI is revolutionizing the process of COVID-19 screening and
diagnosis.
1) FACE SCANNERS
Following the COVID-19 outbreak, various authorities used
IR temperature scanners at different public places to screen
people for a fever. This technology, however, requires the
presence of frontline personnel to carry out the scan. To limit
the exposure of the frontline staff to potential COVID-19
patients, several hospitals, airports, and medical centers have
adopted the use of cameras with AI-based multisensory technology [192]. These cameras can not only enable the authorities to observe the crowds and identify individuals with high
body temperatures, but they can also be used to recognize
their faces and trace their movements. One of the first hospitals to use this technology was the Tampa General Hospital
in Florida, USA. The hospital installed an AI-enabled camera
at its entrance to screen all the entering patients for elevated
body temperatures by giving them a thermal face scan. Their
AI system uses machine learning, and findings of the camera,
to classify whether or not an individual is manifesting the
symptoms of the COVID-19 [188].
2) MEDICAL IMAGING
AI technology has considerable potential to improve
image-based medical diagnosis. According to the researchers
at the UN Global Pulse, analysis of computed tomography (CT) scans and X-rays using AI-enabled tools can save
radiologists’ time by offering more timely medical diagnosis than current tests for the COVID-19 [185]. To this end,
multiple efforts have already been made to employ the use of
AI-enabled medical imaging to diagnose the COVID-19.
• A Beijing-based start-up that specializes in building an
oncology data platform and performing medical data
analysis, LinkingMed, has put forth an AI-based model
for screening pneumonia through CT scan analysis.
Since pneumonia is one of the most common clinical features of the COVID-19, identifying the presence
of pneumonia can help identify potential COVID-19
patients. LinkingMed’s open-source AI model is based
on Baidu’s parallel distributed deep learning platform -
PaddlePaddle [192].
• A joint effort between the researchers at the University of Waterloo and an Ontario-based AI start-up,
DarwinAI, has yielded a Convolutional Neural Network (CNN) to diagnose COVID-19 using chest X-rays.
Labeled COVID-Net, this AI algorithm has been made
open source by the research team to facilitate the development of AI tools over their model.
• Another AI model for diagnosing the COVID-19 using
X-rays has been put forth by a few researchers at the
Delft University of Technology, Netherlands. Named
CAD4VOCID, this model is built on top of an AI model
developed at the same University for the diagnosis of
tuberculosis.
Although the use of AI-powered medical imaging techniques
has been perceived to have great potential in COVID-19
diagnosis, several radiologists have voiced some issues concerning such techniques. Firstly, the lack of unbiased data
hinders the performance of AI models. Secondly, the use of
medical imaging techniques can potentially contaminate the
equipment used, and may well cause the disease to spread
further [185].
3) AI-POWERED MEDICAL DIAGNOSIS IN SOUTH KOREA
In the Republic of Korea, several AI-powered tools have
helped the country in quick examination and identification
of COVID-19 patients. An algorithm to detect unusual observations in the patient’s chest X-rays, VUNO’s Chest X-Ray
Image Support Decision Tool, has the potential to recognize the individuals in need of intensive care. To do so,
the algorithm studies the patient’s X-ray images and examines
whether or not there is an issue with the patient’s lungs.
Another AI-platform named AiHub has been developed in
the Republic of Korea by an AI-based medical and security
solutions company - JLK inspection. The platform uses the
AI and big data capabilities of several imaging devices to
diagnose any lung conditions that the patient might have, in a
matter of seconds. In addition to various COVID-19 diagnosis
platforms, AI has also played an essential role in accelerating
the development of testing kits in Korea. These testing kits
have been approved by not only the authorities in Korea but
also by the European Union [193].
4) COVID-19 VOICE DETECTION SYSTEMS
Voice detection is one of the simplest technologies that can
be employed to identify potential COVID-19 patients. During
these difficult times, when there is a serious dearth of testing
kits, voice detection platforms can act as a screening measure
90250 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
to decide who needs to be tested. For more details on how
voice detection platforms are currently in use, kindly refer to
section XIV-E.
From all the examples presented above, it is crucial to note
that AI is better suited to assist the screening of COVID-19
patients rather than diagnosing them altogether. To be able
to diagnose any COVID-19 patient accurately, AI devices,
platforms, and algorithms must be sufficiently robust so as
to detect all possible mutations of the virus.
D. CURATIVE RESEARCH
Being novel, one of the major problems with the
SARS-CoV-2 is the lack of existing research and treatment
protocols for the virus. However, by analyzing the current
cases of the COVID-19 as well as the existing research on
different diseases, AI can prove to be a beneficial technology
to speed up the process of drug development. Several organizations and research labs have already adopted the use of AI
to identify potential treatments for the COVID-19. AI can not
only expedite the drug development process, but it can also
aid in the process of discovering existing drugs.
1) DRUG DEVELOPMENT
Machine learning (ML), a subset of AI, has proved its effectiveness in the process of drug development in the times
of previous health emergencies. For example, during the
Ebola epidemic, Bayesian ML models were used to speed
up the process of discovering molecular inhibitors against
the virus [194]. Similarly, the authors of [195] adopted the
use of ML-assisted virtual screening and scoring to speed up
the process of discovering viral inhibitors against the avian
H7N9 virus responsible for recurring influenza epidemics in
China. In light of the current pandemic, ML models similar to
such models can aid in expediting the process of developing
drugs that can possibly be used to treat the COVID-19.
2) REPURPOSING EXISTING DRUGS/COMPOUNDS
In addition to being able to aid in drug development, scientists
are also using AI to help in identifying existing drugs that can
be repurposed to treat the COVID-19.
• A Germany-based start-up named Innoplexus AG has
exercised the use of its AI-powered drug discovery
platform to identify a combination of existing drugs
that may prove useful in the treatment of the COVID19. After extensive analysis of existing data associated
with the COVID-19, their platform has revealed that
Chroloquine, an anti-malaria drug, may work better in
combination with Remdesivir (an experimental antiviral
originally developed to treat Ebola) or Tocilizumab (an
immunosuppressive drug) or Pegasys (used to treat Hepatitis B & C) or Clarithromycin (an antibiotic) [196].
• A similar effort is being made by a British start-up
named Exscientia in collaboration with Diamond
Light Source, UK and Calibr, a division of the
California-based Scripps Research Institute. Exscientia
aims to use its AI drug delivery platform to arrive at a
combination of compounds that could prove to be beneficial in treating the COVID-19. To do so, Exscientia
intends to screen some 15000 clinically-ready molecules
present in Calibr’s compound library against three key
viral drug targets of the SARS-CoV-2 [197]. Earlier this
year, Exscientia developed the first-ever AI-created drug
to enter the clinical trials [185].
• Researchers from the Republic of Korea and the USA
are using deep learning to investigate the effectiveness of an existing antiretroviral drug used to treat
HIV/AIDS named Atazanavir, in the treatment of the
COVID-19 [198].
• Researchers at a UK-based AI company, Benevolent
AI, have identified Baricitinib (a drug for the treatment of rheumatoid arthritis) as a potential drug to
treat the COVID-19. Following their research, Baricitinib has entered a controlled trial with the United
States National Institute of Allergy and Infectious Diseases (NIAID) [198].
• Gero, AI-powered drug discovery and drug repurposing
platform developed by a group of scientists in Singapore, has assisted in the identification of several existing
drugs, including a drug named Afatinib (used to treat
non-small cell lung cancer), that could potentially be
used to treat the COVID-19 [185].
• Various ML techniques are also being used to identify drug candidates by predicting drug-target interactions (DTIs) between the virus’s proteins and existing
drugs. The authors of [199], for example, built a
deep learning Deeper-Feature Convolutional Neural
Network (DFCNN) system that can identify/classify
protein-ligand interactions with reasonably high accuracy. Thus, the use of AI can not only help in suggesting possible candidates for treatments but also
analyze their expected effectiveness. Another example of this approach is given in [200], where a deep
learning-based drug-target interaction model Molecule
Transformer-Drug Target Interaction (MT-DTI) has
been developed to identify commercially available drugs
capable of acting on SARS-CoV-2 viral proteins.
Although much effort is being put into the discovery of
such treatments, it is highly unlikely that any of them will be
available shortly. These candidate treatments have to undergo
extensive scientific checks and clinical trials before they are
approved for commercial use.
E. VIRUS MODELING AND ANALYSIS
The key to developing a successful treatment against
COVID-19 is to understand the virus itself. Since viruses
cannot reproduce by themselves, they rely on host cells to
manufacture copies of their DNA. To do this, a virus typically
infects a host cell by binding itself to the host’s receptors via a
lock and key mechanism. The working mechanism for most
inhibitor-based agents is to prevent this from happening by
VOLUME 8, 2020 90251V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 12. Debunking myths surrounding the COVID-19 (information source: WHO).
blocking the receptors of the target cells. Thus, the design of
effective inhibitors requires scientists to model the binding
mechanism. Machine learning happens to be one of the most
useful tools in the scientist’s arsenal for building such models.
In the past, ML models trained with protein data have
proved to be successful in predicting protein-protein interactions (PPIs) between the H1N1 virus and human body cells,
thereby eliminating the need to model the entire virus-host
interactome [188]. Machine learning can also be used to
model various protein folding mechanisms that the virus
uses to sustain itself. Reference [201], for example, employs
deep learning algorithms to predict the structure of a protein from its amino acid sequence. Knowing a protein’s
three-dimensional structure is of great importance, as its functioning is strongly correlated to its structure.
Amid the current COVID-19 health crisis, DeepMind,
Google’s AI company, has adopted the use of its AlphaFold
system to predict the structure of the proteins associated
with the SARS-CoV-2. These predictions can aid scientists
in better understanding the overall structure of the virus, and
consequently, in developing a new drug to treat the COVID19 [185]. It is important to note, however, that DeepMind has
made it clear that these predictions have not been experimentally verified [188].
F. HOST IDENTIFICATION
The SARS-CoV-2 is a member of the BetaCov genera of the
coronaviridae family. Typically, genomes of such viruses are
a mix of bat and rodent genomes. To date, the mammalian
host that facilitated the transmission of the COVID-19 to
human beings is an unknown variable. To this end, ML models can be used to effectively compare the viral genome with
known genomes and identify similarities between them. Such
a database of known genomes is available in [202]. In [203],
the authors have proposed the use of a random forest algorithm to identify the hosts for the influenza-A virus. Another
example of such an approach is given in [204]. Such models
can be extended to include the SARS-CoV-2 as well.
G. BUSTING FAKE NEWS
The uncertain times following the outbreak of the COVID19 have bred several myths and conspiracy theories (refer to
Fig. 12). Much misinformation has been making the rounds
on social media platforms. To curb the propagation of these
fake news and provide verified information, technology companies like Google, Youtube, and Facebook have employed
the use of AI techniques. All these platforms have made an
effort to screen content for the presence of even the slightest bit of misinformation. Youtube, in particular, has placed
stringent measures to take down any video propagating fake
news [192].
H. ENFORCING THE LOCKDOWN MEASURES
Many countries around the world, including China, India,
the USA, and the UK, are adopting the use of AI to enforce
social distancing and lockdown measures. In China, Baidu,
one of the largest AI and internet companies in the world, has
developed computer vision (CV) powered infrared cameras
to scan public places. These cameras can not only identify
90252 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
people with high body temperatures, but via the use of their
inbuilt facial recognition system, they can also recognize citizens who are not following the lockdown measures. A similar
CV camera system has been deployed in Oxford, England,
to monitor if the crowds are following the social distancing
measures. An AI-based start-up in the USA - Landing AI,
helmed by one of the most renowned AI experts in the world
- Andrew Ng, has also developed a social distancing detection
tool that monitors crowds and alerts the authorities whenever
social distancing guidelines are breached [185].
I. CHALLENGES
Artificial Intelligence can conceivably play an essential role
in mitigating the impact of the COVID-19 pandemic. However, at present, AI systems are still in the prefatory stages.
The several challenges and limitations hindering the application of AI in COVID-19 impact management are as follows:
i) To yield reliable and accurate results, AI models require
a substantial amount of training data. However, owing
to the unprecedented nature of the pandemic, there is
a dearth of historical data on which to train AI models, which has consequently rendered several AI models
inefficient [185].
ii) It is not only the absence of open data that has impeded
the performance of AI models, too much noisy and
outlier data has also presented a challenge to the efficient
use of AI technologies. Google Flu Trends’ failed initiative sheds light on the fact that a deluge of data hubris
can potentially inundate AI algorithms and inhibit their
functioning [185].
iii) Another limitation faced by AI systems, particularly
machine learning models, is their inherent assumption
that all possible contingencies in any given situation are
the same as the ones exhibited in the dataset they have
been trained on [185].
iv) The use of AI techniques for crowd surveillance is seen
by many as a breach of privacy. Although at present, people have apprehended the fact that public health concerns
are more important than data privacy concerns, the privacy pitfalls associated with the use of AI have instilled
a sense of fear among the public that governments may
continue to monitor them even after the pandemic is
over [184].
v) Another limitation of AI in its current form is its dependence on human knowledge. Human expertise is fundamental to guide the implementation of AI techniques
and make a significant difference in the fight against the
COVID-19 pandemic [184].
Despite the several challenges facing the AI systems,
their contribution to the fight against the COVID-19 pandemic cannot be overlooked. In recent years, AI technology has made stunning advances in the fields of NLP, ML,
deep learning, data analytics, among others. Such developments serve to prove the potential of AI in assisting the
COVID-19 pandemic management system.
XVI. BLOCKCHAIN
Blockchain technology has been under extensive deliberation amongst researchers and industrialists in recent
times, especially since the onset of Blockchain 2.0 &
Blockchain 3.0 [205]. Gradually, this technology is extending its presence to almost all the major domains, including the insurance sector, the transportation industry, drone
communication technologies, and even the healthcare
sector [206], [207]. The current health crisis, brought by
the COVID-19, is neither localized nor independent. The
COVID-19 pandemic has left no space for seclusion, and
people all around the globe need to stand united to get through
this crisis. The nature of the pandemic itself is distributed
in nature. Therefore, distributed ledger technologies, such as
blockchain, can be highly beneficial in regards to dealing with
this situation. Blockchain technology enables individuals and
organizations from any corner of the world to become a part
of a single interconnected network that facilitates the secure
sharing of data. The tamper-proof feature of blockchain
makes it resistant to unauthorized changes, and the use of
consensus algorithms and smart contracts minimizes the
potential of the dissemination of bogus data and fraudulent
information. Blockchain-based applications can be employed
to monitor and manage the COVID-19 patients digitally,
thereby relieving some burden on the hospital staff and other
healthcare personnel (refer to Fig. 13). Mentioned below are
some of the significant ways in which blockchain technology
can help in the fight against the COVID-19:
• Facilitating Increased Testing and Reporting
• Recording the Details of the COVID-19 Patients
• Managing the Lockdown Implementation
• Preventing the Circulation of Fake News
• Enabling an Incentive-Based Volunteer Participation
Platform
• Enabling a Secure Donation Platform for Supporters
• Limiting Supply Chain Disruptions
We dissect each one of these ways in the subsections that
follow.
A. INCREASED TESTING AND REPORTING
Various countries, such as China, Germany, and the Republic
of Korea, have emphasized the need for extensive testing of
individuals as the eventual means to curb the spread of the
virus. However, in order to ensure efficiency, tests must be
carried out intelligently, and accurate data in regards to the
number of tests performed needs to be maintained. To this
end, blockchain technology can help in setting up distributed
check-up points for testing the patients who are showing
symptoms related to COVID-19. The coordinators of all these
check-up points can act as nodes of the same distributed
blockchain network. These nodes can continuously update
data regarding the number of tests performed and the number
of laboratory-confirmed cases in their local check-up point on
this network. This can help in getting an accurate report on
the number of tests being conducting and the number of
VOLUME 8, 2020 90253V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 13. Blockchain-based DLT architecture for COVID-19 impact management.
positive cases recorded in each area. These reports can further
help the authorities and healthcare officials to strategize a
plan to combat the spread of disease in the areas reporting
a high number of COVID-19 positive patients. The shared
blockchain network can act as a single source for all the users
to update and retrieve the data. Due to blockchain’s inherent
feature of being immutable, data stored in the network will
be tamper-proof and can, therefore, be trusted by all the
healthcare professionals and government authorities.
B. RECORDING COVID-19 PATIENT DETAILS
Apart from securely storing the test reports, the blockchainbased distributed platforms can also act as a promising solution for recording COVID-19 patient details. As soon as a
person tests positive for the COVID-19, all of his/her details,
including sex, age, medical history, underlying health conditions, the severity of the disease, the symptoms developed,
and the recommended line of treatment, can be securely
added on the network. A platform with up-to-date data on
the COVID-19 patients can help facilitate the study of the
disease’s clinical characteristics and help all the health centers that are part of the network, better understand better the
disease’s growth pattern. In the near future, any health center
dealing with a confirmed case of the COVID-19 can refer to
these studies to anticipate the kind of facilities and medicines
required to deal with the situation at hand.
C. MANAGING THE LOCKDOWN IMPLEMENTATION
Living under lockdown conditions is an unprecedented situation for a majority of the people around the world. The
essential needs of the public have to be met to empower them
to stay at home and follow the lockdown restrictions strictly.
People from the police department, healthcare department,
Non-Governmental Organizations (NGOs), and other volunteers need to work in sync with the government authorities
to achieve the intended results of the lockdown successfully. Following the implementation of lockdown measures,
multiple reports have surfaced claiming that people residing
in easily accessible areas are utilizing extra services while
people living in remote areas are kept bereft of even the fundamental necessities. To this end, blockchain technology can
aid the government and non-government bodies to oversee
the requirements of people in different regions of the country
and efficiently manage the lockdown implementation. All the
authorized groups or individuals associated with enforcing
the lockdown can act as nodes in the blockchain network and
can register the needs of the residents in their designated area
on the network. All the participating nodes in the blockchain
network are allowed to check for the requirements listed by
the nodes of different areas, following which the intended
groups may take appropriate actions to satisfy those needs.
This will help to limit the imbalance in the supply of services
in different areas and consequently result in a more stringent
lockdown implementation.
D. PREVENTING THE CIRCULATION OF FAKE NEWS
Following the outbreak of the COVID-19, one of the major
concerns for governments worldwide has been to limit the
spread of misinformation. Various unsolicited messages are
being forwarded, giving rise to feelings of unrest amongst the
citizens. Besides spreading rumors and fake news, some messages are particularly inflammatory and instill the feelings
of xenophobia amongst the readers. However, since several
social platforms are currently in use, it becomes difficult for
the authorities to monitor the authenticity of the information
being shared in each of these platforms. Moreover, even if the
90254 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
authorities are able to detect an unfactual message, it becomes
difficult for them to track the original initiator of the message.
To this end, the use of a public blockchain network for
information sharing can be a highly promising solution to
curb the spread of rumors, conspiracy theories, fake news, and
inflammatory remarks. By forcing all message initiators to
sign their message with a digital signature, the authorities can
keep track of who shared which message. Although the use
of consensus algorithms will ensure that no misinformation
makes it into the network in the first place, even if it does,
the authorities can quickly determine the message initiator
based on his/her digital signature. Such a platform will prevent people from falling prey to fraudulent information.
E. INCENTIVE BASED VOLUNTEER PARTICIPATION
The general behavior of the individuals is that they tend to
respond quickly to the incentives offered. Incentives may be
simple words of appreciation, a monetary benefit, a small
gift, or a certificate acknowledging his/her work. Blockchain
technology makes use of a robust consensus mechanism that
can be used to facilitate the secure distribution of incentives
in different ways to the deserving candidates [208], [209].
In the current state of crisis that is scaling up at a rapid
pace, it becomes crucial for countries to prompt their citizens to share vital data and also to involve them in impact
management activities [210]. To this end, a blockchain-based
incentive mechanism, such as the ones proposed in [211],
and [212], can prove to be highly useful in motivating a
large number of citizens to act as volunteers for the COVID19 crisis management. Volunteers can help by distributing
food, masks, and other essential products. Furthermore, they
can also help by reporting the identities of people 1) breaking
social distancing protocols, 2) hoarding items of daily use,
and 3) misusing the current state of panic among people to
charge them extra for even the most fundamental necessities. All the participants in the blockchain network can be
rewarded with some tokens or certificates of appreciation to
acknowledge their work done and motivate them to participate with even more enthusiasm.
F. SECURE DONATION PLATFORM
Following the massive impact of the COVID-19 pandemic
globally, especially on those belonging to the underprivileged class, several people and organizations around the
world are coming forward to help the ones less fortunate
than themselves. Since, in these dire times, not everyone
cannot go out and personally help the needy, people have
chosen to donate in several international and national relief
funds. However, the reports of fraudulent bank accounts
and relief funds have instilled a feeling of insecurity among
the people who were otherwise willing to donate. Recently,
in India, a group of fraudsters was caught collecting donations by creating a fake bank account under the same name
as the one initiated by the Indian prime minister [213].
To this end, a secure and transparent donation platform is
required to quash the skepticism surrounding the validity
and transparency of existing donation platforms and, consequently, enable more citizens to extend monetary help.
Various blockchain-based crowdfunding platforms have been
proposed in recent times [214], [215]. Blockchain-based
platforms can ensure a secure collection of money while
also warranting transparency in regards to where the donated
money is being used.
G. LIMITING SUPPLY CHAIN DISTRUPTIONS
The onset of the COVID-19 has been particularly troublesome for international trade and supply chains. Amid the
lockdown measures currently imposed in several countries,
most organizations around the world are experiencing considerable difficulties in maintaining the flow of goods and
services [216]. Supply chain disruptions, further exacerbated
by trade restrictions, have caused a majority of suppliers to
halt production and several logistic partners to postpone the
transport of goods. Technologies, such as blockchain, are
being hailed as the key to reforming the trade networks and
making the supply chain more tolerant of such emergencies
in the future.
The past few years have seen several attempts made by
organizations around the world to incorporate blockchain in
their supply chains in a bid to increase supply chain visibility,
lack of which is cited as the primary reason for supply chain
disruptions. In existing systems, even if the manufacturers are
familiar with any difficulties being faced by their immediate
suppliers, they might be oblivious to the challenges faced by
their supplier’s partners. Knowledge of such challenges can
allow manufacturers to arrange for temporary solutions to
deter supply chain problems [217]. However, owing to the
insecurities of losing a competitive edge, suppliers may be
leery of disseminating their partner’s details. To this end, permission blockchains can make it feasible for the supplier to
share data without actually disclosing their partner’s identity.
H. CHALLENGES
A few technical and non-technical challenges hinder the
application of blockchain in the COVID-19 impact management. Before blockchain-based solutions can be implemented
in the current situation, these issues must be adequately
addressed.
i) The first non-technical challenge to blockchain implementation is the lack of awareness about blockchain and
its potential. Furthermore, several people have reservations regarding the use of blockchain since they associate
blockchain only with cryptocurrencies and fraudulent
activities.
ii) Although non-technical challenges can be handled
by increased awareness, the main challenges to
blockchain implementation are the technical ones.
Blockchain-based platforms often suffer from their lack
of scalability. The current crisis necessitates the use of
a highly scalable solution since it is affecting almost
all people around the world. Currently, only a few
VOLUME 8, 2020 90255V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
blockchain-based platforms are available, and almost all
of them have inherent scalability constraints.
iii) The response to the current pandemic requires the consolidation of various emerging and legacy technologies.
Since blockchain technology is relatively new and immature, it becomes difficult to integrate blockchain applications with legacy systems
iv) One of the significant advantages of blockchain,
the absence of any central authority, may sometimes backfire. To ensure the proper functioning of
blockchain-based applications, it is essential to properly
enforce government regulations and standards in the
design and development of such applications.
Although blockchain technology is relatively new and its
entire potential is yet to be explored, the disastrous impact
of the COVID-19 pandemic has warranted the use of
blockchain-based transparency solutions for enhanced impact
management techniques. In the coming times, due to the
several benefits that it offers, blockchain technology has the
potential to become an indispensable part of the healthcare
industry and the rapid response system.
XVII. 5G NETWORK TECHNOLOGY
5G refers to the fifth generation of wireless communication technology supporting mobile networks globally [218].
In comparison to 4G, 5G is expected to have better performance in terms of higher speed, lower latency, wider
range, increased availability, and more reliability. Together
with other concomitant technologies like IoT and AI, 5G
network technology has the potential to revolutionize the
healthcare sector. The commercialization of 5G technology
in China has already transformed its response mechanism to
the COVID-19 pandemic by providing better assistance to
the frontline staff and facilitating improved virus tracking,
patient monitoring, data collection, and analysis [219]. Citing
China as an example, in this section, we discuss the various
ways in which countries can adopt 5G to help improve the
efficiency of their efforts in resisting the COVID-19 health
crisis.
A. 5G+ TELEMEDICINE
As defined in section X-C, telemedicine refers to the practice
of remotely monitoring the patients. Although the use of
drones, smart wearables, and mobile applications can augment the functionalities of the telemedicine sector, 5G network technology is a necessity to realize those functionalities. Due to its limited bandwidth and data transfer speed,
the existing 4G networks cannot support real-time highquality video conferencing, which is an essential requirement
for seamless consultation teleconferencing [220]. Furthermore, 4G LTE networks often hinder the connection of IoMT
devices to cloud platforms, consequently rendering them
inefficient. To this end, 5G with its features like ultra-low
latency, and high-speed data transmission can enable mobile
networks to address these issues. Furthermore, 5G can
enable immersive virtual and augmented reality (VR/AR)
applications, which can conceivably lead to an interactive
experience in telemedicine, and equip caregivers to provide
immediate expertise in regards to possible complications and
treatment strategies [221].
China, where the 5G technology was commercially
unveiled in early November last year, has already drawn on
some of the features that 5G networks bring to telemedicine.
Various hospitals and medical centers in China have launched
5G+ telemedicine platforms for COVID-19 patients. For
example:
• West China Hospital has launched a COVID-19 5G+
teleconsultation platform with assistance from China
Telecom.
• A hospital affiliated to the Kunming Medical University has launched a 5G-based online platform for free
COVID-19 diagnosis and treatment [222].
• An emergency facility in Wuhan, Huoshenshan Hospital, has launched a 5G+ remote consultation platform.
This consultation platform has enabled a more efficient
diagnosis and treatment of the COVID-19 patients in
the hospital, by equipping the healthcare professionals in Beijing to work with the medical team of the
hospital [223].
B. 5G+ MEDICAL IMAGING
Recent years have seen medical imaging techniques like Picture Archiving and Communication Systems (PACS), become
an indispensable part of diagnosis and treatment. In tandem
with the next-generation cellular networks and technologies
like AI and big data analytics, PACS can offer enhanced
data analysis & management, while requiring minimal human
effort. In a specialist field hospital in Wuhan, Leishenshan
Hospital, 5G-enabled medical imaging platforms allowed
for real-time diagnosis of COVID-19 patients, and in doing
so, relieved some of the load on the hospital’s medical
staff [223].
C. 5G+ THERMAL IMAGING
Thermal imaging technology, initially developed for
anti-aircraft defense, has now found its way into several
domains, including healthcare, where it has proved to be
particularly propitious. The establishment of 5G networks has
facilitated the development of 5G-enabled thermal imaging
systems that can have several applications in defense and
healthcare. A 5G+ IR thermal imaging monitoring system
can enable the real-time temperature of moving bodies with
high accuracy and precision. The data accumulated by the
systems can then be transmitted to the central monitoring
system with ultra-low latency using 5G networks. For the
COVID-19 outbreak, this functionality can mean around-theclock public temperature monitoring. In China, several 5G+
thermal imaging systems have already been consolidated in
robots and UAVs, which have been deployed in public spaces
of several cities to reduce the spread of the COVID-19 [223].
90256 VOLUME 8, 2020V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
FIGURE 14. 5G epidemic monitoring platform.
D. 5G+ ROBOTS
Following the COVID-19 outbreak, several attempts have
been made around the globe to develop and deploy robots to
ease the burden on the first-line officials. Although some of
these attempts have already been discussed in section XII-A,
this section focuses mainly on 5G-powered robots. In addition to having more functionalities, 5G-enabled robots are
often more efficient in performing the assigned tasks.
1) 5G ROBOTS DEPLOYED BY AIS IN THAILAND
In Thailand, Advanced Info Services (AIS), the country’s
largest phone operator, has leveraged 5G technology in various ways to fight the outbreak of the COVID-19. AIS has
installed 5G networks at 20 hospitals and deployed several 5G
robots to aid the hospitals in augmenting their telemedicine
facilities. Apart from serving as a means of communication
between the medics and the patients, these robots have the
ability to perform thermal scans [224].
2) CHINA MOBILE’S 5G ROBOTS IN SHANGHAI
As part of its effort to contain the spread of COVID-19,
a Chinese telecommunications operator, China Mobile, has
provided six 5G-enabled intelligent robots to the Shanghai
Public Health Clinical Center. These robots can perform a
multitude of operations, such as sanitizing the health center
premises and delivering medicines to the patients, to name a
few. In addition to the robots, telecom operators in Shanghai
have deployed smart devices such as 5G thermal imaging
cameras and 5G health monitors in their bid to combat the
COVID-19 crisis [225].
3) CloudMinds’ 5G ROBOTS IN WUHAN
A field hospital, staffed with several 5G-enabled smart robots,
was recently opened in Wuhan, China. These robots, provided by a Beijing-based company called CloudMinds, can
clean and disinfect the premises, deliver medicine to the
patients, and measure their temperature. This facility, commonly referred to as the Smart Field Hospital, also employed
the use of various other IoT devices to ease the burden on the
hospital staff. Patients at the facility wore smart bracelets and
rings that synced with CloudMinds’ AI platform to enable the
health workers to continually track their patients’ vital signs,
including their temperature, heart rate, and blood oxygen
levels, without requiring to be physically present with them
at all times [145].
4) PATROL ROBOTS IN MULTIPLE CITIES OF CHINA
A local robotics company based out of Guangzhou, China,
has recently designed 5G police patrol robots on top of the
Advantech-developed edge computer MIC-770. These smart
robots, born at the intersection of AI, IoT, 5G, and cloud
computing technologies, are equipped with five infrared thermometers & high-resolution cameras that allow them to
measure the body temperatures of up to 10 people at once.
Furthermore, by employing the use of environmental sensing,
these robots can also determine if someone is wearing a mask
VOLUME 8, 2020 90257V. Chamola et al.: Comprehensive Review of the COVID-19 Pandemic
or not. Anytime the robot encounters someone who is not
wearing a mask or has high body temperature, it immediately
sends an alert to the local authorities [226]. These robots have
been deployed in public places of multiple cities in China,
including Shanghai, Guangzhou, and Guiyang.
E. CHALLENGES
Since the outbreak of the COVID-19, several technological solutions have been proposed for mitigating its impact.
Among them, IoT, drone technology, and AI have been at the
forefront. However, to realize the transformative potential of
these technologies, there is a need for a cellular network that
can overcome the bandwidth, latency, and flexibility issues
inherent to the current network technology. The responsibility
for this rests with the next-generation 5G cellular networks.
The integration of tools like UAVs, robots, and telemedicine
platforms with 5G-supported features like high-speed data
transmission, ultra-low latency, and advanced data analytics,
can allow for an efficient system for monitoring the crowds,
detecting infected individuals, and providing treatment to
them, all without the need for any physical human contact
(refer to Fig. 14). In the future, such an epidemic control
system also has the potential to be one of the building blocks
for the development of a more dynamic smart city management model [223]. However, at present, the implementation
of 5G networks faces several challenges, some of which are
mentioned below:
i) Since the deployment of 5G networks is still in nascent
stages, one of its pitfalls is the lack of infrastructure
to support their working. Furthermore, the high costs
associated with the installation and maintenance of 5G
networks have made its wide-scale deployment difficult
for governments and telecom operators.
ii) On their own, 5G networks cannot revolutionize the
healthcare sector. They can prove to be effective only
when used in tandem with other emerging technologies
like IoT, AI, and cloud computing.
iii) At present, there are no established guidelines that regulate the use of a patient’s confidential data collected
using 5G healthcare systems. Besides data confidentiality, several other security issues associated with the use
of 5G are yet to be resolved [221].
Although the wide-scale deployment of 5G networks in the
healthcare industry is likely to take a few years, an increasing
number of medical centers are already contemplating the
use of 5G-enabled healthcare systems to enhance the quality
of medical service and patient experience, reduce the cost
of medical care, and minimize the burden on healthcare
personnel [221].
XVIII. CONCLUSION
While the world continues to grapple with the impact of
the COVID-19 pandemic, complementary efforts of various
emerging technologies, such as IoT, UAVs, AI, blockchain,
and 5G, are endeavoring to alleviate its impact. Keeping
that as the foundation of this work, we offer some of the
latest insights on the COVID-19 pandemic. We begin this
paper with a comprehensive review of the COVID-19 itself,
in which we explore its clinical features, transmission mechanism, and diagnosis procedures. Following this, we discuss
the stages the disease goes through in the course of its spread.
We also list the various treatment efforts being made to
put an end to the pandemic and the preventive measures to
be followed till the time that is possible. To calibrate the
disastrous impact of the COVID-19, we also take a broad
look at the state of the global economy following its outbreak. In the thorough discussion post this, we dissect the
various technological interventions made in the direction of
COVID-19 impact management. Primarily, our discussion
focuses on the use of emerging technologies such as IoT,
drones, AI, blockchain, and 5G in mitigating the impact of
the COVID-19 pandemic. Till the time a cure for this disease
surfaces, the responsibility to manage and limit its impact
rests largely with these technologies.
ACKNOWLEDGMENT
The statements made herein are solely the responsibility of
the authors.




NEW_PAPER



SPECIAL SECTION ON EMERGING DEEP LEARNING
THEORIES AND METHODS FOR BIOMEDICAL ENGINEERING
Received April 30, 2020, accepted May 11, 2020, date of publication May 14, 2020, date of current version May 28, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2994762
CovidGAN: Data Augmentation Using Auxiliary
Classifier GAN for Improved Covid-19 Detection
ABDUL WAHEED1
, MUSKAN GOYAL 1
, DEEPAK GUPTA 1
, ASHISH KHANNA1
,
FADI AL-TURJMAN 2
, AND PLÁCIDO ROGERIO PINHEIRO 3,4, (Member, IEEE)
1Maharaja Agrasen Institute of Technology, New Delhi 110086, India
2Artificial Intelligence Department, Research Center for AI and IoT, Near East University, 99138 Mersin, Turkey
3State University of Ceará, Fortaleza 60714903, Brazil
4University of Fortaleza, Fortaleza 60811905, Brazil
Corresponding author: Deepak Gupta (deepakgupta@mait.ac.in)
ABSTRACT Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy
and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19.
Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This
has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy
of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning
networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because
the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short
time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images
by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called
CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized
to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85%
accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this
method will speed up COVID-19 detection and lead to more robust systems of radiology.
INDEX TERMS Deep learning, convolutional neural networks, generative adversarial networks, synthetic
data augmentation, COVID-19 detection.
I. INTRODUCTION
Coronavirus disease is a respiratory disease caused by severe
acute respiratory syndrome coronavirus 2 (SARS-CoV-2).
COVID-19 was initially detected in Wuhan, China,
in December 2019, and has spread worldwide since then leading to the ongoing 2020 coronavirus pandemic. More than
4.18 million cases and 286,000 deaths have been registered
in more than 200 countries and territories as of 12 May 2020.
Since no vaccines or cures exist, the only efficient way of
human protection against COVID-19 is to reduce spread by
prompt testing of the population and isolation of the infected
individuals.
Certain health symptoms combined with a chest X-ray
can be used to diagnose this infection. A chest X-ray can
be used as a visual indicator of coronavirus infection by
the radiologists. This led to the creation of numerous deep
The associate editor coordinating the review of this manuscript and
approving it for publication was Shuihua Wang .
learning models, and tests have shown that it is highly likely
that patients with COVID-19 infection are detected correctly
by using chest radiography images.
Convolutional neural networks (CNNs) have attained stateof-the-art performance in the field of medical imaging,
given enough data [1]–[4]. Such performance is accomplished by training on labeled data and fine-tuning its millions of parameters. CNNs can easily overfit on small
datasets because of the large number of parameters, therefore, the efficiency of generalization is proportional to the
size of the labeled data. With limited quantity and variety
of samples, the biggest challenge in the medical imaging
domain is small datasets [5]–[7]. The medical image collection is a very expensive and tedious process that requires
the participation of radiologists and researchers [6]. Also,
since the COVID-19 outbreak is recent, sufficient data of
chest X-ray (CXR) images is difficult to gather. We propose to alleviate the drawbacks by using synthetic data
augmentation.
91916 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 8, 2020A. Waheed et al.: CovidGAN: Data Augmentation
Data augmentation methods are employed to extend the
training dataset artificially. Current data augmentation techniques use simple modifications to incorporate affinity like
image transformations and color adjustments, such as scaling, flipping, converting, improving contrast or brightness,
blurring, and sharpening, white balance, etc [8]. This classical
data augmentation is fast, reliable, and easy. However, in this
augmentation, the changes are limited because it is structured
to turn an existing sample into a slightly altered sample.
In other words, classical data augmentation does not produce
completely unseen data. A modern, advanced form of augmentation is synthetic data augmentation which overcomes
the limitations of classical data augmentation. Generative
Adversarial Network (GAN) is one such innovative model
that generates synthetic images. It is a powerful method
to generate unseen samples with a min-max game without
supervision [9]. The general concept of the GANs is to use
two opposing networks (G(z) and D(x)), where one (G(z)
generator) produces a realistic image to trick the other net
that is equipped to better discriminate between the true and
false images (D(z) discriminator). The aim of the generator
is to minimize the cost value function V(D, G) whereas the
discriminator maximizes it [10]. Related works and contributions are discussed below.
A. RELATED WORKS
Recently, the GAN framework is used by many medical
imaging techniques. Zhao et al. [11] developed a multi-scale
VGG16 network and a DCGAN based model, Forward and
Backward GAN (F&BGAN) to generate synthetic images
for lung-nodules classification. Beers et al. [12] trained a
PGGAN (progressively grown generative adversarial network) to synthesize medical images of fundus pictures showing premature retinopathic vascular pathology (ROP) and
glioma multimodal MRI pictures. Dai et al. [13] applied
GAN in order to produce segmented images of lung and
heart from chest X-ray. A patch-based GAN was developed
in Nie et al. [14] to convert brain CT pictures to the corresponding MRI. They also suggested an automated image
optimization model. Xue et al. [15] suggested two GAN
networks called a Segmentor and a Critic which studied the
connection between a binary brain tumor segmentation map
and brain MRI pictures. Schlegl et al. [16] utilized GAN to
study the data distribution of healthy tissue using patches in
the retinal region. The GAN was then checked for anomaly
detection in retinal images on patches of both unseen and
healthy imagery.
The lack of data in medical imaging led us to explore ways
of expanding image datasets. In the present research, we are
focusing on improvements in COVID-19 detection. In order
to synthesize standard CXR images, we developed an Auxiliary Classifier Generative Adversarial Network (ACGAN)
based model.
In a research published in the journal Radiology [17], chest
radiography outperformed laboratory testing in the detection of 2019 novel coronavirus disease. The frequency of
anomalies in radiographical images rapidly increased after
the onset of symptoms and peaked during the days of illness.
The researchers in [18], [19] concluded that chest radiography should be used as the main COVID-19 screening method
(also known as SARS-CoV-2). In particular, CXR imaging
has various advantages like readily available and accessible,
easily portable, and it helps in the rapid prioritization of
COVID-19 suspected patients. Since the pandemic is recent,
there are only a limited number of CXR images available for
study. Therefore, we develop CovidGAN to generate artificial
training data for CNN. The generation of artificial data is
very effective in the case of small datasets and when the data
includes sensitive information. GANs can synthesize images
from scratch from any specific category and can produce
satisfactory results when combined with other methods.
Many research projects and innovations related to
COVID-19 have been proposed [20]–[22]. This paper, however, to the best of our knowledge is the first one to present a
GAN architecture for improvement in COVID-19 detection.
B. CONTRIBUTIONS
In this study, we use CNN for COVID-19 detection. CNNs
are extensively used in the field of computer vision. These
are widely used to examine visual imagery, and also work in
image classification. In the last few years, several studies of
medical imagery have applied CNNs and have recorded better
performance [6]. We combine synthetic CXR images generated using CovidGAN with our proposed CNN architecture.
This research has the following contributions:
1) Propose an Auxiliary Classifier Generative Adversarial
Network (ACGAN) based GAN, called CovidGAN for
the generation of synthetic CXR images.
2) Design a CNN-based model for COVID-19 detection.
3) Using CovidGAN for augmentation of training dataset
with the CNN model for improved detection of
COVID-19.
The remaining transposition is as follows. Section II defines
the dataset and the CNN architecture for COVID-19
detection. Section III elaborates on the method of synthetic data augmentation for the extension of the dataset.
Section IV and V show the results and conclusion of this
research, respectively. Section VI discusses the limitations of
this study.
II. COVID-19 DETECTION
This section describes the characteristics of the dataset used
and the CNN architecture for COVID-19 detection.
A. DATASET GENERATION
The dataset is composed of 1124 CXR images. More precisely, there are 403 images of COVID-CXR and 721 images
of Normal-CXR. To generate the dataset we collected the
images from three publicly accessible datasets: 1) IEEE
Covid Chest X-ray dataset [23] 2) COVID-19 Radiography Database [24] and 3) COVID-19 Chest X-ray Dataset
VOLUME 8, 2020 91917A. Waheed et al.: CovidGAN: Data Augmentation
Initiative [25]. The decision to develop the dataset on these
three datasets is driven by the fact that all of them are
open-sourced and completely available to the public and
research communities. The collected images are merged and
the duplicate images are removed from the dataset. Image
Hashing method is used to remove the duplicate images. This
method creates a hash value that uniquely identifies an input
image based on the contents of an image.
The most striking trend is the limited number of cases and
associated CXR pictures of COVID-19 that indicate the scant
availability of COVID-19 data in the public domain. Samples
of the dataset are given in Fig. 4 A.
B. CNN ARCHITECTURE
In this research, a VGG16 network is used for COVID-19
detection. A VGG16 architecture consists of twelve 3 × 3
convolutional layers. Some convolutional layers are followed by the max-pooling layer and finally, it has three
fully-connected layers in the end. The stride is fixed to 1 pixel
in all the convolutional layers. The five max-pooling layers
use a fixed stride of 2 and a 2 × 2 pixel filter. A padding
of 1 pixel is done for the 3 × 3 convolutional layers. All the
layers of the network use ReLU as the activation function.
The advantage of VGG16 is its simplicity and depth. Its deep
architecture extracts features with low spatial resolution and
give good results on image classification problems.
Our CNN uses VGG16 architecture which is connected
with four custom layers at the end. A global average pooling
layer is followed by a 64 units dense layer and a dropout layer
with 0.5 probability. Lastly, a softmax layer is attached to find
the prediction of the network.
The dataset consists of 932 training samples
(COVID-CXR: 331 images and Normal-CXR: 601 images)
and 192 testing samples (COVID-CXR: 72 images and
Normal-CXR: 120 images). The image preprocessing steps
involved are resizing and normalizing. Since the scale
of the images varies in the dataset, all the images are
resized to 112 × 112 × 3, using image processing SciKit.
Further, each image is normalized by rescaling the pixels
from [0, 255] to [0, 1]. Our CNN gets a fixed size CXR image
of 112 × 112 × 3.
Since a VGG16 network has a million parameters,
it requires a lot of training data and computing resources.
Therefore, fine-tuning is performed to modify the parameters
of the pre-trained VGG16 model so that it can adapt to
the new task in hand. The custom layers of the model are
trained, without updating the weights of VGG16 layers. Thus,
fine-tuning updates the weights of the custom layer. This
allows the new output layers to learn to interpret the learned
features of the VGG16 model; which is achieved by setting
the ‘‘trainable’’ property on each of the VGG layers to False
before training.
Training and implementation details: Adaptive Moment
Estimation (Adam) [26] is used as the optimizer and categorical_cross_entropy as the loss function. Adam is a
method for stochastic optimization which calculates adaptive
FIGURE 1. ACGAN Architecture.
learning rates for parameters. ReLU is used as the activation
function of the network. The proposed CNN had approximately 14 million parameters. The learning rates of Adam
are controlled by the parameter beta. The hyperparameters
used for training are learning_rate = 0.001, beta = 0.9,
and batch_size = 16. The network is trained for 25 epochs
and after training, 85% accuracy is achieved. The proposed
architecture is trained and tested using Keras deep learning
library.
III. GENERATING SYNTHETIC IMAGES
The major drawback in the above CNN model was the small
dataset. To extend the training data and boost the results
of COVID-19 detection, we increased the data by synthetic
augmentation. This section elaborates the method of augmentation in detail.
A. AUXILIARY CLASSIFIER GENERATIVE ADVERSARIAL
NETWORK (ACGAN)
Generative Adversarial Networks (GANs) utilizes two neural
networks that compete with one another to create new virtual
instances of data which can be transmitted as real data [10].
GANs are extensively used for image generation. In this
research, we use a version of GAN called Auxiliary Classifier
GAN to perform data augmentation.
GANs find it difficult to generate high-resolution samples
from highly variable data sets. Conditional GAN (CGAN) is
a variant of GAN which allows the model to rely on outside
information to improve the sample quality. In CGAN, a latent
space point and a class label are given as input to the generator
and it attempts to generate an image for that class [27]. The
discriminator is provided with an image as well as a class
label, and it decides if the image is true or false.
AC-GAN is a type of CGAN that transforms the discriminator to predict a particular image’s class label instead of
receiving it as an input. It stabilizes the training process and
allows the generation of high-quality images while learning
a representation that is independent of the class label [28].
ACGAN architecture is shown in Fig. 1.
ACGAN applies the associated class label c and noise z to
each produced sample [28]. The generator G utilizes both to
produce Xfake = G(c,z) images. The discriminator D gives
91918 VOLUME 8, 2020A. Waheed et al.: CovidGAN: Data Augmentation
FIGURE 2. CovidGAN complete Architecture with generator and discriminator.
FIGURE 3. Layered Architecture of CovidGAN generator.
a distribution of probability over class labels and sources.
P(S | X), P(C | X) = D(X).
The log-likelihood of source class Ls and correct class Lc
forms the objective function.
Lc = E[log P(C = c | Xreal)]
+ E[log P(C = c | Xfake)] (1)
Ls = E[log P(S = real | Xreal)]
+ E[log P(S = fake | Xfake)] (2)
D maximizes Ls + Lc and G maximizes Lc - Ls
. We propose
a GAN architecture based on ACGAN called CovidGAN,
that produces synthetic images of CXR to improve Covid-19
detection.
B. SYNTHETIC IMAGE AUGMENTATION USING CovidGAN
1) COVIDGAN GENERATOR ARCHITECTURE
The generator takes a latent vector of noise (which is a
random normal distribution with 0.02 standard deviation)
and class label as input, to output a single 112 × 112 × 3
image. The class label is passed through an embedding layer
of 50 dimensions for categorical input. Then, it is further
passed through a 7 × 7 node dense layer with linear activation
to output a 7 × 7 × 1 tensor. The point in latent space is
interpreted by a 1024 × 7 × 7 node dense layer to give
activations that can be reshaped to 7 × 7 × 1024 to get many
copies of a low-resolution version of the output image. The
tensors generated from class label and noise (that is 7 × 7 × 1
and 7 × 7 × 1024) are concatenated and passed through four
transpose convolutional layers to upsample the 7 × 7 × 1024
feature maps, first to 14 × 14 × 512, then 28 × 28 × 256, then
56 × 56 × 128 and finally to 112 × 112 × 3. Each transpose
convolutional layer, except for the last one, is followed by a
batch normalization layer and an activation layer. The model
uses methodologies such as ReLU activation, a kernel of
size (5, 5), stride of (2, 2) and a hyperbolic tangent (tanh)
activation function in the output layer. The total parameters
of the generator are approximately 22 million. The output of
the generator is an image of shape 112 × 112 × 3. Layered
architecture of the generator is given in Fig. 3.
2) COVIDGAN DISCRIMINATOR ARCHITECTURE
The discriminator model is a CNN architecture that has two
output layers and takes one image of shape 112 × 112 × 3
as input. The model outputs a prediction if the image is real
VOLUME 8, 2020 91919A. Waheed et al.: CovidGAN: Data Augmentation
FIGURE 4. A: Real images in dataset, B: Synthetic images generated by CovidGAN.
(class = 1) or fake (class = 0), and also outputs the class label
that is COVID-CXR or Normal-CXR. Each block of discriminator represents a convolutional layer, which is followed by
a batch normalization layer, an activation layer and a dropout
layer with 0.5 probability. The input is downsampled from
112 × 112 × 32 to 56 × 56 × 64, then 28 × 28 × 128,
then 14 × 14 × 256 and finally to 7 × 7 × 512. The model
uses a kernel of size (3, 3), a stride that changes alternatively
from (1, 1) to (2, 2) and LeakyReLU activation function with
a slope of 0.2. Discriminator has approximately 2 million
parameters. The final output is flattened and the probability of
the image’s reality and the probability of the image belonging
to each class is estimated. The first output layer with sigmoid
function predicts the realness of the image. The second output
layer with softmax function predicts the label.
3) TRAINING PROCEDURE
The generator model is stacked on top of the discriminator model. Initially, the layers of the discriminator are
set as non-trainable. Thus, only the generator gets updated
via the discriminator. This forms a composite model of
GAN, which we call CovidGAN. The CovidGAN is trained
to synthesize CXR images for both COVID-CXR and
Normal-CXR class. The image preprocessing step involved
resizing (112 × 112 × 3) and normalizing the images from
[0, 255] to [−1, 1]. (Normalization is a process that changes
the range of pixel values. Its purpose is to convert an input
image into a range of pixel values that are more familiar
or normal to the senses). Adam is used as the optimizer
function. Adam is easy to implement, works on sparse gradients, requires little memory space, and is computationally
efficient. Therefore, Adam is the best choice for the optimization of the model. The following hyperparameters are
used for training CovidGAN: batch_size = 64, learning_rate
= 0.0002, beta = 0.5 (beta is the momentum of Adam optimizer), number of epochs = 2000. CovidGAN has approximately 24 million parameters and it takes around 5 hours
to train the model. The GAN gets optimized using two
loss functions, one for each output layer of the discriminator. The first layer uses binary_crossentropy and second
sparse_categorical_crossentropy. The complete architecture
is trained using Keras deep learning library.
The complete CovidGAN architecture is shown in Fig. 2.
The synthetic images generated from CovidGAN are shown
in Fig. 4 B. CovidGAN generated 1399 synthetic images of
Normal-CXR and 1669 synthetic images of COVID-CXR.
IV. RESULTS AND DISCUSSION
In this section, we analyze the effect of synthetic data augmentation technique used for improved COVID-19 detection. Initially to perform COVID-19 detection we used the
CNN classifier defined in section II. Then to improve the
performance of CNN we used synthetic data augmentation technique. The performance of the model is observed
on 192 testing samples (the testing samples consists of only
actual data of COVID-CXR: 72 images and Normal-CXR:
120 images). We found that synthetic data augments produced (shown in Fig. 4 B) from CovidGAN enhanced the
performance of CNN. An accuracy of 85% is achieved with
actual data (with 0.89 precision and 0.69 recall for COVID
class) that increased to 95% with synthetic augments (with
0.96 precision and 0.90 recall for COVID class). A detailed
analysis is shown in Table 1. The results and Environment
Setup are presented in this section.
A. EVALUATION MEASURES AND ENVIRONMENT SETUP
The implementation of CNN and CovidGAN architecture is
done using Keras [29] deep learning library. All training and
testing processes are performed using Nvidia RTX 2060 GPU
with 6GB memory and Intel Core i7 9th generation CPU with
16GB RAM.
We used precision, recall (or sensitivity), F1-score, and
specificity to measure and analyze the performance of the
CNN model using synthetic data augmentation technique.
Precision is the classifier’s ability to not mark a negative
sample as positive and recall is the classifier’s ability to
91920 VOLUME 8, 2020A. Waheed et al.: CovidGAN: Data Augmentation
TABLE 1. Performance comparison for Covid-19 detection.
classify all those with the disease correctly (true positive
rate). F1-score is the weighted average of precision and recall.
Specificity is the ability of the classifier to correctly identify
those without the disease (true negative rate). In addition
to total accuracy, the macro-average and weighted average
are also calculated. The formulas of the measures are given
below:
precision =
TP
TP + FP
(3)
sensitivity = recall =
TP
TP + FN
(4)
F1score = 2 ∗
recall ∗ precision
recall + precision
(5)
specificity =
TN
TN + FP
(6)
Total accuarcy =
PTP
Total Covid19 samples
(7)
where TP is true positives, FP is false positives, and FN is
false negatives. Macro-average finds unweighted mean for
each label without taking the label imbalance into account.
Weighted average is calculated by using true instances of each
label.
B. PERFORMANCE ANALYSIS OF SYNTHETIC DATA
AUGMENTATION
Table 1 analyzes the COVID-19 detection performance of
CNN with synthetic data augmentation technique. We can see
that when CNN is used on actual data (CNN-AD), the detection accuracy is only 85% (with 69% sensitivity and 95%
specificity). As described in the previous section, we used
CovidGAN data augmentation to generate synthetic images
of CXR. It is observed that training CNN with actual and
synthetic images (CNN-SA) yields 95% accuracy (with 90%
sensitivity and 97% specificity), which is a clearly a better
performance rate.
An increase in precision and recall is also recorded for
both COVID (0.96 precision and 0.90 recall) and Normal
(0.94 precision and 0.97 recall) class. This suggests that the
synthetic augments produced have meaningful features that
help in the enhancement of CNN performance.
C. VISUALIZATION USING PCA
We use the PCA visualization and confusion matrix for analysis of the results. Principal Component Analysis (PCA) is a
method which reduces the dimension of feature space such
that new variables are independent [30], [31]. PCA retains
large pair distances in order to optimize variance.
Steps involved in PCA:
1) Standardization: The mean of all the dimensions of
the dataset is calculated, except the labels. The data is scaled
so that each variable contributes equally to analysis. In the
equation given below, z is the scaled value, x is the initial,
and µ and σ are mean and standard deviation, respectively.
z =
x − µ
σ
(8)
2) Covariance Matrix Computation: Covariance is measured between 2 dimensions. In a 3-dimensional data set
(A, B, C), the covariance between the A and B dimensions,
the B and C dimensions, and the A and C dimensions is measured. The covariance of two variables X and Y is computed
using the following formula given below:
Cov(X, Y ) =
1
n − 1
Pn
i=1
(Xi − X
0
)(Yi − X
0
) (9)
where X
0
and Y
0
are arithmetic mean of X and Y respectively,
and n is number of observations. The resultant covariance
matrix would be a square matrix of n x n dimensions, i.e for
a 3 dimensional data the covariance matrix will be 3 × 3.
3) Compute Eigenvectors and corresponding Eigenvalues: The eigenvector and corresponding eigenvalues are
computed for the covariance matrix. The corresponding
eigenvalue is the factor by which the eigenvector is scaled.
The eigenvector of the matrix A as a vector u that satisfies
the following equation:
Au = λu (10)
where λ is the eigenvalue. This means that the linear transformation is defined by λ and the equation can be re-written
as:
(A − λI)u = 0 (11)
where I is the identity matrix.
VOLUME 8, 2020 91921A. Waheed et al.: CovidGAN: Data Augmentation
FIGURE 5. PCA visualization.
FIGURE 6. Confusion matrix for Covid-19 detection using CNN with actual
data.
4) Choose k eigenvectors with the largest eigenvalues:
The eigenvectors with respect to their decreasing order of
eigenvalues are sorted, k is chosen out of them, where k is
the number of dimensions in the dataset.
5) Recasting data along Principal Components’ axes
In the last step, our samples are transformed onto the new
subspace by re-orienting data from the original axes to the
ones that are now represented by the principal components.
Final Data = Feature - Vector * Transpose (Scaled (Data))
So lastly, principal components are computed and the data
points in accordance with the new axes are projected.
The features or high-dimensional data are taken from the
last layer of CNN. The features of the real images and synthetic images are plotted in Fig. 5. We can see that synthetic
images (shown in red and green) are close to real images
(shown in purple and blue).
The confusion matrices for COVID-19 detection are plotted in and Fig. 6 and Fig. 7. The confusion matrix is used
to summarize the performance of the CovidGAN model.
We recorded the performance of the model for 192 testing
samples (COVID-CXR: 72 images and Normal-CXR: 120
images). In the dark blue colored diagonal of the matrix are
the correct classifications, whereas all other entries are misclassifications. It can be seen in Fig. 6 that 22 COVID-CXR
images are misclassified as Normal-CXR (false negative)
and 6 Normal-CXR images are misclassified as COVID-CXR
(false positive) when CNN is trained on actual data. But in
FIGURE 7. Confusion matrix for Covid-19 detection using CNN with
synthetic data augmentation and actual data.
Fig. 7 only 7 images are misclassified as Normal-CXR when
CNN is trained on actual data and synthetic augments (generated from CovidGAN). Also, the number of false positives
is reduced to 3.
V. CONCLUSION
In this research, we proposed an ACGAN based model
called CovidGAN that generates synthetic CXR images to
enlarge the dataset and to improve the performance of CNN
in COVID-19 detection. The research is implemented on a
dataset with 403 COVID-CXR images and 721 Normal-CXR
images. Our limited dataset highlights the scarcity of medical
images in the research communities.
Initially, the proposed CNN architecture is used to classify
the two classes (that is COVID-CXR and Normal-CXR).
Further, the performance of CNN with synthetic data augmentation technique is investigated.
Synthetic data augmentation adds more variability to the
dataset, by enlarging it. CovidGAN is used to generate synthetic images of chest X-ray (CXR). An improvement in classification performance from 85% to 95% accuracy is recorded
when CNN is trained on actual data and synthetic augments.
An increase in precision and recall of both the classes are also
observed.
Our findings show that synthesized images of CXR
have significant visualizations and features that help in the
detection of COVID-19. Lastly, a detailed analysis of the
performance of our CNN architecture with synthetic data
augmentation technique is given in Table 1.
In conclusion, we proposed a way to enhance the accuracy
of COVID-19 detection with minimal data by generating
synthetic medical images of chest X-ray. Despite its excellent
results, CovidGAN is not intended to compete with laboratory testing. Instead, we hope that this approach leads to
stronger and more reliable radiology systems.
In the future, we intend to improve the quality of the
synthetic CXR images by training a Progressive Growing
GAN [32].
91922 VOLUME 8, 2020A. Waheed et al.: CovidGAN: Data Augmentation
VI. LIMITATIONS
This analysis still has a variety of limitations. Firstly, GAN
architecture and training can be improved further. Secondly,
we used a small dataset because of the time constraints and
difficulty in gathering enough data. The quality of the synthetic samples produced in this research could be improved
by integrating more labeled data which improves the learning
process of GAN. Thirdly, the dataset is obtained from various
sources and cross-center validations were not conducted in
this analysis. We have made every effort to ensure that the
data collected is correctly labeled. Any mistake in data labeling, however, would probably affect the results reported. Such
an impact could be especially pronounced when the dataset
is small. Lastly, the only way to reliably detect COVID-19 is
through medical assistance and clinical testing. The findings
of this paper provide promising results that encourage the
use of this approach to make more robust radiology systems.
This paper also promotes a systematic large-scale gathering
of COVID-CXR images.
ACKNOWLEDGMENT
This research is dedicated to those impacted by the
COVID-19 pandemic and those who are assisting in whatever way they can to fight this war. We would also like to
thank doctors, nurses and all the healthcare providers who
are putting their lives at risk in combating the coronavirus
outbreak.




NEW_PAPER


56 The Radio Science Bulletin No 372 (March 2020)
Telecommunications Health and Safety
James C. Lin
University of Illinois at Chicago
851 South Morgan Street, M/C 154
Chicago, IL 60607 USA
E-mail: lin@uic.edu
The Covid-19 Pandemic and 5G Cellular 
Telecommunication Systems
Recently, there were several odd or unusual reports 
coming out of the UK about linking the coronavirus 
disease (COVID-19) pandemic to the rollout of 5G 
communication systems [1]. It sounded rather bizarre; 
even as a conspiracy theory, it did not make sense! While 
both 5G and COVID-19 are global phenomena happening 
at around the same time, it boggles the mind how the two 
got entangled. On second thought, it is not as shocking as 
it may seem upon fi rst encounter! 
By now (as I write this in early May 2020), the 
coronavirus has been established as a global pandemic with 
rapidly increasing case counts and fatalities worldwide [2]. 
The impact and interruptions of computer “viruses” on 
private citizen, commerce, corporation, and government 
operations and common lives have been widely publicized 
and recognized for quite some time, now. They have been 
slowly embedded into the public consciousness as an 
undesirable hi-tech affl iction still in search of an eff ective 
remedy. Moreover, for a couple of years if not longer, various 
groups have been broadcasting and escalating politicized 
or overblown concerns about 5G security challenges and 
threats.
Aside from the array of socio-technical issues 
surrounding the 5G cellular mobile network and technology, 
the palpable politicization of 5G has caused bewilderment 
and consternation in its deployment. It has certainly impacted 
the pace with which investment decisions are being made: 
namely, to engage5G as a hare or tortoise.
The onset of coronavirus COVID-19, a complex and 
devastating global pandemic, on top of a public already 
jittery about computer viruses and 5G wireless cellular 
technology perhaps conjures up horrors in some people’s 
minds of being attacked by pandemic viruses or malevolent 
cells, even the type associated with 5G cell phones. The 
script is not neoteric. Scapegoating has been a cultural norm 
in some quarters for no less than 2000 years. 
The fact is that there is no link between the COVID-19 
virus and 5G cell-phone technology or 5G communication 
base-station towers. These are totally diff erent constructs: 
they are not even close. None of the conspiracy theories 
that try to link 5G and the coronavirus scientifi cally make 
any sense. The electromagnetic radiation from 5G devices 
and systems is not carrying the COVID-19 virus or any 
other microbial virus into which humans can come into 
contact, nor can infect anyone.
Proponents of 5G mobile technology hail 5G as a 
faster and more secure technology than its predecessors, 
3G and 4G systems, which incidentally are not necessarily 
entirely secure, either. They can be just as vulnerable to 
attempts such as real-time location tracking and surveillance 
practices. However, there are 5G security concerns and 
issues that can be somewhat more complicated. A central 
vulnerability or key threat is that it may allow spying 
on users: not new, either. Nevertheless, this is a system 
architecture and technology or regulatory issue, but not a 
biological or health eff ect matter or challenge. 
5G cellular mobile technology is a telecommunication 
platform that is multifaceted in radio-frequency (RF) 
engagement and varied in operational scope and 
performance. It includes an extremely wide range of multiple The Radio Science Bulletin No 372 (March 2020) 57
RF bands. Its frequency coverage may be roughly separated 
into two ranges: the sub-6 GHz bands, and 24 GHz to 
60 GHz frequencies that reach well into the millimeterwave region. The frequency ranges have often been further 
divided into low-band 5G, mid-band 5G, and high-band 
5G. Low-band 5G begins at about 400 MHz and often uses 
existing or previous 3G or 4G frequencies or newly opened 
frequencies to operate, which, for example, may overlap with 
the current 4G band. The mid-band 5G especially includes 
the frequencies around 3 GHz and 4 GHz. However, the 
primary 5G technological advances are associated with the 
high-band 5G, promising performance bandwidths as high 
as 20 GHz and multiple-input and multiple-output (MIMO), 
using 64 to 256 antennas at short distances, and off ering 
performance up to 10 times that of the current 4G networks.
From the perspective of frequency allocation, 5G 
encompasses an enormous range, from 3 GHz to 60 GHz 
and beyond, in one giant skip from 4G. Even with current 
technological advances, the demand and performance 
challenges clearly vary immensely from the low to high 
bands. The anticipated performance bandwidth of 20 GHz 
obviously is not viable or supportable at low band. By design 
default or spectrum necessity, the bandwidth performance 
will only be accomplished by leapfrogging to the high-band 
5G. For biological matters, it is not obvious whether the 
biological responses to high-band 5G radiations would 
be akin to earlier generations or low-band 5G radiations, 
given the distinctive characteristics of mm-wave and its 
interaction with the complex structure and composition of 
pertinent biological tissues. 
In 2011, the World Health Organization’s (WHO’s) 
International Agency for Research on Cancer (IARC) 
classifi ed exposure to RF radiation as a possible carcinogen 
to humans. The IARC had then evaluated available scientifi c 
studies and concluded that while evidence was incomplete 
and limited, especially regarding results from animal 
experiments, epidemiological studies of humans reported 
that increased risks for gliomas (a type of malignant brain 
cancer) and acoustic neuromas (or acoustic schwannomas – 
a non-malignant tumor of Schwann-cell-sheathed auditory 
nerves on the side of the brain) among heavy or long-term 
users of cellular mobile telephones are suffi ciently strong 
to support a classifi cation of being possibly cancer causing 
in humans for exposure to RF radiation [3, 4].
The classification of RF radiation as possibly 
carcinogenic to humans is third on the IARC groupings 
of carcinogenic risk to humans. The highest category is 
Group 1, which is reserved for agents that are found to 
be carcinogenic to humans. It is followed by Group 2A: 
probably carcinogenic to humans; 2B: possibly carcinogenic 
to humans; then Group 3: not classifi able as to its 
carcinogenicity to humans; and lastly, Group 4: probably 
not carcinogenic to humans. 
Recently, the National Toxicology Program (NTP) of 
the US National Institute of Environmental Health Science 
(NIEHS) reported observations of two types of cancers in 
laboratory rats given life-long exposure to RF radiation used 
for 2G and 3G wireless cellular mobile telephone operations 
[5]. This was the largest health eff ect study ever undertaken 
by NIEHS/NTP. It concluded, among other observations, 
that there was statistically signifi cant and “clear evidence” 
that the RF radiation had led to the development of malignant 
schwannoma (a rare form of tumor) in the heart of male 
rats. Further, there was “equivocal evidence” for the same 
schwannoma risk among female rats. NTP also noted that 
there were unusual patterns of cardiomyopathy, or damage to 
heart tissue, in both RF-exposed male and female rats when 
compared with concurrent control animals. In addition, 
based on statistical signifi cance, the pathology fi ndings 
showed indications of “some evidence” for RF-dependent 
carcinogenic activity in the brain of male rats, specifi cally 
glioma. However, the fi ndings for female rats were deemed 
as providing only “equivocal evidence” for malignant 
gliomas when compared with concurrent controls [6, 7].
Note that the NTP uses fi ve categories of evidence for 
carcinogenic activity to classify the strength of evidence 
observed in their reports: “clear evidence” and “some 
evidence” for positive fi ndings; “equivocal evidence” for 
uncertain results; “no evidence” for no observable eff ects; 
and “inadequate study” for results that cannot be evaluated 
because of major experimental fl aws.
Shortly after the NTP report, the Cesare Maltoni 
Cancer Research Center at the Ramazzini Institute 
in Bologna, Italy, published the fi nal results from its 
comprehensive study on carcinogenicity in rats exposed 
(either lifelong or prenatal until death) to 2G/3G, 1800 MHz 
RF radiation [8]. The study involved whole-body exposure 
of male and female rats under plane-wave equivalent or 
far-zone exposure conditions. The authors estimated that the 
whole-body SARs were roughly 0.001 W/kg, 0.03 W/kg, and 
0.1 W/kg during exposures of 19 h/day for approximately 
two years. A statistically signifi cant increase in the rate of 
schwannomas in the hearts of male rats was detected for the 
highest RF exposure. Furthermore, an increase in the rate 
of heart Schwann cell hyperplasia was observed in exposed 
male and female rats at the highest RF exposure, although 
this was not statistically signifi cant. An increase in the rate 
of gliomas was observed in exposed female rats at the 
highest exposure level, but it was not deemed statistically 
signifi cant [9]. It is important to note that the recent NTP and 
Ramazzini RF exposure studies presented similar fi ndings 
in heart schwannomas and brain gliomas. Two relatively 
well-conducted RF exposure studies employing the same 
strain of rats thus showed consistent results in signifi cantly 
increased cancer risks.
More recently, an Advisory Group for IARC has 
recommended including re-evaluation of carcinogenicity 
of human exposure to RF radiation, with high priority, in 
their Monograph series [10]. 58 The Radio Science Bulletin No 372 (March 2020)
As mentioned above, the 5G frequency domain 
is divided into low, mid, and high bands. The operating 
frequencies at low and mid bands can overlap with the 
current 4G band at 6 GHz or below. The biological eff ects of 
RF radiations at these lower-frequency bands are thus likely 
to be comparable to 2G, 3G or 4G. However, the scenarios 
of high band 5G, especially for 24 GHz to 60 GHz in the 
mm-wave region for high-capacity, short-range wireless 
data communications, are relatively recent new arrivals, 
and pose considerable challenge to health-risk assessment.
There is a paucity of data on permittivity and 
coupling such as refl ection, transmission, and induced 
energy deposition in biological tissues in the mm-wave 
frequency band.
In principle, at mm-wave frequencies, the induced 
fi elds and energy deposition in biological medium can 
be determined in much the same manner as for RF if the 
permittivity of the relevant biological tissues at these 
frequencies is known. Although there were some earlier 
extrapolations based on Debye formulas and using complex 
dielectric permittivity of the skin at lower frequencies, 
some measurements for skin within the mm-wave range are 
available for humans [11] and rodents [12]. Note that skin 
tissue is not homogeneous but consists of multiple layers 
of stratum corneum, epidermis, and dermis. Moreover, it 
is diff erentiated according to body location: for example, 
forearm and palm skins have thin and thick stratum corneum, 
respectively. 
It has been shown that the mm-wave permittivity of 
diff erent skin layers may be described by the Debye equation 
with a single relaxation time [13]. Measured data for human 
skin in the frequency range of 37 GHz to 74 GHz showed that 
the measured results tended to be lower compared to earlier 
extrapolations. More importantly, at mm-wave frequencies, 
the permittivity of skin is governed by cutaneous free water 
content. Available information for 30 GHz to 90 GHz thus 
indicates that the behavior of relative permittivity follows 
that of the lower RF frequencies. Specifi cally, the real and 
imaginary parts of permittivity for skin decrease from 20 
to 6 and 20 to 12, respectively. 
The power refl ection coeffi cients for frequencies from 
37 GHz to 74 GHz decreased from 60% to 45% and 40% 
to 20% for skin on the forearm and palm, respectively. 
The power transmission coeffi cient for skin on the forearm 
showed an increase from 55% to 65%, respectively, between 
30 GHz and 90 GHz. It is noteworthy that a thick stratum 
corneum in the palm causes an increase in transmission 
because of the layer-matching phenomenon at higher 
mm-wave frequencies. The penetration depth of a plane 
wave fi eld decreases from 0.8 mm to 0.4 mm and 1.2 mm 
to 0.7 mm for skin on the forearm and palm, respectively, 
between 30 GHz and 90 GHz. Induced energy deposition 
increases with mm-W frequency. However, at the highest 
frequencies the energy deposition in the deeper regions 
inside the skin is lower because of the reduced penetration 
depth at these frequencies [14].
Studies on mm-wave interactions aimed both toward 
biological eff ects and medical applications began nearly 
50 years ago, most notably in the former Soviet Union. A 
comprehensive review of research on biological eff ects of 
mm-waves from the former Soviet Union showed that at 
intensities of 100 W/m2
 or less, mm-wave can aff ect cell 
growth and proliferation, enzyme activity, genetic status, 
function of excitable membranes, peripheral receptors, and 
other biological systems [15]. 
A recently published review included 45 in vivo 
studies conducted using laboratory animals and other 
biological preparations, and 53 in vitro studies involving 
primary cells and cultured cell lines [16]. The review was 
based on published data from scientifi c papers written in 
English available through the end of 2018 using 6 GHz to 
100 GHz as the RF source. However, because fewer studies 
were reported at 30 GHz or below and at frequencies higher 
than 90 GHz, the review mainly covered published studies 
conducted in the mm-wave frequency range from about 
30 GHz to 65 GHz.
This industry-supported review noted that aside 
from the wide frequency ranges, the studies were diverse 
both in subjects and end points investigated. Biological 
eff ects were observed to occur both in vivo and in vitro 
for diff erent biological endpoints studied. Indeed, the 
percentage of positive responses at non-thermal levels in 
most frequency groups was as high as 70%. (Higher mmwave intensities, up to 200 W/m2
, did not seem to cause 
any greater responses.) For example, in the 53 in vitro 
studies involving primary cells ( n  24 ) or cell lines (
n  29 ), approximately 70% of the primary cell studies 
and 40% of the cell line investigations showed eff ects that 
were related to mm-wave exposure. However, the protocol 
applied for control of biological target or culture medium 
temperature during mm-wave exposure was unclear in a 
large fraction of these studies. 
While many of these investigations with mmwave exposures reported biological responses, there is 
inconsistency in the dependence of biological eff ects and 
mm-wave intensity used for exposure. The number of 
reported in vitro and in vivo laboratory investigations were 
also modest and diverse, considering the wide 5G mmwave frequency domain. The jury on biological eff ects or 
health impact is still out on 5G. Moreover, there is a lack of 
ongoing controlled laboratory investigations. Simply put, 
the existing scientifi c data is inadequate for any reliable 
assessment or conclusion with confi dence.




NEW_PAPER


Received May 13, 2020, accepted June 17, 2020, date of publication June 19, 2020, date of current version July 1, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3003810
Iteratively Pruned Deep Learning Ensembles
for COVID-19 Detection in Chest X-Rays
SIVARAMAKRISHNAN RAJARAMAN 1
, (Member, IEEE), JENIFER SIEGELMAN2
,
PHILIP O. ALDERSON3
, LUCAS S. FOLIO4,5, LES R. FOLIO6
,
AND SAMEER K. ANTANI 1
, (Senior Member, IEEE)
1Lister Hill National Center for Biomedical Communications, National Library of Medicine, Bethesda, MD 20894, USA
2Takeda Pharmaceuticals, Cambridge, MA 02139, USA
3School of Medicine, Saint Louis University, St. Louis, MO 63104, USA
4Functional and Applied Biomechanics Section, Clinical Center, National Institutes of Health, Bethesda, MD 20892, USA
5Walt Whitman High School, Bethesda, MD 20817, USA
6Radiological and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, MD 20894, USA
Corresponding author: Sivaramakrishnan Rajaraman (sivaramakrishnan.rajaraman@nih.gov)
This work was supported by the Intramural Research Program of the National Library of Medicine (NLM), and the U.S. National Institutes
of Health (NIH).
ABSTRACT We demonstrate use of iteratively pruned deep learning model ensembles for detecting
pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus
(2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are
trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific
feature representations. The learned knowledge is transferred and fine-tuned to improve performance
and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or
COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and
improve memory efficiency. The predictions of the best-performing pruned models are combined through
different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that
the weighted average of the best-performing pruned models significantly improves performance resulting in
an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The
combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning
resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening
using chest radiographs.
INDEX TERMS COVID-19, convolutional neural network, deep learning, ensemble, iterative pruning.
I. INTRODUCTION
Novel Coronavirus disease 2019 (COVID-19) is caused
by the new Severe Acute Respiratory Syndrome
Coronavirus 2 (SARS-CoV-2) that originated in Wuhan in
the Hubei province in China and has spread worldwide.
The World Health Organization (WHO) declared the outbreak a pandemic on March 11, 2020 [1]. The disease is
rapidly affecting worldwide population with statistics quickly
falling out of date. As of April 12, 2020, there are over
1.8 million confirmed cases reported globally with over
100,000 reported deaths. Lung disease that causes difficulty
in breathing has been reported as an early indicator along
with hyperthermia in the COVID-19 infected population [1].
The associate editor coordinating the review of this manuscript and
approving it for publication was Victor Hugo Albuquerque .
The lung abnormalities caused by non-2019-nCOV viruses
are observed as peripheral or hilar and visually similar to,
yet often distinct from, viral pneumonia and other bacterial
pathogens [2].
Reverse transcription-polymerase chain reaction
(RT-PCR) tests are performed to detect the presence of
the virus and are considered the gold standard to diagnose
COVID-19 infection. However, they are reported to have
variable sensitivity and in some geographic regions may not
be widely available [3]. While not currently recommended
as primary diagnostic tools, chest X-rays (CXRs) and computed tomography (CT) scans have been used to screen for
COVID-19 infection and evaluate disease progression in
hospital admitted cases [3], [4]. While chest CT offers greater
sensitivity to pulmonary disease, there are several challenges
to its use. These include the non-portability, the requirement
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 115041S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 1. Graphical abstract of the proposed study.
to sanitize the room and equipment between patients followed
by a delay of at least an hour [4], the risk of exposing
the hospital staff and other patients, and persons under
investigation (PUIs) to the virus. Although not as sensitive,
portable CXRs are considered as an acceptable alternative
[4] since the PUIs can be imaged in more isolated rooms,
limiting personnel exposure and because sanitation is much
less complex to obtain than with CT.
Automated computer-aided diagnostic (CADx) tools
driven by automated artificial intelligence (AI) methods
designed to detect and differentiate COVID-19 related thoracic abnormalities should be highly valuable given the heavy
burden of infected patients. This is especially important in
locations with insufficient CT availability or radiological
expertise and CXRs produce fast, high throughput triage such
as in a mass casualty [5]. Automated approaches, once validated, have been shown to reduce inter- and intra-observer
variability in radiological assessments [6]. Additionally,
CADx tools have gained immense significance in clinical
medicine by supplementing medical decision making and
improving screening and diagnostic accuracy [7]. These tools
combine elements of radiological image processing with
computer vision for identifying typical disease manifestations and localizing suspicious regions of interest (ROI).
At present, recent advances in machine learning, particularly
data-driven deep learning (DL) methods using convolutional
neural networks (CNNs), have shown promising performance
in identifying, classifying, and quantifying disease patterns
in medical images. This is particularly true for CT scans
and CXRs [7]. These models learn the hierarchical feature
representations from medical images to analyze for typical
disease manifestations and localize suspicious densities for
ROI evaluation [7].
In this study, we highlight the benefits offered through the
use of an ensemble of iteratively pruned DL models toward
distinguishing CXRs showing COVID-19 pneumonia-related
opacities, from bacterial pneumonia, and normals using publicly available CXR collections. Fig. 1 shows the graphical abstract of the proposed study. Fig. 2 shows instances
of CXRs being normal, showing bacterial pneumonia, and
COVID-19-related pneumonia.
A custom CNN and a selection of pretrained CNN models are trained on a large-scale selection of CXRs to learn
CXR modality-specific feature representations. The learned
knowledge then is transferred and fine-tuned to classify the
normal and abnormal CXRs. We leverage the benefits of
modality-specific knowledge transfer, iterative pruning, and
FIGURE 2. CXRs showing (A) clear lungs, (B) bacterial pneumonia
manifesting as consolidations in the right upper lobe and retro-cardiac
left lower lobe, and (C) COVID-19 pneumonia infection manifesting as
peripheral opacities in the left lung.
ensemble strategies to reduce model complexity, improve
robustness, generalization, and inference capability of the DL
model.
The remainder of the manuscript is organized as follows:
Section II discusses prior works. Section III discusses
the datasets and methods used toward modality-specific
knowledge transfer, iterative pruning, and ensemble learning. Section IV elaborates on the results obtained, and
Section V concludes the study with a discussion on the merits
and limitations of the proposed approach and future work
directions.
II. PRIOR WORK
A. COVID-19 DETECTION
A study of the literature reveals several AI efforts for
COVID-19 screening. The authors of [3] distinguished
COVID-19 viral pneumonia manifestations from that of other
viral pneumonia on chest CT scans with high specificity.
It was observed that COVID-19 pneumonia was found to be
peripherally distributed with ground glass opacities (GGO)
and vascular thickening. The authors of [8] established
a publicly available collection of 275 CT scans showing
COVID-19 pneumonia manifestations and trained a deep
CNN to achieve 0.85 F-score in classifying CTs as normal or showing COVID-19 pneumonia-related opacities.
The authors of [9] used a customized CNN and pretrained
AlexNet model to classify CXRs as normal or showing
COVID-19 pneumonia with 94.1% and 98% accuracy respectively. The authors of [10] used a ResNet-50 [11] CNN to
classify normal, pneumonia, and COVID-19 viral pneumonia manifestations in CXRs and achieved an accuracy of
98.18 % and F-score of 98.19. CXRs are also commonly
analyzed to diagnose and differentiate other types of pneumonia including bacterial and non-COVID-19 viral pneumonia
[2]. The authors of [12] proposed a custom CNN model
that was designed by combining manual design prototyping with a machine-driven designing approach to classify
CXRs as normal or showing non-COVID-19 or COVID-19
pneumonia-related opacities with 92.4% accuracy.
B. MODALITY-SPECIFIC KNOWLEDGE TRANSFER
With limited amounts of COVID-19 pneumonia CXR data,
traditional transfer learning strategies offer promise [13]
where the learned feature representations are fine-tuned to
115042 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
improve performance. However, unique challenges posed
in the appearance of medical images [6] including high
inter-class similarity and low intra-class variance lead to
model bias and overfitting resulting in reduced performance and generalization. These issues can be alleviated
through modality-specific knowledge transfer by retraining
CNN models on a large CXR image collection to learn
modality-specific feature representations. Modality-specific
model knowledge transfer [14] and ensembles [15] have
demonstrated superior disease ROI localization compared to
individual constituent models.
C. MODEL PRUNING
To alleviate burdens from computing resources, DL models
can be pruned to reduce the inference cost and facilitate
deployment in low-resource conditions with no loss or even
improvement in performance. Reed [16] performed a neural model pruning to decrease computational complexity.
Hassibi et al. [17] deleted network parameters by leveraging
the second derivative term in the Taylor series and improved
model generalization. The authors of [18] found that the
earlier layers in the neural networks have low activations
that can effectively be excluded from the network without
affecting the model performance. They proposed an iterative
optimization method to gradually eliminate the neurons with
the least activations toward reducing the memory and power
requirements and promoting faster model inference. When
applied to medical imaging, the authors of [19] proposed a
genetic algorithm-based pathway evolution strategy to prune
DL models. This resulted in a 34% reduction in the network
parameters and improved the mass classification performance
in breast mammograms. A systematic weight pruning strategy [20] was used to prune a YOLO-model [21] based pneumonia detector for classifying CXRs as normal or showing
pneumonia-like manifestations using the Radiological Society of North America (RSNA) [22] CXR collection. However,
there is room for further research in this area.
D. ENSEMBLE CLASSIFICATION
CNNs are non-linear models that learn complex relationships
from the data through error backpropagation and stochastic
optimization, making them highly sensitive to random weight
initializations and the statistical noise present in the training
data. These issues can be alleviated by ensemble learning
by training multiple models and combining their predictions
where an individual model’s weaknesses are offset by the
predictions of other models. Combined predictions are shown
to be superior to individual models [23]. There are several
ensemble strategies reported in the literature including max
voting, simple and weighted averaging, stacking, boosting,
blending, and others that are shown to minimize the variance
error and improve generalization and performance of CNN
models. Applied to CXRs, the authors of [7], [14], and [24]
leveraged the use of an ensemble of CNN models toward
improving TB detection in CXRs. An averaging ensemble
of pretrained CNNs was used by the authors of [25] toward
improving cardiomegaly detection using CXRs.
TABLE 1. Dataset characteristics. Numerator and denominator denotes
the number of train and test data respectively (N = Normal,
UP = Pneumonia of unknown type, BP = Bacterial (proven)
pneumonia, CP = COVID-19 pneumonia).
III. MATERIALS AND METHODS
A. DATA COLLECTION AND PREPROCESSING
Table 1 shows the distribution of CXRs across different
categories. We used the following four publicly available
CXR collections in this retrospective analysis:
1) PEDIATRIC CXR DATASET [2]
The authors collected from Guangzhou Women and
Children’s Medical Center in Guangzhou, China, the anteriorposterior (AP) CXRs of children from 1 to 5 years of
age, showing normal lungs, bacterial pneumonia, and
non-COVID-19 viral pneumonia. Expert radiologists curated
the CXR collection to remove low-quality chest radiographs.
2) RSNA CXR DATASET [22]
This multi-expert curated dataset includes images from the
National Institutes of Health (NIH) CXR-14 dataset [26].
The dataset was released for the Kaggle pneumonia detection challenge, organized jointly by RSNA and NIH. The
collection includes normal CXRs and abnormal images with
non-pneumonia and pneumonia-like opacities. The images
are made available at 1024×1024 pixel resolution in DICOM
format.
3) TWITTER COVID-19 CXR DATASET
A cardiothoracic radiologist from Spain made available a
collection of 134 CXRs with 2K×2K pixel resolution in
JFIF format via Twitter of SARS-CoV-2 positive subjects.
(https://twitter.com/ChestImaging)
4) MONTREAL COVID-19 CXR DATASET [27]
A publicly available periodically updated GitHub repository
that includes COVID-19 CXR cases and other pulmonary
viral disease manifestations in AP, posterior-anterior (PA),
and AP-Supine views. As of April 7, 2020, the repository had
179 CXRs showing COVID-19 pneumonia-related opacities.
We performed patient-level splits of these CXR collections
to allocate 90% for training and 10% for testing at different stages of learning discussed in this study. We randomly allocated 10% of the training data to validate the DL
models. The ground truth (GT) for the test set, comprising
of 27 CXRs showing COVID-19 pneumonia-related opacities
is set by the verification of publicly identified cases from
expert radiologists who annotated the test set.
B. LUNG ROI SEGMENTATION
While mild COVID-19 cases mimic common upper
respiratory viral infections, advanced disease results in
VOLUME 8, 2020 115043S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
FIGURE 3. The segmentation approach showing U-Net based mask
generation and Lung ROI cropping.
FIGURE 4. Architecture of the customized CNN model. (I/P = Input,
CONV = Convolution, GAP = Global average pooling, DO = Dropout,
D = Dense with Softmax activation, N = Normal predictions,
A = Abnormal Predictions).
respiratory dysfunction and is the principal cause for
triggering mortality. In developing DL solutions for detecting
the disease, it is important to guard them against irrelevant
features that could severely affect reliable decision-making.
For this study, we performed U-Net based semantic segmentation [28] to segment the lung pixels from the background.
We used a U-Net with Gaussian dropout layers [29] added to
the U-Net encoder. A dropout ratio of 0.2 was empirically
determined and used in this study. Fig. 3 illustrates the
segmentation steps performed in this study.
We used a collection of CXRs with lung masks from
[30] to train the U-Net model to generate lung masks of
256 × 256 pixel resolution for the aforementioned datasets.
We used model checkpoints to monitor its performance and
stored only the best model weights to generate the final lung
masks. These masks then are superimposed on the CXR
images to crop them as a bounding box containing the lung
pixels. The cropped lungs are resized to 256×256 pixel resolution. The lung crops are further preprocessed by performing
pixel rescaling, median filtering for noise removal and edge
preservation, normalization for mean, and standardization for
identical feature distribution. The preprocessed lung crops are
used for model training and evaluation at different stages of
learning discussed in this study.
C. MODELS AND COMPUTATIONAL RESOURCES
We evaluated the performance of a customized CNN and
a selection of ImageNet pretrained CNN models, viz.,
a) VGG-16 [31], b) VGG-19 [31], c) Inception-V3 [32], d)
Xception [33], e) InceptionResNet-V2 [32]; f) MobileNet-V2
[34], g) DenseNet-201 [35], and h) NasNet-mobile [36].
Our customized CNN is a linear stack of strided separable
convolution layers, global average pooling (GAP), and a
dense layer with Softmax activation. Fig. 4 shows the architecture of the custom CNN used in this study. We used
Dropout to reduce issues due to model overfitting by providing restricted regularization and improving generalization
by reducing the model sensitivity to the specifics of the
training input [29]. We used strided convolutions that were
shown to improve performance on several visual recognition
benchmarks, compared to max-pooling layers [37]. Separable
convolutions were used to reduce model parameters [33] and
FIGURE 5. Architecture of the pretrained CNNs. (I/P = Input,
PCNN = truncated model, ZP = Zero-padding, CONV = Convolution,
GAP = Global Average Pooling, DO = Dropout, D= Dense with Softmax
activation, O/P = Output).
improve performance compared to conventional convolution
operations. The number of separable convolutional filters are
initialized to 32 and increased by a factor of two in the
successive convolutional layers. We used 5 × 5 filters and
a stride length of 2 in all convolutional layers. We added a
GAP layer to average the spatial feature dimensions that are
fed into the final dense layer with Softmax activation.
We used the Talos optimization package [38] to optimize
the parameters and hyperparameters of the customized CNN
that include a) dropout ratio, b) optimizer and c) non-linear
activation function. The model is trained and evaluated
with the optimal parameters to classify the CXRs to their
respective categories.
We instantiated the pretrained CNN with their ImageNet
weights and truncated them at the fully-connected layers.
The following layers are added to the truncated model:
(a) zero-padding, (b) a strided separable convolutional layer
with 5 × 5 filters and 1024 feature maps, (c) GAP layer,
(d) Dropout layer with an empirically determined dropout
ratio of 0.5, and (e) final dense layer with Softmax activation.
Fig. 5 shows the customized architecture of the pretrained
models used in this study.
We optimized the following hyperparameters of the
pretrained CNNs using a randomized grid search method
[39]: (a) momentum, (b) L2-regularization, and (c) initial
learning rate of the Stochastic Gradient Descent (SGD) optimizer. The search ranges were initialized to [0.85 0.99],
[1e−10 1e−3], and [1e−9 1e−2] and for the momentum,
L2-regularization, and the initial learning rate respectively.
The pretrained CNNs were retrained with smaller weight
updates to improve generalization and categorize the CXRs
to their respective classes. Class weights were used during
model training to penalize the overrepresented classes to
prevent overfitting and improve performance [40]. We used
model checkpoints to store the best model weights for further
analysis.
D. MODALITY-SPECIFIC TRANSFER LEARNING
AND FINE-TUNING
We performed modality-specific transfer learning where
the customized CNN and ImageNet pretrained models are
retrained on the RSNA CXR collection to learn CXR
modality-specific features and classify the CXRs into
normal and abnormal categories. The RSNA CXR collection includes normal CXRs and abnormal images containing pneumonia-related opacities. In this way, the weight
layers are made specific to the CXR modality through
learning the features of normal and abnormal lungs. The
learned knowledge is transferred and fine-tuned to a related
task of classifying CXRs that are pooled from pediatric,
115044 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
Twitter COVID-19, and Montreal COVID-19 CXR collections, respectively, as normal, or showing bacterial pneumonia, or COVID-19 pneumonia-related opacities, to improve
classification performance.
The top-3 performing modality-specific CNNs are
instantiated and truncated at their deepest convolutional
layer and added with the following layers: (a) zero-padding,
(b) a strided separable convolutional layer with 5 × 5 filters and 1024 feature maps, (c) GAP layer, (d) Dropout
layer and (e) final dense layer with Softmax activation. The
modified models are fine-tuned to classify CXRs as being
normal or showing bacterial pneumonia or COVID-19 viral
pneumonia. Class weights were used during model training to
award higher weights to the under-represented class to reduce
issues due to class imbalance and improve generalization
and performance. Fine-tuning is performed through SGD
optimization and model checkpoints were used to store the
best weights for further analysis.
E. ITERATIVE MODEL PRUNING
We iteratively pruned the fine-tuned models to find the
optimal number of neurons in the convolutional layers to
reduce model complexity with no loss in performance.
We gradually eliminated the neurons with fewer activations
at each time step through iterative pruning and model retraining. We used the average percentage of zeros (APoZ) [18],
the percentage of zero neuron activations observed with the
validation dataset, as the measure to rank the neurons in each
convolutional layer. We iteratively pruned a percentage of
neurons with the highest APoZ from each layer at each time
step and retrained the pruned model. The process is repeated
until the maximum percentage of pruning is achieved. The
best-pruned model is then selected from the collection of
iteratively pruned models based on their performance with
the test set. The retrained pruned model is expected to achieve
similar or better performance than the unpruned models with
reduced model complexity and computational requirements.
The algorithm for iterative pruning performed in this study is
described below:
F. LEARNING ITERATIVELY PRUNED ENSEMBLES
The best performing pruned models are selected to construct
the ensemble to improve prediction performance and generalization as compared to any individual constituent model.
We used several ensemble strategies including max voting,
averaging, weighted averaging, and stacking to combine the
predictions of the pruned models toward classifying CXRs as
normal or showing bacterial or COVID-19 viral pneumoniarelated opacities. For the stacking ensemble, we used a neural
network-based meta-learner that learns to optimally combine the predictions of the individual pruned models. The
meta-learner consisting of a single hidden layer with nine
neurons is trained to interpret the multi-class input from
the top-3 pruned models and a final dense layer outputs
the predictions to categorize the CXRs to their respective
classes.
Algorithm 1 Iterative Pruning
Input: B = {(xi, yi)|xi ∈ X, yi ∈ Y }, pruning percentage
(P), maximum pruning percentage (M)
1. Train and evaluate the base models on B and store the
best model weights
2. while percent pruned (PP) <= M do
a. Calculate the number of filters in each convolutional layer
b. Identify and delete P percentage of filters in each
convolutional layer with the highest average percentage of zeros
c. Retrain and evaluate the pruned model on B and
store the best-pruned weights
d. PP + = P
e. Incrementally prune the network, retraining it each
time and save the pruned model
end while
Return: M + 1 number of pruned models
G. VISUALIZATION STUDIES
Visualizing the learned behavior of the DL models is a
debated topic, particularly in medical visual recognition
tasks. There are several visualization strategies reported in
the literature that include (a) visualizing the overall network structure and (b) gradient-based visualization that
performs gradient manipulation during network training.
Gradient-weighted class activation mapping (Grad-CAM)
is a gradient-based visualization method that computes the
scores for a given image category concerning the feature maps of the deepest convolutional layer in a trained
model [41]. The gradients that are flowing backward are
pooled globally to measure the importance of the weights
in the decision-making process. In this study, we verified
the learned behavior of the pruned models by comparing
salient ROI with consensus GT annotations from experienced
radiologists.
H. STATISTICAL ANALYSES
We analyzed the model’s performance for statistical
significance at different stages of learning. We used confidence intervals (CI) as the measure to analyze the skill
of the CNN models. A shorter CI infers a smaller margin
of error or a relatively precise estimate while a larger CI
allows more margin for error and therefore results in reduced
precision [42]. We computed the 95% CI values for the
AUC at different learning stages to explain the models’
predictive performance. The CI values are computed to be
the Clopper–Pearson exact interval that corresponds to the
separate 2-sided interval with individual coverage probabilities of (0.95)1/2
. We used StatsModels version 0.11.0 to
compute CI measures. The codes associated with this study
are made available at https://github.com/sivaramakrishnanrajaraman/Iteratively-pruned-model-ensembles-for-COVID19-detection-in-CXRs.
VOLUME 8, 2020 115045S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 2. Optimal values for the parameters and hyperparameters for the
custom and pretrained models obtained through optimization tools
(M = Momentum, ILR = Initial learning rate, L2 = L2-weight decay,
and D = Dropout ratio).
TABLE 3. Performance metrics achieved during modality-specific transfer
learning using the RSNA CXR dataset (Acc. = Accuracy; Sens. = Sensitivity,
Prec. = Precision, F = F-score, MCC = Matthews correlation coefficient,
and Param. = trainable parameters). The values in square brackets show
the 95% CI that are computed to be the Clopper–Pearson exact interval
corresponding to the separate 2-sided interval with individual coverage
probabilities of (0.95)1/2.
IV. RESULTS AND DISCUSSION
The optimal values for the parameters and hyperparameters
obtained for the customized and pretrained CNNs with
the Talos optimization tool and randomized grid search,
respectively, are shown in Table 2.
Table 3 shows the performance achieved through
modality-specific knowledge transfer, by the customized and
pretrained CNNs using the RSNA CXR dataset.
It can be observed that the VGG-16, VGG-19, and
Inception-V3 models were more accurate than the other models under study. The aforementioned models demonstrated
promising AUC values with a shorter CI and hence a smaller
margin of error, thereby offering precise estimates compared
to the other models. This is because the architecture depths
of the VGG and Inception-V3 models are optimal to learn
the hierarchical representations of features from the CXR
data and classify them into normal and pneumonia classes.
Considering the F-score and MCC that give a balanced
measure of precision and recall, the aforementioned models
delivered performance that was superior to the other models.
TABLE 4. Performance metrics achieved by the top-3 modality-specific
knowledge transfer models on the target tasks.
The top-3 performing modality-specific knowledge
transfer models (VGG-16, VGG-19, and Inception-V3) are
instantiated with their modality-specific weights and truncated at their fully connected layers and appended with the
task-specific heads. Table 4 shows the performance achieved
by the task-specific models toward the following classification tasks: (a) binary classification to classify CXRs as
normal or COVID-19 pneumonia and (b) multi-class classification to classify CXRs as normal or as showing bacterial
pneumonia or COVID-19 pneumonia.
It can be observed that for the binary classification task, all
the models are 100% accurate, however, VGG-16 has the least
number of trainable parameters. For multi-class classification, it can be observed that the Inception-V3 model was more
accurate with a shorter CI for the AUC metric, signifying that
it has the least margin for error and hence provides a more precise estimate. Considering F-score and MCC, the InceptionV3 model delivered superior performance compared to
VGG-16 and VGG-19 models.
For the multi-class classification task, the predictions
of the task-specific models (VGG-16, VGG-19, and
Inception-V3) are combined through several ensemble
methods including max voting, simple averaging, weighted
averaging, and model stacking. We didn’t perform ensemble
learning for the binary classification task since the individual models are 100% accurate in classifying CXRs as
normal or showing COVID-19 pneumonia-related opacities.
Table 5 shows the performance achieved for the multi-class
classification with different ensemble strategies. It can be
observed that a simple average of the models’ predictions
is more accurate with a shorter CI for the AUC metric,
signifying a smaller margin of error and therefore, higher
precision, compared to other ensemble methods. Considering
the F-score and MCC, the averaging ensemble outperformed other ensemble strategies in classifying CXRs as
normal, or as showing bacterial pneumonia or COVID-19
viral pneumonia.
For the multi-class classification task, we iteratively
pruned the task-specific models (VGG-16, VGG-19, and
115046 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 5. Performance metrics achieved by the unpruned models through
different ensemble strategies for the multiclass classification task.
TABLE 6. Performance metrics achieved by the best iteratively pruned
models and compared with the baseline unpruned models from Table 4
(U-unpruned and P-pruned).
Inception-V3) by removing 2% of the neurons with the
highest APoZ in each convolutional layer at a given time
step and retrained the pruned model to evaluate its performance on the validation set. We used model checkpoints to
store the best-pruned model that gave a superior performance
with the validation set. The process is repeated until the
maximum pruning percentage of 50% is reached. We then
evaluated the performance of all the pruned models on the test
set. The pruned model that achieved superior performance
with the test set is used for further analysis.
Table 6 shows a comparison of the performance achieved
by the pruned models to that of the baseline, unpruned
task-specific models shown in Table 4. It can be observed
that the pruned models are more accurate than their unpruned
counterparts. Considering the F-score and MCC metrics,
the pruned models are found to deliver superior performance than the unpruned models. It is interesting to note
that the performance improvement is achieved with a significant reduction in the number of parameters. As can
be seen, the number of parameters in the pruned VGG16 model reduced by 46.03% compared to its unpruned
counterpart. Similarly, the number of trainable parameters
reduced by 16.13% and 36.1% for the pruned VGG-19 and
Inception-V3 models, respectively, with the added benefit of
FIGURE 6. Grad-CAM Visualizations showing salient ROI detection by
different pruned models. (A) CXR showing COVID-19 viral
pneumonia-related opacities with GT annotations, (B) VGG-16 pruned
model, (C) VGG-19 pruned model, and (D) Inception-V3 pruned model.
Bright red corresponds to the pixels carrying higher importance and
hence weights for categorizing the test sample to the COVID-19 viral
pneumonia category.
performance improvement in terms of accuracy, F-score, and
MCC metrics, compared to their unpruned counterparts.
Fig. 6 shows the results of performing Grad-CAM
visualizations to localize the salient ROIs used by the different pruned models to classify a sample test CXR into the
COVID-19 viral pneumonia category. The visualizations are
compared with consensus GT annotations provided by the
expert radiologists. The predictions of the pruned models are
decoded for the test sample. Two-dimensional heat maps are
generated in bright red, which corresponds to the pixels carrying higher importance and hence weights for categorizing
the test sample to COVID-19 pneumonia infected category.
Distinct color transitions are observed for varying ranges
of pixel importance toward making the predictions. Salient
ROIs are localized by superimposing the heat maps on the
input sample CXR. It is observed that the pruned models
precisely localize the salient ROI. This underscores the fact
that the pruned models have learned the implicit rules that
generalize well and conform to the experts’ knowledge about
the problem.
Table 7 shows a comparison of the performance metrics
achieved with the different ensemble strategies for the
unpruned and pruned models toward classifying the CXRs as
normal or showing bacterial pneumonia, or COVID-19 viral
pneumonia.
While performing weighted averaging ensemble for both
unpruned and pruned models, the predictions are awarded the
importance based on their F-score and MCC measures that
offer a balanced measure of precision and sensitivity. From
Table 6, it can be observed that the pruned and unpruned
VOLUME 8, 2020 115047S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
TABLE 7. Comparing the performance metrics achieved with the pruned
and unpruned model ensembles from Table 4.
FIGURE 7. Confusion matrix obtained with the weighted-average pruned
ensemble.
Inception-V3 model delivered superior performance, followed by VGG-19 and VGG-16 models. In this regard, we
assigned weights of 0.5, 0.3, and 0.2 to the predictions of
Inception-V3, VGG-19, and VGG-16 models, respectively.
It can be observed that the weighted averaging ensemble
of the predictions of the pruned models delivered superior
performance in all aspects. Fig. 7 and Fig. 8 shows the confusion matrix and AUC curves, respectively, obtained with the
weighted-averaging pruned ensemble.
The 95% CI for the AUC metric has the shortest error
margin with a more precise estimate than that obtained with
the other ensemble methods. Considering the F-score and
MCC, the weighted averaging ensemble outperformed the
other ensemble strategies in classifying CXRs as normal,
bacterial pneumonia, or COVID-19 viral pneumonia.
FIGURE 8. ROC curves showing micro/macro-averaged and class-specific
AUC obtained with the weighted-average pruned ensemble.
V. CONCLUSION
The COVID-19 pandemic has had an enormously negative
impact on population health and national economies worldwide. Early diagnosis has often been suboptimal and serological tests have not been widely available. The opportunity to
utilize CXRs as part of the diagnostic approach could add an
important and nearly universally available tool to the battle
against COVID-19 or other respiratory viruses that might
emerge in the future. In the current study, we demonstrate
that this can be done by applying ensemble DL to findings
seen in CXRs.
Modality-specific transfer learning performed with a
large-scale CXR collection with a diversified data distribution helped in learning CXR modality-specific features. The
learned feature representations served as a good weight initialization and improved model adaptation and generalization
compared to ImageNet pretrained weights, when transferred
and fine-tuned for a related CXR classification task.
Iterative pruning of the task-specific models and selection
of the best performing pruned model not only improved
prediction performance on the test data but also significantly
reduced the number of trainable parameters. This is because
there are redundant network parameters (neurons) in a deep
model that do not contribute to improving the prediction
performance. If these neurons with lesser activations can be
identified and removed, it results in a faster and smaller model
with similar or improved performance than the unpruned
models. This would facilitate deploying these models on
browsers and mobile devices.
We further improved the performance by constructing
ensembles of the pruned models. By empirically evaluating
the performance of the pruned models and awarding weights
based on their predictions, we observed that the weighted
averaging ensemble of the pruned models outperformed the
other ensemble methods.
We performed visualization studies to validate the
pruned model localization performance and found that the
pruned models precisely localized the salient ROI used in
categorizing the input CXRs to their expected categories.
115048 VOLUME 8, 2020S. Rajaraman et al.: Iteratively Pruned DL Ensembles for COVID-19 Detection in CXRs
We observe that combined use of CXR modality-specific
knowledge transfer, iterative model pruning, and ensemble learning reduced prediction variance, model complexity,
promoted faster inference, performance, and generalization.
However, the success of this approach is controlled by two
broad factors: (i) dataset size and inherent variability, and
(ii) computational resources needed for successful deployment and use. With dataset size, we specifically refer to the
minimum number of topically relevant images, in this case,
CXRs with viral pneumonia that are distinct from bacterial and normal images, that are needed to build confidence
into the ensemble. With computational resources, we recognize the training time and memory constraints required for
practicable deployment. However, low-cost GPU solutions,
high-performance computing (HPC), and cloud technology
would address the feasibility in this regard. Future studies
could explore visualizing and interpreting the learned behavior of the pruned model ensembles and their application
to other screening situations like COVID-19 detection and
localization in 3D CT scans, etc. At present, we expect that
the proposed approach can be quickly adapted for detection
of COVID-19 pneumonia using digitized chest radiographs.




NEW_PAPER


Received February 10, 2021, accepted March 7, 2021, date of publication March 10, 2021, date of current version March 23, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3065456
Bias Analysis on Public X-Ray Image Datasets
of Pneumonia and COVID-19 Patients
OMAR DEL TEJO CATALÁ 1
, ISMAEL SALVADOR IGUAL 1
,
FRANCISCO JAVIER PÉREZ-BENITO 1
, DAVID MILLÁN ESCRIVÁ 1
,
VICENT ORTIZ CASTELLÓ 1
, RAFAEL LLOBET 1,2
,
AND JUAN-CARLOS PERÉZ-CORTÉS 1,3
1
Instituto Tecnológico de Informática (ITI), Universitat Politècnica de València, 46022 Valencia, Spain
2Department of Computer Systems and Computation (DSIC), Universitat Politècnica de València, 46022 Valencia, Spain
3Department of Computing Engineering (DISCA), Universitat Politècnica de València, 46022 Valencia, Spain
Corresponding author: Ismael Salvador Igual (issalig@iti.upv.es)
This work was supported by Generalitat Valenciana through the ‘‘Instituto Valenciano de Competitividad Empresarial—IVACE’’ under
Grant IMDEEA/2020/69.
ABSTRACT Chest X-ray images are useful for early COVID-19 diagnosis with the advantage that
X-ray devices are already available in health centers and images are obtained immediately. Some datasets
containing X-ray images with cases (pneumonia or COVID-19) and controls have been made available
to develop machine-learning-based methods to aid in diagnosing the disease. However, these datasets
are mainly composed of different sources coming from pre-COVID-19 datasets and COVID-19 datasets.
Particularly, we have detected a significant bias in some of the released datasets used to train and test
diagnostic systems, which might imply that the results published are optimistic and may overestimate the
actual predictive capacity of the techniques proposed. In this article, we analyze the existing bias in some
commonly used datasets and propose a series of preliminary steps to carry out before the classic machine
learning pipeline in order to detect possible biases, to avoid them if possible and to report results that are
more representative of the actual predictive power of the methods under analysis.
INDEX TERMS
Deep learning, COVID-19, convolutional neural networks, chest X-ray, bias, segmentation, saliency map.
I. INTRODUCTION
Chest X-ray (CXR) radiography is the most widely accepted
imaging modality for detecting pneumonia and it is becoming crucial for tracking the clinical evolution of COVID-19
patients [1]. The COVID-19 disease is caused by Severe
Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2)
and has become a global pandemic in a few months. Early
diagnosis is a key factor due to the stealthy contagious nature
of the virus and a lack of vaccines or effective treatments
and, thus, it helps to prevent further spreading and to control
it under the existing healthcare facilities. The small size of
the acquisition devices, their ease of operation and their low
cost make them more widely available than the Computer
Tomography (CT) equipment, despite image quality and the
diagnostic performance of CT are superior.
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
As a response to the COVID-19 outbreak, the scientific
community has rapidly reacted and a lot of works using CXR
images for COVID-19 detection have been published. The
majority of them make use of well-known CNN architectures such as VGG [2], ResNet [3]–[5], SqueezeNet [3], [6],
DenseNet [7] and also combine them with decision trees [8]
and Support Vector Machines (SVM) [9]. Given the difficulty
of obtaining COVID-19 samples, GAN networks have been
used [10], [11] in order to enhance the performance. Moreover, other approaches [12], [13] based on multi-resolution
methods report results that are comparable to those obtained
by CNNs.
Machine learning models need large amounts of data
which, in this case, are difficult to acquire, being the existing
collections a mix of already well-known datasets and new
COVID-19 image datasets. This heterogeneous mixture of
observations provides more variety and usually reduces epistemic uncertainty. However, if these datasets, for instance, are
42370 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 1. Workflow of the different experiments. From left to right: Network activations, Image features evaluation and
background expansion and lung exclusion.
not equally balanced (label-wise), they may induce a certain
amount of dataset bias to the training phase. This happens
when the images can be easily discriminated by features not
relevant to the task, i.e. if the dataset inadvertently contains
some distinctive features which are not related to the disease
and are not shared among the source datasets. For instance,
let’s assume an extreme case. Two image datasets are formed
by two different classes, that is, dataset A made of class A
samples and dataset B of class B samples. Let’s assume in
most dataset A samples there is a white rectangle on the top
right corner, and the true class features are not as trivial.
Classifiers will focus on the easiest feature to discriminate
between classes and not the true class features. Therefore,
this leads to poor generalization; given a new dataset C
full of class A, samples with no white rectangle will be
misclassified.
We have detected significant biases in some of the
most commonly used datasets intended for pneumonia and
COVID-19 detection and we suspect that the accuracy
reported in some studies might be due in part to them, and thus
not directly related to the image features that could characterize the disease. These biases could arise, for example, when
using some specific devices to acquire images of patients with
a low probability of suffering the disease (mainly controls),
and different ones for those patients with a high probability of
suffering it (mainly cases). This could happen, for example,
when most of the patients are screened in certain health services and highly suspicious patients are derived to a different
area or, even worse, when, aiming to increase the number
of controls or cases, a dataset is expanded with samples
coming from significantly different origins and labeled with
unbalanced class identifiers. In these cases, a CNN trained
to discriminate between cases and controls could learn to
differentiate images from different origins rather than finding
features actually related to the disease.
Therefore, to effectively assess the performance of the
classifier, there must exist a previous study of the dataset bias,
so that the results can be validated. Thus, we present several
studies to assess the validity of the results. The following
datasets will be used to perform the experiments: BIMCV
Padchest, CheXpert, RSNA and a COVID-19 image data
collection that we will refer to as COVIDcxr, which will be
further described in Section II-A.
The main contributions of this work are:
• To propose a bias analysis methodology to assert the
validity of the results achieved on a dataset.
• To study the possible existence of bias in three broadly
used pneumonia classification datasets.
• To study the effect of mixing several datasets.
This work is structured as follows: Section I outlines the
problem of bias in CXR datasets. After that, the datasets
and networks used, along with the proposed methodology are
described in Section II. The workflow related to this section
can be seen in Figure 1. Section III shows the results achieved
using this article’s methodology over the proposed datasets
and Section IV gives an analysis of the results. Finally, conclusions are presented in Section VI.
II. METHODS
A. DATASETS
Several public datasets have been used in this article:
• PADCHEST1
[14] is a CXR dataset that includes
more than 160K images from 67625 patients that were
reported by radiologists at Hospital de San Juan (Spain)
1http://bimcv.cipf.es/bimcv-projects/padchest/
VOLUME 9, 2021 42371O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
from 2009 to 2017. The reports are labeled with
174 different radiographic findings, 19 differential diagnoses and 104 anatomic locations. 27% of the reports
were manually annotated by trained physicians and the
remaining set was labeled using a supervised method
based on a Recurrent Neural Network with attention
mechanisms. Generated labels were validated, achieving
a 0.93 Micro-F1 score using an independent test set.
For the experiments, only Posterior-Anterior images are
considered. Therefore, there are 9110 images in the
remaining dataset: 6790 control and 2320 pneumonia
images.
• RSNA pneumonia dataset2
is made up of images from
the National Institutes of Health (NIH) and labeled by
the Radiological Society of North America along with
the Society for Thoracic Radiology and MD.ai. The goal
of this dataset was to develop an AI classifier capable of
distinguishing between pneumonia and control images,
so it was released in a Kaggle competition in 2018.
It consists of 26684 images from which 20672 are control and 6012 are pneumonia images.
• CheXpert dataset3
[15] is provided by Stanford
University and contains 224316 chest radiographs
of 65240 patients with labels of 14 sub-categories. The
exams were performed at Stanford Hospital between
October 2002 and July 2017. Structured labels for the
images were created by an automated rule-based labeler,
which the researchers developed to extract observations
from free-text radiology reports. From the 224316 chest
radiographs, this article only takes the ones related to
pneumonia and control cases. Therefore, 5870 images
are remaining in the dataset: 4878 control and 992 pneumonia images.
• COVID-19 image data collection (COVIDcxr)4
[16] is
a project to collect X-ray and CT images that present
COVID-19, SARS, MERS and ARDS from online
sources. These sources are varied: scientific publications, websites, etc. As of June 2020, COVIDcxr has
around 424 COVID-19 images and is one of the largest
COVID-19 datasets publicly available to the best of our
knowledge.
B. MOTIVATION
The motivation for this study comes from analyzing the
results of a neural network trained to classify between
radiographic images of patients with pneumonia and healthy
control patients in order to determine the validity of the
classification. An interesting first validation can be done by
visualizing the network’s activation heatmaps. When we performed these checks against networks trained with pneumonia datasets, we observed many suspicious patterns, as these
heatmaps often highlighted areas of the image which did not
2https://www.kaggle.com/c/rsna-pneumonia-detection-challenge
3https://www.healthimaging.com/topics/artificial-intelligence/stanfordresearchers-release-chest-x-ray-dataset-train-ai
4https://github.com/ieee8023/covid-chestxray-dataset
contain lung tissue (see Figure 2). This made us suspect that
the networks were learning to classify, achieving large values
of AUC ROC, using features unrelated to the task. Thus,
the datasets might be biased.
FIGURE 2. Lung heatmaps for BIMCV’s dataset.
Grad-CAM [17] allows us to visualize the gradient of the
label in the final convolutional layer to produce a heatmap
depicting regions of the image that are relevant for the prediction. Blue pixels and red pixels correspond to low and
high values of the gradient at the final convolutional layer,
respectively.
As observed in Figure 2, there are highly activated regions
in areas without lung presence when the expected activation
should be inside the lung. It is not known how many pixels
inside the lungs should show an activation, as no detection
mask is available. However, we can assume that the activation
map in a control patient should not exceed a given threshold,
whilst a positive case’s map should show widespread activations within the lungs. Nonetheless, the activated area outside
the lungs should be minimal in all cases. For this reason,
a measure to inform about the distribution of the activated
pixels could be useful.
Given a heatmap image I = {pij} ∈ Matn,m(R), where
n is the number of rows, m the number of columns, and
pij represents the pixel value at row i and column j. Let A
be a region of interest and B its complement. Let t be the
activation map threshold, and let R and W be the number of
pixels with an activation value higher than t that are in A and
B respectively.
We can calculate the percentage of pixels with an activation
value over a threshold that fall outside an expected region as
the quotient between W and W + R (see Figure 3 and the
equations below, where p ∈ {pij} = I).
Considering activated pixels in region W as false positives (FP) and activated pixels in region R as true positives
(TP), the above quotient corresponds to the False Discovery
42372 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 3. Activation regions diagram.
Rate (FDR), which is the complement of the Positive Predictive Value (PPV).
R = TP = |(p > t) ∩ A|
W = FP = |(p > t) ∩ B|
FDR =
FP
FP + TP
FDR = 1 − PPV
For instance, in this task, any activated pixel that falls
outside the lungs is marked as wrong (W), as no information
should be found there. The lower this value, the better. This
score is designed to measure the validity of the trained CNN
classifier based on its activation maps and allows the selection
of different operation points depending on the threshold t to
be applied to the heatmaps. In this work, t is set to 90% of the
maximum heatmap value.
Table 1 shows the computed FDR for the activation maps
under three different datasets. It is worth noting that some
image findings are usually located on the border of the lungs,
so if the highlighted area is near the border, some pixels
might easily fall outside the region (A) and be considered as
wrong (W). On the grounds of the information provided by
the FDR, further experiments would be required to measure
the extent to which this phenomenon affects the datasets.
TABLE 1. False discovery rate of activation maps for three different
datasets.
Additionally, some suspicious patterns appeared when
visualizing the grayscale histograms of the images.
Ideally, gray levels of images from different sources should
be equally distributed, but in practice, this may not happen
and give rise to inaccurate conclusions. The histograms
of the images may be considered as Probability Density
Functions (PDFs) and may serve to measure the variability
among gray-level distributions using a methodology based
on information geometry [18]. This methodology has been
successfully applied to characterize EHR (Electronic Health
Record) data [19], [20], to assess the variability among
patients with different headache pain intensity [21], or to
detect pixel distribution differences among images acquired
from different mammographs [22].
Given a set of PDFs, this approach is based on the computation of the distance between each pair of PDFs using
the Jensen-Shannon distance. The simplex where each point
represents a PDF and the distance between two points is
the Jensen-Shannon distance between the two PDFs they
represent is known as a statistical manifold, which in turn
is a Riemannian manifold. For visualization purposes, this
simplex may be embedded in a real Euclidean space by using
Multidimensional Scaling [23] and, finally, projected into two
dimensions using a dimension reduction algorithm such as
Principal Component Analysis.
This methodology was applied three times to a random
balanced sample of 2000 individuals (1000 pneumonia cases
and 1000 controls) of each dataset mentioned, which will
be described in section II-A. Firstly, it was applied to the
histograms of the complete images and, after a segmentation step, which will be described in detail in section II-D,
the variability analysis was applied only to the histograms
of the backgrounds, and then to the histograms of the lungs
(see Figure 4). The variability of the three datasets is shown
in Figure 5.
In the center row of Figure 5, which depicts the distributions of the backgrounds of the different datasets, we can see
that the first two columns show distinct clusters composed
predominantly of cases or controls that allow a certain degree
of discrimination without taking into account the lung tissue.
In fact, the last row, which represents lung area, shows fewer
differences between the cases and control patient histograms.
In the last column, corresponding to CheXpert’s dataset, these
differences are not evident.
This could imply that, for some datasets, as BIMCV and
RSNA, a Machine Learning algorithm can classify pneumonia and control cases using features outside the lungs.
C. NETWORK
In this article, Convolutional Neural Networks (CNNs) are
used to classify the CXR images. These Machine Learning models have been widely employed in the last years
for image classification, particularly in the field of medical
imaging. The CNN topology used is VGG16 [24], which
is broadly reported as a good classifier for chest image
analysis [25]–[27]. In this scenario, a common practice with
this type of networks is to trim the last layers (usually
dense layers) and add a lighter classifier, which in this
VOLUME 9, 2021 42373O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 4. Example of case and control patient histograms. The first row shows the histogram of the whole image for an example of a case and a
control patient, the second row shows the histogram of the background (the image with the lung area subtracted) and, the last one shows the
histogram of the lungs.
case is a Global Average Pooling followed by a Multilayer
Perceptron, which projects the pooled features of VGG’s
last convolution to 64 dimensions before performing the
classification.
Transfer learning technique is a common practice within
Deep Learning models. It is proven that pretrained networks, in particular their first layers, are generic and
can be transferred to new domains without requiring
special training. In fact, it also facilitates training for
domains with a scarce amount of training samples. Therefore, the VGG16 network used is pretrained with Imagenet dataset, and the last 2 convolutional layers, along
with the classification layers, are unfrozen for domain
training.
It is noteworthy that the network structure is, up to a
point, not critical for the conclusions drawn in this article,
as it is not trying to present advancement in the state-of-theart classification for the datasets used. The focus is rather
on comparing the results obtained for images coming from
different datasets, and whether those results suggest the presence of classification biases within the data. Nonetheless,
it must at least achieve an acceptable accuracy in order to
ensure the extracted features are good enough and close to
the ones extracted in other articles.
D. SEGMENTATION
By segmenting the lungs, it is possible to remove parts of
the image that do not contain relevant information and that
can be a source of noise or bias, such as the presence of text
annotations that can identify a machine or a hospital, or the
appearance of images coming from specific medical devices
that have been used in more cases than control patients or vice
versa.
Lung segmentation in CXR images has been successfully
tackled with different approaches during the last years [28].
For this work, a U-Net network has been trained on the
Montgomery dataset [29]. Moreover, we have manually
labeled a total of 1115 images coming from BIMCV’s
42374 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 5. Image histogram variability. The first row represents the variability of the histograms of the complete images, the second row the variability of
the background histograms (the images with the lung area subtracted), and the third row the histograms of the lungs. The first column represents a
sample of BIMCV’s dataset, the second column a sample of RSNA’s, and the last, a sample of CheXpert’s.
Padchest dataset to increase the number of training images.
Figure 6 shows the segmentation results. This network
achieves 0.974 DICE and 0.934 IoU scores over the Montgomery test partition, where DICE and IoU are defined as
follows, being A and B the predicted segmentation mask and
the true segmentation mask.
DICE =
2 | A ∩ B |
| A | + | B |
IoU =
A ∩ B
A ∪ B
VOLUME 9, 2021 42375O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
E. BIAS ANALYSIS
This work proposes a methodology to measure the degree of
bias in a dataset. The focus is on the classification of pneumonia or COVID against control samples, but the methods
can be generalized to other classification tasks where prior
knowledge of the region of interest is available.
As stated before, areas that should not contain information about the problem can be possibly used to discriminate
between classes, for example, text annotations or image features related to the medical devices employed. In order to
solve this problem, we make use of a segmentation algorithm
to extract the relevant regions which in this case are the lungs
(see Figure 6). These regions will be referred to as masks.
The rest of the image will be considered as background
(see B in Figure 3).
FIGURE 6. Lung segmentation (left) and after post-process (right).
To check the previous hypothesis presented in II-B,
two experiments were carried out by training a model
with different image areas according to the following
ideas:
• We want to study how the background affects the results.
Starting from an image that contains only the lungs
(the background is erased), the visible region is progressively expanded to include more background by
means of sequential dilation operations over the mask
(see Figure 7a). An unbiased dataset should not increase
the classification accuracy along this process.
• We want to analyze how the lack of lung area affects
the results; this time starting from the whole image and
progressively removing the lungs (see Figure 7b). The
classification accuracy over an unbiased dataset should
progressively drop from its maximum value (whole
image) to 0.5 AUC ROC.
Thus, adjusting the expansion or exclusion of the lung region
will allow us to trace the variation of the accuracy metric.
We used images scaled to 256 × 256 pixels. For background
expansion, lung segmentation masks were dilated 0, 10, 30,
50, 80, 120 and 140 pixels and for lung exclusion, masks were
eroded 0, 10, 20, 30, 40 and 100 pixels (from right to left
in Figure 7).
Figure 7a shows the lung segmented area in blue and
the background expansion in green. Also, Figure 7b shows
the lung exclusion area in yellow. Additionally, a detailed
workflow for this experiment is shown in Figure 8
F. COMBINATION ANALYSIS
Combining datasets can be useful to enlarge the sample size,
increase the variability explained by the data, and reduce the
epistemic uncertainty of the classifiers. This latter is related
to the problem-domain knowledge of the model, being it the
uncertainty or lack of knowledge bound to the limited amount
of data. However, if the combination and the balance among
the classes are not carefully controlled, a classifier may learn
to discriminate between features of the different datasets.
To check this hypothesis, we mixed RSNA and CheXpert
datasets to achieve a balanced combination by adding positive
pneumonia observations from the RSNA dataset into CheXpert. The latter is a highly unbalanced dataset (83% of negative and 27% of positive observations after our pre-process
and segmentation validity filters), so it could be considered
a good idea to add positive samples from another dataset.
Needless to say, if the images from RSNA have distinct
features that allow the classifier to tell them apart from
CheXpert, for example including a large proportion of images
from a particular equipment brand or model, the system will
learn to classify the images from that equipment as positive,
regardless of any image content that could be related to the
disease.
Additionally, we simulated the combination of
COVID-19 and control datasets and evaluated their bias
with the proposed method. In particular, the datasets combined are positive COVID-19 cases from COVIDcxr with
CheXpert’s negative control samples. COVIDcxr is built with
datasets from different origins, hence this experiment illustrates the likely problematic effects of heterogeneous data
combinations.
Based on our methodology that probes the discrimination
induced outside the lungs, the expectations about the results
of the experiment, if there is bias in the dataset, are: (1) the
background expansion could increase the accuracy and
(2) the accuracy when occluding the lungs should differ
significantly from the 0.5 AUC ROC. Did the results follow
these predictions, the hypothesis would be confirmed.
III. RESULTS
A. BACKGROUND EXPANSION AND LUNG EXCLUSION
STUDY
In the previous section, we proposed to examine the performance of classification experiments varying the addition of
background and the reduction of the lung area. The expected
results of the first test for a non-biased dataset, where the
background area is added to the initial lung-only images,
is that the classification rate stays constant (or almost constant, due to possible imprecise segmentation and other random perturbations), as the disease information is already
present from the beginning.
In the second scenario, the accuracy should potentially
drop from the value achieved when the network sees the
complete image to a value close to 0.5 AUC ROC when the
lungs are completely removed. This drop is not necessarily
42376 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 7. Background expansion and lung exclusion. (a) The original contour area is shown in blue and the expanded area contour in green (b) The
contour of the removed area is shown in yellow.
FIGURE 8. Bias analysis’s workflow.
linear, but will be shown in the graphs as a straight red line,
as can be seen in the right part of Figure 9, to offer a simplified
graphical representation of the expected behavior. In the left
part of the figure, the green line represents the classification
rate obtained using only the lung area.
This analysis has been performed in the three datasets:
• The first one (see Figure 9a), BIMCV, clearly shows
a significant bias within the data, as the classification
rate steadily increases with the background expansion.
The second graph shows that removing the lung area is
not associated with a significant decrease in accuracy,
as it should, and even with the complete exclusion of the
lungs the classifier achieves almost 0.88 AUC ROC.
• The second one (see Figure 9b), RSNA, displays a
slightly lower but still consistent bias within the data
in both graphs. However, the RSNA dataset was harder
to segment than the other ones and, thus, part of the
variability shown could arise from poorly segmented
images. Nonetheless, a 0.79 AUC ROC is achieved with
the lungs completely occluded, which is far from the
expected 0.5 AUC ROC.
• The third one (see Figure 9c), CheXpert, conveys interesting results. The left graph’s trend is the one expected
for an unbiased dataset, as it doesn’t vary along with
the background expansion. Nevertheless, the precision
achieved when the lung is completely occluded is
around 0.74 AUC ROC. This implies that the bias is not
located specifically in the background, but it must lie in
the whole image.
B. COMBINATION STUDY
As mentioned before, the combination study seeks to evaluate
how the combination of datasets might provoke the creation
of biased data and how the methodology proposed can detect
these weaknesses in the final data collection.
The experiments of Section III-A have been reproduced
using the combined dataset. Figure 10(a) shows the effect
of varying background expansion and lung exclusion when
the combination is designed to balance CheXpert with RSNA
cases (4878 control and 992 positive pneumonia images from
CheXpert plus 3886 positive images from RSNA, giving a
balanced dataset with 50% observations from each class).
The last experiment explored a combination of 4878 images
of control patients from CheXpert and the whole set
of 424 COVID-19 images from COVIDcxr. This dataset
combination is typical of the recent crisis scenario, where few
images from the new disease are available, they are obtained
from different locations, under uncontrolled conditions, with
different equipment and acquisition protocols, etc. This is the
worst-case scenario and the results are in accordance with it,
as can be seen in Figure 10(b).
The results for these experiments show, in a similar fashion
to Chexpert’s base case, that the bias is ubiquitous in the
VOLUME 9, 2021 42377O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 9. Accuracy as a function of the background expansion and lung reduction. The green dotted lines
mark the correct behavior of a non-biased dataset when more and more background is included, and the
red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from the
analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line indicating the
standard deviation.
image. Despite increasing the amount of background inside
the images doesn’t affect the accuracy, the effect of the lung
occlusion is not remarkable within the results.
IV. DISCUSSION
Deep learning has been receiving a lot of attention
as a very powerful methodology for analyzing medical
images [30]. The ability of Convolutional Neural Networks (CNN) to obtain excellent results even when it is used
as a blackbox, as opposed to the classical design of ad-hoc
algorithms, has attracted many researchers.
Some works using CNNs for COVID-19 detection on
cxr images report high accuracies for a variety of network
architectures. In particular, studies using VGG16 report [9]
89.8% accuracy for a dataset built of 180 COVID-19 and
200 control samples, 90% accuracy is obtained [27] for a
dataset composed of 202 COVID-19 images, 300 of pneumonia and 300 negative and 93.48% accuracy [31] is achieved
using a dataset that contains 224 COVID-19 images, 700 of
pneumonia and 504 negative. The fact that VGG16 achieves
good results for detecting pulmonary diseases strengthens
the hypothesis that the features extracted by the network
are relevant to the task and therefore, as detected from our
experiments, related to some sort of bias within the images.
One of the drawbacks of CNNs is that they often need
large amounts of data to learn and, while generic CXR
databases are available, public existing COVID-19 datasets
are composed of a few images that were collected by
volunteers [16]. As a consequence, these datasets show
unbalanced labels and a mix of different data sources that
42378 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 10. Addition of positive samples from RSNA and COVIDcxr to CheXpert’s dataset. The green dotted
lines mark the correct behavior of a non-biased dataset when more and more background is included, and
the red dotted lines indicate the expected reduction of the classification rate as the lungs are removed from
the analysis. Blue lines show the accuracy for a given expansion or reduction with a vertical line
indicating the standard deviation.
makes getting a robust model and reliable performance
measures difficult. In this regard, some articles report the
problem of small and unbalanced datasets for COVID-19
detection [4], [32], and propose solutions to mitigate the
problem.
Bias analysis has been tackled by other authors. For
instance, in [33] the authors proposed that train and test
partitions should come from different datasets (related to the
same task), as the classifier is trying to achieve maximum
performance over a certain task and not over a dataset. This
may also assert the true generalization capacity of the classifier. On the other hand, [34] sought to minimize the effects
of different biased datasets by way of converting different
dataset observations to prototypes, greatly reducing possible
intra-dataset specific features.
Recently, [35] addresses this issue for COVID-19 detection
and reports that the problem of mixing different datasets may
lead the network to learn background information. Our study
performs a similar approach to the one presented in thisarticle, i.e. both study possible biases within the lungs. [35]
occludes the lungs with rectangular fixed-size black boxes
and measures the accuracy achieved. However, the proposed
methodology extends the concept proposed to more precise
masks and progressive inclusion and exclusion of information
to the learning process. This allows the ability to detect
where the bias approximately is and enables more precise bias
estimation.
Furthermore, [36] studies bias within the nCov2019 dataset
using information about patients (symptoms, comorbidities,
age, and sex). This dataset collects clinical data from different sources rather than images. They found significant bias
related to the origin of the data and exposed several issues
related to multisource variability.
This article is focused on detecting some biases within
widely used CXR datasets to glimpse the degree to which
these biases affect the results and proposes a bias detection
methodology to assert the validity of results. This methodology makes use of techniques such as heatmap visualization,
histogram analysis and selective image occlusion which are
combined to evaluate which parts of the images are being
used as discriminative features for a classification task. In this
work, this methodology has been applied in two case scenarios, one for the existence of bias on individual pneumonia
datasets and another to detect the existence of bias in a mix
of datasets.
V. LIMITATIONS OF THE STUDY
Regarding possible limitations, there could be a problem with
the methodology proposed, since the segmentation masks
used for expansion and reduction may be biased themselves.
The segmentation process might be more prone to fail in
images with pneumonia since the borders of the lungs are
more diffuse, whereas this could not happen in images of
control patients. This could pose a significant difference
VOLUME 9, 2021 42379O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 11. Lung occlusion with fixed-size rectangular boxes.
between cases and controls masks, and therefore, we might
be introducing a new bias that would imply a problem with
the proposed methodology.
However, to rule this out, we designed an experiment where
the occlusion masks were substituted by rectangles the size
of the lungs. This experiment is similar to the one presented
in [35], but here we ensure that the lungs are completely
removed using the segmentation mask shape whereas in the
aforementioned work they just place a fixed size black rectangle in the central area leaving some lung area uncovered.
Some examples from our method can be seen in Figure 11.
The results achieved for BIMCV’s dataset can be seen
in Figure 12, where the differences found are not significant,
suggesting that the shape of the lung masks is not influencing
the bias detection algorithm proposed.
Furthermore, to increase the confidence in our conclusions,
we pre-processed all the images by means of CLAHE histogram normalization to assert how this pre-process affected
the results. As can be seen in Figure 13, there is no difference
in the results achieved between the normalized and plain
images.
Talking about strengths, the results of the experiments
described in Section III-B demonstrated that the classification
rate does not improve when the background area is included
in the images, which means that either there is no bias
specifically on the background or the most significant bias
is already within the lungs. However, when the lung area
is progressively removed from the image we find in both
experiments that the accuracy does not decrease, suggesting
FIGURE 12. Comparison between fine-grain and squared masks for BIMCV’s dataset.
42380 VOLUME 9, 2021O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets
FIGURE 13. Comparison between normalized and plain BIMCV’s dataset.
that the system is classifying the images according to some
elements present in the whole image, not only inside the
lungs. That result confirms the hypothesis that powerful systems like Convolutional Networks can find subtle features
in the images and give optimistic classification results if no
measures are taken to avoid biases in the data.
To summarize, further research should be conducted to
reduce the impact of the intrinsic bias for the datasets whose
images are collected from several sources. Recent literature
has demonstrated the emergence of methodologies useful
to reduce the impact of such a bias. Image preprocessing methods [22] or deep learning architectures designed
to deal with biased datasets [37] may be a good starting
point.
VI. CONCLUSION
In this work, a novel methodology to assess the existence of
bias in CXR image datasets is presented. Techniques such
as activation heatmap visualization, histogram analysis and
selective image occlusion are combined to evaluate which
part of the images are being used as discriminative features
for a classification task. In this case, the regions of interest
were the lungs. The datasets used show different levels of
bias, these comprising datasets that try to make information quickly available in an urgent scenario like the current
COVID-19 crisis. Some examples are BIMCV’s collection or
the combination of datasets created for this purpose, which
are the ones with more problems. The results are confirmed
with the other methodologies used, such as the FDR of the
activation map or the histogram analysis.
The study of the effects of combining datasets from different sources is especially interesting because it shows that, if it
is not strictly controlled, important biases can be induced in
the final dataset. A typical solution for the lack of samples
of a given class is to compile different datasets into one that
collects all the categories to study, as the recent COVID-19
datasets. In particular, the widely used COVIDcxr dataset,
built from different sources, might in fact have included
significant biases that inadvertently affected the results published. This kind of heterogeneous dataset often mix observations coming from very diverse equipment, acquisition protocols and processing software. In that context, features found
by Deep Convolutional Networks in the images, including the
background areas, are enough to get a good classification rate,
whilst the actual performance of the classifier for the clinical
task attempted can be much lower.
ACKNOWLEDGMENTS
The authors would like to thanks of gratitude to BIMCV
and the other teams that compiled and made available the
datasets used in this work. The experiments were conducted employing Instituto Tecnológico de Informática (ITI)
High-Performance Computing platform, which is funded
by IVACE and AVI, and implemented within ITI Data
Space, being these experiments a TECH4CV’s project use
case.
VOLUME 9, 2021 42381O. D. T. Catalá et al.: Bias Analysis on Public X-Ray Image Datasets



NEW_PAPER



Received October 16, 2020, accepted October 19, 2020, date of publication October 22, 2020, date of current version November 4, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3033146
A Novel Parametric Model for the Prediction and
Analysis of the COVID-19 Casualties
ONDER TUTSOY 1
, ŞULE ÇOLAK 1
, ADEM POLAT 1
, AND KEMAL BALIKCI 2
1Department of Electrical-Electronics Engineering, Adana Alparslan Türkeş Science and Technology University, 01250 Adana, Turkey
2Department of Electrical and Electronics Engineering, Osmaniye Korkut Ata University, 80000 Osmaniye, Turkey
Corresponding author: Onder Tutsoy (otutsoy@atu.edu.tr)
ABSTRACT Coronavirus disease (COVID-19) outbreak has affected billions of people, where millions of
them have been infected and thousands of them have lost their lives. In addition, to constraint the spread
of the virus, economies have been shut down, curfews and restrictions have interrupted the social lives.
Currently, the key question in minds is the future impacts of the virus on the people. It is a fact that
the parametric modelling and analyses of the pandemic viruses are able to provide crucial information
about the character and also future behaviour of the viruses. This paper initially reviews and analyses
the Susceptible-Infected-Recovered (SIR) model, which is extensively considered for the estimation of the
COVID-19 casualties. Then, this paper introduces a novel comprehensive higher-order, multi-dimensional,
strongly coupled, and parametric Suspicious-Infected-Death (SpID) model. The mathematical analysis
results performed by using the casualties in Turkey show that the COVID-19 dynamics are inside the
slightly oscillatory, stable (bounded) region, although some of the dynamics are close to the instability region
(unbounded). However, analysis with the data just after lifting the restrictions reveals that the dynamics of
the COVID-19 are moderately unstable, which would blow up if no actions are taken. The developed model
estimates that the number of the infected and death individuals will converge zero around 300 days whereas
the number of the suspicious individuals will require about a thousand days to be minimized under the current
conditions. Even though the developed model is used to estimate the casualties in Turkey, it can be easily
trained with the data from the other countries and used for the estimation of the corresponding COVID-19
casualties.
INDEX TERMS COVID-19 casualties, parametric model, prediction, SpID model, SIR model.
I. INTRODUCTION
Coronavirus disease (COVID-19) is described as a contagious respiratory disease caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) [1]. It was
first noticed in Wuhan, China in December 2019, and then
spread rapidly to all over the world [2]. The World Health
Organization (WHO) declared the COVID-19 outbreak as
a pandemic on March 11, 2020 [3]. CoVs are classified as
alpha-, beta-, gamma- and delta- coronaviruses [4]. Bats lead
to alpha- and beta-type coronaviruses, while birds and pigs
cause gamma- and delta-type coronaviruses. Though alphatype coronaviruses have mild symptomatic effects, beta-type
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
coronaviruses are more severe [5] since they result in serious
problems especially in respiratory systems [6], [7].
Seven human coronaviruses have been detected to date [8].
229E (1966) and NL63 (2004) have been alpha-type, while
OC43 (1967), HKU1 (2005), SARS-CoV (Severe Acute Respiratory Syndrome, 2002) and MERS-CoV (Middle East
Respiratory Syndrome, 2012) have been beta-type [9]. The
two zoonotic viruses, SARS and MERS, had led to serious
diseases which caused a large number of deaths and they
have had the most catastrophic impact among all the known
coronaviruses in the world [5]. SARS was first seen in southern China and spread to 29 countries in less than a year.
There were more than 8000 people infected with the virus
and 774 deaths were reported between November 2002 and
July 2003 [10]. MERS was identified in 2012 in Saudi Arabia
with the death of a 60-year-old patient and affected around
193898
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 8, 2020O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
2500 people in 27 countries where 848 of them lost their
lives [11].
As in the case of SARS-CoV and MERS-CoV, the
COVID-19 is also thought to be transmitted from bats to
humans. The mortality rate of the COVID-19 virus outbreak
is larger than the SARS virus and its transmission rate is
also much more significant than them [12]. The COVID-19
is transmitted from human to human through droplets that
spread from the coughs or sneezes of people with the disease. The virus may have different effects on the infected
people where some people show mild symptoms and recover
without hospitalization. The most common symptoms of
the COVID-19 are fever, dry cough, and tiredness. Difficult
breathing, chest pain, and loss of speech are some of the
more severe symptoms as well. Since, there are no drugs or
vaccines that have been proven to protect people from the
COVID-19, it is still uncontrollable [13].
During the pandemic periods, international organizations
such as the WHO and the public authorities have required
comprehensive and accurate short-term and long-term estimators to identify the most appropriate strategies and take the
necessary measures. These estimators, known as models, provide forecasting in the short and long term are of great importance. Therefore, modelling the pandemic plays a significant
role to overcome the detrimental effects of the pandemic
viruses in the presence of the uncertainties. It is possible
to use mathematical and statistical methods to model the
pandemic, analyse its characteristics and evaluate its control
mechanisms [14], [15]. Modelling the pandemic enables to
examine the dynamics of the infectious diseases in detail and
estimate the infection parameters. Additionally, it provides
insights about the effects of the interventions (closing the
schools, quarantine of infected people, social distancing etc.)
to control the outbreak.
Modelling approaches can be classified as parametric and
non-parametric. In terms of the non-parametric approaches,
machine learning methods such as Neural Networks (NN)
and Support Vector Machines (SVM) are considered without
specifying the parameters and the data spaces [16]. Thus,
it is not possible to know where to map the real data in the
imaginary solution space. In addition, the estimated solution
can correspond to a local region instead of the global where
the estimates are only valid in a small region. Since they
are generally iterative approaches, it is likely for them to
converge somewhere in the parameter space which might not
be the optimum, especially in the stochastic cases. Moreover,
even though the statistical analysis approaches are available
for the non-parametric modelling approaches, they are usually not rigorous as the exact model parameters are unavailable. Finally, the non-parametric models have a bias-variance
trade-off dilemma and they require testing and validation data
together with the training data [17].
With respect to the parametric modelling approaches,
they necessaire accurate insights about the real systems
(i.e. orders, zeros, coupling, and forcing terms) behind the
available data. Therefore, they require initial observations
and analysis of the source data. However, when the model
structure is constructed, performing a parametric modelling
approach is straightforward. The linear and non-linear models
can be obtained easily and extensive analyses of them can be
achieved by using the well-known mathematical approaches
such as the roots, eigenvalues, and imaginary components.
Since the batch type optimization approaches together with
the iterative ones are available for the parametric modelling,
it is possible to reach the terminal parametric solution in
one step. More importantly, the detrimental impacts of the
stochasticity in the data can be eliminated as the batch type
optimizations can able to ignore the random variables. Lastly,
the parametric models can reveal key knowledge about the
strong and weak sides of the real systems such as failing
treatments, so that policies can be developed to control the
behaviour of them as desired under uncertainties [18].
Recently, a number of parametric models were proposed for the estimation of the COVID-19 casualties.
Peng et al. formulated a Suspected-Exposed-InfectedRecovered (SEIR) model to analyse the casualties in five
regions of China [19]. Similarly, Massonis et al. used the
SEIR model to analyse the identifiability and observability of the COVID-19 parameters [20]. Zhao and Chen
considered Susceptible-Unquarantined Infected-Quarantined
Infected-Confirmed Infected (SUQC) model to estimate
the casualties in China [21]. Maier and Brockmann used
Susceptible-Infected-Recovery (SIR) model to analyse the
COVID-19 casualties of Hubei province of China [22].
Giordano et al. proposed an extensive Susceptible-InfectedDiagnosed-Ailing-Recognized.
Threatened-Healed-Extinct (SIDARTHE) model to analyse the casualties in Italy [23]. Chang et al. focused on
the known pandemic dynamics to analyse the casualties in
Australia [24]. Even though these models provide some
insights about the COVID-19, since they are mostly based on
known parameters such as the infectious rate, cure rate, and
mortality rate, their parameters are not optimized. Thus, it is
not possible to know whether the individual parts of a multidimensional model and its other parameters are covered and
constructed properly.
In addition, a number of non-parametric modelling
approaches have been available. Chinnazzi et al. considered a global metapopulation disease transmission model to
reveal the effects of the travel limitations enforced in Wuhan
city of China on the spread of the virus [25]. Lauer et al.
considered a non-parametric statistical approach to analyse
the median incubation and symptoms development periods
from 50 provinces outside Wuhan and Hubei provinces of
China [26]. However, all these models have used simple
statistical approaches or synchronized parameters which are
highly likely to fail when the internal dynamics of the virus
or external uncertainty vary.
Based on these corresponding gaps in the literature, the key
contributions of this paper can be summarized as;
1) This paper develops a Suspicious-Infected-Death
(SpID) model, which has utterly unknown dynamics.
VOLUME 8, 2020 193899O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
2) The developed SpID model is highly coupled since the
suspicious, infected, and death casualties are strongly
dependent on each other.
3) Each sub-model of the developed SpID has 2nd order
internal dynamics to represent the peaks and fluctuations
in the COVID-19 casualties.
4) To learn the unknown parameters of the SpID model,
the exact bases corresponding to the parameter space of
the model are constructed and the unknown parameters
are learnt by performing a batch type Least Squares (LS)
estimator.
5) The model with the determined parameters has been
extensively analysed by utilizing the mathematical tools.
6) Predicted future COVID-19 casualties for Turkey have
been provided by using the developed model.
In the rest of the paper, Section II reviews the SIR
model, Section III introduces the proposed SpID model,
Section IV formulates the LS based parameter learning
approach, Section V analysis the COVID-19 casualties in
Turkey, Section VI provides the key insights of the SpID
model, Section VII presents the predicted future casualties
for Turkey and finally, Section VIII summarizes the work.
II. REVIEW OF THE SIR MODEL
This section reviews the SIR model adopted for the estimation of the COVID-19 casualties. The gained insights
in this section greatly contribute to the construction of the
comprehensive new mathematical SpID model presented in
Section III.
A. THE SIR MODEL
The SIR model is expressed with unforced (homogeneous),
time-invariant, slightly coupled, three individual first-order
ordinary differential equations (ODE) as:
S˙ (t) = −βS (t)I (t)
˙I (t) = βS (t)I (t) − γ R (t)
R˙ (t) = γ R (t) (1)
where;
• S(t) represents the Susceptible (S) individuals who may
be infected and have a lack of immunity,
• I(t) represents the Infected (I) individuals who are
exposed and become infected after contracting the disease,
• R(t) represents the Recovered (R) individuals who have
gained immune to the disease and are not infectious,
• β represents the transmission rate,
• γ represents the infectious rate.
Next section discusses the properties of the SIR model in
terms of covering the dominant COVID-19 dynamics.
B. PROPERTIES OF THE SIR MODEL
We can summarize the key properties of the SIR model as
1) Its S(t) and I(t) sub-models are non-linear due to
S(t)I(t) multiplication,
2) Each ODE (sub-model) is first order,
3) Its I(t) sub-model has linear coupling with R(t) through
the γ parameter.
4) It is a continuous model due to time derivatives,
5) It is a deterministic model since it does not cover any
uncertainties
Next section constructs a new model called as SpID.
III. THE SpID MODEL
The SpID model does not contain the number of the recovered people R as in the SIR model because the optimization algorithms mainly focus on minimization such as the
number of the suspicious, infected, and death people, rather
than the number of the recovered people requiring maximization. In addition, the proposed SpID model does not
explicitly cover the parameters such as β and γ , instead it
has unknown parameters where the optimization algorithms
determine them implicitly.
To provide consistency between the constructed model
and the real system, casualties in Turkey are referred. Even
though the magnitudes of the casualties in the worldwide
are different, the overall character of them such as peaks,
increments, and decays are similar. Thus, the proposed model
can be easily adopted for the other cases in different countries.
A. SUSPICIOUS MODEL
The proposed model considers the number of the suspicious
Sp(t) casualties rather than the number of the susceptible S(t)
casualties as in the SIR model. This is because
• The developed SpID model aims at modelling the number of the suspicious casualties Sp(t) which directly
feeds the number of the infected and death casualties.
• The number of the suspicious casualties Sp(t) cover the
number of the people who have been tested and/or quarantined based on suspicion of being infected, in which
the corresponding data are revealed daily by the state
authorities.
To develop a model for the suspicious casualties Sp(t),
three steps are followed.
Step 1: Consider the internal dynamics of the number of
the suspicious people. As can be seen from Fig. 3, the number of the suspicious people has two moderate peaks (overshoots), which imply that the model is almost overdamped
(not exactly damped). Thus, the system can be represented as
a 2nd order linear system as
Sp¨ (t) = a1Sp˙ (t) + a0Sp (t) (2)
where a1 and a0 are the unknown parameters which will be
determined in Section IV.
Step 2: It is the fact that the number of the infected people
I has an important role in the number of the suspicious people
since the infected people are infectious. So that they continue
spreading the virus until they are completely isolated. Therefore, the suspicious model should be coupled with the number
of the infected people as
Sp¨ (t) = a1Sp˙ (t) + a0Sp (t) + b3I (t) (3)
193900 VOLUME 8, 2020O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
where b3 is the unknown parameter that scales up the impact
of the infected people on the number of the suspicious people.
Fitting the suspicious data of Turkey shows that the suspicious model (3) reflects the general character of the real
system.
FIGURE 1. Real data of Turkey for the suspicious (red solid line) and the
model estimated with a simple parameter fitting (blue dotted line).
As can be seen from Fig. 1, except the awareness (transient
period) and the lockdowns, the constructed model (6) carries
general properties of the pandemic.
Step 3: It is important to note that the model estimation
has larger frequencies than the real one. This is because
that the real data is discrete (collected daily samples), but
the constructed model is continuous. Hence, the continuous
model (3) is converted in its discrete form as
Spk+2 = a1Spk+1 + a0Spk + b3Ik (4)
The parameters a1, a0 and b3 are kept unchanged in continuous and discrete models as they are only unknown parameters, not specifically defined parameters.
B. INFECTED MODEL
To develop a model for the infected casualties, four steps are
followed.
Step 1: Consider the internal dynamics of the infected
number of the people shown by Fig. 3. It has a large peak
(overshoot); henceforth, it is underdamped. Therefore, it is at
least 2nd order represented as
¨I (t) = b1
˙I (t) + b0I (t) (5)
where b1 and b0 are the unknown parameters of the infected
model.
Step 2: The number of the suspicious people affects the
number of the infected people. Hence the model (5) becomes
¨I (t) = b1
˙I (t) + b0I (t) + a3Sp (t) (6)
where a3 is the unknown parameter scaling up the impact of
the number of the suspicious people on the infected number
of people.
Step 3: The number of the deaths has a role on the number
of the infected people (i.e. increased number of deaths reduce
the number of the infected people). Thus, the model (6)
becomes
¨I (t) = b1
˙I (t) + b0I (t) + a3Sp (t) + d3D (t) (7)
where d3 is the unknown parameter scaling up the impact of
the number of the deaths on the infected number of people.
Step 4: Similarly, the continuous time model (7) in discrete
form is
Ik+2 = b1Ik+1 + b0Ik + a3Spk + d3Dk (8)
The infected model (8) is 2nd order and highly coupled.
Next section presents the model of the death.
C. DEATH MODEL
To develop a model for the death casualties, three steps are
followed.
Step 1: The number of deaths in Fig. 4 has a large peak
(overshoot), henceforth the system is slightly damped with at
least 2nd order dynamics which can be represented as
D¨ (t) = d1D˙ (t) + d0D (t) (9)
where d1 and d0 are the unknown parameters.
Step 2: Since the number of the infected people directly
affects the number of the deaths, the model (9) can be
improved as
D¨ (t) = d1D˙ (t) + d0D (t) + b4I (t) (10)
where b4 is the scaling factor of the number of the infected
people on the number of the deaths.
Step 3: The continuous model (10) in its discrete form is
Dk+2 = d1Dk+1 + d0Dk + b4Ik (11)
Next section presents the LS based optimization approach
to determine the unknown parameters of the proposed SpID
model.
IV. LS BASED PARAMETER LEARNING
This section formulates the bases and the unknown parameter
vectors of the SpID model together with the labelled output.
This section also provides the batch type LS based unknown
parameter estimation approach to learn the unknown parameters offline.
A. CONSTRUCTION OF THE BASES
To perform the LS based optimization, initially a basis should
be constructed for each part of the SpID model. For the
basis of the suspicious model, consider the right-hand side
of the discrete model (4) and formulate the corresponding
basis φSp as
φSp
= [Sp (2, . . . ,N − 1) Sp (1, ...N − 2) I (1, . . . ,N − 2)]
T
(12)
VOLUME 8, 2020 193901O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
where N is the length of the data. Similarly, to construct the
basis for the infected φI
, consider the right-hand side of the
discrete model (8) which yields
φI = [I (2, . . . ,N − 1) I (1, . . . ,N − 2) Sp (1, . . . ,N − 2)
D (1, . . . ,N − 2)]
T
(13)
Lastly, take into account the right-hand side of the discrete
model (11) to construct the basis for the deaths φD as
φD
= [D (2, . . . ,N − 1) D (1, . . . ,N − 2) I (1, . . . ,N − 2)]
T
(14)
These bases have information about the past casualties of the
COVID-19 and will be used for formulation of the estimated
and parametrized casualties.
B. ESTIMATED AND PARAMETRIZED CASUALTIES
The estimated model consists of the unknown parameter
vectors defined as
wSp =

a1 a0 b3
T
wI =

b1 b0 a3 d3
T
wD =

d1 d0 b4
T
(15)
where wSp, wI
, wD are the unknown parameter vectors of
the suspicious, infected and deaths models respectively. The
estimated individual models are
yˆSp = w
T
SpφSp
yˆI = w
T
I φI
yˆD = w
T
DφD (16)
where yˆSp, yˆI
, yˆD are the estimated outputs or future casualties
for the suspicious, infected and death sub-models. To perform
the LS optimization, the next step is to label the real outputs
presented next.
C. THE REAL OUTPUTS
To construct the real outputs, consider the left-hand sides of
the discrete models (4), (8) and (11). The real outputs (nonparametrized) are
ySp = Sp (3, . . . ,N)
T
yI = I (3, . . . ,N)
T
yD = D (3, . . . ,N)
T
(17)
where ySp, yI
, yD are the real outputs. Finally, next section
formulates the LS.
D. LS FORMULATION
Consider the real outputs (17) and estimated outputs (16)
by reducing the indices of the parameters and variables. The
error between them provides a tool for the estimation of the
unknown parameter vector (15). The error vector e is
e = y − ˆy (18)
where y =

ySp yI yD
T
and yˆ =

yˆSp yˆI yˆD
T
. To ensure
positive definiteness in the estimates, square the error e in (18)
and expand as
e
2 =

y − w
T φ
T 
y − w
T φ

= y
T
y − wφ
T
y − y
Tw
T φ + wφ
Tw
T φ (19)
To determine the unknown parameters w which minimizes the
squared error (19), take the gradient of (19) as
∂e
2
∂w
= −2φ
T
y + 2φ
T φw (20)
The unknown parameter vector w in (20) is obtained by
setting it zero as
w =

φ
T φ
−1
φ
T
y (21)
This formulation of the unknown parameter vector (21) can
now be used to analyse the developed model in Section VI
and to predict the future casualties of the COVID-19 in
Section VII.
E. PSEUDO-CODE FOR THE SpID MODEL
In this sub-section, we provide a simple pseudo-code to apply
the SpID model for the casualties of the other countries.
Algorithm 1 Pseudo-Code of the SpID Model
Input: Reported suspicious (Sp), infected (I) and death D
casualties
Output: Estimated models yˆSp, yˆ
Î
, and yˆD
1. Construct the bases φSp, φI and φD given by equations
(12), (13) and (14).
2. Construct the output vectors ySp, yI
, and yD given by
Equation (17).
3. Determine the unknown parameters of each submodel by using the LS optimizer in Equation (21).
4. Obtain the estimated outputs yˆSp, yˆ
Î
, and yˆD by using
Equation (16).
Next section presents the analysis of the COVID-19 data.
V. ANALYSIS OF THE DATA: COVID-19
CASUALTIES IN TURKEY
This part of the paper provides a brief presentation and
analysis of the COVID-19 casualties in Turkey. This data is
used for determining the unknown parameters of the model in
Section V and also is used for the analysis of the model and
predicted future casualties in Sections VI and VII.
A. SUSPICIOUS CASUALTIES
Fig. 2 shows the daily suspicious casualties (tested due to
appearance of the symptoms) reported by the Health Ministry of Turkey. As can be seen, initially no suspicious
casualties have been reported even though the deaths have
been reported. The number of the suspicious casualties has
increased quite sharply for about 40 days and then due to
193902 VOLUME 8, 2020O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
FIGURE 2. Daily suspicious casualties of Turkey.
mostly imposed curfews and lockdowns for about 30 days
duration, the number of the suspicious casualties has reduced
moderately. However, it continues climbing after lifting the
restrictions.
FIGURE 3. Daily infected casualties of Turkey.
B. INFECTED CASUALTIES
Fig. 3 shows the daily infected casualties reported by the
Health Ministry of Turkey. It is clear that the number of the
infected people sharply reaches the peak after around 30 days
of 12 of March 2020. The number of the infected casualties
reduces from 5000 to under 1000 after imposing restrictions
and raising social awareness against the virus. Nevertheless, the number of the infected people slightly increases
after releasing the restrictions. However, it is noticeable that
despite the large increase in the number of the suspicious
people (Fig. 2), increase in the number of the infected people
is limited (Fig. 3). This is likely because the latest tests are
for protection purpose rather than the existence of the strong
evidences of the COVID-19 symptoms.
C. DEATH CASUALTIES
Fig. 4 shows the number of the deaths stemmed from the
COVID-19 virus in Turkey. It is clear that the character of
the deaths (Fig. 4) is strongly correlated with the number of
the infected people (Fig. 3), but not with the number of the
suspicious people (Fig. 2). It is clear that the number of the
deaths has reduced from 130s to 20s, but it has not minimized.
D. BOUNDEDNESS OF THE CASUALTIES
Previously it is shown that the infected and death casualties are largely reduced, but they fluctuate around their new
FIGURE 4. Daily death casualties of Turkey.
FIGURE 5. Convergence regions of, a) Suspicious, b) Infected, c) Death.
equilibrium points after removing the curfews. As can be seen
from Fig. 5, all the elements of the SpID model converge
the bounded regions and these regions have a number of
periods where small variations yield different periods. While
the suspicious casualties have the largest region (Fig. 5a),
the death casualties have the smallest region (Fig. 5c).
VI. ANALYSIS OF THE SpID MODEL
This section provides the insightful analysis of the coupled
and higher order parametric SpID model.
A. COMMENTS ON THE SpID MODEL
The learned parameters of the SpID model with the LS
estimator (21) are
Spk+2 = 1.55Spk+1 − 0.55Spk + 0.10Ik
Ik+2 = 1.80Ik+1 − 0.80Ik + 0.00001Spk − 0.16Dk
Dk+2 = 1.79Dk+1 − 0.83Dk + 0.001Ik (22)
Insight 1: All the individual past casualties have strong
impact on the current casualties since the coefficients of the
past values are, for instance 1.55Sk+1 − 0.55Sk for Sk+2
in (22), and likewise for the others.
Insight 2: Infected number of the people slightly affects
the number of the suspicious people since 0.10Ik in (22).
Insight 3: However, the role of the number of the suspicious people on the number of the infected people is limited
(0.00001Sk ) due to widely performed precautious tests for the
people who start their tasks (i.e. soldiers, workers).
VOLUME 8, 2020 193903O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
Insight 4: Also, the role of the infected number of the
people on the number of the deaths is limited since the
majority of the infected people have recovered after successful treatments.
B. EIGENVALUE BASED ANALYSIS OF THE SpID MODEL
Eigenvalues of the coupled and 6th order discrete model (22)
provides key information about the future behaviour
(decrease or increase unboundedly and the time to reach
a certain level). Therefore, the eigenvalues of the whole
data and the data after the restrictions (late data) have been
evaluated.
Since the model is discrete, any eigenvalue smaller than
1 yields stable response (convergent) whereas any eigenvalue larger than 1 leads to instability (unbounded or infinity
response). Based on this fact, the following insights can be
deduced.
FIGURE 6. Eigenvalues of the whole and late data.
Insight 1: When the whole data is considered, the real
eigenvalues in rectangle 1 of Fig. 6 are close to 1. They
are in stable region, but they are also close to the instable
region. Therefore, any internal change or external effect can
easily drive these eigenvalues outside the stability region.
Henceforth, all the casualties can explode.
Insight 2: When the whole data is considered, there are
imaginary eigenvalues in rectangle 2 of Fig. 6. These imaginary values imply fluctuations in the casualties, but they are
considerably small compare to the real part of the eigenvalues, which are less than 1. Thus, the casualties will slightly
fluctuate over a period of time.
Insight 3: The dominant eigenvalue of the whole data is
represented with 0.99 in rectangle 1 of Fig. 6. The other
eigenvalues of the whole data will disappear, but the dominant
eigenvalue will be insignificant around 900 days later if there
are no disturbances or changes in the conditions.
Insight 4: When the late data (after the lockdowns) is
considered, the two of the real eigenvalues in rectangle 3 of
Fig. 6 are just larger than 1. Henceforth, the response is unstable and the casualties explode unboundedly if no action is
taken against them. However, since the unstable eigenvalues
are slightly larger than 1, the casualties will increase
sluggishly.
Insight 5: When the late data is considered, there are
imaginary values in rectangles 4 and 5 of Fig. 6, which are
quite large compare to their real values. Therefore, the future
casualties will be largely oscillatory.
FIGURE 7. Mean errors in estimates.
C. MEAN ERROR IN MODEL ESTIMATES
Since the bases of the parametric optimization algorithm
are small and exact, so that the corresponding parameter
space, errors in the estimates are expected. As can be seen
from Fig. 7 mean error in the estimation of the suspicious
casualties (Mean ESp) is around 100, mean error in the
estimation of the infected casualties (Mean EI ) is about
10 and mean error in the estimation of the death casualties (Mean ED) is significantly less than 1. These results
confirm that the developed model can quite accurately estimate the infected and death casualties in the presence of the
unknown uncertainties. Even though the mean error for the
suspicious casualties (Mean ESp) seems large, compare to an
average of 60000 daily suspicious casualties, it is acceptable
as well.
Next section now presents the future estimates of the
COVID-19 determined based on the model predictions.
FIGURE 8. Future COVID-19 casualties for, a) Suspicious, b) Infected,
c) Death.
VII. PREDICTION OF THE FUTURE COVID-19
This section provides the predicted future casualties estimated by the model (22) under the current conditions. Fig. 8a
193904 VOLUME 8, 2020O. Tutsoy et al.: Novel Parametric Model for the Prediction and Analysis of the COVID-19 Casualties
shows that the number of the suspicious casualties is minimized around 1000 days whereas the number of the infected
and death people reach their minimum around 300 days.
There exists a peak in the results due to small imaginary parts
of the eigenvalues discussed in Section VI-B.
VIII. LIMITATIONS OF THE STUDY
The proposed model is developed by taking into consideration the suspicious, infected, and death casualties, but it
does not take into account the intensive care and intubation
casualties, non-pharmacological policies, pharmacological
policies, and unknown uncertainties. In the future, modified
versions of the model that include these issues can easily be
developed based on our current proposed approach. Later,
the developed model should be incorporated with artificial
intelligence approaches to create policies for future pandemic
casualties.
IX. CONCLUSION
The paper initially has reviewed the SIR model adopted for
the COVID-19 casualties’ estimation. Then, the novel comprehensive SpID model has been introduced, analysed and
justified. Later, the unknown parameters of the model have
been determined by using the LS based parametric optimization approach for the COVID-19 casualties in Turkey. The
results show that the developed model can closely estimate
the casualties in Turkey. In addition, the model predicts that
the number of the infected and death people will be minimized in 300 days, whereas the number of the suspicious
casualties will reach their minimum around 1000 days. Even
though the model is trained and analysed by using COVID-19
casualties in Turkey, its unknown parameters can be adapted
for the casualties in other countries in the world.
Thus, the COVID-19 authorities of the countries can plan
new measures against the virus in the short-medium-long
terms, and accordingly, update their regulations in the fields
of economy, travel and health systems according to the
predictions of the model we propose.



NEW_PAPER


Technology
COVID-19 Artificial Intelligence Diagnosis
Using Only Cough Recordings
Jordi Laguarta , Ferran Hueto, and Brian Subirana
Abstract—Goal: We hypothesized that COVID-19 subjects, especially including asymptomatics, could be accurately discriminated only from a forced-cough cell phone
recording using Artificial Intelligence. To train our MIT
Open Voice model we built a data collection pipeline of
COVID-19 cough recordings through our website (opensigma.mit.edu) between April and May 2020 and created the
largest audio COVID-19 cough balanced dataset reported
to date with 5,320 subjects. Methods: We developed an
AI speech processing framework that leverages acoustic
biomarker feature extractors to pre-screen for COVID-19
from cough recordings, and provide a personalized patient
saliency map to longitudinally monitor patients in real-time,
non-invasively, and at essentially zero variable cost. Cough
recordings are transformed with Mel Frequency Cepstral
Coefficient and inputted into a Convolutional Neural Network (CNN) based architecture made up of one Poisson
biomarker layer and 3 pre-trained ResNet50’s in parallel,
outputting a binary pre-screening diagnostic. Our CNNbased models have been trained on 4256 subjects and
tested on the remaining 1064 subjects of our dataset.
Transfer learning was used to learn biomarker features on
larger datasets, previously successfully tested in our Lab
on Alzheimer’s, which significantly improves the COVID-19
discrimination accuracy of our architecture. Results: When
validated with subjects diagnosed using an official test,
the model achieves COVID-19 sensitivity of 98.5% with a
specificity of 94.2% (AUC: 0.97). For asymptomatic subjects it achieves sensitivity of 100% with a specificity of
83.2%. Conclusions: AI techniques can produce a free, noninvasive, real-time, any-time, instantly distributable, largescale COVID-19 asymptomatic screening tool to augment
current approaches in containing the spread of COVID-19.
Practical use cases could be for daily screening of students, workers, and public as schools, jobs, and transport
reopen, or for pool testing to quickly alert of outbreaks in
groups. General speech biomarkers may exist that cover
several disease categories, as we demonstrated using the
same ones for COVID-19 and Alzheimer’s.
Index Terms—AI diagnostics, convolutional neural networks, COVID-19 screening, deep learning, speech recognition.
Manuscript received August 3, 2020; revised August 31, 2020 and
September 21, 2020; accepted September 21, 2020. Date of publication September 29, 2020; date of current version December 25, 2020.
(Corresponding author: Brian Subirana.)
Jordi Laguarta is with the MIT AutoID Laboratory, Cambridge, MA
02139 USA (e-mail: laguarta@mit.edu).
Ferran Hueto and Brian Subirana are with the MIT AutoID Laboratory,
Cambridge, MA 02139 USA, and also with the Harvard University, Cambridge, MA 02138 USA (e-mail: fhueto@mit.edu; subirana@mit.edu).
Digital Object Identifier 10.1109/OJEMB.2020.3026928
Impact Statement—We present the dataset, model architecture and performance of a zero-cost, rapid and instantly distributable COVID-19 forced-cough recording AI
pre-screening tool achieving 98.5% accuracy, including
100% asymptomatic detection rate. An orthogonal set
of biomarkers may be developed to diagnose COVID-19,
Alzheimer’s and perhaps other conditions.
I. INTRODUCTION
S TRICT social measures in combination with existing tests
and consequently dramatic economic costs, have proven
sufficient to significantly reduce pandemic numbers, but not
to the extent of extinguishing the virus. In fact, across the
world, outbreaks are threatening a second wave, which in the
Spanish flu was way more damaging than the first one [1].
These outbreaks are very hard to contain with current testing
approaches unless region-wide confinement measures are sustained. This is partly because of the limitations of current viral
and serology tests and the lack of complementary pre-screening
methods to efficiently select who should be tested. They are
expensive making the cost of testing a whole country each day
impossible, e.g. $8.6B for the US population alone assuming
a $23 test [2]. And to be effective, they often require subjects
remain isolated for a few days until the result is obtained. In
contrast, our AI pre-screening tool could test the whole world
on a daily, or even hourly basis at essentially no cost. In terms of
capacity, in the week leading up to July 13, 2020, daily diagnostic
testing capacity in the United States was fluctuating between
520,000 and 823,000 tests. However, certain experts forecasted
the need for 5 million tests per day by June, increasing to 20
million tests per day by July [3]. The unlimited throughput
and real-time diagnostic of our tool could help intelligently
prioritize who should be tested, especially when applied to
asymptomatic patients. In terms of accuracy, in an evaluation of
nine commercially available COVID-19 serology tests, in early
phase (7-13 days after onset of disease symptoms) sensitivities
vary between 40-86% and AUC vary between 0.88-0.97 [4].
Meanwhile, our tool with AUC 0.97 achieves 98.5% sensitivity.
It has been proposed optimal region-wide daily testing and
contact tracing could be a close substitute to region-wide confinement in terms of stopping the spread of the virus [5] and
avoid the costs of stopping the economy. However, many current
attempts at testing, contact tracing, and isolation like the UK
initially employed, have been far from successful [6]. This is
mainly caused by many countries lacking the tools at the time to
employ an agile, responsive, and affordable coordinated public
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
VOLUME 1, 2020 275276 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, 2020
health strategy [6]. Therefore, as the virus spreads to countries
who cannot afford country-wide daily testing nor confinement,
a large-scale, low-cost, and accurate pre-screening tool may
be essential to prioritize tests for rapidly detecting and locally
preventing outbreaks. Different AI approaches have recently
been proposed to support the management of the pandemic
[7]–[10].
An AI coughing test would provide some advantage that
may partially offset the issues with existing biological testing
approaches. Capabilities of our AI tests include: non-invasive
real-time results, essentially zero variable cost, accessible by
anyone, and capable to longitudinally monitor patients.
As any AI deep learning approach, we needed training data
and a modelling strategy. To address the data component, which
was not available, we initiated a worldwide crowd-sourced effort to collect COVID-19 forced-cough audios along with 10
multiple choice questions related to the diagnosis of the disease
and relevant symptoms as shown in Table I. Our MIT Open
Voice COVID-19 Cough dataset [10] sets a new benchmark as
the largest audio health dataset with several hundred thousand
coughs of which 5,320 COVID-19 positive and negative balanced subjects were selected for this research. We selected all
COVID-19 positives and, randomly, an equivalent number of
negative ones from the rest of our dataset.
To address the modelling strategy, we were inspired by our
research on Alzheimer’s [11] and the growing evidence of recently reported symptoms of COVID-19 patients who suffered
neurological impairments such as temporary neuromuscular impairment and loss of smell during and post infection [12]–[14].
After trying unsuccessfully a few basic CNN models, the
connection between COVID-19 and the brain is what led us
to pivot the COVID-19 modelling efforts to our Open Voice
Brain Model framework (OVBM), based on the Brain Model
of the MIT Center for Brain Minds and Machine [15], since
we had recently applied it to the diagnostic of Alzheimer’s
achieving above state-of-the-art accuracy of 93.8%. Our MIT
OVBM framework is based on orthogonal acoustic biomarkers
to diagnose and create an individualized patient saliency map to
longitudinally monitor patients [11].
In the following sections we present the data collection
pipeline for this study (Section II.A), an overview of our
COVID19 AI model (Section II.B), the four biomarkers
(Section II.C) and the results (Section III), including our model
performance on pre-screening COVID-19 subjects, followed by
an evaluation of the biomarkers and our individualized patient
longitudinal saliency map. We conclude in Sections IV and V
with a brief summary, limitations, and implications on suggested
next steps for the deployment in practice of our COVID-19
pre-screening tool, suggesting a pooling strategy, and, more
broadly, implications of our approach for the role of AI in
Medicine going forward.
II. METHODS
A. COVID-19 Cough Dataset
Approved by the MIT COHUES Institutional Review
Board, in April 2020 we initiated a worldwide cough data
collection effort of through our website recording engine
TABLE I
THE SELECTION FOR THE COVID-19 SUBJECTS FOR PERFORMANCE
COMPARISON AIMED TO REPRODUCE A SCENARIO WHERE SUBJECTS ARE
REQUESTED TO VOLUNTARILY USE A SCREENING TOOL. THAT IS WHY THE
RATIO IS NOT EXACTLY BALANCED IN TERMS OF ANY SPECIFIC
DEMOGRAPHIC STATISTIC. INSTEAD, WE CHOSE THE SPLIT TO REFLECT
THE VOLUNTARY PARTICIPATION IN OUR CROWD-SOURCING EXERCISE,
WHICH IN THE CASE OF COVID-19 POSITIVES WAS 41.8% MALE, 53.0%
FEMALE AND 8.9% OTHER BECAUSE THAT WAS THE RATIO OF VOLUNTARY
PARTICIPANTS. NOTE THE RATIO OF CONTROL PATIENTS INCLUDED A 6.2%
MORE FEMALES, POSSIBLY ELICITING THE FACT THAT MALE SUBJECTS ARE
LESS LIKELY TO VOLUNTEER WHEN POSITIVE. THUS, THE PERCENTAGES
REFLECT OUR SAMPLE AND THEREFORE PRODUCE WHAT WE FEEL IS THE
BEST ESTIMATE OF OVERALL PERFORMANCE IF A SCREENING TOOL WAS
VOLUNTARILY USED AT SCALE. IN ANY CASE, OUR EXTENSIVE DATABASE
ALLOWS SELECTIVE TRAINING FOR OTHER DEMOGRAPHICS. NOTE THE ‘HIT’
COLUMN SHOWS THE MODEL ACCURACY ON EACH RESPECTIVE
SUBGROUP. THE CATEGORIES PERSONAL, DOCTOR AND OFFICIAL
CORRESPOND TO THE SOURCE OF DIAGNOSTIC ENTERED BY EACH
SUBJECT, WHETHER THEY TOOK AN OFFICIAL TEST, HAD A DOCTOR’S
DIAGNOSIS, OR SIMPLY A PERSONAL ASSESSMENT. THE LAST ROW SHOWS
THE RESULTS OF APPLYING THE SAME BIOMARKERS TO ALZHEIMER’S [11]
(opensigma.mit.edu) with the aim of creating the MIT Open
Voice dataset for COVID-19 cough discrimination [10]. We
collected variable length cough audio recordings (on average
3 coughs per subject) accompanied by a set of 10 multiple
choice questions related to the diagnosis of the disease and
general subject information: age, sex, country, region; whether,
when and outcome of medical diagnosis done and whether theLAGUARTA et al.: COVID-19 ARTIFICIAL INTELLIGENCE DIAGNOSIS USING ONLY COUGH RECORDINGS 277
Fig. 1. Overview architecture of the COVID-19 discriminator with
cough recordings as input, and COVID-19 diagnosis and longitudinal
saliency map as output. A similar architecture was used for Alzheimer’s
[11].
source of diagnosis was an official test, a doctor’s evaluation or
a personal assessment; and finally information about symptoms
and days since their onset. Symptoms requested included fever,
tiredness, sore throat, difficulty breathing, persistent pain or
pressure in the chest, diarrhoea and coughing.
So far, we have an estimated subject count of 2,660 COVID-19
positives and a 1-10 ratio of positive to control subjects. Recording was available on various browsers and devices, reducing any
possible device specific bias. Data was anonymized before being
collected on our secure server and samples were saved without
compression in WAV format (16kbs bit-rate, single channel,
opus codec). Samples that had no audio content (e.g. where
the file was 44 bytes) were removed. No segmentation was
performed on the cough recordings used to train and test.
We used all the COVID-19 positive samples in our dataset
and randomly selected the same number of COVID-19 negative
subjects for a balanced distribution. We only used samples with
two conditions, first a diagnostic had been done in the last 7 days
and, second, with symptoms onset no longer than 20 days and
where symptoms continued until the sample was captured. The
subject forced-cough audios and diagnostic results were used to
train and validate the COVID-19 discriminator. 4256 subjects
(80%) were used for training and 1064 (20%) for validation.
Table I provides more details on the patient distribution for the
randomly sampled patients selected from the dataset.
B. Overview of the COVID-19 Model Architecture
Our proposed architecture, drawn in Fig. 1, takes a recording
with one or more coughs, performs two pre-processing steps
with the recording and inputs it into a CNN based model to output
a pre-screening diagnostic along with a biomarker saliency map
(e.g. in Fig. 3(c)).
As pre-processing, each input cough recording is split into
6 second audio chunks, padded as needed, processed with
the MFCC package [16] and subsequently passed through
biomarker 1. The output of these steps becomes the input to
a CNN as described in the next paragraph.
The CNN architecture is made up of three ResNet50s in parallel. The 7 × 7 × 2048 4-d tensor output layer of each ResNet50
model is concatenated in parallel as depicted in Fig. 1. In the
baseline models, these ResNet50s are not pre-trained. In the
best performing model, they are pre-trained to capture acoustic
features on biomarkers 2,3 and 4 as described in Section II.C.
The output of these three concatenated tensors is then pooled
together using a Global Average Pooling 2D layer, followed by
a 1024 neuron deeply connected neural network layer (dense)
with ReLU activation, and finally a binary dense layer with
sigmoid activation. The whole architecture is trained on the
COVID-19 cough dataset for binary classification. The various
chunk outputs from the CNN architecture are aggregated using
competing schemes to generate the subject’s saliency map as
illustrated in Fig. 3(c). The results of this paper and presented
in Table I are based solely on the first audio chunk outputs.
Future work may show that aggregation can not only improve
explainability but also increase diagnostic accuracy.
C. COVID-19 Model Biomarkers
The MIT Open Voice Medicine architecture uses the same
four biomarkers we previously tested for the detection of
Alzheimer’s which achieved above state-of-the-art accuracy
[11]. These four biomarkers inspired by medical community
choices [17]–[21] are: muscular degradation, changes in vocal
cords, changes in sentiment/mood, and changes in the lungs and
respiratory tract.
1) Biomarker 1 (Muscular Degradation): Following memory decay models from [22], [23] we introduced muscle fatigue
and degradation features by modifying input signals for all train
and test sets with the Poisson mask in Equation 1. Poisson decay
is a commonly occurring distribution in nature [24] which has
previously been proposed to model muscular degradation. We
find it effective since removing this biomarker roughly doubles
the error rate in official predictions. To capture the influence of
muscular degradation in individual predictions, we developed
a muscular degradation metric based on comparing the output
with and without this initial Poisson step. This metric is the
normalized ratio of the prediction with and without the mask
and it is incorporated in the saliency map as illustrated in Fig. 3.
For COVID negatives this metric is plotted directly; and for
positives we plot one minus this metric.
The Poisson mask applied on a cough recording MFCC point,
Ix, is calculated by multiplying this value by a random Poisson
distribution of parameters Ix and λ, where λ is the average of all
values in the MFCC.
M (Ix) = P oiss (λ) Ix (1)
P oiss (X = k) = λke−k
k! (2)
2) Biomarker 2 (Vocal cords): Subjects with lung diseases
often have distinct expressions of vocal cords biomarkers as
compared to healthy ones [25]. For example, studies have reported phonation threshold pressure, the minimal lung pressure
necessary to start and hold vocal fold oscillation, correlates to
vocal fatigue [26]. Therefore, we were interested in creating a
vocal cord biomarker model capable of detecting changes in
basic features of vocal cord sounds in continuous speech.
We focused on developing a Wake Word model [27] for a
very universal sound ”mmmmmm”. We trained a ResNet50
[28] with input shape (300, 200) from MFCC to discriminate
the word ’Them’ from others using LibriSpeech, an audiobook
dataset with ≈1,000 hours of speech [29]. The model was278 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, 2020
TABLE II
THE FIRST THREE ROWS SHOWS THE UNIQUE PERCENTAGE OF SAMPLES
DETECTED BY EACH INDIVIDUAL BIOMARKER FOR COVID-19 AND
ALZHEIMER’S, DEMONSTRATING THE DISCRIMINATORY VALUE OF THE EXACT
SAME THREE BIOMARKERS FOR BOTH DISEASES. THE NEXT THREE ROWS
FOCUS ON THE OVERLAP BETWEEN TWO BIOMARKERS DEMONSTRATING
HOW ORTHOGONAL THEY ARE TO EACH OTHER
trained by creating a balanced sample set of 11,000 two-second
audio chunks, half containing the word and half without it, and
achieved a validation accuracy of 89%.
We found that the learned features from this biomarker enable
the detection of variations in the vocal cords that exist between
COVID-19 and control subjects, discriminating 54% of the test
set. As shown in Table II, for 19% of the subjects, this is the
only biomarker to correctly discriminate them.
3) Biomarker 3 (Sentiment): Studies [14] show a cognitive decline in COVID-19 patients and clinical evidence supports the importance of sentiments in the early-diagnosis of
neurodegenerative decline [19], [30]. Different clinical settings
emphasize different sentiments, such as doubt [31] or frustration [31] as possible neurodegenerative indicators. To obtain
a biomarker that detects this decline, we trained a Sentiment
Speech classifier model to learn sentiment features on the
RAVDESS speech dataset [32], which includes actors intonating
in 8 emotional states: neutral, calm, happy, sad, angry, fearful,
disgust, and surprised. A ResNet50 [28] was trained on 3 second samples for categorical classification of the 8 intonations
with input shape (300, 200) from MFCC which achieved 71%
validation accuracy.
4) Biomarker 4 (Lungs and Respiratory Tract): The human cough has already been demonstrated to be helpful in
diagnosing several diseases using automated audio recognition
[33], [34]. The physical structure of the lungs and respiratory
tract get altered with respiratory infections, and in the early days
of the COVID-19, epidemiologists listened to the lungs while
patients forced coughs as part of their diagnostic methods. There
is evidence that many other diseases may be diagnosed using AI
on forced-coughs. An algorithm presented by [35] uses audio
recognition to analyse coughs for the automated diagnosis of
Pertussis - a contagious respiratory disease that if left untreated
can be fatal. Algorithms based on cough sounds collected using
smartphone devices are already diagnosing pneumonia, asthma
and other diseases with high levels of accuracy [36]–[39]. Therefore, a biomarker model capable of capturing features on the
lungs and respiratory tract was selected.
Past models we created with a superset of the cough dataset
collected through MIT Open Voice for COVID-19 detection
[10] accurately predicted a person’s gender and mother tongue
Fig. 2. The top orange line with a square shows the ROC curve for the
set of subjects diagnosed with an official test with AUC (0.97), while the
bottom blue curve with a circle shows the ROC curve for all subjects in
the validation set. The square shows the chosen threshold with 98.5%
sensitivity and 94.2% specificity on officially tested subjects, and the
black circle shows the chosen threshold for high sensitivity (94.0%)
on the whole validation set, although any point on the curve could be
chosen depending on the use case.
based on one cough. We hypothesized that such models capable
of learning features and acoustic variations on forced coughs
trained to differentiate mother tongue could enhance COVID-19
detection using transfer learning. We stripped from the dataset
all metadata but the spoken language of the person coughing
(English, Spanish), and split audios into 6s chunks. A ResNet50
[28] was trained on binary classification of English vs Spanish
with input shape (600, 200) from MFCC and 86% accuracy. We
found that the cough biomarker is the one that provides the most
relevant features with 23% unique detection and 58% overall
detection as shown in Table II.
III. RESULTS
A. COVID-19 Forced-Cough Discrimination Accuracy
Our model achieves a 97.1% discrimination accuracy on
subjects diagnosed with an official test. The fact that our model
discriminates officially tested subjects 18% better than selfdiagnosed, as shown in Table I, is consistent with this discrepancy being caused by self-diagnostic errors. These errors can
contribute to the expansion of the virus even if subjects are well
intentioned, and our tool could help diminish this impact. To
that end, it is remarkable that our tool discriminates 100% of
asymptomatics at the expense of a false positive rate of 16.8%.
Note the tool sensitivity/specificity can be tailored depending
on the use case, such as improving specificity at the cost of
sensitivity, as shown in Fig. 2.
B. Biomarker Saliency Evaluation
To measure the role of each biomarker in the discrimination
task, we compared the results between a baseline model and the
complete model with and without each biomarker. The baseline
model is defined as the same architecture shown in Fig. 1 trained
on COVID-19 discrimination as in our model but without the
pre-trained biomarker model features. Therefore, the baselineLAGUARTA et al.: COVID-19 ARTIFICIAL INTELLIGENCE DIAGNOSIS USING ONLY COUGH RECORDINGS 279
Fig. 3. A. The numbers on the x-axis describe the number of layers in the biomarker models fine-tuned to COVID-19. The fewer required to beat
the baseline (which is the same architecture trained on COVID-19 discrimination without the pre-trained biomarker models) shows the relevance
of each biomarker for COVID-19. “Complete: shows the final COVID-19 discriminator with all the biomarkers integrated. B. The white dotted part
of the bar shows the performance gained when the Cough biomarker model is incorporated, while pre-trained denotes individually training the
biomarker models for COVID-19 before integrating them into the multi-modal architecture on Fig. 1. C. shows the explainable saliency map derived
from biomarker model predictions to longitudinally track patient progression and is analogous to the saliency map derived for Alzheimer’s [11].
OVBM denotes the final model diagnostic. The BrainOS section shows the model aggregated prediction for 1-4 coughs of a subject. The COVID-19
progress factor calculates based on the 1-4 cough predictions, a possible degree of severity from the quantity of acoustic information required for
a confident diagnostic. The voting confidence and salient factor indicate, based on the composite predictions of individual biomarker models, the
aggregate confidence and salient discrimination for each subject.
model has the exact same number of neurons and weights
but is initialized randomly instead of with pre-trained models.
From Fig. 3(a), the lungs and respiratory track biomarker model
requires very few layers to be fine-tuned to COVID-19 discrimination to beat the baseline which emphasizes the relevance of its
pre-learned features. Meanwhile, sentiment requires retraining
many more features in order to surpass the baseline showing
that although the pre-learned features bring value, they may be
less closely related. Fig. 3(b) shows leave-one-out significance
by measuring the performance loss when a chosen biomarker
model is removed. Compared to the sentiment biomarker, the
vocal cord biomarker contributes twice the significance in terms
of detection accuracy.
We illustrate similar metrics in Table II by showing the
percentage of unique patients captured by each biomarker.
This is consistent with each biomarker model bringing complementary sets of features, and suggests incorporating additional biomarker models may increase the diagnostic accuracy and explainability of the MIT OVBM AI architecture for
COVID-19. Note that the three biomarkers are quite distinct
because in pairs they find no unique subjects.
As shown in Fig. 3(c), on top of the diagnostic accuracy
for COVID-19, our AI biomarker architecture outputs a set of
explainable insights for doctors to analyse the make-up of each
individual diagnostics as follows: the Sensory Stream indicates
the expression of the chosen biomarkers; the BrainOS shows
the model confidence improvement as more coughs from one
subject are fed into it, signalling the strength of the diagnosis
and in turn potentially of the disease severity; the Symbolic
CompositionalModels provides a set of composite metrics based
on the Sensory Stream and BrainOS. Together, these modular
metrics could enable patients to be longitudinally monitored
using the saliency map of Fig. 3(c), as well as for the research
community to hypothesize new biomarkers and relevant metrics.
Future research may demonstrate to what extent our model can
promptly detect when a COVID-19 positive subject no longer
has the disease and/or is not contagious.
IV. DISCUSSION
We have proven COVID-19 can be discriminated with 98.5%
accuracy using only a forced-cough and an AI biomarker focused approach that also creates an explainable diagnostic in
the form of a disease progression saliency chart. We find most
remarkable that our model detected all of the COVID-19 positive
asymptomatic patients, 100% of them, a finding consistent with
other approaches eliciting the diagnostic value of speech [40].
Our research uncovers a striking similarity between
Alzheimer’s and COVID discrimination. The exact same
biomarkers can be used as a discrimination tool for both, suggesting that perhaps, in addition to temperature, pressure or pulse,
there are some higher-level biomarkers that can sufficiently
diagnose conditions across specialties once thought mostly disconnected. This supports shared approaches to data collection
as suggested by the MIT Open Voice team [27].
This first stage of developing the model focused on training
it on a large dataset to learn good features for discriminating
COVID-19 forced-coughs. Although coughs from subjects that
were diagnosed through personal or doctor assessment might
not be 100% correctly labelled, they enable training the model
on a significant variety and quantity of data, essential to reduce
bias and improve model robustness. Thus, we feel the results
on the set of subjects diagnosed with an official test serve as
an indicator that the model would have similar accuracy when
deployed, and to verify this we are now undergoing clinical trials
in multiple hospitals. We will also gather more quality data that
can further train, fine-tune, and validate the model.
Since there are cultural and age differences in coughs, future
work could also focus on tailoring the model to different age
groups and regions of the world using the metadata captured,
and possibly including other sounds or input modalities such as
vision or natural language symptom descriptions.
Another issue that may be researched is whether cough segmentation can improve the results. For the screening outputs
to have diagnostic validity, there must be a process to verify280 IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY, VOL. 1, 2020
Fig. 4. In cases where there are very few infected individuals, a group
pre-screening tool can be derived from the COVID-19 OVBM model to
accurately alert infected groups while avoiding false-positives as illustrated in the graph. With the current accuracy, shown in blue, a threshold
of 3 positives in a group of 25 are required so that only 1% of groups of
25 with no cases are falsely labelled and therefore unnecessarily tested
via expensive biological tests. In other words, in a campus with 2500
yet uninfected students, only 25 will have to be tested with biological
methods until 3 people in a class of 25 catch the virus, in which case
the screening will alert of the outbreak. The x-axis shows how the
required number of positives in a group, 3 in this example, drops if the
COVID-19 model accuracy improves. Each line shows percent of groups
of 25 people falsely tagged with COVID-19 with a minimum number of
COVID-19 positives in it. As a second example, assume a country like
New Zealand, with very few COVID-19 cases, wanted to screen for new
early outbreaks and to do so tested 50M inhabitants using a PCR or
serology test with 99% specificity. The country would purchase 50M
tests and obtain 500 000 false-positives. Meanwhile, assume a group
test yielding a 99.9% test accuracy was used, i.e. requiring 5 positives
instead of 3 in the example above. Of the, 2M groups of 25, only 2000
groups would be falsely tagged or 50 000 people. Hence, 0.1% of the
cost and 0.1% of the false positives otherwise. The value of this group
testing tool is that it enables organizations and countries to pre-screen
its whole population daily, and rapidly locate incipiently infected groups,
without the necessity of using an expensive PCR or serology test on
each inhabitant.
recordings correspond to coughs. In the official tests of our
dataset only three recordings corresponded to speech instead
of coughs and we had to sort these manually since there is still
no way to do so automatically.
This non-invasive, free, real-time pre-screening tool may
prove to have a great potential to complement current efforts
to contain the disease in low-infected areas as well as to
mitigate the impact in highly-infected areas, where unconscious
asymptomatics may spread the virus. We contend the MIT Open
Voice approach presented has great potential to work in parallel
with healthcare systems to augment current approaches to manage the spread of the pandemic, especially if combined with
broader uses of an open approach, as is being attempted by the
https://www.openvoicenetwork.org. We present some possible
example use cases:
Population daily screening tool: As workers go back to
work, students go back to school, and commuters use public
transport, to name a few, methods are required to screen infected COVID-19 carriers, especially asymptomatics. The only
screening method currently available is using thermometers,
however this study [41] showed only 45% of mild-moderate
COVID-19 cases have fever (this represents 9% of COVID-19
positives when asymptomatics are included). Meanwhile our
tool detects 98.5% of COVID-19 positives, including 100% of
asymptomatics.
Pre-selection of candidates for test pooling: The test pooling
strategy is expected to be employed in many countries, especially in low-incidence areas to rapidly identify a sub group of
individuals likely to be infected, however, “preliminary results
show there is no dilution and no decrease on test sensitivity when
minipools of five samples each are used” [42]. Group testing with
our tool as shown in Fig. 4, could pre-screen school classrooms,
factories or even countries on a daily basis signalling probable
infected candidate groups for smaller test pooling batches.
COVID-19 test in countries where PCR/serology testing is
not possible: The availability of COVID-19 tests worldwide
is far from evenly distributed. “Even where there is enough
money, many African health authorities are unable to obtain the
supplies needed as geopolitically powerful countries mobilise
economic, political, and strategic power to procure stocks for
their populations” [43]. This pre-screening tool has the potential
to bring large-scale detection to areas of the world were testing
is too expensive or logistically complex, essential to halt the
spread of the disease worldwide.
V. CONCLUSION
We have created an AI pre-screening test that discriminates
98.5% COVID-19 positives from a forced-cough recording, including 100% of asymptomatics, at essentially no cost and with
an accompanying saliency map for longitudinal explainability.
A group outbreak detection tool could be derived from this
model to pre-screen whole-populations on a daily basis, while
avoiding the cost of testing each inhabitant, especially important
in low-incidence areas where the required post-test confinement is harder to justify. Figure 4 shows that by deriving the
COVID-19 cough discrimination model for a group test, it
can correctly detect the presence of COVID-19 in 99.9% of
groups of 25 people with 5 positives, and 95% of groups with
3 positives.
As part of our ongoing clinical trials, data pipelines with
hospitals worldwide have been setup to continue to improve
the tool including: Mount Sinai and White Planes Hospitals
in the US, Catalan Health Institute in Catalonia, Hospitales
Civiles de Guadalajara in Mexico, and Ospedale Luigi Sacco
in Italy. We plan on leveraging this data to further train and
validate our models with the aim of improving pandemic
management practices. Note from Fig. 4 how the number of
COVID-19 positives required in group testing greatly drops as
the individual model improves, calling for a larger database and
further refinement of our model.
To that end, we have reached an agreement with a Fortune
100 company to demonstrate the value of our tool as part of their
COVID-19 management practices. As we have shown there are
cultural and age differences in coughs, future work could focus
on tailoring the model to different age groups and regions of the
world using the metadata captured, something we would like to
test at the company site.
Eventually we hope our research methods inspire others
to develop similar and complementary approaches to diseaseLAGUARTA et al.: COVID-19 ARTIFICIAL INTELLIGENCE DIAGNOSIS USING ONLY COUGH RECORDINGS 281
management beyond dementia and COVID-19, possibly expanding our initial set of orthogonal audio biomarkers. We
have followed the MIT Open Voice approach [27], [10] that
postulates voice samples may eventually be broadly available
if shared by smart speakers and other ever-listening devices
such as your phone. Voice may be combined into a multi-modal
approach including vision, EEG and other sensors. Pandemics
could be a thing of the past if pre-screening tools are always-on
in the background and constantly improved. In [44] we introduce
“Wake Neutrality” as a possible approach to make that vision a
reality while we discuss associated legal hurdles.




NEW_PAPER


Received September 22, 2020, accepted September 26, 2020, date of publication September 29, 2020,
date of current version October 12, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3027685
COVID-19 Control by Computer Vision
Approaches: A Survey
ANWAAR ULHAQ 1
, (Member, IEEE), JANNIS BORN 2
, (Member, IEEE),
ASIM KHAN 3
, (Member, IEEE), DOUGLAS PINTO SAMPAIO GOMES 3
, (Member, IEEE),
SUBRATA CHAKRABORTY 4
, (Senior Member, IEEE),
AND MANORANJAN PAUL 1
, (Senior Member, IEEE)
1School of Computing and Mathematics, Charles Sturt University, Port Macquarie, NSW 2795, Australia
2Department for Biosystems Science and Engineering, ETH Zurich, 4058 Basel, Switzerland
3College of Engineering and Science, Victoria University, Melbourne, VIC 3011, Australia
4Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW 2007, Australia
Corresponding author: Anwaar Ulhaq (aulhaq@csu.edu.au)
This work was supported by Charles Sturt University, COVID-19 Fund.
ABSTRACT The COVID-19 pandemic has triggered an urgent call to contribute to the fight against an
immense threat to the human population. Computer Vision, as a subfield of artificial intelligence, has
enjoyed recent success in solving various complex problems in health care and has the potential to contribute
to the fight of controlling COVID-19. In response to this call, computer vision researchers are putting
their knowledge base at test to devise effective ways to counter COVID-19 challenge and serve the global
community. New contributions are being shared with every passing day. It motivated us to review the recent
work, collect information about available research resources, and an indication of future research directions.
We want to make it possible for computer vision researchers to find existing and future research directions.
This survey article presents a preliminary review of the literature on research community efforts against
COVID-19 pandemic.
INDEX TERMS Artificial intelligence, COVID-19, computer vision, review, survey.
I. INTRODUCTION
COVID-19, known as an infectious disease is caused by
severe acute respiratory syndrome (SARS-CoV-2) [1] and
named coronavirus due to its visual appearance (under an
electron microscope) to solar corona (similar to a crown) [2].
The fight against COVID-19 has motivated researchers
worldwide to explore, understand, and devise new diagnostic
and treatment techniques to culminate this threat to our generation. In this article, we discuss how the computer vision
community is fighting with this menace by proposing new
types of approaches, improving efficiency, and speed of the
existing efforts.
The scientific response to combat COVID-19 has been
far quicker and widespread. A keyword search on PubMed
and the major open-access preprint repositories (arXiv,
bioRxiv and medRxiv) revealed that in 2019, 735 published papers included the word ‘‘coronavirus’’. FIGURE 1
illustrates our findings. During the first half of 2020, this
number has increased a thirty-fold and rose to astounding
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
21,806 articles. For comparison, the SARS pandemic, with
less than 10,000 confirmed infections and <1,000 deaths,
led roughly to a four-fold increase over two years (2002:
221 and 2004: 822). After the occurrence of MERS in 2012
(less than 3,000 confirmed infections and 1,000 deaths to
date) a doubling in coronavirus related papers over four years
(2011 to 2015) was observed.
The Economist has dubbed the current Herculean task
science of the times with the hope that such efforts would
help speed up the development of a COVID-19 vaccine [3].
Numerous approaches in computer vision have been proposed so far, dealing with different aspects of combat the
COVID-19 pandemic. These approaches vary in terms of
their approach to the fundamental questions:
• How can medical imaging facilitate faster and reliable
diagnosis of COVID-19?
• Which image features correctly classify conditions as
Bacterial, Viral, COVID-19, and Pneumonia?
• What can we learn from imaging data acquired from
disease survivors to screen critical and non-critical ill
patients?
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 179437A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 1. A portrayal of current increase in research articles about coronavirus related research. Since their discovery in the early 1960s,
coronavirus research has increased substantially; especially after the SARS outbreak in 2002 made clear their pandemic potential. Previously,
the most productive full year was 2004 with 822 coronavirus papers. The SARS-CoV-2 pandemic has caused a leap, with 21,806 articles only in the
first half of 2020 (reference date for the analysis was 30 June 2020). Note that the y-axis is displayed in log-scale for visual clarity and that the
height of the coloured bars shows their relative contribution.
• How can computer vision be used to enforce social
distancing and early screening of infected people?
• How can 3D computer vision help to maintain healthcare equipment supply and guide the development of a
COVID-19 vaccine?
The answers to these questions are being explored, and
preliminary work has been done.
The contribution of this review article is as follows:
This review article classifies COVID-related computer vision
methods into broad categories and provides salient descriptions of representative methods in each group. We aspire
to give readers the ability to understand the baseline efforts
and kickstart their work where others have left. Furthermore,
we aim to highlight new trends and innovative ideas to build a
more robust and well-planned strategy during this war of our
times.
Our survey will also include research articles in pre-print
format due to the time urgency imposed by this disease.
However, one limitation of this review is the inclusion of
the risk of lower quality and work without due validation.
Many of the works have not been put into the clinical trial
as it is time-consuming. Nevertheless, our intention here is
to share ideas from a single platform while highlighting the
computer vision community efforts. We hope that our reader
is aware of these contemporary challenges. This article is an
extended and revised version of the earlier preprint survey [4].
We follow a top-down approach to describe the research
problems that require urgent attention. We start with disease
diagnosis, discuss disease prevention and control, followed
by treatment-related computer vision research work.
We have organised the paper as follow: Section 2 describes
the overall taxonomy of computer vision research areas by
classifying these efforts into three classes. Section 3 provides a detailed description of each research area, relevant papers, and a brief description of representative work.
Section 4 describes available resources, including research
datasets, their links, deep learning models, and codes.
Section 5 provides the discussion and future work directions
followed by concluding remarks and references.
II. HISTORICAL DEVELOPMENT
The novel coronavirus SARS-CoV-2 is the seventh member
of the Corona viridae family of viruses which are enveloped,
non-segmented, positive-sense RNA viruses [5]. The mortality rate of COVID-19 is less than that of the severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) coronavirus diseases (10% for SARS-CoV
and 37% for MERS-CoV). However, it is highly infectious,
and the number of cases is on continuous rise [6].
The disease outbreak first reported in Wuhan, the Hubei
province of China, after several cases of pneumonia with
unknown causes were reported on 31 December 2019.
A novel coronavirus was discovered as the causative
organism through in-depth sequencing analysis of samples of patient’s respiratory tract at Chinese facilities on
7 January 2020 [6]. The outbreak was announced as
a Public Health Emergency of International Concern on
30 January 2020. On 11 February 2020, the World Health
Organization (WHO) announced a name for the new coronavirus disease: COVID-19. It was officially being considered
pandemic after the 11 March announcement by WHO [7].
III. TAXONOMY OF KEY AREAS OF RESEARCH
In this section, we describe the classification of computer vision techniques that try to counter the menace of
COVID-19. For better comprehensibility, we have classified
them into three key areas of research: (i) diagnosis and prognosis, (ii) disease prevention and control, and (iii) disease
treatment and management. FIGURE 2 shows this taxonomy.
In the following subsections, we discuss the research fields,
179438 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 2. Classification of computer vision approaches for COVID-19 Control. Our survey classifies COVID-19 related computer vision
methods into three broad categories.
the relevant papers, and present a brief representative description of related works.
A. DIAGNOSIS AND PROGNOSIS
An essential step in this fight is the reliable, faster, and affordable diagnostic process that can be readily accessible and
available to the global community. According to Cambridge
dictionary [8], diagnosis is: ‘‘the making of a judgment about
the exact character of a disease or other problem, especially
after an examination, or such a judgment’’ and prognosis is
‘‘a doctor’s judgment of the likely or expected development
of a disease or of the chances of getting better’’.
Currently, Reverse transcriptase quantitative polymerase
chain reaction (RT-qPCR) tests are considered as the gold
standard for diagnosing COVID-19 [9]. During such a test,
small amounts of viral RNA are extracted from a nasal
swab, amplified, quantified. Virus detection is then performed using a fluorescent dye. Although accurate, the test
is time-consuming, manual and requires biomolecular testing facilities which limits its availability in large scales and
third-world countries. Care has to be taken in interpreting
negative test results. A meta-study estimated the sensitivity
over the disease process and found a maximal sensitivity
of 80%, eight days after infection [10]. Some studies have
also shown false-positive PCR testing [11].
1) COMPUTED TOMOGRAPHY (CT) SCAN
An alternative approach is the use of a radiology examination
that uses computed tomography (CT) imaging [12]. A chest
CT scan is a non-invasive test conducted to obtain a precise
image of a patient’s chest. It uses an enhanced form of X-Ray
technology, providing more detailed images of the chest than
a standard X-Ray. It produces images that include bones, fats,
muscles, and organs, giving physicians a better view, which
is crucial when making accurate diagnoses.
A Chest CT scan is of two types: namely high-resolution
and spiral chest CT scan [13]. The high-resolution chest CT
scan provides more than a slice (or image) in a single rotation
of the X-Ray tube. The spiral chest CT scan application
involves a table that continuously moves through a tunnel-like
hole while the X-Ray tube follows a spiral path. The advantage of the spiral CT is that it is capable of producing a
three-dimensional image of the lungs.
Important CT features include ground-glass opacity, consolidation, reticulation/thickened interlobular septa, nodules, and lesion distribution (left, right or bilateral lungs)
[14]–[17]. The most observable CT features discovered in
COVID-19 pneumonia include bilateral and sub pleural areas
of ground-glass opacification, consolidation affecting the
lower lobes. Within the intermediate stage (4-14 days from
symptom onset), crazy-paving pattern and possibly observable Halo sign become important features as well [6], [11],
[12], [12], [14]–[18]. One case of CT images is shown in
FIGURE 3 that illustrates ground glass opacities and ground
halo features. As the identification of disease features is timeconsuming, even for expert radiologists, computer vision can
help by automating such a process.
2) REPRESENTATIVE WORK, EVALUATION AND DISCUSSION
To date, various CT-scanning automated approaches have
been proposed [8], [12]–[16], [18]–[27]. To discuss the
approach and performance of the computer vision CT-based
disease diagnosis, we have selected some recent representative works that provide an overview of their effectiveness.
It is worth noting that they have been presenting different performance metrics and using a diverse number of images and
VOLUME 8, 2020 179439A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 3. CT images adapted from [6], [18] portray CT features related to COVID-19. Ground glass opacities (top) and ground glass halo (bottom).
datasets. These practices make their comparison very challenging. Some of the metrics include Accuracy, Specificity,
Sensitivity, Positive predictive value (PPV), Negative predictive value (NPV), Area Under Curve (AUC), and F1 score.
A quick elucidation on their definition can be useful. The
accuracy of a method finds how correct the values are predicted. The precision finds the reproducibility of the measurement; Recall presents how many of the correct results are
discovered while F1-score uses a combination of precision
and recall for a balanced average result.
The first class of work discussed here approaches diagnosis as a segmentation problem. Chen et al. [22] has proposed a CT image dataset of 46,096 images of both healthy
and infected patients, labelled by expert radiologists. It was
collected from 106 patients admitted with 51 confirmed
COVID-19 pneumonia and 55 control patients. The work
used deep learning models for segmentation only so that
it could identify the infected area in CT images between
healthy and infected patients. It was based on UNet++
semantic segmentation model [23], used to extract valid areas
in the images. It used 289 randomly selected CT images
and tested it on other 600 randomly selected CT images.
The model achieved a per-patient sensitivity of 100%, specificity of 93.55%, the accuracy of 95.24%, PPV (positive
prediction value) of 84.62%, and NPV (negative prediction
value) of 100%. In the retrospective dataset, it resulted in a
per-image sensitivity of 94.34%, the specificity of 99.16%,
the accuracy of 98.85%, PPV of 88.37%, and NPV of 99.61%.
The trained model from this study was deployed at the Renmin Hospital of Wuhan University (Wuhan, Hubei province,
China) to accelerate the diagnosis of new COVID-19 cases.
It was also open-sourced on the Internet to enable a rapid
review of new cases in other locations. A cloud-based
open-access artificial intelligence platform was constructed
to provide support for detecting COVID-19 pneumonia
worldwide. For this purpose, a website has been made
available to provide free access to the present model at
(http://121.40.75.149/znyx-ncov/index). TABLE 1 presents
a description of the representative techniques for CT based
COVID-19 diagnosis.
The second type of work considered COVID-19 as a binary
classification problem. Li et al. [24] proposed (COVNet),
to extract visual features from volumetric chest CT using
transfer learning on the RESNET50. Lung segmentation was
179440 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
TABLE 1. Representative works for CT based COVID-19 diagnosis.
VOLUME 8, 2020 179441A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
TABLE 1. (Continued.) Representative works for CT based COVID-19 diagnosis.
performed as a pre-processing task using the U-Net model.
It used 4356 chest CT exams from 3,322 patients from the
dataset collected from 6 hospitals between August 2016 and
February 2020. The sensitivity and specificity for COVID-19
are 90% (114 of 127; p-value<0.001) with 95% confidence
interval (CI) of [95% CI: 83%, 94%] and 96% (294 of
307; p-value<0.001) with [95% CI: 93%, 98%], respectively.
The model was also made available online for public use at
https://github.com/bkong999/COVNet.
The diagnosis problem was also approached as a
3-category classification task: distinguishing healthy patients
from those with other types of pneumonia and those with
COVID-19. Li et al. [24] used data from 88 patients diagnosed with the COVID-19, 101 patients infected with bacteria pneumonia, and 86 healthy individuals. It proposed
the DRE-Net (Relation Extraction neural network) based
on ResNet50, on which the Feature Pyramid Network
(FPN) [25] and the Attention module was integrated to represent more fine-grained aspects of the images. An online
server is available for online diagnoses with CT images at
http://biomed.nsccgz.cn/server/Ncov2019.
A recent landmark study was published by Mei et al. [27]
in Nature Medicine. In a cohort of 906 RT-PCR tested patients
(419 COVID-positive), a two-stage CNN was combined with
an MLP on clinical features (age, sex, exposure history,
symptoms) and the diagnostic performance was compared
to senior radiologists. A ‘‘slice selection CNN’’ was used to
select abnormal CT scans which were subsequently classified by the ‘‘disease diagnosis CNN’’. Interestingly, fusing a
512-dimensional vector of the CT scans with clinical features
yielded a joint model that significantly outperformed the
CNN-only model in ROC-AUC and specificity. On a test set
of 279 patients, the joint model surpassed senior radiologists
in ROC-AUC (0.92 vs. 0.84), while showing worse specificity
(83% vs. 94%) and statistically insignificant better sensitivity
(84% vs. 75%). The model also correctly identified 68% of
positive patients who exhibited normal CT scans according to
the radiologists. It hints toward the potential of deep learning
179442 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 4. Chest CXR of an elderly male patient ( Wuhan, China, who travelled to Hong Kong, China). Provided are three chest XR chosen out of the daily
chest CXR for this patient. The consolidation can be observed in the right lower zone on day 0 persist into day four, followed by novel consolidate
changes in the right mid-zone periphery and perihelia region. Such type of mid-zone change improved on the day seven-film. Image adapted from [41].
to pick-up complex, disease-relevant patterns that may stay
indiscernible for radiologists.
Due to limited time available for annotations and labelling,
weakly-supervised deep learning-based approaches have also
been developed using 3D CT volumes to detect COVID-19.
Zheng et al. [26] proposed 3D deep convolutional neural Network (DeCoVNet) to Detect COVID-19 from CT volumes.
The weakly supervised deep learning model could accurately predict the COVID-19 infectious probability in chest
CT volumes without the need for annotating the lesions for
training. The CT images were segmented using a pre-trained
UNet. It used 499 CT volumes for training, collected from
13 December 2019 to 23 January 2020, and 131 CT volumes for testing, collected from 24 January 2020 to 6 February 2020. The authors chose a probability threshold of 0.5 to
classify COVID- positive and COVID- negative cases. The
algorithm obtained an accuracy of 0.901, a positive predictive value of 0.840, and a high negative predictive value
of 0.982. The developed deep learning model is available at
https://github.com/sydney0zq/covid-19-detection.
3) X-RAY IMAGERY
One drawback of using CT imaging is the need for high
patient dose and enhanced cost [43]. The low availability
imposes Additional challenges for CT in remote areas and
the need of patient relocation and exhaustive disinfection
of the scanner rooms (several hours per day) that risk contagion for staff and other patients [44]. These disadvantages call into play chest X-Ray radiography (CXR) as a
preferred first-line imaging modality with lower cost and
a wider availability for detecting chest pathology. Digital
X-Ray imagery computer-aided diagnosis is used for different diseases, including osteoporosis [45], cancer [46] and
cardiac disease [39]. However, as it is really hard to distinguish soft tissue with a poor contrast in X-Ray imagery, contrast enhancement is used as pre-processing step [47], [48].
Lung segmentation of chest X-Rays is a crucial and important
step in order to identify lung nodules and various segmentation approaches are proposed in the literature [49]–[52].
CXR examinations show consolidation in COVID-19
infected patients. In one study at Hong Kong [41], three
different patients had daily CXR, two of them showed progression in the lung consolidation over 3-4 days. Further CXR
examinations show improvement over the subsequent two
days. The third patient showed no significant variations over
eight days. However, a similar study showed that the ground
glass opacities in the right lower lobe periphery on the CT are
not visible on the chest radiograph, which was taken 1 hour
apart from the first study. FIGURE 4 illustrates a scenario
with three chest XR chosen out of the daily chest CXR for a
patient. The consolidation can be observed in the CSR image.
In a large-scale study of 636 ambulatory COVID-19 patients,
Weinstock et al. found that 58% of CXR was normal and 89%
were normal or mildly abnormal [53]. Interstitial changes
(24%) and GGOs (19%) were the most prominent symptoms, and abnormalities were most prevalent in the lower
lobe (34%). While the sensitivity of CXR is significantly
lower than for CT, the American College of Radiology (ACR)
recommends to conduct CXR with portable devices and only
if ‘‘medically necessary’’ for better radiological analysis. It
moreover firmly advises to not use any imaging technique
for COVID-19 diagnosis but instead suggests biomolecular
tests [54]. In the realm of AI,
Various CXR-related automated approaches are proposed.
The following section discusses the most salient work, while
TABLE 2 presents a more systematic presentation of such
methods.
4) REPRESENTATIVE WORK, EVALUATION AND DISCUSSION
To date, many deep learning-based computer vision models
for X-Ray COVID-19 were proposed. One of the most significant development is the model COVID-Net [58] proposed
VOLUME 8, 2020 179443A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
TABLE 2. Representative work for X-Ray based COVID-19 diagnosis.
by Darwin AI, Canada. In this work, human-driven principled
network design prototyping is combined with machine-driven
design exploration to produce a network architecture for
the detection of COVID-19 cases from chest X-Ray. The
first stage of the human-machine collaborative design strategy is based on residual architecture design principles. The
dataset used to train and evaluate COVID-Net is referred
to as COVIDx [58] and comprise a total of 16,756 chest
radiography images across 13,645 patient cases. The proposed model achieved 92.4% accuracy 80% sensitivity for
COVID-19 diagnosis.
The initial network design prototype makes one of three
classes: a) no infection (normal), b) non-COVID19 infection (viral and bacterial), and c) COVID-19 viral infection. The goal is to aid clinicians to decide better which
treatment strategy to employ depending on the cause of
179444 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 5. Architectural diagram of COVID-Net [42]. We can observe High architectural diversity and selective long-range connectivity.
infection since COVID-19 and non-COVID19 infections
require different treatment plans. In the second stage,
data, along with human-specific design requirements, act
as a guide to a design exploration strategy to learn and
identify the optimal macro- and microarchitecture designs
to construct the final tailor-made deep neural network
architecture. The proposed COVIDNet network diagram
is shown in FIGURE 5 and available publicly at https://
github.com/lindawangg/COVID-Net.
Hemdan et al. [59] proposed the COVIDX-Net based
on seven different architectures of DCNNs; namely
VGG19, DenseNet201 [60], InceptionV3, ResNetV2,
InceptionResNetV2, Xception, and MobileNetV2 [61].
These models were trained on COVID-19 cases provided by Dr Joseph Cohen and Dr Adrian Rosebrock,
available at https://github.com/ieee8023/covid-chestxraydataset [62]. The best model combination resulted in
F1-scores of 0.89 and 0.91 for normal and COVID-19 cases.
Similarly, Abbas et al. [63] proposed a Decompose, Transfer, and Compose (DeTraC) approach for the classification of COVID-19 chest X-Ray images. The authors
applied CNN features of pre-trained models on ImageNet
and ResNet to perform the diagnoses. The dataset consisted of 80 samples of normal CXRs (with 4020 x
4892 pixels) from the Japanese Society of Radiological Technology (JSRT) Cohen JP. COVID-19 image data
collection, available at https://githubcom/ieee8023/covidchestxray-dataset [62]. This model achieved an accuracy
of 95.12% (with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of 93.36%). The
code is available at https://github.com/asmaa4may/DeTraC
COVId19.
Ghoshal and Tucker et al.. [57] introduced UncertaintyAware COVID-19 Classification and Referral model with
the proposed Dropweights based on Bayesian Convolutional
Neural Networks (BCNN). For COVID-19 detection to be
meaningful, two types of predictive uncertainty in deep learning were used on a subsequent work [64]. One of it is Epistemic, or Model uncertainty accounts for the model parameters uncertainty as it does not take all of the aspects of the
data into account or the lack of training data. The other is
Aleatoric uncertainty that accounts for noise inherent in the
observations due to class overlap, label noise, homoscedastic
and heteroscedastic noise, which cannot be reduced even if
more data were to be collected. Bayesian Active Learning by
Disagreement (BALD) [65], is based on mutual information
that maximizes the information between model posterior and
predictions density functions approximated as the difference
between the entropy of the predictive distribution and the
mean entropy of predictions across samples.
A BCCN model was trained on 68 Posterior-Anterior
(PA) X-Ray images of lungs with COVID-19 cases from
Dr Joseph Cohen’s Github repository [62], augmented the
dataset with Kaggle’s Chest X-Ray Images (Pneumonia)
from healthy patients. It achieved 88.39% accuracy on the
available dataset. This work additionally recommended visualisation of distinct features, as an additional insight to point
prediction for a more informed decision-making process.
It used the saliency maps produced by various state-of-the-art
methods, e.g. Class Activation Map (CAM) [66], Guided
VOLUME 8, 2020 179445A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
Backpropagation, and Guided Gradient, and Gradients to
show more distinct features in the CSR images.
A Capsule Network-based Framework called
COVID-CAPS [67] is proposed for the Identification of
COVID-19 cases from X-ray Images. A lightweight deep
neural network (DNN) based mobile app is proposed in [68]
that can process noisy images of chest X-ray (CXR)
for point-of-care COVID-19 screening and is available
at url:https://github.com/xinli0928/COVID-Xray. A 3-step
approach to fine-tune a pre-trained ResNet-50 architecture
to improve model performance is proposed by [58]. Similar
other works are proposed recently [69]–[71].
To the best of our knowledge, [72] reported the
largest dataset including 144,167 images from 750 patients
(400 COVID patients). As deep-learning models are
data-hungry and most other projects perform transfer learning
on extremely small datasets (often < 1000 images), this
is a remarkable project and a first step towards signifying
more realistic and clinically relevant performance estimates.
The classifier achieves a sensitivity of 95% and a specificity
of 93%. Besides, a segmentation model is trained with the
deep supervision strategy and shown to identify lesion areas
of the positive predictions. One drawback of the work is that
the models operate autonomously and the lesions identified
by the segmentation model may by no means have been
relevant for the positive prediction of the classifier.
5) ULTRASOUND IMAGING
Lung ultrasound (LUS) is evolved over the last few years to
its theoretical and operative aspects. One of the characteristic features of LUS is its ability to define the alterations
affecting the ratio between tissue and air in the superficial
lung [55], [78].
The practical advantages of LUS are numerous: US devices
are portable, bringing along the salient benefit of performing
a point-of-care LUS at the patient’s bedside or even home that
can easily be repeated for monitoring purposes. LUS minimizes the requirement for transferring the patient, controlling
the potential risk of further infection and spreading it among
health care personnel.
In contrast to CT and X-Ray, US is non-irradiating, and
the instruments are cheap and thus highly available even
outside developed countries [79]. However, ultrasound is
operator-dependent and to follow standardized protocols for
LUS like the BLUE protocol [80], experienced technicians
are desired. This is boon and bane: While conducting a full
LUS can take a few minutes and cause significantly higher
portions of data than other modalities, the auto-correlation is
exceptionally high and diagnostic patterns are visible only in
few frames. LUS was repeatedly shown superiority to CXR
for diagnosing pulmonary diseases (for review see [81]),
especially in resource-limited settings [82]. For COVID-19,
LUS patterns are correlated to disease stage, comorbidities
and severity of pulmonary injury [83] and most dominantly
include B-lines, vertical artifacts that range from the pleural deep into the lung [84]. Importantly, LUS was lately
reported higher sensitivity and equal specificity than CXR
in diagnosing COVID-19 [85]. In a comparison of LUS to
CT, it was shown that for all typical features of LUS in
COVID-19 patients, analogs to known patterns in CT scans
could be found [86]. FIGURE 6 illustrates the detection
of COVID-19 from ultrasound images. While LUS is used
commonly as a first-line examination method in European
countries like Italy [87], it is not mentioned in the ACR recommendations as clinical practice for COVID [54]. Besides,
some articles argued that LUS can assist early diagnosis
and assessment of COVID and even found better sensitivity of LUS in detecting certain features [88]. This has
caused a vivid debate on the role of LUS for the COVID
pandemic [89]–[92].
6) REPRESENTATIVE WORK, EVALUATION AND DISCUSSION
Since LUS is a less established practice for examining
COVID-19 patients, less clinical data is recorded and publicly available. It is presumably a primary reason why fewer
computer vision projects focus on it, despite the advocacy of
recent trends in medicine (see above).. TABLE 3 presents a
more categorical presentation of such methods.
Preliminary investigations for clarifying the diagnostic and
prognostic role of LUS in COVID-19 are underway. Computer vision on ultrasound imaging became increasingly popular in the last years [93], but comparably little work has been
done on LUS.
The first work to apply computer vision on ultrasound probes of COVID-19 patients was POCOVID-Net,
a deep convolutional neural network with a VGG backbone [94]. POCOVID-Net introduced an LUS dataset
that initially consisted of 1103 images (654 COVID19, 277 bacterial pneumonia, and 172 healthy controls), sampled from 64 videos. As of July 2020,
the dataset contains ∼150 videos and ∼50 images, resembling the largest publicly available dataset of LUS:
https://github.com/jannisborn/covid19_pocus_ultrasound.
Besides, the trained models were deployed and can be freely
used at: https://pocovidscreen.org. On the initial dataset,
POCOVID-Net reports a video accuracy of 92% and a sensitivity and specificity of 96% and 79% for COVID-19 respectively. It accounts for a preliminary proof-of-concept that
COVID-19 can be automatically distinguished from other
pulmonary conditions through LUS, and it opens a branch
to follow up on the granularity of the differentiation.
On the updated POCOVID-Net dataset, performance could
be improved with an accuracy of 94%, sensitivity and specificity of 98% and 91% in a 5-fold cross-validation on LUS
videos [95]. This work utilizes Bayesian deep learning to
compute uncertainty estimations that are deemed crucial for
medical imaging [96]. [95] then demonstrated how epistemic
uncertainty estimations (measured by Monte Carlo dropout)
could let the model self-recognize low confidence situations.
Additionally, the authors computed and validated CAMs
with the help of medical experts and found that the model
learns in a completely unsupervised fashion to highlight lung
179446 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 6. Detection of COVID-19 from ultrasound images: Ultrasound imagery is widely available and accessible throughout the world and therefore,
can be a valuable tool for monitoring disease progression. Adapted from [55].
TABLE 3. Representative works for infected disease prevention and control.
consolidations (94% sensitivity) and, to a lesser extent,
A-lines (62%).
The CAMs were overall found helpful for diagnosis by the
experts. However, it leaves room for improvement in B-line
detection. Interestingly, the performance could be mildly
improved when the classifier was coupled with the segmentation model by [97].
The named work by [97] introduced a rich stack of CNN
models for segmentation and severity assessment of COVID19 patients. Based on ∼1000 images from convex probes
of 33 patients, an ensemble of 3 segmentation models (UNet,
UNet++ and Deeplabv3+) is shown to reliable extract both,
A-lines and COVID biomarkers (accuracy 96%, binary dice
score 0.75). Besides, they classify COVID severity on four
levels (0 to 3). They introduce a so-called regularised spatial transformer network that performs a weak localization
by extracting two transformed image sections that, ideally,
should contain pathological artifacts. Their model achieves
a precision of 70% and a recall of 60% on the four-class
classification. However, despite the authors claim to release
a dataset of 277 LUS videos from 35 patients with a total
of almost 60,000 frames, to date, only 60 videos can be
VOLUME 8, 2020 179447A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 7. Temperature screening in process with thermal imagery of a subject who is talking on a mobile phone; (a) after 1 min of talking and (b) after
15 min of talking. It shows that the temperature of the encircled region increased from 30.56 to 35.15 C after 15 min of talking. The temperature of the
region around the ear (indicated by an arrow) elevated from 33.35 to 34.82C. A similar system can be used for COVID-19 related fever screening.Adapted
from [56].
accessed (after the account request is manually approval).
No annotations are available for those videos, rendering a
validation of the results effectively impossible.
As B-lines are maybe the most critical LUS feature in
COVID patients, [98] presented a specialized approach for
line artifact quantification that utilizes a non-convex regularization technique dubbed Cauchy proximal splitting.
This technique outperforms state-of-the-art B-line identification [99] and detects 87% of the B-lines in 9 COVID-19
patients, reducing the error margin by 40% compared to [99].
Since ultrasound equipment is small and portable options
are available (POCUS devices), the impact of webindependent, on-device analysis is high, especially since LUS
belongs to the standard repertoire even in remote medical
facilities.
Future projects could, for example, improve the mediocre
results found in an ablation study with mobile-friendly
CNNs [95] to facilitate on-device processing.
B. PREVENTION AND CONTROL
WHO has provided some guidelines on infection prevention
and control (IPC) strategies for use when infection with a
novel coronavirus is suspected [104]. Major IPC tries to
control transmission in health care settings that include early
recognition and source control and applying standard precautions for all patients. It also includes implementation of
additional empiric precautions like airborne precautions for
suspected cases of COVID-19, implementation of administrative controls, and use of environmental and engineering
controls. Computer vision applications are providing valuable
support for the implementation of IPC strategies.
1) REPRESENTATIVE WORK, EVALUATION AND DISCUSSION
Protective techniques to control the virus spread in the
early stage of disease progression were considered very
early, as the usage of masks. Some countries like China
implemented it as a control strategy at the start of the epidemic. Computer vision-based systems greatly facilitated
such implementation.
Wang et al.. [100] proposed the Masked Face Recognition approach using a multi granularity masked face recognition model, resulting in 95% accuracy on a masked face
image dataset. The data was made public for research and
provided three types of masked face datasets, including
Masked Face Detection Dataset (MFDD), [105], Real-world
Masked Face Recognition Dataset (RMFRD) and Simulated Masked Face Recognition Dataset (SMFRD) [106].
A similar strategy is the use of Infrared thermography.
It can be used as an early detection strategy for infected people, especially in crowns like passengers at an airport-various
medical applications of infrared thermography re summarised by Lahiri et al. [56], including fever screening.
Somboonkaew et al. [107] introduced a mobile platform that
can be used for an automatic fever screening system using
forehead temperature. Ghassemi et al. [108] has discussed
the best practices for standardized performance and testing
of infrared thermographs. An Infection Screening System
based on Thermography and CCD Camera is proposed by
Negishi et al. [109] with Good Stability and Swiftness for
Non-contact Vital-Signs Measurement by Feature Matching
and MUSIC Algorithm. Earlier for SARD spread control.
A computer vision system to help in fever screening by
Chiu et al. [102] was used in earlier outbreaks of SARS. From
13 April to 12 May 2003, 72,327 patients and visitors passed
through the only entrance allowed at TMU-WFH where a
thermography station was in operation. FIGURE 7 illustrates
the use of thermal imagery for temperature screening.
Additional miscellaneous approaches for prevention and
control are also worth noting. An example is pandemic drones
using remote sensing and digital imagery, which were recommended for identifying infected people. Al-Naji et al. [110]
have used such a system for remote life sign monitoring in
179448 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 8. Visualizations shown by using different saliency maps that provide additional insights diagnosis. These maps help to identify the areas of
activation that can lead to disease progression monitoring and severity detection. Adapted from [57].
disaster management in the past. A similar application is to
use vision-guided robot control for 3D object recognition
and manipulation. Moreover, 3D modelling and printers are
helping to maintain the supply of healthcare equipment in
this troubled time. Pearce [101] discusses RepRap-class 3-D
printers and open-source microcontrollers. The applications
are relevant since mass distributed manufacturing of ventilators has the potential to overcome medical supply shortages.
Lastly, germ scanning is an essential step against combating
COVID-19. Hay and Parthasarathy [103] has proposed a
convolutional neural network for germ scanning such as the
identification of bacteria Light-sheet microscopy image data
with more than 90% accuracy.
C. TREATMENT AND CLINICAL MANAGEMENT
Although various attempts and claims of vaccinations development are announced in the media, however, there is no
agreed and widely used treatment for disease caused by the
virus at the moment. However, many of the COVID-19 symptoms can be treated.depending on the clinical condition of the
patient. An improvement in clinical management practices
is possible through automating various practices with the
help of computer vision. One example is the classification
of patients based on the severity of the disease and advising
them appropriate medical care. FIGURE 8. provides a scenario of progression and severity monitoring by using different saliency maps that provide additional insights diagnosis.
These maps help to identify the areas of activation that can
lead to disease progression monitoring and severity detection.
FIGURE 9 illustrates the Corona score calculation on a 3D
model of patients CT images for patient disease progression.
It is one of the ways infected areas can be visualised, and
disease severity can be predicted for better disease management and patient care. TABLE 4 presents a more categorical
presentation of such methods.
1) REPRESENTATIVE WORK, EVALUATION AND DISCUSSION
An essential part of the fight against the virus is clinical
management, which can be done by identifying patients that
are critically ill so that they get immediate medical attention
or ventilator support. A disease progression score is recommended to classify different types of infected patients in [35].
It is called ‘‘corona score’’ and is calculated by measurements
of infected areas and the severity of disease from CT images.
The corona score measures the progression of patients over
time, and it is computed by a volumetric summation of the
network-activation maps.
MacLaren et al. [111] supports that radiological evidence can also be an essential tool to distinguish critically ill patients. Wang et al. [112] used depth camera
and deep learning as abnormal respiratory patterns classifier
that may contribute to the large-scale screening of people
infected with the virus accurately and unobtrusively. Respiratory Simulation Model (RSM) is developed to control
the gap between scarce real-world data and a large amount
of training data. They proposed GRU neural network with
VOLUME 8, 2020 179449A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
FIGURE 9. Method of corona score calculation for patient disease progression monitoring is illustrated. It is one of the ways infected areas can be
visualised, and disease severity can be predicted for better disease management and patient care. [35].
TABLE 4. Representative works for infected disease treatment and progression monitoring.
bidirectional and attentional mechanisms (BI-AT-GRU)
to classify six clinically significant respiratory patterns
(Eupnea, Tachypnea, Bradypnea, Biots, Cheyne-Stokes,
and Central-Apnea) to identify critically ill patients. The
proposed model can classify the respiratory patterns with
accuracy, precision, recall, and F1 of 94.5%, 94.4%, 95.1%,
and 94.8%, respectively. Demo videos of this method
working in situations of one subject and two subjects
can be accessed online (https://doi.org/10.6084/m9.figshare.
11493666.v1).
179450 VOLUME 8, 2020A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
The CoV spike (S) glycoprotein is the main target for vaccines, therapeutic antibodies, and diagnostics that can guide
future decisions. The virus connects to host cells through
its trimeric spike glycoprotein. Using biophysical assays,
Wrapp et al. [113] illustrated that this protein binds to their
common host cell receptor at least ten times more tightly than
the corresponding spike protein of severe acute respiratory
syndrome (SARS)-CoV. Protein X-ray crystallography can
discover the atomic structure of molecules and their functions. It can further facilitate scientists to design new drugs
targeted to that function. MAchine Recognition of Crystallization Outcomes (MARCO) [114] initiative has introduced
deep convolutional networks to achieve an accuracy of more
than 94% on the visual recognition task of identifying protein
crystals. It uncovers the potential of computer vision and deep
learning for drug discovery.
Quantitative structure-activity relationship (QSAR) analysis has perspectives on drug discovery and toxicology [115].
It employs structural, quantum chemical and physicochemical features calculated from molecular geometry as
explanatory variables predicting physiological activity. Deep
feature representation learning can be used for QSAR analysis by incorporating 360◦
images of molecular conformations. Uesawa [116] has proposed QSAR (Quantitative
structure-activity relationship) analysis using deep learning
using a novel molecular image input technique. Similar techniques can be used for drug discovery to pave the way for
vaccine development for COVID-19.
IV. DATASET AND RESOURCES
A. CT IMAGES
• COVID-CT-Dataset [117] - The University of San Diego
has released a data set with 349 CT images containing
clinical findings of COVID-19. It claims to be the largest
of its kind. To demonstrate its potential, an AI model is
trained, achieving 85% accuracy. The data set is available at https://github.com/UCSD-AI4H/COVID-CT.
• An image-based model working with CTs for
COVID-19 diagnosis can be found at https://github.com/
JordanMicahBennett/SMART-CT-SCAN_BASEDCOVID19_VIRUS_DETECTOR/.
B. CX-RAY IMAGES
• COVID-19 Radiography database [118] - A team of
researchers from Qatar University, Doha, and the University of Dhaka, Bangladesh, along with collaborators from Pakistan and Malaysia with medical doctors
have created a database of chest X-Ray images for
COVID-19 positive cases along with Normal and
Viral Pneumonia images. In the current release,
there are 219 COVID-19 positive images, 1341 normal images and 1345 viral pneumonia images. The
authors said that they would continue to update
this database as soon as new X-Ray images for
COVID-19 pneumonia patients. The project can be
found at GitHub with MATLAB codes and trained
models: https://github.com/tawsifur/COVID-19-ChestX-Ray-Detection. The research team managed to classify COVID-19, Viral pneumonia and Normal Chest
X-Ray images with an accuracy of 98.3%. This scholarly
work was submitted to Scientific Reports (Nature), and
the manuscript was uploaded to ArXiv. Please make sure
to give credit while using the dataset, code and trained
models.
• COVID-19 Image Data Collection [62]- An initial
COVID-19 open image data collection is provided by
Joseph Paul Cohen. all images and data are released
under the following URL https://github.com/ieee8023/
covid-chestxray-dataset.
• COVIDx Dataset [42] - This is the release of the
brand-new COVIDx dataset with 16,756 chest radiography images across 13,645 patient cases. The current
COVIDx dataset is constructed by the open-source chest
radiography datasets at https://github.com/ieee8023/
covid-chestxray-dataset and https://www.kaggle.com/c/
rsna-pneumonia-detection-challenge. It is a combination of data provided by many parties: the Radiological
Society of North America (RSNA), others involved in
the RSNA Pneumonia Detection Challenge, Dr Joseph
Paul Cohen, and the team at MILA, involved in the
COVID-19 image data collection project for making
data available to the global community.
• Chest X-Ray8 [119] - The chest X-Ray is one of
the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-Ray imaging studies
accompanied by radiological reports are accumulated
and stored in many modern hospitals’ Picture Archiving and Communication Systems (PACS), available at
https://nihcc.app.box.com/v/ChestXray-NIHCC).
C. OTHER IMAGES
• Lung ultrasound dataset [94] - An open data collection initiative similar of LUS, similar to the one
by Cohen et al. for CT and CXR. The growing
database is continuously updated and while it partially collects data from dispersed public sources it
also releases unpublished clinical data. The dataset is
thought to facilitate differential diagnosis from LUS
and provides 4 classes (healthy, bacterial pneumonia, COVID-19 and non-COVID viral pneumonia. As
of July 2020, the dataset contains ∼150 videos and
∼50 images resembling the largest publicly available
dataset of LUS: https://github.com/jannisborn/covid19
_pocus_ultrasound.
• Masked Face Recognition Datasets [100] - Three types
of masked face datasets were introduced, including
Masked Face Detection Dataset (MFDD), Real-world
Masked Face Recognition Dataset (RMFRD) and Simulated Masked Face Recognition Dataset (SMFRD).
MFDD dataset can be used to train an accurate masked
face detection model, which serves for the subsequent
VOLUME 8, 2020 179451A. Ulhaq et al.: COVID-19 Control by Computer Vision Approaches: A Survey
masked face recognition task. RMFRD dataset includes
5,000 pictures of 525 people wearing masks and
90,000 images of the same 525 subjects without
masks. To the best of our knowledge, this is currently
the world’s largest real-world masked face dataset.
SMFRD is a simulated masked face data set covering
500,000 face images of 10,000 subjects. These datasets
are available at https://github.com/X-zhangyang/RealWorld-Masked-Face-Dataset.
• Thermal Images Datasets - There is no dataset
of thermals for high fever screening. However,
a fully annotated thermal face database and its
application for thermal facial expression recognition were proposed by Kopaczka [120]. Information on further ideas of related data that can be
figured out by using such systems is available at
http://www.flir.com.au/discover/public-safety/thermalimaging-for-detecting-elevated-body-temperature/.
V. DISCUSSION AND FUTURE WORK
Overall, it is encouraging that the computer vision research
community had a massive response in return to the call for
fighting COVID-19 epidemic. Data was collected and shared
in a short time, and researchers proposed various approaches
to address different challenges related to disease control.
It became possible due to recent success in the field of
deep learning and artificial intelligence. Web repositories like
GitHub and ArXiv have contributed significantly to the rapid
sharing of information. However, the impact of this research
work is limited due to lack of clinical testing, fair evaluation
and appropriate imaging datasets.
We argue that COVID-19 research landscape is quite broad
that covers more than imaging and becomes beyond the scope
of computer vision research. Similarly, we did not include
any machine learning or signal processing work that does
not include imaging modality. Most of the research work is
performed around disease diagnosis problem with various
performance metrics and without clinical trials that make it
hard to compare their performance.
Similarly, various research datasets have been released for
research purpose since the outbreak of the epidemic. However, these datasets can offer only limited scope and problem
domains. For instance, for disease progression, often multiple images related to single patients are required with the
timeline. Similarly, to evaluate different imaging modalities,
researchers require multimodal imaging data related to the
same patient that is not yet available for research purposes.
The future work includes the fair performance comparison of
different approaches, collection of a vast universal dataset and
benchmark. We hope that the collective efforts of computer
vision community like Imagaenet challenge can fill up this
gap.
VI. CONCLUDING REMARKS
In this article, we presented an extensive survey of
computer vision efforts and methods to combat the
COVID-19 pandemic challenge and also gave a brief review
of the representative work to date. We divide the described
methods into four categories based on their role in disease
control: Computed Tomography (CT) scans, X-Ray Imagery,
Ultrasound imaging and Prevention and Control. We provide detailed summaries of preliminary representative work,
including available resources to facilitate further research and
development. We hope that, in this first survey on Computer
vision methods for COVID-19 control with extensive bibliography content, one can find give valuable insight into this
domain and encourage new research. However, this work can
be considered only as an early review since many computer
vision approaches are being proposed and tested to control
the COVID-19 pandemic at the current time. We believe
that such efforts will be having a far-reaching impact with
positive results to periods during the outbreak and post the
COVID-19 pandemic.



NEW_PAPER



Received February 10, 2021, accepted February 25, 2021, date of publication March 8, 2021, date of current version March 19, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3064371
Assessing the Effectiveness of Isolation and
Contact-Tracing Interventions for Early
Transmission Dynamics of COVID-19
in South Korea
HOHYUNG RYU 1
, ARSEN ABULALI 2
, AND SUNMI LEE 2
1Department of Mathematics, Kyung Hee University, Seoul 02447, South Korea
2Department of Applied Mathematics, Kyung Hee University, Yongin 17104, South Korea
Corresponding author: Sunmi Lee (sunmilee@khu.ac.kr)
This work was supported by the Samsung Science & Technology Foundation under Project SSTF-BA2002-02.
ABSTRACT Recent COVID-19 outbreaks pose serious public health challenges all around the world. South
Korea had experienced the early outbreak of the COVID-19 pandemic and implemented early effective
interventions. The 2020 COVID-19 outbreak in South Korea showed spatial hot spots and super-spreading
events. As a result of these super-spreading events, three huge outbreaks of the COVID-19 have occurred
in Korea from February to December 2020. To capture the intrinsic nature of heterogeneity, an agent-based
model has been developed focusing on early transmission dynamics of COVID-19 in South Korea. Based
on the social empirical contact information of early confirmed cases of COVID-19, we have constructed a
scale-free network. Our agent-based model has incorporated essential individual variability such as different
contact numbers and infectivity levels. In the absence of vaccines or treatment, contact tracing, caseisolation, quarantine are the most critical interventions to prevent larger outbreaks. First, we investigate the
impacts of critical factors on various epidemic outputs such as incidence and cumulative incidence. These
critical factors include contact numbers, transmission rates, infectivity of presymptomatic or asymptomatic
cases, and contact-tracing with quarantine intervention. Furthermore, the effectiveness of case isolation
and contact-tracing (followed by quarantine) is evaluated under various scenarios. Our results indicate
that case isolation combined with contact-tracing quarantine is much more effective under a moderate
level of R0 (smaller transmission rates or contact numbers) and presymptomatic cases. However, the
efficacy of interventions reduces significantly for a higher level of R0 (larger transmission rates or contact
numbers) with a high level of infectivity (in presymptomatic cases). This highlights the key role of efficient
contact-tracing and case-isolation to mitigate larger outbreaks or super-spreading events.
INDEX TERMS COVID-19 transmission dynamics, agent-based model, a scale-free network, presymptomatic cases, case-isolation, contact-tracing and quarantine interventions.
I. INTRODUCTION
A novel coronavirus (COVID-19) has been found in the
city of Wuhan in the Hubei Province of China in December 2019, and the COVID-19 has rapidly spread to other
parts of China and many other countries including South
Korea. The first case of COVID-19 in South Korea was a
Chinese woman who traveled from China and confirmed on
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
January 20, 2020 [1]. Then, few primary cases (from international travels including Wuhan, China) lead to 7,382 confirmed cases in total, which was the largest outbreak of
COVID-19 other than China (as of March 9, 2020) [2]. The
total confirmed cases of COVID-19 increased to 20,652 as
of September 30, 2020. The characteristics of the recent
COVID-19 outbreak in South Korea showed significant spatial heterogeneity with two huge outbreaks; cases were mostly
concentrated in Daegu and Gyeongsang province (the first
wave) and Seoul and Gyeonggi (the second wave) [3]. This is
41456 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
due to a super-spreading event (SSE) and SSE is recognized
as the feature that many infectious disease outbreaks have in
common [6], [7]. Recent outbreaks of the same coronavirus
family including 2003 SARS-CoV and 2015 MERS-CoV
showed super-spreading events [8]–[11].
The incubation period of COVID-19 varies in a range
of 2 to 14 days, after which, patients start having symptoms like fever, dry cough, and tiredness [12]. Less common symptoms such as nasal congestion, runny nose, sore
throat, diarrhea, aches, and pains are generally less severe and
develop gradually [13]. In some cases, there are no noticeable symptoms but they still can infect other people (these
individuals are called ‘‘presymptomatic’’ or ‘‘asymptomatic’’
cases). There is empirical evidence of presymptomatic
cases and asymptomatic cases in the COVID-19 outbreaks
[14]–[16]. However, some patients having COVID-19 suffer
from serious respiratory disorders. In the absence of vaccine
or treatment, the only effective mitigation interventions are
non-pharmaceutical strategies both in the individual and the
community levels. This includes isolation and quarantine of
exposed individuals, social distancing, sanitary regulations
(personal protection and hygiene measures like hand washing, or using masks). Particularly, contact tracing of infected
individuals plays a critical role in the early stage of the disease
outbreak. It is very important to detect the symptoms at the
earliest possible stage.
Mathematical modeling can be useful to evaluate the
effectiveness of contact tracing in emerging or reemerging infectious diseases [19], [20]. Many research groups
have investigated the effectiveness of non-pharmaceutical
interventions for the recent COVID-19 outbreaks [21]–[25].
Empirical contact tracing during the COVID-19 outbreaks in
South Korea and USA was identified and analyzed, respectively, in [17], [18]. In both works, higher transmissions of
COVID-19 within close contact environments (households)
were observed, and the role of efficient contact tracing was
highlighted for mitigation strategies.
An agent-based model using a smartphone-based contact network was proposed and further, a differential
equation-based model was developed [23], [26]. They evaluated several possible scenarios and highlighted the importance of smartphone-contact tracing on controlling the
COVID-19 outbreak. Next, a social contact survey was used
to develop an agent-based model. They investigated the
impacts of different close contacts on the distribution of secondary cases (by untraced infections) in the UK [24]. Another
agent-based model was built with different social contacts
from the BBC Pandemic data set, including household, work,
school, or other in the UK [25]. They concluded a high proportion of self-isolation and their contact tracing will achieve
control of COVID-19.
There are various complex factors (contact numbers,
transmission probability, incubation periods, infectious periods, viral load, etc.) that influence disease transmission
dynamics greatly [27]. These factors with different levels of individual variability have been incorporated into
mathematical models using branching process approaches
[21], [28]–[33] and agent-based modeling approaches [8],
[34]–[36]. Contact pattern is one of the most important
sources of transmission heterogeneity [19], [37]. Studies
of contact networks in sexually transmitted diseases have
long revealed high variability in the number of contacts
per individual and highlighted the importance of those individuals described as ‘‘super-spreaders’’ for the onset of
an epidemic [38]. Similar conclusions about the importance of super-spreading events were drawn from contact
tracing data collected from recent epidemic outbreaks of
airborne-transmitted diseases like those of the severe acute
respiratory syndrome (SARS-CoV) [39], [40]. The social
contact structure is a key factor for transmission dynamics and hence it is essential to investigate the effectiveness
of possible intervention scenarios. Many studies developed
network-models using social contact data to identify particular patterns of disease transmission [20], [41]–[43].
In this work, we develop an agent-based model to incorporate the intrinsic nature of heterogeneity focusing on early
transmission dynamics of COVID-19 in South Korea. A high
level of uncertainty and heterogeneity is common in generating secondary cases of emerging infectious diseases. This
is due to individual variations including social/behavioral
features (different levels of contact patterns or numbers) and
epidemiological characteristics (different levels of infectivity
in presymptomatic or asymptomatic cases). We incorporate
empirical contact patterns of confirmed cases in the early
COVID-19 outbreak into our agent-based modeling framework. Especially, our contact network has been constructed
by a scale-free network based on the social empirical contact tracing data provided by the Korea Centers for Disease
Control & Prevention (KCDC) [3]. Furthermore, we incorporate essential epidemiological features such as the incubation
period (with different levels of infectivity in presymptomatic
cases) and the infectious periods from the early empirical
COVID-19 cases. We explore the impacts of critical factors
on various epidemic outputs, including incidence and cumulative incidence. The critical factors include the index cases,
the transmission rates, presymptomatic cases with different
levels of infectivity, and case isolation with different quarantine levels. Finally, we investigate the effectiveness of case
isolation and contact-tracing (followed by quarantine) under
various epidemic scenarios.
II. CHARACTERISTICS OF EARLY TRANSMISSION
DYNAMICS OF COVID-19 IN KOREA
A. DATA AND SOURCES
The daily confirmed cases of COVID-19 have been publicly available from the Korea Centers for Disease Control and Prevention (KCDC), and the Ministry of Health &
Welfare of South Korea [3]. Epidemiological surveillance
(confirmed cases and their effective contact numbers with
tracing information) also have been disclosed daily to the
public [2]. Therefore, we gathered these necessary information from the KCDC website, WHO, and news/media
VOLUME 9, 2021 41457H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 1. Time series of COVID-19 incidence is displayed from January 20 to February 20 in Korea: incidence in Daegu and
Gyeongbuk area (red bar) and the rest of Korea (gray bar) are shown. Note that an explosive outbreak initiated by
super-spreading events in Daegu and Gyeongbuk area on 18-20 February [2]–[5].
FIGURE 2. Transmission tree for COVID-19 is displayed from January 20 to February 20 in Korea: the complete transmission tree remains unknown and
under investigation [2]–[5]).
reports and these have been incorporated into our agent-based
model [4], [5]). The infection-tree (or trasnmission-tree) and
the contact-network have been constructed based on these
information.
The 2020 COVID-19 outbreak in South Korea showed
spatial hot spots and super-spreading events in Daegu and
Gyeongsang Province (Gyeongbuk) initiated on 18 February 2020. Figure 1 shows the time series of COVID-19 from
January 20 to February 20 in Korea: red bars show incidence in Daegu & Gyeongbuk area and gray bars show
the rest of Korea. An explosive outbreak was initiated in
Daegu & Gyeongbuk area on 18-20 February. This explosive
outbreak results in generating a few large clusters (including the Shincheonji church and Daenam health care) of the
COVID-19 outbreak from February 20 to March 20.
B. TRANSMISSION TREE AND CONTACT PATTERNS
Figure 2 illustrates the transmission tree for early
infection tracing data of COVID-19; the identification
number is assigned to each case and yellow denotes imported
from abroad while blue denotes local transmission). Due to
unknown contact information of early 107 confirmed cases
in infection tracing, a partial transmission tree is shown
(the complete transmission tree remains unknown and under
investigation [2], [4], [5]). Most primary COVID-19 cases
that occurred in the first half month (see yellow cases from
January 20–February 4, 2020) were imported from Wuhan,
China (the COVID-19 epicenter), and abroad. As described in
the transmission tree, most of the imported cases did not generate secondary cases except the 3rd and 4th, and 16th cases.
Local transmission within Korea have occurred in the second
half month (see blue cases from February 5–February 20,
2020). Note that the 31st case became a superspreader on
February 18 (the 31st case turned out to be the index case of
the Shincheonji church in Daegu).
Next, empirical contact data of confirmed cases are displayed in the left panel of Figure 3. This distribution indicates
a typical distribution of social contact patterns; a majority of
people have a small number of contacts while a few have a
large number of contacts. Therefore, it can be approximated
41458 VOLUME 9, 2021H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 3. Distribution of contact numbers from confirmed cases are
shown in the left panel and distribution of secondary cases for
107 confirmed cases of COVID-19 (the early stage) is displayed in the right
panel [2]–[5].
TABLE 1. Baseline parameter values.
by a scale-free network framework (degree distribution follows a power-law distribution ≈ x
−2.5
). The right panel
of Figure 3 presents the distribution of secondary cases for
107 confirmed cases of COVID-19 from January 20 to February 20. An SSE is defined as an event resulting in more than
the average number of secondary infections from a single
infectious individual. Clustering and SSEs result in disease
propagation dynamics that appear characteristically ‘‘bursty’’
(an explosive growth) as observed in Daegu & Gyeongbuk
area (due to the case number 31).
III. AGENT-BASED MODELING FOR
COVID-19 TRANSMISSION DYNAMICS
A. STOCHASTIC AGENT-BASED MODEL
In this subsection, an agent-based model has been developed to incorporate the intrinsic nature of heterogeneity
including social/behavioral features (different levels of contact patterns or numbers) and epidemiological characteristics
(different levels of infectivity in presymptomatic or asymptomatic cases). We incorporate empirical contact patterns
of confirmed cases in the early COVID-19 outbreak into
our agent-based modeling framework. Especially, our contact
network has been constructed by a scale-free network based
on the social empirical contact tracing data provided by the
Korea Centers for Disease Control & Prevention (KCDC) [3].
In our model, a total number of agents, N is used. Each
agent can have one of the following four epidemiological
statuses: Susceptible individuals (S), Exposed individuals (or
presymptomatic individuals) (E), Infectious and confirmed
individuals (I), and Recovered or removed individuals (R).
FIGURE 4. A schematic diagram of a scale-free network with 100 nodes.
For incidence, a ‘‘susceptible agent’’ becomes exposed with
a probability defined by a transmission rate function depending on effective contacts with n infectious individuals (i.e.,
the susceptible agent has n infectious neighbors at time t),
which is defined as
β(t) = 1 − (1 − β0)
n
, (1)
where β0 is the background transmission rate (the probability of getting infected) and β(t) gets larger as n increases
(i.e., more infected neighbors increases the probability of
getting infected). A newly-infected person becomes infectious (presymptomatic before symptom onset) and remains
in the exposed stage for an incubation time drawn from a
gamma probability density function (PDF) with a mean of
γ1 days and a standard deviation of σγ1
days. Next, exposed
individuals become infectious (symptomatic) and remain so
for a duration of time drawn from a gamma PDF with a mean
of γ2 days and a standard deviation of σγ2
days. Subsequently,
an infected agent recovers with immunity or die. There is
a little probability of relapse from recovered individuals.
However, it is negligible for the early outbreak (one month
period of time), it has not been considered in our model. For
simplicity, a gamma PDF is used for both the incubation and
infectious period; these have been estimated from COVID19 confirmed cases [12], [13]. Also, we assume that exposed
individuals are partially infectious (presymptomatic cases).
There is evidence of empirical data that they are likely to
infect people [15]. Hence, we carry out the sensitivity analysis of the level of infectivity of presymptomatic individuals
(five different levels). The outline of the disease transmission
progression with contact tracing and isolation is given in
Algorithm 1.
B. SOCIAL CONTACT NETWORK AS A SCALE-FREE
NETWORK
There are various complex factors (contact numbers, transmission probability, incubation periods, infectious periods,
viral load, etc.) that influence disease transmission dynamics
VOLUME 9, 2021 41459H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
Algorithm 1 Agent-Based Model of COVID-19 Transmission
Input: N, QR, β0, T ,
Output: |E|, |I|, |R|, |Q|, F (number of people in a group)
1: M ← ScaleFree(N) F (generate network)
2: I ← sk F sk random element of S
3: S ← S \ sk
4: for t = 1 to T do
5: et ← ContactTracing(M, I, β0)
6: S ← S \ et
7: E ← E ∪ et
8: M ← Isolation(M, S, E, I, QR)
9: it ← AfterIncubationPeriod(E, γ1, σγ1
)
10: I ← I ∪ it
11: E ← E \ it
12: rt ← AfterInfectiousPeriod(I, γ2, σγ2
)
13: R ← R ∪ rt
14: I ← I \ rt
15: end for
greatly. Contact pattern is one of the most important sources
of transmission heterogeneity [19], [37]. In particular, social
empirical network can be approximated by a scale-free network [20]. Thus, employing a more realistic assumption of
contact information will improve the accuracy of the model
prediction.
As mentioned in the previous section, empirical contact
data of confirmed cases are displayed in the left panel
of Figure 3. This distribution indicates a typical distribution of social contact patterns; a majority of people have a
small number of contacts while a few have a large number of contacts. Therefore, it can be approximated by a
scale-free network framework (degree distribution follows
a power-law distribution). We build an agent-based model
by incorporating this empirical contact-structure. We construct this scale-free network based on the empirical contact
patterns provided by KCDC [3]. As observed in Figure 3,
degree distribution of empirical contact information follows
a power-law distribution (≈ x
−2.5
). A scale-free network
was built using the algorithm as described in [46]. Figure 4
displays a schematic diagram of a scale-free network with
100 nodes. All descriptions and values of our model parameters listed in Table 1.
C. CRITICAL FACTORS OF AGENT-BASED MODELING FOR
COVID-19 TRANSMISSION DYNAMICS
There are some essential factors of the early COVID-19 transmission dynamics; We considered the following scenarios; 1.
the index case (or the basic reproduction number, R0), 2. the
transmission rates (β), 3. the proportion of presymptomatic
infections, and 4. the proportion that contacts were traced
and quarantined. We investigate the impacts of these essential
factors on COVID-19 transmission dynamics. We assumed
isolation (or quarantine) prevents all further transmission in
the model (perfect effectivity).
First, the ‘‘index case’’ is an individual who diagnosed
with the infection, and is the starting point of contact tracing
at the initial time (or day 1). The basic reproduction number, R0, is one of the most important quantities in mathematical epidemiology. It defines the average number of
secondary infections by one infected individual in a completely susceptible population. One can obtain an analytic
expression of the basic reproduction number (R0) for standard mathematical models [45]. However, in general, there
are no analytic expressions of R0 for agent-based models,
hence, we employ the method for determining R0 described
in [47].
At the initialization phase of each simulation run, all agents
except an index case agent are set to be S status, and a
predetermined index case agent is set to be I status (the index
case is the first infected individual). Due to a high level
of heterogeneity in the number of contacts of a scale-free
network, we divide the index cases into the five ranges
depending on their contact numbers or links. The bottom
panel of Figure 5 shows degree distributions of top 100 index
cases from the scale-free network; five different ranges of
index cases are chosen based on the R0 distribution (see
the top panel of Figure 5). The first scenario is the index
case which has the maximum number of contacts and the
index case is chosen randomly from the rest of four scenarios.
The baseline scenario is selected as R0 = 2.84 as reported
in [44].
Secondly, a susceptible agent becomes exposed with a
probability defined by a transmission rate function depending
on the number of contacts with how many infected individuals. Here, five different ranges of the background transmission rate, β0 are considered [0.01, 0.015, 0.02, 0.025, 0.03].
The baseline scenario is set as β0 = 0.02 (a moderate level
of transmission rates).
As discussed in the previous subsection, there is evidence
that exposed individuals can infect people with less probability [15]. The impacts of their infectivity level are investigated
(presymtomatic cases are infectious by these five levels).
We explore an infectivity level in presymptomatic cases is
varied from 0% (not infectious at all) to 80% (the highest
level of infectivity). Again, five different infectivity levels
of presymptomatic cases are implemented: [0%, 20%, 40%,
60%, 80%]. The baseline scenario is chosen as PL = 40%
since there is empirical evidence of a proportion of presymptomatic or asymptomatic cases of COVID-19 [14], [15].
Lastly, the impacts of case-isolation with contact-tracing
intervention scenarios are investigated. In the absence of
treatments or vaccines of COVID-19, the Korean government has implemented non-pharmacy interventions such
as case-isolation combined with acquaintance quarantine
(from contact tracing intervention) [17], [48]. We implement
case-isolation and contact tracing interventions as follows;
the infected and confirmed individuals (who are in I class)
are identified first, then all individuals who had effective contacts (neighbors) with these infected individuals are traced.
Next, the infected individuals are isolated and then a pre41460 VOLUME 9, 2021H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 5. The top panel shows the distributions of 1000 simulations of secondary cases (R0
) under five different index cases
from the scale-free network. Degree distributions of top 100 index cases from the scale-free network are displayed in the bottom
panel.
defined proportion of individuals (who had contact with
infected individuals) are selected and quarantined (randomly
selected from contract-traced individuals). This predefined
proportion is called ‘‘quarantine ratio’’ (QR).
It is almost impossible to trace every single individual
who can be infectious in recent COVID-19 outbreaks due
to presymptomatic or asymptomatic cases [14], [15]. Therefore, we have to assume realistic quarantine ratios which can
produce untraced infectious individuals. In our simulations,
the quarantine ratio is varied from 0% (no quarantine intervention) to 80% (the maximum level of quarantine intervention); five different levels of quarantine are implemented:
[0%, 20%, 40%, 60%, 80%]. The baseline scenario is QR =
40%. All interventions of case-isolation and contact-tracing
begin at t = 7. This implies that the contact tracing followed
by quarantine has been started on day 7 (a week after the first
infection begins).
We explore the impacts of these essential factors listed
below on COVID-19 transmission dynamics in the next
section.
• Initial cases: five different ranges of the index case are
considered.
• Transmission rates: five different ranges of transmission
rate β are considered.
• Presymptomatic infections: five different levels of infectivity in presymptomatic cases are explored.
• Contact tracing and quarantine ratio: five different levels
of acquaintance quarantine ratios are implemented.
IV. SIMULATION RESULTS
All susceptible agents are located in a scale-free network and
one infected agent (‘‘the index case’’) is randomly chosen
from the five predefined ranges (all other agents are S status).
A Monte Carlo simulation is carried out with 1000 trials
using the same set of parameter values. The averaged output
(or distributions) is presented for our numerical simulations.
Baseline parameter values are given in Table 1. Note that we
vary one of the essential parameters while other parameters
are fixed as their baseline parameter value.
A. THE IMPACT OF INDEX CASES ON THE BASIC
REPRODUCTION NUMBER
As mentioned in the previous section, the basic reproduction
number is computed as follows; one agent is randomly chosen
and set as an infected individual (this agent is called ‘‘the
index case’’) in a completely susceptible population (the
rest of all agents are susceptible). We repeat this process
1000 times and obtain the distributions of secondary cases.
Figure 5 presents the results of R0 distributions with a mean
(in the top panel). Since the scale-free network has a high
level of heterogeneity in the number of contacts, a majority
of individuals having a small number of the contact, while a
small number of individuals have a very large number of the
contact.
Therefore, we choose the index cases depending on
their contact numbers or links. The bottom panel of Figure 5 presents degree distributions of 100 index cases
VOLUME 9, 2021 41461H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 6. Time series of incidence, cumulative incidence, cumulative quarantined individuals, and the effective reproductive
number, Reff are compared under the four critical factors. For each factor, 1000 run is simulated and the time series of average
are displayed under five different ranges. Clearly, the index case and the level of quarantine ratio play a key role in reduction of
cumulative incidence.
(top 100 individuals from the maximum number of contact)
from the scale-free network. Five different ranges of index
cases with the vertical line are chosen based on the R0
distribution as shown in the top panel of Figure 5. Sensitivity analyses of R0 are conducted by varying these index
cases. The index case with the maximum number of contacts
(584 contacts) shows the maximum value of R0 (with mean
10.95). As expected, this indicates that the index case has a
significant impact and a larger number of contacts lead to a
larger R0.
B. THE IMPACT OF CRITICAL FACTORS ON EPIDEMIC
OUTPUTS
In this subsection, we investigate the impact of the four
critical factors in terms of various epidemic outputs, including incidence, cumulative incidence, cumulative quarantined
individuals, and the effective reproductive number. Figure 6
illustrates epidemic profiles under these four critical factors
as mentioned in the previous section. Each column represents
the time series of incidence, cumulative incidence, cumulative quarantined individuals, and the effective reproductive
number. Each row represents the four critical factors and the
summary of the four epidemic outputs is illustrated. For each
factor, the average output of 1000 simulations is displayed as
a solid smooth curve.
The top panels of Figure 6 show the four epidemic outputs
under the five different ranges of index cases. The results
are straightforward with a strong linear relationship between
incidence and the index cases; incidence gets larger as R0
increases, leading to larger cumulative incidence and quarantined individuals as well. The rightmost panel shows the
results of the effective reproductive number, Reff, which is
41462 VOLUME 9, 2021H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 7. Epidemic outputs: peak size, peak time, final size, and epidemic duration are compared under the four critical
factors. For each factor, 1000 run is simulated and their distributions are displayed. The index case and the level of
presymptomatic cases have the strong correlation with cumulative incidence.
FIGURE 8. Incidence under the five different index cases are compared in the absence of interventions (neither isolation nor
quarantine). Without any interventions, much larger outbreaks than the actual COVID-19 outbreak were observed regardless of
the index cases.
consistent with the incidence results; Reff under all index
cases becomes below 1 after the peak (around day 7, due to
the interventions started on day 7).
The top middle panels (the second row) show the impact of
an infectivity level of presymptomatic cases on the epidemic
outputs (five different ranges from 0 to 80%). It is worth noting that the impact of infectivity in the presymptomatic cases
is significant; the largest level (80%) can make the outbreak
much worse than 60% resulting in much larger quarantined
individuals (twice of 60%). The rightmost panel shows the
results of the effective reproductive number, Reff becomes
below 1 around day 10). They are almost indistinguishable
since the index case was fixed as the baseline scenario
R0 = 2.84.
The next middle panels (the third row) of Figure 6 display
the impact of the quarantine ratio (QR) on the three epidemic
outputs (five different ranges from 0 to 80%). Incidence
and cumulative incidence decrease in a nonlinear fashion as
the quarantine ratio (QR) increase. Interestingly, the number
of quarantined individuals are the same under all the five
different levels, however, the impact of the QR on cumulative
incidence is significant (20% is twice small of 0%), that
is, the effectiveness is dramatically improved by even 20%
quarantine of individual who had contact with the confirmed
VOLUME 9, 2021 41463H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 9. The top panel compares cumulative incidence under five
different levels of QR (left: cumulative incidence and right: cumulative
quarantined). The bottom panel show epidemic duration under five
different levels of QR (left: epidemic duration and right: quarantine
duration).
cases. Lastly, the bottom panels of Figure 6 presents the
impact of the transmission rate, β on the three epidemic
outputs (five different ranges from 0.01 to 0.03). Incidence
and cumulative incidence increase in a linear fashion as the
transmission rate increases. Overall, the effective reproductive number, Reff becomes below 1 after the interventions
started. Recall that the effective reproductive number, Reff
is the time-varying R0, which captures the effects of control
measures (case-isolation and contract tracing followed by
quarantine). It is desirable to achieve that Reff < 1 so that the
outbreak does not grow. It turns out that Reff is more sensitive
to the index case and the transmission rate.
Next, more detailed epidemic outputs of 1000 simulation
run under the four critical factors are displayed in Figure 7.
These epidemic outputs include peak size, peak time, cumulative incidence, and epidemic duration. Overall trends are
similar in all critical factors; as R0 (due to the index cases)
decreases, the four epidemic outputs get smaller (leftmost
columns). As the infectivity level of presymptomatic cases
increases, the four epidemic outputs get larger (middle left
columns) while the four epidemic outputs get smaller for
a larger level of the quarantine ratio (QR) (middle right
columns). It is interesting to note that there is a threshold
in all epidemic outputs when the quarantine ratio, QR=20%.
In particular, the peak sizes and cumulative incidences show
a dramatic reduction at QR=20% (one third reduction).
The impact of the transmission rate on epidemic outputs is
straightforward; epidemic outputs increase linearly as the
transmission rate increase (rightmost columns).
The index cases (or R0), the level of presymptomatic cases,
the quarantine ratio (QR) play a key role in the reduction of all
the epidemic outputs. Specifically, the infectivity level gets
larger, the peak size and peak time increase exponentially.
Besides, case-isolation combined with the largest level of the
quarantine ratio QR is the most effective intervention (significant reduction). Even implementing QR=20% can reduce
the peak size and cumulative incidence greatly. Due to the
feature of a scale-free network, there are larger variances in all
epidemic outputs (compare with the results in homogeneous
contact structures [8]). These findings suggest that more
elaborate contract tracing and quarantine interventions should
be implemented in the presence of a larger number of contacts and a higher level of infectivity in the presymptomatic
cases
C. THE IMPACT OF INTERVENTION STRATEGIES
In this section, the impacts of case-isolation with
contact-tracing followed by quarantine interventions are presented. First, the time series of incidence in the absence
of interventions are displayed in Figure 8 (neither isolation
nor quarantine is implemented). The results under the five
different index cases are compared with the actual COVID19 incidence (see red bar). It is worth noting that the results
with the index case of the maximum contact number initially grow fastest but all cumulative incidence and epidemic
duration are eventually become similar regardless of which
index cases are initiated. This is because no matter which
one started and it reached the case with maximum contact
numbers (the feature of a scale-free network).
The level of quarantine ratio (QR) is varied and its impacts
are compared on the cumulative incidence and epidemic duration. Figure 9 shows the cumulative incidence and epidemic
duration under five different levels of quarantine ratio (QR).
The top panel displays cumulative incidence (left blue bar)
and cumulative quarantined individuals (right red bar). Note
that even a 20 % quarantine level reduces almost one-quarter
cumulative incidence of 0% QR (blue bar is reduced to
150 from 650). This threshold of QR=20% (a dramatic reduction) is observed in the previous results of the four epidemic
outputs as shown Figure 7. Epidemic duration is shown in
the bottom panel (left: epidemic duration and right: quarantine duration). A larger level of QR, a shorter the epidemic
duration (or the quarantine duration)i.e., the linear reduction
is observed straightforwardly.
Lastly, the impacts of the following three critical factors
are investigated as we vary the level of quarantine ratio (QR)
from 0 to 80%. Figure 10 compares the cumulative incidence
under the three distinct values of the background transmission rate β0, the index cases, and the infectivity level of
presymptomatic cases. The left panel shows the results of
three different transmission rates, β0 as varying the level of
quarantine ratio (QR). We get a larger outbreak size for a
larger transmission rate (see yellow squared curve). Again,
we observe that implementing only a 20 % quarantine ratio
reduces the outbreak sizes greatly for a moderate level of
transmission rates (red circle and blue diamond curves). The
middle panel shows the results of the three distinct index
cases. The impact of the index cases is less significant (all
three curves are very similar) and the outbreak is manageable
with a 20 % quarantine ratio for all three index cases (or
R0). The right panel shows the results of three different
infectivity levels of presymptomatic cases. Similarly, we get a
larger outbreak size as an infectivity level of presymptomatic
increases (see yellow squared curve). However, it is consistent that there is a threshold; a 20 % quarantine level reduces
41464 VOLUME 9, 2021H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
FIGURE 10. Cumulative incidence is compared under the five different levels of QR. The left panel shows the results of three different transmission rates,
β. The middle panel shows the results of three index cases and the right panel shows the results of three presymptomatic ratios.
FIGURE 11. Daily incidence of COVID-19 (bar graph) is compared with the model output (solid curve) from January to September 2020. Time window is
divided based on the three distinct characteristics of COVID-19 transmission dynamics; the first wave, small sporadic outbreaks, and the second wave.
the outbreak sizes greatly for a moderate infectivity level of
presymptomatic (red circle and blue diamond curves).
D. RECENT COVID-19 TRANSMISSION DYNAMICS
In this subsection, we present the recent COVID-19 transmission dynamics. Figure 11 compares the daily incidence of
COVID-19 and the model output (the green bar for COVID19 data and the solid curve for the model output). The model
outputs are obtained on three-time windows as shown in
a vertical dashed line. The three-time window was divided
based on the distinct characteristics of COVID-19 outbreaks;
the first wave, the small sporadic outbreaks, and the second
wave. Note that the first wave occurred in mid-February to
March 2020 (due to the explosive outbreak in Daegu and
Gyeongbuk) and the small sporadic outbreaks of Seoul and
Gyeonggi continued from the end of April to the beginning
of August. Lastly, the second wave happened from August to
September 2020.
These two major outbreaks are due to the super-spreading
events; firstly, the early outbreak was focused on the Daegu
and Gyeongbuk areas from February to April due to the
Shincheonji church-related clusters (5,571 cases out of a
total 7,382 cases from January 20 to March 9, 2020).
Secondly, the second outbreak was focused on the Seoul
and Gyeonggi area in August and September, which was
triggered by the Sarangjeil church-related gathering on
August 15th (1,156 cases out of a total 5,457 cases from
August 15 to September 9, 2020). This highlights that one
possible realization can be explosive outbreaks in the absence
of case-isolation intervention. This also implies that even
implementing only case-isolation could reduce the outbreak
size significantly (or prevent explosive outbreaks such as the
Shincheonji outbreak in Daegu).
This highlights that one possible realization can be
explosive outbreaks in the absence of contact-tracing and
case-isolation intervention. This also implies that even
implementing only case-isolation could reduce the outbreak size significantly (or prevent explosive outbreaks such
as the first outbreak or the second outbreak as shown
in Figure 11).
V. DISCUSSIONS
Social (or physical) contact patterns play a critical role in
recent disease transmission dynamics. However, due to the
complexity of modern human lifestyles, the exact empirical
contact pattern is very difficult to obtain. Moreover, the hidden feature of presymptomatic or asymptomatic cases makes
it nearly impossible to trace all the contacts by infected
individuals (100% perfect contact tracing is not available
yet) as reported in [24]. Therefore, we construct the social
contact pattern using a scale-free network since empirical
VOLUME 9, 2021 41465H. Ryu et al.: Assessing the Effectiveness of Isolation and Contact-Tracing Interventions
social contact patterns can be approximated by a scale-free
network [20].
An agent-based model on a scale-free network is developed for the early stage outbreak of COVID-19 in South
Korea, 2020. In particular, we mainly focus on the impacts
of the four critical factors, index cases, transmission rates,
presymptomatic cases, and isolation and contact-tracing followed by quarantine. Through this mathematical framework,
we assessed the effectiveness of different ranges of case
isolation and contact-tracing (quarantine) interventions.
The most important finding of the present study is that
isolation with a high level of contact-tracing and quarantine is
the most effective intervention strategy. Prompt intervention
played a significant role in mitigating the COVID-19 outbreak. The intervention of case isolation combined with contact tracing and quarantine was effective when there were
few index cases and their contact information was available
at the early stage of the COVID-19 outbreak. Our results
suggest that under the lower value of R0 (lower transmission rates, index cases with a smaller number of contacts
during their infectious period, or a lower infectivity level of
presymptomatic cases), an achievable combination of control measures (case isolation with effective contact tracing,
and quarantine of exposed persons) can contain the COVID19 outbreak. Indeed, such measures appear to have formed the
basis of effective control on a smaller scale, likely contributed
to the prevention of major outbreaks in other main cities of
South Korea except Daegu and Gyeongbuk areas or Seoul and
Gyeonggi areas.
On the other hand, the index case of the Shincheonji church
in Daegu was in a presymptomatic stage (without severe
symptoms but infectious) and went to the massive gathering at the Shincheonji church several times (a large number
of close contacts) [48], [49]. In this case, efficient contact
tracing was almost impossible. In the absence of such effective countermeasures, COVID-19 spread in Daegu dramatically. As a result, the total 5571 (more than 75%) confirmed
cases of South Korea (as of March 9, 2020). Our results
show that the severity of the COVID-19 outbreak would
have been significantly lessened by isolating confirmed individuals followed by prompt contact-tracing and quarantine
interventions.
Our findings indicate that the outbreak size has reduced
substantially when super-spreading events (the index case
with higher contact numbers) were isolated although the quarantine level was only 20 %. It means that the case isolation
combined with effective contact tracing is the key solution to
mitigate the larger outbreak. Hence, the importance of effective monitoring systems that can identify those individuals
has stressed again. This result suggests that much attention
should be paid to super-spreading events when dealing with
a novel or unknown infectious disease outbreak.
We have some limitations of our study since we have
focused on the early stage of COVID-19 transmissions. Several issues should be considered for future study. Firstly,
a complete Korean population with empirical social contact
patterns can be employed. Recently, vaccination has been
distributed in many countries, therefore, it should be considered as a critical mitigation intervention as well.
VI. CONCLUSION
In this work, we develop an agent-based model to incorporate the intrinsic nature of heterogeneity focusing on early
transmission dynamics of COVID-19 in South Korea. A high
level of uncertainty and heterogeneity is common in generating secondary cases of emerging infectious diseases. This
is due to individual variations including social/behavioral
features (different levels of contact patterns or numbers) and
epidemiological characteristics (different levels of infectivity
in presymptomatic or asymptomatic cases).
As observed in the first and the second wave of the recent
COVID-19 outbreak, there exists a possibility of such a huge
outbreak due to a high level of uncertainty and variability in
the absence of effective interventions. Thus, how to detect
super-spreading events as early as possible becomes a critical
and challenging issue, and building and maintaining active
monitoring systems is important at the early stage of any
potential disease outbreak. There is always probability of anyone you encounter can potentially transmit disease, therefore,
cautious contact tracing should be implemented by not only
public officials but also by individuals.
In the absence of vaccines and treatments, South Korea
has implemented and maintained stringent interventions such
as large-scale epidemiological investigation, rapid diagnosis,
case-isolation, contact-tracing, quarantine, and social distancing. It would be worthy of investigating the impacts of
various interventions on the recent COVID-19 dynamics in
future research.



NEW_PAPER


Received October 10, 2020, accepted October 13, 2020, date of publication October 20, 2020, date of current version November 9, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3032584
Modeling the COVID-19 Pandemic Using an
SEIHR Model With Human Migration
RUIWU NIU1
, ERIC W. M. WONG 1
, (Senior Member, IEEE),
YIN-CHI CHAN 1
, (Member, IEEE), MICHAËL ANTONIE VAN WYK 2
, (Senior Member, IEEE),
AND GUANRONG CHEN 1
, (Life Fellow, IEEE)
1Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China
2School of Electrical and Information Engineering, University of the Witwatersrand at Johannesburg, Johannesburg 2000, South Africa
Corresponding author: Eric W. M. Wong (eeewong@cityu.edu.hk)
This work was supported in part by the Health and Medical Research Fund, in part by the Food and Health Bureau, and in part by The
Government of the Hong Kong Special Administrative Region, China, under Grant 16171921.
ABSTRACT The 2019 novel coronavirus disease (COVID-19) outbreak has become a worldwide problem.
Due to globalization and the proliferation of international travel, many countries are now facing local
epidemics. The existence of asymptomatic and pre-symptomatic transmissions makes it more difficult to
control disease transmission by isolating infectious individuals. To accurately describe and represent the
spread of COVID-19, we suggest a susceptible-exposed-infected-hospitalized-removed (SEIHR) model with
human migrations, where the ‘‘exposed’’ (asymptomatic) individuals are contagious. From this model,
we derive the basic reproduction number of the disease and its relationship with the model parameters.
We find that, for highly contagious diseases like COVID-19, when the adjacent region’s epidemic is not
severe, a large migration rate can reduce the speed of local epidemic spreading at the price of infecting the
neighboring regions. In addition, since ‘‘infected’’ (symptomatic) patients are isolated almost immediately,
the transmission rate of the epidemic is more sensitive to that of the ‘‘exposed’’ (asymptomatic) individuals.
Furthermore, we investigate the impact of various interventions, e.g. isolation and border control, on the
speed of disease propagation and the resultant demand on medical facilities, and find that a strict intervention
measure can be more effective than closing the borders. Finally, we use some real historical data of
COVID-19 caseloads from different regions, including Hong Kong, to validate the modified SEIHR model,
and make an accurate prediction for the third wave of the outbreak in Hong Kong.
INDEX TERMS COVID-19, modified SEIHR model, disease transmission model, disease control, human
migration.
I. INTRODUCTION
The Coronavirus Disease 2019 (COVID-19) pandemic has
resulted in over 34.4 million reported cases and 1.02 million
deaths throughout 188 countries and territories (as of
3 October 2020) [1] and has caused great concern among
governments, the World Health Organization, and scientists worldwide over the past few months. The outbreak
of COVID-19 has been more rapid and widespread than
the Severe Acute Respiratory Syndrome (SARS) outbreak
in 2003 and the Middle East Respiratory Syndrome (MERS)
outbreaks in 2012 in Saudi Arabia [2], [3] and 2015 in
South Korea. If stringent intervention measures are not taken
The associate editor coordinating the review of this manuscript and
approving it for publication was Derek Abbott .
to restrain the pandemic, COVID-19 may eventually reach
the same level of devastation as the ‘‘Spanish Flu’’, which
infected 500 million people and caused 17–50 million deaths
worldwide [4].
One reason why COVID-19 spreads so rapidly is that
infectious individuals are contagious in the latent period, and
a significant proportion of infected individuals do not show
any symptoms throughout the entire course of the disease [5].
Since these cases are extremely difficult to detect and isolate,
they can easily cause what are known as pre-symptomatic and
asymptomatic transmissions, respectively, making it much
harder to control the outbreak. Furthermore, the exponential
increase of the numbers of patients in most regions has had
a devastating impact on healthcare systems worldwide, further increasing the already high death rates. Therefore, it is
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.
For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 195503R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
extremely important to monitor the spreading processes of
COVID-19 and study its medical and social impacts.
A. MATHEMATICAL MODELS FOR EPIDEMIOLOGY
In the early 20th century, Ross [6] established a mathematical
model for the transmission of malaria between humans and
mosquitoes, and proposed the concept of a threshold value
for the spreading of the disease. This concept was further
refined by MacDonald [7] who proposed what has become
known as the basic reproduction number R0 of a disease.
R0 has the property that an epidemic will persist if R0 > 1
but will diminish if R0 < 1. Therefore, the derivation of R0
is a key step in the development of various epidemiological
models.
A definitive work on epidemiological models is due
to Kermack and McKendrick [8], [9], who proposed
compartmental models to describe the number or proportion of individuals within a population in various
states (‘‘compartments’’) using a set of differential equations. Examples of compartmental models include the
susceptible-infected-recovered (SIR) model [8], susceptibleinfected-susceptible (SIS) model [9], and susceptibleinfected-recovered-susceptible (SIRS) model [10], which are
used to describe diseases spreading where recovery from
infection provides permanent immunity, no immunity, and
time-limited immunity, respectively. For diseases that have
latent periods in spreading, like seasonal flu, the susceptibleexposed-infected-recovered (SEIR) model [11] is used
instead. For a detailed study on how to obtain R0 for various
compartmental models, see [12].
The compartmental models described above are based on
mean-field approximations, i.e. the behavior of the population is considered representable by the mean behavior of all
individuals in the same compartment. In reality, the transmission rates of some individuals (‘‘superspreaders’’) can be
substantially higher than the average. Network-based models [13], [14] can be used to model the disease-spreading
capability of individuals. Network models can also be used
to describe the interactions between people and epidemics in
multiple cities. It was shown [15] that restricting migration,
while delaying the spread of disease between cities, did not
necessarily constrict the epidemic peak in some cities.
Nevertheless, due to the simplicity of mean-field models
compared to network-based models, in this article we use
a mean-field-approximation-based compartmental model to
track the evolution of COVID-19 in a community and show
how such a simple model can still lead to new insights regarding disease control. We not only make the E compartment
contagious, but also add a new H compartment to the aforementioned SEIR model to represent isolated or hospitalized
cases and examine the effects of migration into and out of
the affected community, as well as the effects of parameter
changes corresponding to various government interventions.
Our model is the first to consider simultaneously all concerned features to describe COVID-19, although each has
been considered separately in some previous work [16].
B. RELATED STUDIES ON COVID-19
During the initial spread of COVID-19, some traditional and
modified SEIR models were used to predict the genesis of the
epidemic in Wuhan [17]. However, these models generally
did not consider the asymptomatic transmission capabilities
of COVID-19, corresponding to ‘‘exposed’’ individuals in the
SEIR model. This led to a significant underestimation of the
extent of the COVID-19 spread. This omission was generally
corrected in later studies; for example, the study in [18]
emphasizes the importance of early interventions to shield
susceptibles from infection, rather than targeting infected
cases alone, especially for diseases with asymptomatic transmission such as COVID-19.
1) TRANSMISSION DYNAMICS
It is crucial to understand the transmission dynamics of the
COVID-19. With an accurate estimate of the basic reproduction number, governments can take effective actions against
the pandemic. It was shown in [19] that the basic reproduction
number of the COVID-19 is higher than SARS. In [20],
the transmission dynamics and the geographical characteristics of the COVID-19 pandemic in Italy is studied and the
basic reproduction number is estimated for different areas.
In [21], the importance of air pollution-to-human transmission and the human-to-human transmission is demonstrated,
suggesting that the former is stronger than the latter. Furthermore, the containment measures in Italy in [22], where it is
found that the sequence of restrictions imposed to mobility
and human-to-human interactions can significantly reduce
the virus transmission.
2) MIGRATION EFFECTS
The consideration of migration effects was also a key feature in many COVID-19 studies. In [23], the study on the
early dynamics of transmission in Wuhan showed that newly
introduced cases in one area might eventually lead to new
outbreaks. In [24], it warns that a global pandemic might
happen unless substantial interventions are taken globally.
In [25], a modified SEIR model is used, with migration into
and out of the susceptible and exposed states, showing a good
fit between the estimated and observed data for three Chinese
provinces and for China as a whole. Additionally, an artificial
intelligence technique was used for model prediction, using
training data obtained from SARS, and demonstrated to be
remarkably accurate. Migration data for China was used
in [26], predicting that the numbers of infections in most
cities in China would peak between middle February and
early March 2020, which was indeed the case. In light of these
results, we will also incorporate migration into our proposed
compartmental model.
3) TRAVEL RESTRICTIONS
With regards to the implementation of travel restrictions,
in [27] a complex network model is implemented and two
strategies are compared: adaptive clustering, which mimics
195504 VOLUME 8, 2020R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
self-isolation of small cliques within a larger community,
and instant clustering, which mimics the imposition of
hard border controls between cities and/or countries. It was
demonstrated that the adaptive clustering strategy was more
effective for preventing epidemic spread than instant clustering, due to the remaining weak connections between clusters caused by the impossibility of perfect border control.
Additionally, in [28] the adverse effect of delaying the introduction of travel restrictions is demonstrated: by the time
border controls were imposed on Wuhan on 23 January 2020,
many Chinese cities had already received a large number
of infected travelers. While a slight delay in epidemic progression was observed abroad, it was concluded that travel
bans are only effective when combined with a significant
reduction in local disease transmission. On the other hand,
a study of human outflow from Wuhan in the weeks before
the 23 Jan 2020 lockdown [29] suggests a strong correlation
between the migration flow size from Wuhan to each Chinese
province and the scale of the epidemic in that province (up to
mid-February 2020).
C. CONTRIBUTIONS OF THIS ARTICLE
Enlightened by the SEIR model and recognizing the features
of COVID-19, in this article we propose a compartmental
model to study the spreading process of COVID-19 and its
impact on the public healthcare systems. We modify the SEIR
model as follows: First, we modify the E compartment of
the SEIR model to allow for asymptomatic transmissions;
Second, we introduce a hospitalized (denoted H) compartment, thus forming an SEIHR model. Unlike the ‘‘infected’’
(I) compartment, individuals in the H compartment are
assumed not to transmit the disease to others, due to strict
quarantine measures within the hospital setting. As a result,
we find that in the SEIHR model, the key factor influencing
the overall transmission rate is that of the ‘‘exposed’’ (i.e.
asymptomatic but potentially infectious) individuals, rather
than those in the I compartment which are assumed to be
transferred to the H compartment quickly. In other words,
the quick transfer of infected people from the I compartment
to the H compartment can effectively isolate these people
from the susceptible population and further lower the speed
of disease transmission. Note that the number of people in
the E and I compartments are assumed to be unknown, and
only people in the H compartment are observable as having
the disease.
In addition to the H compartment, we also model the effect
of migration to and from each of the various compartments
in the SEIHR model. We introduce a parameter to describe
the relative scale of the epidemic in the external region, and
discover that, when the local pandemic is more severe than the
global one, border control policies may not be very helpful for
lowering the transmission speed of the virus. However, if we
do not impose the border control policy, the exported cases
will spread the disease worldwide. Next, we fit the parameters
of our model to COVID-19 caseload data from five global
regions and compare the quality of our fit against the SIR
TABLE 1. Definition of parameters. Note that not all parameters are used
in some of the models in this article.
and SEIR models, as well as quantifying the effect of various
local intervention measures. The results demonstrate that by
using a single parameter to represent the overall strength of
all local interventions at a given stage of the epidemic, we can
capture the local dynamical changes and further forecast the
epidemic trend.
Compared with the traditional SIR and SEIR model,
the additional compartment (H) and the dynamics between
all compartments help us capturing the property of the
COVID-19 pandemic more accurately. The contribution presented here distinguishes itself from previous work on compartmental models by being able to more efficiently represent
characteristics of infection-spread dynamics and interventions. This is reflected in the fitting accuracy achieved for
a given control effort. Furthermore, the proposed model is
heuristically justifiable and interpretable from a human perspective, requiring only five compartments, making it of great
practical value in applied epidemiology.
II. MODEL AND ANALYSIS
With regards to the insight previously gained regarding the
COVID-19 pandemic, we propose an SEIHR model with
migration to estimate the progression of COVID-19 outbreak. In addition to modeling human migration, our proposed SEIHR model differs from the traditional SEIR model
in that we add a hospitalized (H) compartment and make
the exposed (E) state contagious, to model transmissions
from both asymptomatic and pre-symptomatic people. The
proposed model thus consists of five states: susceptible (S),
exposed (E), infected (I), hospitalized (H) and removed (R).
The number of deaths in the proposed SEIHR model is estimated as a fixed proportion of the number of removed people.
Natural births and deaths can be incorporated as ‘‘migration’’
to and from a non-alive state.
Table 1 shows all the parameters used in the SEIHR model.
The system of differential equations that describes the SEIHR
model can be written as
dS(t)
dt
=

−εk
E(t)
N(t)
− αk
I(t)
N(t)
+ (1in − 1out)

S(t), (1a)
VOLUME 8, 2020 195505R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 1. Inter-compartmental dynamics of the SEIHR model.
dE(t)
dt
=

εk
E(t)
N(t)
+ αk
I(t)
N(t)

S(t)
+ [−β − δE + 1in − 1out] E(t), (1b)
dI(t)
dt
= βE(t) + [−γ − δI − 1out] I(t), (1c)
dH(t)
dt
= [γ + 1in + 1out] I(t) − δH H(t), (1d)
dR(t)
dt
= δEE(t) + δI I(t) + δH H(t), (1e)
where S(t), E(t), I(t), H(t) and R(t) are the number of susceptible, exposed, infected, hospitalized and removed individuals, respectively, satisfying S(t)+E(t)+I(t)+H(t)+R(t) =
N(t) for all t ∈ [t0,∞).
The infection mechanism of this SEIHR model is described
by Fig. 1. In the new model, a susceptible (S) individual will
contact with an average of k individuals per day, with an exponentially distributed interval between contacts (i.e. a Poisson
process). For each contact with an exposed (E) or infected (I)
individual, a susceptible individual will contract the disease
with probability ε or α, respectively, thus moving to the
exposed (E) compartment.
The exposed (E) compartment is composed of people do not exhibiting any symptoms, among which some
(with probability δE
δE+β
) will remain undetected until their
own self-recovery or death, thereby entering the removed
(R) compartment. It is assumed that recovered proportions
acquire permanent immunity from reinfection. The remaining
proportions in the E compartment will become symptomatic
after an exponentially distributed latent period with mean
1/β, thus entering the infected (I) compartment.
Regarding the remaining compartments, infected (I) people will recover or die before being detected with probability
δI
δI+γ
, while the remainder will be hospitalized after they are
identified, thus entering the hospitalized (H) compartment.
It is assumed that the people in the H compartment are not
contagious due to strict quarantine measures. Finally, people
in the H compartment will recover or die and thus move to the
removed (R) compartment after an exponentially distributed
hospitalization period with mean 1/δR.
Regarding human migration in the proposed model, only
people in the S, E, and R compartments may move freely
into or out of the system. The immigration and emigration
rates of people into and out of the R compartment are assumed
to be equal, such that the population of the R compartment
depends on intake from the other four compartments only.
Assuming that a state change does not occur first, people in
one of these compartments (S and E) will leave the population
at a rate of 1out. Meanwhile, for people in the S or E compartment, new people will enter that compartment from outside
the system at a rate of 1in. In other words, the migration
rate into and out of each compartment is proportional to the
size of that compartment. On the other hand, the H compartment does not allow immigration or emigration. Finally,
the I compartment allows both immigration and emigration;
however, all migrants into or out of the I compartment are
immediately detected and transferred to the H compartment,
i.e. ‘‘emigrants’’ from the I compartment are not actually
allowed to leave the community.
A. BASIC REPRODUCTION NUMBER
It is important to determine the basic reproduction number,
denoted R0, of the disease propagation process. To do so,
define X = (S, E, I, H, R). Assume that there is a disease free equilibrium (DFE), namely E
0 = (S, 0, 0, 0, 0),
in system (1a–1e). We begin by deriving the next-generation
matrix [12] of our proposed system (1a–1e). First, we define
the matrices F, denoting the rate of new individuals into the
infectious E and I compartments, and V, denoting the rate of
transfer of individuals from the E and I compartments to the
non-infectious H and R compartments. Matrices F and V can
be written respectively as
F =

kε + 1in kα
0 0 
V =

β + δE + 1out 0
−β γ + δI + 1out
.
The next-generation matrix of the system is defined as
FV −1
:
FV −1
=

kε + 1in kα
0 0 




1
β + δE + 1out
0
β
(β + δE + 1out)(γ + δI + 1out)
1
γ + δI + 1out



=





kε + 1in
β + δE + 1out
+
kαβ
(β + δE + 1out)(γ + δI + 1out)
kα
γ + δI + δout
0 0





.
According to [12], the basic reproduction number R0 is the
largest eigenvalue or spectral radius of the next-generation
matrix. Since the eigenvalues of a triangular matrix are the
elements of its main diagonal,
R0 = ρ(FV −1
)
=
kε + 1in
β + δE + 1out
+
kαβ
(β + δE + 1out)(γ + δI + 1out)
.
(2)
195506 VOLUME 8, 2020R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 2. Contour graph of R0 with respect to different parameters, where β = 0.14, γ = 1,
δE = δI = δH = 0.1. Colors represent the values of R0
. Black solid lines represent contour lines of R0
.
The first term in R0 is the number of people who are infected
by other exposed people during one infection cycle, and
the second term is the number of people who are infected by
other infected people. When R0 > 1, the disease outbreak
will be sustained; when R0 < 1, the disease will die out.
B. ACCOUNTING FOR EXTERNAL EPIDEMIC STRENGTH
According to Fig. 1, when modeling migration, the strength
of the epidemic in the external population is assumed to be
equal to the strength of the epidemic in the local population.
However, in many situations, this is not the case; for example,
during the initial stages of the COVID-19 pandemic, the
number of infected individuals in Wuhan was much higher
than in the rest of the world. Therefore, we introduce a scaling
factor of q ≥ 0 to denote the external epidemic strength,
which represents the ratio of the percentage of individuals in
the external regions that are exposed or infected compared to
the local region. Then, system (1a–1e) can be written as
dS(t)
dt
=

−εk
E(t)
N(t)
− αk
I(t)
N(t)

S(t)
+
1 −
(q − 1)(E(t) + I(t))
S(t)

1in − 1out
S(t),
(3a)
dE(t)
dt
=

εk
E(t)
N(t)
+ αk
I(t)
N(t)

S(t)
+ [−β − δE + q1in − 1out] E(t), (3b)
dI(t)
dt
= βE(t) + [−γ − δI − 1out] I(t), (3c)
dH(t)
dt
= [γ + q1in + 1out] I(t) − δH H(t), (3d)
dR(t)
dt
= δEE(t) + δI I(t) + δH H(t). (3e)
Similarly to Sec. 2.1, the basic reproduction number R0 of
system (3a–3e) is derived as
R0 =
kε + q1in
β + δE + 1out
+
kαβ
(β + δE + 1out)(γ + δI + 1out)
.
(4)
If q > 1, it means the global pandemic is more severe
than the local epidemic. When q = 1, the global pandemic
has the same infection level as the local epidemic. While for
q < 1, the local epidemic is more severe than in other regions.
Note that for systems without immigration, i.e. 1in = 0, the
evolution of the system is independent of q and one can assign
the value of q = 1 for model fitting purposes.
C. SENSITIVITY OF R0 TO THE MODEL PARAMETERS
In carrying out simulations, some basic assumptions are
made. The latent period is set as 7 days (β = 0.14), the hospitalization rate γ is set as 1, and the recovery rate is set as
δE = δI = δH = 0.1.
Figure 2 shows how R0 changes according to changes
in the various model parameters. Figure 2a shows that the
VOLUME 8, 2020 195507R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
transmission rate of exposed individuals, ε, has a major influence on R0, compared with the transmission rate of infected
individuals, α. The reason why this happens is because the
hospitalization rate γ is very high, meaning each infected
individual does not have much time to infect others. Figure 2b
shows that social distancing (when k is small) can effectively
reduce R0 for highly contagious strains (when ε = α is large).
From Fig. 2c, without border control, when the transmission
rate is low enough, the epidemic will not emerge even the
scale of the external epidemic is larger than the local one.
According to Fig. 2d, border control (when 1 is small) may
make the local epidemic be even worse when the scale of the
external epidemic (q < 2) is not very large. Essentially, this
is because a high liquidity of people can dilute the density of
the exposed and infected individuals.
There are other ways to reduce R0, such as finding a
method to lower the transmission rate or increasing the recovery rate of the infected individuals. Due to the assumption
that hospitalized individuals will not be contagious, the rate
R0 is not affected by the hospitalized individuals. However,
the recovery rate of hospitalized individuals are influenced
by the occupancy of medical facilities. If the recovery rate
is too low, it will increase hospital occupancy and ultimately
overflow the hospitals. Therefore, it is crucial to expand the
capacity of the hospitals during the pandemic.
III. SIMULATION RESULTS AND DISCUSSIONS
A. NUMERICAL SIMULATION
In order to study the spreading process of COVID-19, we generated a regular network of size N = 106
. By using the
Runge-Kutta method, we simulated varies scenarios of the
epidemic process. Initially, we set S(0) = 106 − 1, E(0) = 1,
I(0) = 0, H(0) = 0, and R(0) = 0.
First, we investigated the impact of the transmission rate ε
and parameter α. As shown by Fig. 3, for a large transmission
rate, the peak of the epidemic comes very early, while for a
smaller transmission rate the peak will be postponed. One
can also see that, when the transmission rate ε is small,
the size of the epidemic is much smaller compared with the
results shown in Figs. 3b and 3c. Furthermore, given a fixed
transmission rate ε, the evolution of the epidemic is nearly
insensitive to changes in α. This is consistent with the results
shown in Fig. 2a. In other words, the epidemic process is more
sensitive to the transmission rate of exposed people, ε.
The influence of the patients on medical facilities is studied
by changing the rate γ of infected people being hospitalized.
Figure 4 shows the number of people being hospitalized to
evolve over time under different hospitalization rates. The
peak Hmax of H(t) and the time when it arrives are related
with γ . When any of these peaks is larger than the local
medical facility capacity, the hospitals will be overwhelmed.
It can also be seen that the peaks of H(t) have a maximum
value.
Next, we simulated the epidemic process under two different border control policies, where 1in = 1out = 0 represents
total lock down and 1in = 1out = 0.1 represents normal
FIGURE 3. Evolution of the SEIHR model, with q = 1, k = 1, β = 0.14,
γ = 1, δE = δI = δH = 0.1 and 1in = 1out = 0.1. The black solid line, red
solid line and blue solid line represent H(t), E(t) + I(t) + H(t), and
cumulative cases, respectively.
FIGURE 4. Evolution of the SEIHR model, with k = 1, ε = 0.25, α = 0.5,
β = 0.14, δE = δI = δH = 0.1 and 1in = 1out = 0. The colored solid lines
represent H(t) for different values of γ .
operation. Figure 5 shows that the policy is continuously
implemented from day one to the day epidemic ends. It can
be seen that the spreading speed of the disease under both
conditions are almost the same. This result can also be derived
195508 VOLUME 8, 2020R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 5. Evolution of the SEIHR model, where q = 1, k = 1, β = 0.14,
γ = 1, δE = δI = δH = 0.1. The black solid line, red solid line and blue
solid line represent the cumulative number of cases for different
transmission rates.
from Fig. 2c, since their R0 values are very close to each
other. However, the final numbers of these cases are smaller
when the border is totally closed. This is because the infected
individuals from outside are also counted when the border
remains open.
Finally, we investigated what kinds of intervention measures would work for epidemic control. To do so, we first need
to quantify the intervention measures. As in Fig. 5, we consider two possible states for border control, i.e. totally closed
(1 = 1in = 1out = 0) and remaining open (1 = 1in =
1out = 0.1). Furthermore, we introduce a scaling factor of
p to denote the strength of various interventions, including
social distancing, environmental disinfection, wearing masks,
and so on, to control the disease. An intervention strength of
0 ≤ p ≤ 1 means that the transmission rates of exposed and
infected persons are both scaled by a factor of p, becoming pε
and pα, respectively. The updated dynamical process between
compartments can be seen in Fig. 6. A p value of one denotes
no intervention, whereas a p value of zero denotes a complete
cessation of local transmission. Thus, we can further obtain
the effective reproduction number as
Re =
pkε + q1in
β + δE + 1out
+
pkαβ
(β+δE +1out)(γ +δI +1out)
.
(5)
Equation (5) shows a way to fit the epidemic process to
empirical data by tuning parameters p and q.
One can see a threshold for the intervention strength from
Fig. 7. For each value of 1 and q, there exists a critical
value pc such that when p > pc, the scale of the epidemic
increases rapidly, while for p < pc, the outbreak is totally
suppressed. This is simply because when p = pc, the effective
reproduction number equals 1.
Furthermore, when q = 1, which means the local pandemic is equivalent in strength to the global one, the critical
value pc is similar for both the open-border and closed-border
cases. On the other hand, when q < 1, i.e. the local pandemic
is more severe than the global one, the critical value pc is
larger than in the closed-border case, meaning that in terms of
controlling the local epidemic, less severe interventions are
required when the borders remain open. On the other hand,
maintaining open borders when q < 1 comes at the cost of
worsening the global pandemic due to exported cases.
B. REAL-DATA ANALYSIS
We used the proposed SEIHR model to fit the real COVID-19
data chosen from five representative regions, i.e., Italy,
Germany, Florida, New York and Hong Kong, to validate the
proposed model. Note that all the cases calculated here are
from compartment H, as lots of patients with mild symptoms
or without any symptoms could be self-cured before they are
detected. Therefore, the sizes of compartments E and I are
unobservable.
First, we fix the values of some of the parameters in our
models: N is the local population of each region, β = 0.14,
γ = 1, δE = δI = δH = 0.1, and 1in = 1out = 0.
For the remaining parameters, the fitted values for each each
region are given in Appendix B. Note that, for Italy, Germany,
Florida, New York, and the third wave of the COVID-19 epidemic in Hong Kong, the migration rates of these regions are
considered to be negligible compared with their populations.
However, migration is taken into account for the second wave
of the COVID-19 epidemic in Hong Kong, where the effect
of migration is prominent.
Second, at the beginning of an outbreak, the epidemic
process will evolve naturally with no additional interventions
initially. From natural growth data, two basic transmission
rates are obtained: ε and α. After that, when intervention
measures are implemented, an index p is introduced, which
is multiplied by R0 to get the effective reproduction number
of the system, Re. When p = 1, it means that there is no
intervention involved. The smaller the p is, the higher the
intervention strength is. Reasonably, the p values are different
for different intervention stages.
1) HONG KONG
When the global pandemic situation is much worse than the
local situation and yet the border remains open, the number
of imported cases becomes significant, as in the second wave
of COVID-19 outbreak in Hong Kong. Figure 8 shows that
the migration part of our model can adequately estimate
the number of imported cases. The blue line represents the
SEIHR model when migration is removed, which fits the
observed number of local cases quite well. The green line
is the simulation of the SEIHR model with migrations (the
VOLUME 8, 2020 195509R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 6. Inter-compartmental dynamics of the SEIHR model when parameters p and q are introduced.
FIGURE 7. Relationship between the final number of cumulative case and
p, where k = 1, β = 0.14, γ = 1, δE = δI = δH = 0.1, ε = 0.25, and α = 0.5.
The red solid line represent the final number of cumulative cases for
different levels of intervention with or without closing the border.
FIGURE 8. The SEIHR model fits with the second wave of
COVID-19 outbreak in Hong Kong. The colored solid lines and dots
represent simulation results and real data, respectively.
migration data is shown in Fig. 13), which fits the observed
number of total cases very well.
However, for the third wave of COVID-19 outbreak in
Hong Kong, the situation is slightly different. The number
of imported cases was minimal due to strict border control.
On the other hand, the number of local cases increased rapidly
because of loosening interventions. In Fig. 9, we successfully predict the trend of the third wave of COVID-19 in
Hong Kong using the SEIHR model without migrations. The
parameter choices for both waves are shown in Table 5.
2) OTHER REGIONS
Figure 10 shows the COVID-19 data in four regions and
the corresponding SEIHR simulation results. As shown
in Fig. 10, the SEIHR model fits well with the real data. For
FIGURE 9. The SEIHR model prediction for the third wave of
COVID-19 outbreak in Hong Kong. The colored solid lines and dots
represent simulation results and real data, respectively.
comparison, we also show the fitting results of SIR and SEIR
models. The results demonstrate that our modified SEIHR
model is much more accurate than the SIR and SEIR models.
For Italy, we assume that the intervention period has only
one stage which lasts to the end of the pandemic. In reality,
different interventions were implemented in different stages.
Therefore, the fitted curve for the SEIHR model deviates from
the real data.
For Germany and Florida, we assume two stages of intervention, with overall intervention strengths of p1 and p2,
respectively. Additionally, p1 < p2, i.e. in the second stage,
certain interventions were relaxed. It can be seen that once
the intervention measures were loosened, the infection rates
in both regions increased immediately. This is because, Re
will grow when intervention measures are reduced.
Note that for Italy, Germany, and Florida, the number and
timing of each intervention period in our modified SEIHR
195510 VOLUME 8, 2020R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 10. The SEIHR, SIR, SEIR model fits with the COVID-19 data in four different regions. The solid
lines and the red dots represent simulation results and real data, respectively.
models were estimated. For New York, to make the fit
more reasonable, we consider the actual dates when certain
intervention policies were implemented. We selected four
intervention policies that might have large impacts on the
pandemic, and divided the intervention period into four stages
accordingly, with intervention strengths of p1, p2, p3 and p4,
respectively. For the first three stages, each stage is more
strict than the previous stage. In contrast, the fourth stage corresponds to a loosening of intervention policies. Therefore,
p1 < p2 < p4 < p3. Figure 10d shows that the model fits the
real data quite well.
3) DISCUSSION
As can be seen from the results, our modified SEIHR model
achieves greater fitting accuracy compared with the SIR and
SEIR models. This suggests that our choice of dynamical
interaction between compartments is better able to capture
hidden unidentified and even unidentifiable dynamics in
this extremely non-linear and time-varying complex environment. Furthermore, by keeping all parameters except p
and q constant throughout the course of an epidemic, our
model requires fewer parameters, updated less frequently,
than many other epidemiological models, e.g. network-based
models. The simulation and data-based analysis results not
only validate the proposed modified SEIHR model but also
present a way to predict the future evolution of COVID-19 in
general.
According to our data analysis, we now know that the intervention measures are effective and that reopening a region
too early may cause a second wave of outbreak. Therefore,
intervention measures must be strictly and continuously
enforced and implemented.
IV. LIMITATIONS OF THE STUDY
First, this study is built on an assumption that the human
population is mixed homogeneously. However, in reality,
the population distributions are mostly heterogeneous. The
heterogeneity of the social contact network sometimes causes
the emergence of super-spreaders, which play an important
role in the epidemic process.
Second, the model we used is a deterministic approach for
modeling the COVID-19 pandemic. As shown in the real data,
there are some stochastic phenomena during the pandemic.
Therefore, our deterministic approach cannot fully model
the daily number of cases of an epidemic, as demonstrated
in Fig. 10b. Nevertheless, numerical results show that our
deterministic approach is still able to provide an accurate
estimate of the total number of cumulative cases in a region.
In summary, while our model is much simpler than other
models (deterministic with only five compartments), and
does not model certain known phenomena such as heterogeneity or the stochastic nature of disease transmission, it can
still obtain relatively accurate predictions for the COVID-19
pandemic.
V. CONCLUDING REMARKS
In this article, we presented a deterministic framework
referred to as the SEIHR compartmental model. Using
the next-generation matrix method, we derived an explicit
expression of the basic reproduction number R0. After
VOLUME 8, 2020 195511R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
FIGURE 11. Relationship between Hmax and γ , where k = 1, ε = 0.25,
α = 0.5, β = 0.14, δE = δI = δH = 0.1 and 1in = 1out = 0. The black
squares represent Hmax for different values of γ .
FIGURE 12. Contour graph of the critical value γc with respect to ε and α,
where k = 1, β = 0.14, δE = δI = δH = 0.1 and 1in = 1out = 0. The
contour graph represents different values of γc .
analyzing the relationship between R0 and the model parameters, we obtained some parameter regions that allow to
control the epidemic outbreak. We also found that, when the
local pandemic is more severe than the global one, allowing
people to move freely into or out of the system can actually
reduce the speed of epidemic, at the price that it will export
diseases to other areas. Then, we performed several simulations, showing that the epidemic process is more sensitive to
the transmission rate of the exposed people than that of the
infected people, due to a strict isolation policy for infected
people who exhibit symptoms. Furthermore, we investigated
how the isolation policy impacts the medical facilities and
found a possible parameter region to lower the risk of hospital
overflow. To that end, we used an intervention index to quantify the strengths of some measures implemented for local
epidemic prevention. Our results show that, when the local
epidemic is more severe than other regions, hard intervention
measures for epidemic control could be more effective than
blindly closing the borders. In addition, by using a set of real
historical COVID-19 data, we validated the model and found
that reopening a region too early may cause anther wave of
pandemic.
Finally, we verified that our model can estimate the evolution of local epidemics (with or without migration) by fitting
the real data of the second and third waves of COVID-19
outbreak in Hong Kong, as well as COVID-19 outbreks in
four other global regions. These numerical results for multiple global regions demonstrate that our proposed modified
SEIHR model is more accurate and robust than the SIR and
FIGURE 13. Evolution of the SEIHR model when intervention measures
are involved, where q = 1, k = 1, β = 0.14, γ = 1, δE = δI = δH = 0.1,
ε = 0.25, and α = 0.5. The black solid line, red solid line, blue solid line
and pink solid line represent the cumulative number of cases for different
levels of intervention without closing the border. The green solid line
represents the cumulative number of cases without intervention, but with
border closed.
FIGURE 14. The migration data of Hong Kong during the second wave of
the COVID-19 pandemic.
SEIR models for estimating COVID-19 caseloads. In particular, our model can accurately model the number of both local
and imported cases during the second wave of COVID-19 in
Hong Kong, using a single parameter to model the relative
strength of the COVID-19 pandemic outside of Hong Kong.
APPENDIX A
ADDITIONAL FIGURES
Figure 11 shows the relationship between Hmax and γ . Note
that there is a critical value γc that allows Hmax to take the
maximum value. When γ < γc and γ → 0, the peak
Hmax will be reduced. But, according to the expression of
R0, the rate R0 will increase thereby causing more infections
when γ is reduced. When γ > γc and γ → 1, meaning
195512 VOLUME 8, 2020R. Niu et al.: Modeling the COVID-19 Pandemic Using an SEIHR Model With Human Migration
TABLE 2. Parameter settings for the SEIHR model.
TABLE 3. Parameter settings for the SEIR model.
TABLE 4. Parameter settings for the SIR model.
TABLE 5. Parameter settings for Hong Kong. For the third COVID-19 wave
in Hong Kong, we estimated the parameters using data up to (1) July 24,
(2) August 2, and (3) August 23.
strict isolation policies are implemented, the peak Hmax will
decrease. At this time, the scale of the epidemic will also be
reduced.
Figure 12 shows how the critical value γc is changed with
ε and α. As shown in the figure, the contour graph is divided
into three regions. In region I, γc = 1, which means that when
γ → 1 the peak Hmax of H(t) will increase. However, due to
small values of ε and α, the value of the peak Hmax is small.
In region II, γc = 1 is also reached. Under this circumstance,
the peak Hmax of H(t) will increase and its value is much
higher due to the large values of ε and α. In region III, because
γc < 1, when γ → 1 the peak Hmax of H(t) decreases, which
further lowers the risk of hospital overflow.
Figure 13 shows the evolution of the SEIHR model when
intervention measures are involved. The intervention is taken
when the number of cumulative cases exceeds 100.
Figure 14 shows the migration data of Hong Kong between
February 28th to April 30th.
APPENDIX B
FITTED PARAMETER VALUES FOR THE FIVE
GLOBAL REGIONS
Tables 2–5 contain the fitted parameter values for the
five global regions analyzed in Section III-B, namely
Italy, Germany, Florida, New York, and Hong Kong. For
Hong Kong, three different predictions are given for the third
wave of the COVID-19 epidemic, using data up to July 24,
Aug 2, and Aug 23, respectively.




NEW_PAPER



Received January 26, 2021, accepted February 25, 2021, date of publication March 8, 2021, date of current version March 15, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3064323
Performance Evaluation of COVID-19 Proximity
Detection Using Bluetooth LE Signal
ZHUORAN SU 1
, (Graduate Student Member, IEEE), KAVEH PAHLAVAN 1
, (Life Fellow, IEEE),
AND EMMANUEL AGU 2
, (Member, IEEE)
1Center for Wireless Information Network Studies, Electrical and Computer Science Department, Worcester Polytechnic Institute, Worcester, MA 01609, USA
2Computer Science Department, Worcester Polytechnic Institute, Worcester, MA 01609, USA
Corresponding author: Zhuoran Su (zsu2@wpi.edu)
This work was supported by the Defense Advanced Research Projects Agency (DARPA) Warfighter Analytics using Smartphones for
Health (WASH) Program under Agreement FA8750-18-2-0077.
ABSTRACT The risk of COVID-19 transmission increases when an uninfected person is less than 6 ft
from an infected person for longer than 15 minutes. Infectious disease experts working on the COVID19 pandemic call this high-risk situation being Too Close for Too Long (TCTL). Consequently, the problem
of detecting the TCTL situation in order to maintain appropriate social distance has attracted considerable
attention recently. One of the most prominent TCTL detection ideas being explored involves utilizing the
Bluetooth Low-Energy (BLE) Received Signal Strength Indicator (RSSI) to determine whether the owners
of two smartphones are observing the acceptable social distance of 6 ft. However, using RSSI measurements
to detect the TCTL situation is extremely challenging due to the significant signal variance caused by
multipath fading in indoor radio channel, carrying the smartphone in different pockets or positions, and
differences in smartphone manufacturer and type of the device. In this study we utilize the Mitre Range
Angle Structured (MRAS) Private Automated Contact Tracing (PACT) dataset to extensively evaluate the
effectiveness of Machine Learning (ML) algorithms in comparison to classical estimation theory techniques
to solve the TCTL problem. We provide a comparative performance evaluation of proximity classification
accuracy and the corresponding confidence levels using classical estimation theory and a variety of ML
algorithms. As the classical estimation method utilizes RSSI characteristics models, it is faster to compute,
is more explainable, and drives an analytical solution for the precision bounds proximity estimation. The
ML algorithms, Support Vector Machines (SVM), Random Forest, and Gradient Boosted Machines (GBM)
utilized thirteen spatial, time-domain, frequency-domain, and statistical features extracted from the BLE
RSSI data to generate the same results as classical estimation algorithms. We show that ML algorithms can
achieve 3.60%∼19.98% better precision, getting closer to achievable bounds for estimation.
INDEX TERMS COVID-19, proximity detection, RSSI features, PACT, classical estimation theory, BLE,
machine learning.
I. INTRODUCTION
With the threat of COVID-19, a highly infectious virus,
maintaining social distance is an effective way to prevent
infection. Specifically, the risk of Covid-19 transmission
increases when an uninfected person is less than 6 ft from
an infected person for longer than 15 minutes (also called
Too Close for Too Long (TCTL)). If the list of people who
are TCTL to each smartphone user can be detected and
tracked passively, they can be notified if the smartphone user
The associate editor coordinating the review of this manuscript and
approving it for publication was Yassine Maleh .
tests positive for COVID-19. Existing opportunistic Radio
Frequency (RF) positioning technologies can be used to track
the infected smartphone user’s daily motion trajectory. The
owners of neighboring smart devices can then be notified
so that they can maintain social distance or get tested if
they are in found to have been TCTL. Although the tradeoff
between the benefits of COVID-19 mitigation using contact
tracing and the intrusion on users’ privacy remains a difficult
social political problem, scientific research in this area has
recently gained momentum. With its short range and low
energy consumption, the use of the ubiquitous Bluetooth Low
Energy (BLE) signal has attracted significant attention. This
VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 38891Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
led Massachusetts Institute of Technology (MIT), Boston,
MA, to lead the Private Automated Contact Tracing (PACT)
consortium [1] to make available several high quality BLE
Received Signal Strength Indicator (RSSI) datasets, which
were gathered in a variety of proximity scenarios. Their goal
was to challenge research and development community to
discover a solution to this timely and important problem.
The reliability analysis of RSSI based BLE ranging is a
complex problem because of the significant variance in the
measured RSSI signal due to the complexity of the multipath
indoor radio propagation causing extensive signal attenuations, fading and interference from other devices operating in unlicensed 2.4 GHz ISM bands. In prior work, real
world measurements studies and characterization of proximity detection using BLE RSSI have been conducted in
a variety of scenarios [2]. Some prior work has proposed
approaches to improve RSSI-based proximity estimation
by integrating data from other sensors including light [3],
accelerometer and gyroscope [4], and user-sensed motion [5].
Some other authors have incorporated information on the
place type [6], user context [7], sensed crowd [8], social context [5], [9], social circles [10], indoor-outdoor detection [11]
and place co-location [12]. A modified path loss model has
also been utilized [13]. Beyond proximity other authors used
RSSI to estimate the mutual orientation between users [14]
and the energy consumption of BLE RSSI proximity detection [15]. In this paper, we present the results of our extensive
comparative performance evaluation of classical estimation
theory and Machine Learning (ML) algorithms for social
distance estimation using the BLE RSSI data. We utilized the
MITRE Corporation Structured Angle dataset of the PACT
project to share generate results and make our observations
from this experiment. We begin by describing the MITRE
Range Angle Structured (MRAS) PACT dataset followed
by a review of RSSI features that are useful for distance
estimation. Then, we present the classical estimation theory,
which facilitates faster proximity computation in a more
logically explainable manner, and ML algorithms that can be
used to estimate user proximity with all the RSSI features.
Finally, we provide our quantitative comparative performance
evaluation of traditional and ML algorithms to solve the social
distance estimation problem using the BLE signal. For the
classical estimation theory results, we present the method
for computing the confidence associated with the distance
estimated using the BLE RSSI behavior models. We also
derive bounds on the confidence of range estimation using the
Cramer-Rao Lower Bound (CRLB). For the ML estimations,
we classified thirteen spatial, time, frequency, and general
statistical features of the BLE RSSI using three different
algorithms: Support Vector Machine (SVM), Random Forest
and Gradient Boosted Machines (GBM). The final outcome
of this extensive study is the comparison of theoretical achievable bounds for social distance range estimation using BLE
RSSI with the empirical results obtained using two theoretical RSSI behavior models and three ML classification
algorithms. The RF cloud around wireless devices present
an opportunity for designing novel cyberspace applications.
The RF cloud contains features of the signal that reflect
the multipath characteristics of the environment at each
location. As a device moves, these multipath characteristics
change rapidly opening an opportunity for other devices to
observe these variations in characteristics and relate them to
a location-dependent cyberspace application [16], [17]. The
PACT project is a new opportunistic cyberspace application
focused on an opportunistic proximity check application benefiting from the RF cloud of the BLE. The Center for Wireless Information Network Studies (CWINS) at the Worcester
Polytechnic Institute (WPI), Worcester, MA has previous
engagement in the PACT project and is now exploring systematic research in this field. Short term, the proximity detection BLE RSSI application can be investigated. Longer term
research could involve extending the BLE signal by including
other sensors. We build on our prior RSSI based positioning
and motion and gesture detection research [18]–[20] for the
current time. In future, we are planning to extend BLE by
incorporating other opportunistic wireless signals including
those from Wi-Fi and Ultra-wideband devices to increase the
precision of range estimation.
II. THE PACT PROMIXITY DATASETS AND
MEASUREMENT SCENARIOS
There are seven datasets made publicly available by the
PACT consortium [1]. Compared with the other datasets,
MRAS dataset is well documented. Moreover, it contains
measurements in various testing scenarios at different distances, which are relevant to our study goals of comparing
the performance of classical and ML algorithms using various features extracted from BLE RSSI measurements. The
MRAS dataset also contains different environment and tester
pose settings. Environment settings specify the properties of
testing area, such as the room size and the tester’s location
in the room. Tester settings defines the way devices are used
by testers, in which way they hold the smartphones, and the
poses of testers. Fig. 1 shows the location of device and
8 selected relative distances between testers for the MRAS
database. Fig. 1.a shows the five scenarios emulating real life
scenarios for position of the smartphone: in hand, in purse,
in shirt pocket, in front pants pocket, and in the back pants
pocket. Fig. 1.b shows the BLE RSSI measurement scenarios
for short range of operation of up to 15 ft. The eight stationary
locations for measurements begin at 3 ft, are increased at
intervals, and end at 15 ft. The distances are identified with
respect to a person who holds the smartphone with BLE beacons. The RSSI measurement data are collected by another
person (a receiver) positioned at the eight labeled distances.
In each test location identified in Fig. 1.b, 5-10 seconds
measurements of BLE RSSI containing 300-400 samples of
the RSSI are measured:
s(k) = RSSI(t)


t=kTs
; k = 1, . . . ,N, (1)
38892 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 1. PACT measurement scenario for the MITRE Range Angle
Structured dataset, (a) five scenarios for location of the smartphone,
(b) eight distances for measurements of the RSSI data base. (Source: PACT
website).
where N is the number of samples in a location and Ts
is
the time interval between two adjacent RSSI measurement
samples.
Table 1 summarizes various operation scenarios reported
in the MRAS measurement database for collecting 300-
400 samples of RSSI in each stationary dataset. The first
two rows capture variations in the room size and locations
of testers in the area. The detailed room size setting is not
provided in the dataset, but a description of the scenarios
is available. For example, the entrance to the bathroom of
apartment is defined as small room, the kitchen is defined
as medium room, and large living room is defined as large
room [2]. The next two rows identify the types of the smartphone and the location of the smartphone on the tester body.
The last row identifies testers pose that is either ‘‘sit’’ or
‘‘stand’’ at the marked location. These datasets were collected
using three versions of Range-Angle Collection Protocol [1]:
Short, Mid and Full. The Full protocol consists of 40 datasets
with RSSI measurements at eight different distances shown
in Fig. 1.b and we used these datasets for our performance
evaluation for different proximity algorithms. We did not
include the Short and Mid versions, which had only two
different distances of 3 ft and 8 ft and did not offer adequate
diversity in measurement distances.
In our selected MRAS dataset, multipath fading characteristics and variation in the environment caused close to
30 dB difference in the values of RSSI in each measurement
set and up to 30 dB variations in average RSSI in individual sets. The RSSI measurements in each location, defined
by (1), are post-processed before feeding them into classical
and ML algorithms respectively. In the classical estimation
algorithms, the training data for RSSI behavior at each location (1), are averaged at each distance. The average RSSI at
TABLE 1. Scenarios for MITRE-Range-Angle-Structured dataset.
each location is then defined by:
Pr =
1
N
X
N
k=1
s(k). (2)
This data post-processing for classical algorithms associates a single average RSSI measurement, Pr
, to each location.
For ML techniques, the RSSI measurements at each location is grouped in overlapping windows of RSSI measurement vectors of length L, whose elements are defined by
y(n) = {s(k + n); k = 0, 1, . . . L − 1}; n = 1, . . . ,N − L.
(3)
This processing associates an N − L set of L dimensional
vectors with each location. We utilized these post-processed
RSSI data to perform our comparative performance evaluations for various classical and ML algorithms. Our performance criterion is the confidence in the decision made by the
algorithm for the task of detecting the social distance of 6 ft
using BLE RSSI measurements gathered using a smartphone
at a given location.
III. FEATURES OF RSSI SHORT RANGE FADING
Motion in the environment affects RF propagation in multipath indoor and urban areas and causes fading in the measured RSSI, which seriously challenges the precision of
RSSI-based ranging [21]. The channel impulse response for
two wireless devices communicating with a range r in a
multipath, indoor, or urban area with N-paths, is represented
by [23]:
hr(αi; τi; θi) =
X
N
i=1
αie
jθiδ(t − τi),
where (αi
, τi
, θi) are the magnitude, time of arrival, phase, and
DOA of the i-th path.
RSSI(t) =
X
N
i=1
|hr(αi; τi; θi)|
2 =





X
N
i=1
αie
jθiδ(t − τi)





2
=





X
N
i=1
αie
jθi





2
VOLUME 9, 2021 38893Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 2. Variation of the received power in dB as a function of the logarithmic distance
between the transmitter and the receiver and how we approach to model them for different
purposes.
We can easily measure this RSSI from a transmitting
wireless device without any synchronization with the source.
Multipath arrival of the signal in indoor and urban areas,
where the applications discussed in this paper operate, causes
extensive fluctuations of the amplitude of the received signal in time. Fig. 2 illustrates the variation of the amplitude
in dBm (RSSI) as a function of the logarithmic distance
between the transmitter and the receiver, r, as a receiver
moves away from a transmitter. This figure also shows how
we approach the modeling of these variations of the RSSI for
different applications. The instantaneous RSSI in a multipath
environment always varies over time and with small local
changes in distance or movement of objects located around
the transmitter and the receiver antennas. The average of the
RSSI decays as the distance increases and we use an RSSI
model to predict the average received RSSI for calculating
the coverage and interference of wireless networks and for
RSSI-based cyberspace applications [23]. The distribution
function of temporal changes in the signal is modeled with a
few distribution functions to analyze the error rate of wireless
modems. The Fourier Transform of these changes is referred
to as the Doppler Spectrum, which reflects the speed of movement of objects or the device in the environment of operation.
As the objects scattered in the area or the wireless devices
move in the environment or we change the frequency of
operation, characteristics of the multipath features fluctuate
drastically and cause fading in measured RSSI. In the wireless communication literature, this phenomenon is discussed
under temporal, frequency-selective, and spatial fading [22].
In this body of knowledge, RSSI features in space, time, and
frequency are modelled using a few physical parameters that
can be measured. These features can be utilized to improve
the reliability of estimates generated by RSSI-base range
estimation techniques.
A. RSSI SPATIAL FEATURES
In classical RSSI-base ranging we use the average RSSI
in dBm for calculating the distance between an antenna and
a device, r. The traditional method to model how the RSSI
is related to the distance from the transmitter is to use linear
regression and least square estimation to calculate the parameters of the model using empirical data [21]. The traditional
statistical linear regression model for the spatial behavior of
RSSI in dBm is:
RSSI : Pr = P0 − 10αlog10(r) + X(σ), (4)
in which r is the distance, X is a Gaussian random variable with variance σ, representing the shadow fading effects,
α is the distance power gradient of the environment, and
P0 is the RSSI at a reference distance from the transmitter. Shadow fading represents variations of the RSSI from
the linear regression line in dB caused by objects shadowing radio propagation paths between the transmitter and
the receiver. We can use the traditional Least Square (LS)
method of statistical modeling to estimate the RSSI spatial behavior model parameters, (P0, α, σ), using measured
RSSI data in different scenarios provided by the PACT
(section II) [21].
An alternative model for short range BLE RSSI is also
reported in the literature [24], which we tested on the PACT
database. Based on empirical measurements of BLE, this
model suggests that the RSSI has an additional sinusoidal
component:
RSSI : Pr =P0 − A cos 
2πr
λ

+ 10α log(r) +X(σ).
(5)
Therefore, in addition to traditional model parameters,
(P0, α, σ), this model has two new parameters (A, λ), A
38894 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 3. RSSI estimation using traditional RSSI behavior model and the alternative BLE specific model for a set of MRAS RSSI
data.
is the amplitude scale of the sinusoidal part and λ is its
spatial wavelength, which we can also estimate using the LS
algorithm. In this paper, we expand the effective range of
this alternative BLE specific model to about 4.5 m (15 ft)
and compare the results with produced using the traditional
linear regression model described by (4). Fig. 3 shows the
difference between classical linear regression RSSI model
described by (4) and the alternative BLE-specific RSSI model
described by (5) using a set of Mitre Corporation MRAS
PACT data in eight distances. The BLE-specific RSSI model
on the average provides a slightly better fit to data for
predicting the measured RSSI values. In section V.A we
compare the performance of classical range estimation algorithms when we used the MRAS RSSI database with both
RSSI models.
B. RSSI FEATURES IN TIME DOMAIN
In RSSI ranging, we measure a sequence of RSSI values in
time at each location and estimate the range of these collective
measurements. Because the person measuring the BLE RSSI
at a location has slight body motions and the objects in the
environment also move, the measured RSSI fluctuations in
amplitude even when the transmitter and the receiver are
held in specific locations. In the multipath RF propagation
literature, these fluctuations are referred to as short range
multipath fading and their characteristics are modelled for
performance evaluation of wireless communications techniques [23]. By using a ML system designed for ranging,
we can benefit from physical parameters of these fading models as features for training the algorithm. Traditionally in data
science we use the mathematical statistics as features of these
signals, the new features extracted from our understanding
of the behavior of RF propagation in multipath environment
can potentially improve the performance of the system. These
features have been demonstrated to be very instrumental in
RSSI-based gesture and motion detection [18], [19]. In this
study, we evaluate the effectiveness of thirteen features of
RSSI in estimating the social distancing between smartphone
users utilizing BLE RSSI. Table 2 is a summary of the radio
propagation and statistical features that we have selected to
train the ML algorithms in our study. We calculated these
features for all BLE RSSI measurements, y(n), defined by
(3) to form a vector that is used to train the ML algorithms in section IV.B. We have divide them into time-domain
(section III.B), frequency domain (section III.C), and traditional statistical features (section III.D). The time domain
RSSI features benefit from classical radio propagation modelling of these fluctuations, which includes fading rate, average fade duration, coherence time, and shape of distribution
of fading, which we describe in the remaining subsection of
this section.
1) CROSSING RATE AND DURATION OF THE FADES
Fig. 4.a shows a sample of the fluctuations of RSSI
sequences, y(n), over time caused by small scale temporal
fading characteristics of the channel. Two interesting features of short-range fading for RSSI measurements are the
fading rate and fading durations. We can calculate the rate
of fluctuation of the envelope of the RSSI caused by multipath fading with these parameters. It is well known that in
Rayleigh fading channels the threshold crossing rate, N(ρ),
and average duration of fade, τ (ρ), are related to the rms
Doppler spread Brms (see section 3.3). Fig. 4.a shows the
definition of the fade rate and the duration of the fade as well
as equations relating them together on a sample of MRAS
measured data. Defining the normalized crossing threshold
as, ρ = A/Arms, in which A and Arms are the threshold level
and rms amplitude of the RSSI, respectively, these relations
are given by (6a) and (6b) [23] in the top two rows of the
time-domain features in Table 2. Given a set of data in a
location (Fig. 4.a) we find the fading rate and fade duration
for the signal and use these values as features to train the ML
algorithm.
VOLUME 9, 2021 38895Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
TABLE 2. Summary of thirteen feature of the RSSI For training machine learning algorithms.
2) COHERENCE TIME
Another feature to determine the speed of fluctuations in
values of RSSI is the coherence time of the signal [23]. The
coherence time is the width of the correlation function of the
samples of the RSSI in a location. For L samples of RSSI
defined by sequence y(n), (3), the normalized autocorrelation
function is given by (6c) in Table 2, in which



my =
1
L
X
L
n=1
y(n)
r(n) =
vuut
1
L
X
L
n=1
[y(n) − my]
2
.
38896 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 4. Summary of time- and frequency-domain features extracted from samples of MRAS RSSI data a) level crossing rate and fade
duration and their relation to rms Doppler spectrum for a sample, b) 50% Coherence time using the autocorrelation function, c) Rayleigh fit
for distribution of amplitude fluctuation, and d) Laplacian fit to doppler spectrum.
As shown in Fig. 4.b, the value of the plot at the intersect
with the 50% line is used as the coherence time. We can
use the coherence time as another time-domain feature of the
small scale fading in a location to train a ML algorithm for
ranging.
3) SHAPE OF FADING DISTRIBUTION
Multipath fading results in fluctuations of the signal amplitude because of the addition of signals with different phases
arriving from multiple paths. This phase difference is caused
by the signals traveling different distances along multiple
arriving paths. Since the phase of the arriving signals changes
rapidly, the received signal amplitude undergoes rapid fluctuation that is often modeled as a random variable with a
Rayleigh distribution given by (6d) in Table 2 [23], where
σray, is the standard deviation of the Rayleigh distribution
function. To model these fluctuations, we can generate a
histogram of the amplitude of the received signal in time and
fit it to a Rayleigh distribution function. Fig. 4.c shows a
sample Rayleigh fit to the MRAS data, by fitting the Rayleigh
distributions to a set of MRAS data, y(n), we can determine
σray, the parameters defining the distribution of that data and
then associate that parameter as a feature per-location for
training the ML algorithm.
C. RSSI FEATURE IN FREQUENCY DOMAIN
Traditionally, RSSI of RF signals have been used in Doppler
radars and for GPS signals to measure the speed to correct
the estimated range for moving objects. In recent years, using
RSSI signal in time and in frequency with intelligent algorithms have attracted attention in new emerging fields for big
data such as gesture [26] and motion detection [18], [19].
Parameters associated with the Doppler spectrum can also
be used for range estimation using ML algorithms. Doppler
spectrum, D(λ), is the magnitude square of the Fourier
transform of variation of the signal in time domain For
a discrete sequence, y(n), using the Fast Fourier Transform (FFT), we can calculate samples of Doppler spectrum
function as:
(
Y (k) = FFT [y(n)]
D(k) = D(λ)|λ=k/Ts = |Y (k)|
2
.
VOLUME 9, 2021 38897Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
We extracted three features from the empirical Doppler
spectrum obtained from a set of data at a location, y(n). The
middle part of Table 2 summarizes these frequency domain
features. These parameters are the energy of the signal, E,
defined by (7a) in Table 2, the RMS Doppler spread, defined
by (7b), and the shape of the Doppler spectrum in indoor
areas, defined by (7c). The RMS Doppler spread is the normalized second moment of the y(n), reflecting the speed of
motions in the environment. We used this parameter in the
previous section for calculating the fade rate and duration as
well. According to the IEEE 802.11 standard organization
model for the RSSI, the Doppler spectrum shape follows
a Laplacian distribution in indoor areas, shown in (7b) of
Table 2 [22]. By normalizing amplitude to one, a = 1. Fitting
with empirical data results in a single parameter, b, reflects
the speed of BLE RSSI fluctuations at a given location.
Fig. 4.d shows a sample of the FFT and the best fit Laplacian
function for the MRAS RSSI data. In this way, we extract
three parameters to represent the frequency domain characteristics of each data sequence y(n), {E, Brms, b}, and use
these three features along with the four time-domain features
and the following six statistical features for training ML
algorithms using the MRAS data.
D. STATISTICAL FEATURES OF RSSI
The features of the signal that we referred to so far in this
section have physical meanings that we borrowed them from
the multipath RF propagation literature [22]. The set of RSSI
data in a location can also be treated as a mathematical
sequence from which we calculate statistical features that are
then fed as inputs to ML algorithms. In this study, we have
included six common statistical features of the RSSI samples
at a location, shown in the last six columns of Table 2, for
training the ML algorithms. The two top rows of statistical
features are mean and peak-to-peak changes of the RSSI
sample at a location. Other traditional RSSI features are
Interquartile Range (IQR), which shows the spread of RSSI.
Skewness and Kurtosis, which are parameters depicting the
shape of RSSI distribution.
IV. PROXIMITY DETECTION ALGORITHMS
The objective of this study is to investigate the accuracy of
classical estimation theory algorithms for Covid-19 proximity detection and compare their performance with the results
obtained using ML algorithms. Classical algorithms use the
empirical measurements to model the behavior of RSSI with
(4) and (5), then calculate the confidence on the estimation based on parameters of these models. This approach
enables faster computation in a more logically explainable
manner and it also enables us to calculate the Cramer-Rao
Lower Bound (CRLB) of the performance achievable by any
algorithm. ML algorithms benefitting from all the spatial,
time, frequency, and traditional statistical features of the RSSI
shown in Table 2, solving the same problem, and providing
their level of confidence on these estimates. In the remainder
of this section, we describe the details of these two classes of
algorithms that we have used in this study.
A. CLASSICAL ESTIMATION ALGORITMS
Classical estimation theory provides methods for modeling,
estimating, and calculating the performance bounds of an
estimator. In the classical estimation theory terminology,
estimation of the range using the RSSI, Pr
, defined by (2),
is referred to as estimation of a single parameter, the range r,
using observation of the function of the parameter, g(r),
in additive Gaussian noise, the shadow fading X(σ),
O : Pr = g(r) + X(σ). (9a)
In our problem, we have a traditional RSSI linear regression model, (4), and its alternative BLE specific model,
(5) [25]:
(
g1(r) = P0 − 10αlog10(r)
g2(r) = P0 − A cos(2πd/λ) + 10α log(r).
(9b)
When we establish the model the classical estimation theory provides us with tools for systematic estimate of the range
and the analysis of the accuracy of the estimation. Given
an RSSI value we can estimate the distance and calculate
the confidence on accuracy of that estimation in observing
the social distance. In addition, classical estimation theory
provides tools for calculation of variance of the estimate using
CRLB on accuracy of a single measurement and optimal
confidence expected from estimation using any algorithm.
1) EMPIRICAL RANGE ESTIMATION AND CONFIDENCE
In classical estimation theory the optimal estimate of the
range, rˆ, for an average RSSI measurement of a device, Pr
,
defined in (2) taken at a specific range, r, is found by solving:
rˆ = g
−1
(O) = g
−1
(Pr). (10a)
For a traditional linear regressive model, (4), we have a
closed form answer for the problem:
rˆ = g
−1
(Pr) = 10−
Pr −P0
10α . (10b)
For the alternate BLE specific model, (5), we find the
numerical solution to
Pr = P0 − A cos(2πr/λ) + 10α log(rˆ). (10c)
If the estimated range is less than or equal to the admissible
social distance of 6 ft given that the device was also within 6
ft range; or when the estimated range is more than 6 ft
and device range is also more than 6 ft, we are confident
that the algorithm works properly. Therefore, the confidence
on the estimate of the classical algorithms for BLE RSSI
measurements at a given distance r is calculated from [21]:
γ (r) = Pr rˆ ≤ 6/Pr ≤ P6

∩

rˆ > 6/Pr > P6
	
= 1 −
1
2
erfc
|P6 − Pr
|
√
2σ

, (10d)
38898 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
where P6 = g(6) is the expected RSSI measured at 6 ft
distance obtained from RSSI behavior model and σ is the
standard deviation of the shadow fading. For our empirical
analysis of the classical estimation methods, we have used
(10d) to calculate the confidence on any set of test data.
We will explain these in more details in the introduction to
section V and Fig. 6.
2) BOUNDS ON RANGING AND CONFIDENCE
Another power tool from classical estimation theory is the
CRLB, which is a bound on the variance of the ranging error
and it is the inverse of the Fisher Information Matrix (FIM)
of the dataset [21]:
σ
2
(r) = CRLB ≥ FIM−1 =

g
0
(r)
2
σ
2
, (11a)
σ(r) is the standard deviation of the ranging error, σ, is the
standard deviation of shadow fading at the location, and g(r)
is the function representing the model for the two models of
RSSI behavior we studied. Substituting the two models given
in (9b) in to (11a), we have:



σ1(r) =
√
CRLB ≥
ln 10
√
N10
σ
α
r
σ2(r) =
√
CRLB ≥
σ
√
N(
2πA
λ
sin(
2πr
λ
) +
10α
ln 10 · α
)
.
(11b)
Equation (11a) provide bounds on the variance of estimate
using the two RSSI behavior models at a given location. In our
COVID-19 social distancing problem, we are interested in
measuring our confidence in a distance estimate. The confident is the probability that the estimated range is less than or
equal to the admissible social distance of 6 ft given that the
device was in fact within the 6 ft range; or probability that
the estimated range is more than 6 ft and device range is also
more than 6 ft. If we assume that distance measurement error
is a zero mean Gaussian random variable, we can model the
distance estimate by
rˆ = r + η [σ(r)] ,
where η [σ(r)] is the measurement noise calculated from the
CRLB of (11a). Therefore, given a distance, r, and assuming
that the distance measurement error is a zero mean Gaussian
random variable, we can calculate our confidence in making
a measurement in one side of 6 ft and estimating it on the
correct side from:
γ (r) = Pr rˆ ≤ 6/r ≤ 6

∩

rˆ > 6/r > 6
	
= 1 −
1
2
erfc
|6 − r|
√
2σ(r)

, (12)
where γ (r) is the bound on confidence of estimating the
distance using RSSI observed at a distance r, and σ(r) is
the variance of estimation defined by (11a). Equations (11a)
and (11b) demonstrate the bounds on estimating a location
from classical models for RSSI behavior, an ideal expected
confidence while (12) demonstrates the confidence on actual
measurements. Equations (10d) an algorithm for calculation
of confidence from the empirical data. In section V, we use
these equations to calculate the bounds on the confidence of
range estimation as well as the confidence of the RSSI measurement based ranging using empirical data (see Fig. 6 in
that section).
B. MACHINE LEARNING ALGORITHMS
In classical range estimation, only the spatial characteristics
of RSSI measured values are utilized without considerations
its temporary characteristics in time and in frequency domain.
ML algorithms can benefit from other features of the signal,
providing a better estimate of the range and distance and
improving the confidence of the result of estimation. In this
paper we intend to compare these two approaches quantitatively. In practice the ML approach is more computationally
sophisticated, and the classical approach is more analytically
complex but simpler to implement. The classical approach
relies on modelling, which enables faster computation in
a more logically explainable manner. Moreover, classical
approaches generalize better to new, previously unseen scenarios. While prior work has typically used either the classical or ML approaches, we explore combining both methods
creating a third hybrid approach that uses classical models
and parameters as inputs to the ML algorithms, facilitating
model-based ML algorithms. In a sense, this is the best of
both worlds, integrating the temporal characteristics in time
and frequency as well as model parameters (see Fig. 5).
Model based ML has shown to be effective in RSSI based
motion and gesture detections to reduce the complexity and
computational time of the algorithms [18], [19], [27], in this
paper we have examined them for the proximity range estimation for COVID-19 social distancing with BLE signals.
In the remainder of this section, we review the three ML
algorithms that we have considered in this study and used
in our comparative performance evaluation among classical:
Random Forest, Gradient Boosted Machines and Support
Vector Machines.
1) RANDOM FOREST
Random Forest is an ML classification algorithm that is an
ensemble of K classifiers Mi, . . . MK , where each classifier
is a decision tree created using a different sub-sample of the
entire dataset [27]. The final classification is obtained by
majority voting of the K decision trees M1 M2, . . . MK . For
a new test point x, the class predicted by the Random Forest
model MK
using majority voting is:
MK
(x) = arg max
cj

vj
|j = 1, . . . .k
	
,
where vj
is the number of trees created from the different
dataset sub-samples, which predict the class of x as cj
. That
is,
vj(x) = | n
MK = cj
|t = 1, . . .K
o
.
VOLUME 9, 2021 38899Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 5. Overview of hybrid model-based ML proximity detection approach.
2) GRADIENT BOOSTED MACHINES (GBM)
We explored classification using XGBoost, a highperformance implementation of GBM also called Gradient
Boosted Trees [28]. The GBM classification model is an
ensemble model that uses K additive functions to predict the
output:
yˆ = φ(xi) =
X
K
k=1
fk (xi), fk ∈ F,
where F is the space of regression trees created from different
subsets of the input dataset. To learn the set of functions
utilized by the model, the following regularized objective is
minimized
L(φ) =
X
i
l(yˆ, yi) +
X
k
(fk ),
where l is a differentiable convex loss function, which measures the difference between the prediction yˆ and target yi
,
and
(f ) = γ T +
1
2
λ||wscore||2
,
in which T is the number of leaves in the tree, γ and λ are
regularization parameters, and wscore is the score of corresponding leaves.
3) SUPPORT VECTOR MACHINES (SVM)
SVM is a ML classification algorithm that tries to discover
a hyperplane that maximizes the margin between the target
classes in feature space [29] and it is based on the theory of
maximum linear discriminants. For two classes to be classified, SVM finds peripheral data points in each class that are
closest to the other class (called support vectors). For a dataset
D with n points xi
in a d-dimensional space, a hyperplane
function h(x) can be defined as
h(x) = w
T
x + b = w1x1 + w2x2 + . . . + wd xd + b,
where w is the weight vector. Overall, n points, the margin of
the linear classifier can be defined as the minimum distance
of a point from the separating hyperplane given as:
δ
∗ = min
xi

yi(w
T xi + b)
||w|| 
.
The SVM classifier finds the optimal hyperplane dividing
the two classes by solving the minimization problem with
objective function:
min
wib

||w||2
2

,
with linear constraints:
h(x) = yi(w
T
xi + b) ≥ 1, ∀xi ∈ D.
Then, the class of a new point z, is predicted as:
yˆ = sign(h(z)) = sign(w
T
z + b).
4) CONFIDENCE CALCULATION
To compare the performance of ML Classifiers with that
of the classical estimation theory, it is necessary to calculate the confidence of the classifications generated by the
SVM, Random Forest, and GBM classifiers. To calculate
this confidence, we split the training data into 8 groups
based on the distance between the transmitter and the
receiver. Then we calculated, the confidence at each distance
from:
γ (r) = Pr rˆ ≤ 6/r ≤ 6

∩

rˆ > 6/r > 6
	 , (13)
which represents the probability of estimating the distance
to be at the correct side of 6 ft social distance barrier. These
results from ML algorithms are comparable with the results
obtained from (13) for the two classical approaches from the
traditional linear regression and the BLE specific models for
RSSI behavior. These experimental results are then compared
with the bounds on confidence in (12) obtained from calculation of the CRLB.
38900 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 6. Bounds on confidence on estimation as a function of distance for MRAS RSSI database (top lines) versus
performance of classical and alternative RSSI behavior modelling range estimation as well as SVM, Random Forest and GBM
ML algorithms.
V. PERFORMANCE OF RANGING WITH BLE SIGNALS
In this section we present the results of applying the algorithms described in section IV, using the BLE RSSI features
described in section III, on the PACT MRAS dataset that
was described in section II. The basic performance criterion
we use is the confidence on correctly estimating the social
distance of 6 ft between smartphone users. That is, the probability of correctly detecting the distance of a device relative
to the 6 ft threshold using RSSI measurements. We begin
by calculating bounds on confidence of RSSI based ranging (section IV.A2), then we present the results of classical
estimation theory ranging (section IV.A1), and finally results
from ML algorithms (section IV.B4).
As the first step, the training data is used for calculating
parameters of the traditional RSSI behavior models using
the LS algorithm. The model parameters are then used to
calculate the CRLB and then the bounds on the confidence.
Then, the test data and model parameters are used for calculating results from the test data to determine the confidence
on classical methods with the two RSSI behavior models.
Finally, we trained the three ML algorithms using the training
data and found the confidence on estimation for the test data
to compare with results of classical methods as well as bounds
on the performance. We refer to the results of calculating the
bounds on the test data using spatial RSSI behavior models as
classical performance evaluation and we present those results
first.
All the test scenarios shown in Table 1 are for the LineOf-Sight (LOS) propagation condition without any object
obstructing the LOS path between the transmitter and the
receiver and the maximum distance is 15 feet (Fig. 1.b).
We begin by presenting the results for our traditional RSSI
behavior model described by (4). We have 40 sets of data for
five scenarios in eight distances. We utilized 75% of the data
to estimate the parameters of the RSSI behavior model with
LS algorithm. The model is trained for LS estimation with
the RSSI averaged at each distance shown in the measurement scenario of Fig. 1.b. The three parameters of the traditional RSSI regressive model, power at the reference point,
distance-power gradient, and standard deviation of shadow
fading, were P0 = −54.94 dBm, α = 1.74 and σ = 3.78 dB,
respectively. We repeat the same procedure on training data to
calculate the five parameters of the alternative BLE specific
model. These parameters, power at the reference point, scale
factor, spatial wavelength, distance-power gradient, and the
standard deviation of shadow fading, were calculated as P0 =
−55.88 dBm, A = −0.93, λ = 11.31, α = 1.51, and
σ = 3.78 dB, respectively.
A. EFFECTS OF DISTANCE ON CONFIDENCE
With these parameters of the RSSI behavior models estimated
using LS estimation, we calculated the bound on standard
deviation of the range measurement error using the CRLB
for the two, classical and BLE specific, models from (15a)
and (15b), respectively. These bound are then applied to (16)
to determine the bounds on confidence on the estimate as a
function of distance, γ (r), for the two RSSI behavior models.
The solid line on top of Fig. 6 shows the plot of bounds on
confidence on estimation as a function of range, γ (r), for
the two path loss models. As shown in this figure, although
alternative model was providing a better estimate of the RSSI
values (Fig. 3), the confidence for estimating the range from
either of the models with the CRLB, remains almost the same.
Alternative model provided a slightly better performance than
the classical linear regression model in Fig. 3 because it
fits better to BLE data before 3.5 m. With the BLE RSSI,
for less than 1.5 m, we are almost 100% confident in the
estimate enabling us to overrule the social distance range of 6
ft and for distances of more than 2.5 m we have the same
confidence that we are observing the social distance rule.
Since models are based on zero mean Gaussian modeling of
the noise, at the exact distance of 6 ft the best algorithms can
VOLUME 9, 2021 38901Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
only detect the range with 50% confidence. The bounds on
confidence, γ (r), plots in Fig. 6 show us best expected confidence that we obtain from RSSI measurements in our test
dataset.
As the next step, we examined the performance of classical
estimation models from solving (12c) to estimate the distance
from the test data. In this part we use the average RSSI’s for
each distance, r, in the remaining 25% of database to solve
(12c) to find our estimate of the distance, rˆ, with each of the
RSSI behavior models. Then we empirically calculated the
confidence from (17) for any specific data set. The bottom
lines of Fig. 6 show the performance of the range estimation with traditional and BLE specific alternative models
obtained from empirical studies. Performance of the classical
estimation algorithms follow the V-shape of the bounds on
the performance, but the quality of estimate is substantially
lower than the bounds. This encouraged us to examine ML
algorithms to improve the performance. The dashed-lines
in Fig. 6 show the results of applying the three different
ML algorithms examined in this paper (section IV.B). The
three ML algorithms, SVM, Random Forest, and GBM will
improve the performance over the classical methods, when
the social distance of the device is 6 ft or larger. However,
on or in the proximity of 6 ft classical models perform slightly
better.
B. EFFECTS OF ENVIRONMENT AND USER BEHAVIOR
In the last section we presented the results of effects of range
on confidence of estimate with classical and ML algorithms
and we compared that with performance bounds that are
achievable as calculated using CRLB. Now that we established the framework for the analysis against the bounds and
trained our algorithms with the training database, it is possible
to explore the relationship between scenarios of operation
and the behavior of the user on the expected performance.
In section II, Table 1, we partitioned the MRAS database
into five different scenarios for the test. We classified the
top two scenarios in the Table 1, describing the area size and
relative location in the area, as scenarios related to the effects
of the environment, and the last two scenarios, describe the
location in which the smartphone is carried and the pose of the
tester, as scenarios describing the user behavior. In this way,
we divide the scenarios into, the environment and user behavior, and analyzed them separately for each of the seven different devices, in the middle column of the Table 1. To make
the comparison more focused and clearer, we first compare
the performance of classical RSSI linear regression model
with that of the GBM ML algorithm. As shown in Fig. 6,
results of confidence analysis with traditional RSSI model
and the BLE specific model are very close. The average of
confidence over all distances for the classical method using
the traditional linear regression in this figure is 69.60% and
the average confidence for the BLE specific model is 69.55%.
As the alternative model has almost the same average confidence as the classical model and the traditional algorithm
offers an easier and more physically explainable method for
estimation, we only compared the classical model with the
best ML algorithms. The GBM classifier has highest average
confidence of 89.58% for the entire dataset, the average
for Random Forest is 84.88%, and SVM has an average
of 73.20% in confidence. All three ML algorithms benefitted
from all thirteen features of the RSSI and performed better
than the classical models. Overall, GBM achieves the best
results. Therefore, the comparison of GBM and traditional
RSSI behavior modeling for our specific problem illustrates
the best performance that the classical and ML algorithms can
achieve with our existing dataset.
We began our analyses of the effects of various parameters
on the performance by looking at the results in different environments. Table 3 shows the confidence in different environmental settings for all tested smartphones with the classical
RSSI model and GBM. The MRAS dataset utilized in this
study was collected by multiple currently cohabiting testers
and in multiple random scenarios to create a comprehensive
dataset. The tests were conducted in various residential buildings or public spaces representing a variety of architecture
and five different space sizes. The testers had to strictly
obey social distancing guidelines if the test was conducted
in publicly accessible locations [1]. The best indoor results
are obtained in medium rooms, near the walls, in congested
areas, by iPhone XS (up to 87.80% for classical and up to
95.77% with GBM) and in outside, the center of the open
areas, by iPhone 8 (86.09% for classical and 97.35% for
GBM). The worst indoor result for the classical is obtained in
medium rooms, the center of room, in open areas, by iPhone
XS Max (50.81%). The worst indoor result for GBM is
obtained in medium rooms, near walls, in congested areas,
and by iPhone 11 (75.88%). The worst outdoor result in open
areas for classical is obtained by iPhone 7 Plus (64.30%).
The worst outdoor result in open areas for GBM is obtained
by iPhone XS(84.41%). The average confidence for indoor
environment is 70.20% for classical, which is about 4.83%
less than that of outdoor (75.03%). The average confidence
for indoor environment is 87.37% for GBM which is 2.24%
less than that of outdoor (89.61). The average confidences are
61.03% and 82.74% in small rooms, 70.05% and 86.38% in
medium rooms, 71.51% and 89.30% in large rooms, 75.08%
and 89.68% in hallways for classical and GBM respectively.
The average confidence increases with the room size. On the
average, GBM shows 17% improvement on confidence over
results achieved by the simple classical regressive model.
Table 4 compares the confidence of estimation using classical estimation approaches with using GBM ML algorithm
for different user behaviors and with different devices. The
best results are obtained under the scenario that both testers
are standing and holding their phones in their front pants
pocket, and by iPhone 8 (86.09% for classical and 97.35%
for GBM). The worst result for GBM is obtained in the
scenario that both testers are sitting and holding their phones
in hand, by iPhone 11 (75.88%). The worst result for classical is obtained in the scenario that Tester1 is standing,
38902 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
TABLE 3. Effect of environment on confidence.
TABLE 4. Effect of user behavior (Tester’s pose and location of phone) on confidence.
Tester2 is sitting and both testers are holding their phones
in their front pants pocket, by iPhone XS Max (50.81%).
The average confidences are 73.60% (classical) and 88.77%
(GBM) if both testers are standing, 61.37% (classical) and
79.22% (GBM) if both testers are sitting, 66.13% (classical)
and 86.53% (GBM) if the Tester1 is standing and Tester2 is
VOLUME 9, 2021 38903Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
FIGURE 7. Bounds on confidence on estimation as a function of distance for MRAS RSSI database (top lines) versus
performance of classical and alternative RSSI behavior modelling range estimation as well as SVM, Random Forest and GBM
ML algorithms.
FIGURE 8. Relation between confidence and number features for SVM, Random Forest, and GBM ML algorithms as the most
important of thirteen features are eliminated from training the algorithms.
sitting, 76.76% (classical) and 89.66% (GBM) if Tester1 is
sitting and Tester2 is standing.
C. EFFECTS OF NUMBER OF FEATURES IN PERFORMANCE
OF MACHINE LEARNING ALGORITHMS
We studied three Machine Learning algorithm, SVM, Random Forest, and GBM. For comparative performance evaluation of these algorithms, we trained the algorithms using
the 13 features shown in Table 2, classified into three subgroups: time-, frequency-domain, and statistical. The ML
algorithms, in addition to confidence, produce measures of
importance of the features. Fig. 7 shows the feature importance for the ML classifiers that we studied. As shown in
the figure, the average RSSI is the most effective feature.
This is the feature that we also used for classical estimation
modelling. Rayleigh parameter and YP2P reflecting variations
in the RSSI have shown to contribute significantly. Since
the MRAS dataset is collected in static environment and the
Doppler Spectrum is related to the speed of moving antenna
and moving object between antennas, the Frequency domain
features have shown less contribution to the classification
compared with the other two groups. Another traditional
approach in ML is to analyze the direct effect of feature
on the performance criteria, which is the confidence in the
decision regarding the 6 ft threshold necessary to observe
social distance. To implement this procedure, we sort the features for any of the algorithms according to their importance
and re-evaluate performance while dropping them one after
another. The intuition here is to demonstrate the importance
of each feature on performance. Fig. 8 shows the result of
gradual removal of features, each time we remove the single feature with the highest importance. The confidence of
distance estimation using SVM drops significantly after the
first three features are removed, demonstrating that the first
three features dominate its performance. The performance
of the Random Forest classifier drops gradually up to the
removal of the first five features. For this algorithm, there
is no sharp drop in performance, demonstrating that more
features contribute to the model’s performance. There is no
dominating contribution by certain features. The accuracy
38904 VOLUME 9, 2021Z. Su et al.: Performance Evaluation of COVID-19 Proximity Detection Using Bluetooth LE Signal
of the GBM classifier increases with the number of features and follows a similar gradual performance degradation
pattern as Random Forest. As both methods are tree-based
ensemble ML methods, the similarity in their performance is
expected.
VI. CONCLUSION
The risk of COVID-19 transmission increases if an uninfected
person is less than 6 ft from an infected person for longer than
15 minutes (also called Too Close for Too Long (TCTL)).
In this paper we have presented research, development, and
comparative analysis of classical estimation theory methods,
which enables faster computation in a more logically explainable manner and novel hybrid model-based ML approaches
for proximity distance estimation using the RSSI information radiated from the broadcast channels of the BLE. Our
results based on analyses of the Mitre Range Angle Structured (MRAS) PACT dataset in five different environments,
with five different location for the smartphone, and eight
different smartphones. Our analyses methodology provided a
framework for the empirical analysis of the estimation confidence when applying both classical estimation theory and ML
algorithms for solving the social distance estimation problem
with BLE RSSI. We derived bounds on the confidence on
estimation using RSSI of BLE as a function of distance. Then,
we compared the performance of classical estimation theory
ranging algorithms with that of the ML algorithms against
the bound and we analyzed the effects of the environment
and user behavior on the performance of the algorithms. The
classical estimation theory algorithms using two models for
RSSI spatial behavior were compared with three different ML
algorithms (Random Forest, GBM and SVM) benefiting from
thirteen features of the RSSI. Classical algorithms showed
an average confidence of 69.60% in correctly estimating the
social distance threshold of 6 ft. The GBM ML algorithm
demonstrated that using the thirteen feature it can increase
the confidence in the estimation of this social distance using
BLE RSSI with an average confidence of 89.58%, which was
19.98% higher than the average confidence achieved using
the classical approach.




NEW_PAPER


Received 6 October 2020; accepted 4 November 2020. Date of publication 6 November 2020;
date of current version 23 November 2020. The review of this paper was arranged by Associate Editor Deze Zeng.
Digital Object Identifier 10.1109/OJCS.2020.3036581
Hierarchical Pooling Strategy Optimization
for Accelerating Asymptomatic
COVID-19 Screening
KEQIN LI 1,2 (Fellow, IEEE) 1 College of Information Science and Engineering, Hunan University, Changsha 410082, China
2 Department of Computer Science, State University of New York, New Paltz, NY 12561 USA
CORRESPONDING AUTHOR: KEQIN LI (e-mail: lik@newpaltz.edu).
ABSTRACT Testing has been a major factor that limits our response to the COVID-19 pandemic. The
method of sample pooling and group test has recently been introduced and adopted. However, it is still not
clearly known how to determine the appropriate group size. In this paper, we treat asymptomatic COVID-19
screening acceleration as an optimization problem, and solve the problem using an analytical approach and an
algorithmic procedure. We develop a two-level hierarchical pooling strategy for accelerating asymptomatic
COVID-19 screening. In the first level, a population is divided into groups, which results in inter-group
acceleration. In the second level, a group is divided into subgroups, which results in intra-group and intersubgroup acceleration. By using our analytical methods and numerical algorithms, we determine the optimal
group size and the optimal subgroup size, which minimize the total number of tests, maximize the speedup of
the hierarchical pooling strategy, and minimize both time and cost of testing. It is discovered that the optimal
group size and the optimal subgroup size are determined by the fraction of infected people. Furthermore, the
optimal group size, the optimal subgroup size, and the achieved speedup grow sublinearly with the reciprocal
of the fraction of infected people. Our research has important social implications and financial impacts. For
example, if the fraction of infected people is 0.01, by using group size of 25 and subgroup size of 5, we can
achieve speedup of at least 11, which means that months of testing time can be reduced to days, and over
91% of the testing cost can be saved. Such results have not been available in the known literature. The paper
makes significant progress and great advance in pooling strategy optimization for accelerating asymptomatic
COVID-19 screening, and represents the contribution of computer science to the global pandemic.
INDEX TERMS Asymptomatic screening, COVID-19, group test, hierarchical pooling strategy optimization,
sample pooling, speedup.
I. INTRODUCTION
A. BACKGROUND AND MOTIVATION
A coronavirus test requires a number of time consuming steps
in the laboratory, which can take several hours. Testing has
been a major factor that limits our response to the COVID-19
pandemic [1]. As governments reopen more businesses and
public spaces, the number of infected people will surge,
especially when there are asymptomatic people [2].
The method of sample pooling and group test has recently
been introduced [7], [8] and adopted [4], [5]. The strategy
involves pooling samples from multiple people. If the test
result of a group of k (k ≥ 2) samples is negative, we know
that all the individual samples are negative. If the test result
of a group of samples is positive, then the individual samples
need to be tested one by one. If the percentage of infected
people is low, this pooling method can potentially significantly reduce the required number of tests and substantially
save the necessary cost of tests. For example, recently, the
City of Wuhan successfully screened 300 asymptomatic individuals from 9,899,828 people in only 19 days (May 14 –
June 1, 2020), by using the pooling method with group size
of five, involving 63 testing laboratories, 1,451 scientists and
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
276 VOLUME 1, 2020professionals, and 701 examination equipments (24 hours a
day without interruption), and reaching a peak testing capacity
of 1 million per day1.
However, it is still not clearly known how to determine the
appropriate group size, although some attempt has been made.
For instance, it has been recommended that the batch size
should be powers of two [9], which depends on the frequency
of positive samples out of all samples. It is clear that the
choice of the best group size can reduce the time and cost
of testing to the maximum extent, and therefore, will have
tremendous practical impact to COVID-19 detection, prevention, response, and control.
B. NEW CONTRIBUTIONS
In this paper, we treat asymptomatic COVID-19 screening acceleration as an optimization problem, and solve the problem
using an analytical approach and an algorithmic procedure.
The main contributions of the paper can be summarized as
follows.  We develop a two-level hierarchical pooling strategy for
accelerating asymptomatic COVID-19 screening. In the
first level, a population is divided into groups, which
results in inter-group acceleration. In the second level,
a group is divided into subgroups, which results in intragroup and inter-subgroup acceleration.  By using our analytical methods and numerical algorithms, we determine the optimal group size and the optimal subgroup size, which minimize the total number of
tests, maximize the speedup of the hierarchical pooling
strategy, and minimize both time and cost of testing.  It is discovered that the optimal group size and the optimal subgroup size are determined by the fraction of
infected people. Furthermore, the optimal group size, the
optimal subgroup size, and the achieved speedup grow
sublinearly with the reciprocal of the fraction of infected
people.  Our research has important social implications and financial impacts. For example, if the fraction of infected
people is 0.01, by using group size of 25 and subgroup
size of 5, we can achieve speedup of at least 11, which
means that months of testing time can be reduced to
days, and over 91% of the testing cost can be saved.
Such results have not been available in the known literature.
The paper makes significant progress and great advance in
pooling strategy optimization for accelerating asymptomatic
COVID-19 screening, and represents the contribution of computer science to the global pandemic. (Note: This paper is a
substantially extended version of an earlier work reported in
[6], where only a one-level pooling strategy was studied.)
In Section II, we consider inter-group (i.e., group level) acceleration, and find the optimal group size. In Section III, we
consider intra-group (i.e., subgroup level or inter-subgroup)
acceleration, and find the optimal subgroup size for a given
group size. In Section IV, we conduct joint optimization for
1http://www.xinhuanet.com/local/2020-06/03/c_1126066386.htm
both inter-group acceleration and intra-group acceleration,
and simultaneously find the optimal group size and the optimal subgroup size. In Section V, we address some practical
issues. In Section VI, we conclude the paper.
II. INTER-GROUP ACCELERATION
In this section, we develop our method to find the optimal
group size by using inter-group acceleration.
A. THE METHOD
We define the following quantities.  p0: the probability that one individual test result is positive;  q0: the probability that one individual test result is negative;  p1: the probability that one group test result is positive;  q1: the probability that one group test result is negative.
The value of p0 is given and known in advance. It is
clear that q0 = 1 − p0. Furthermore, we have q1 = qk
0 = (1 −
p0 )
k , and p1 = 1 − q1 = 1 − qk
0 = 1 − (1 − p0 )
k .
For a single group of samples, if the test result of the group
is negative (which happens with probability q1), only one test
is enough; if the test result of the group is positive (which
happens with probability p1), (k + 1) tests are required, one
for group test, and k for individual tests. Hence, the expected
number of tests for one group using the pooling method is
Tgroup = 1 × q1 + (k + 1) × p1
= qk
0 + (k + 1)(1 − qk
0 )
= k + 1 − kqk
0.
The total number of tests for a population of N (which is
divided into N/k groups and N  k) is
Tpooling =
N
k

Tgroup
=
N
k

(k + 1 − kqk
0 )
= N

1 +
1
k − qk
0

.
Since the number of tests without using pooling is N, the
speedup of the pooling strategy is
S(k) = N
Tpooling
= k
Tgroup
= 1
1 +
1
k − qk
0
.
Our objective is to maximize the speedup.
It is clear that maximizing S(k) is equivalent to minimizing
F(k) = 1
k − qk
0.
VOLUME 1, 2020 277LI: HIERARCHICAL POOLING STRATEGY OPTIMIZATION FOR ACCELERATING ASYMPTOMATIC COVID-19 SCREENING
Note that
∂F(k)
∂k = − 1
k2 − qk
0 ln q0.
To have ∂F(k)/∂k = 0, we need
1
k2 = qk
0 ln
1
q0
,
which implies that k satisfies
k =

 1
q0
k
ln
1
q0
.
Unfortunately, it is not clearly known how to find an analytical
and closed-form solution to the above equation of k at this
stage.
We now develop a numerical algorithm to find k. We define
G(k) = k −
 1
qk
0 ln(1/q0 )
= k − 1
√ln(1/q0 )
 1
√q0
k
.
Our purpose is to solve the equation G(k) = 0. Noticed that
∂G(k)
∂k = 1 − 1
√ln(1/q0 )

ln
1
√q0
  1
√q0
k
,
and
∂2G(k)
∂k2 = − 1
√ln(1/q0 )

ln
1
√q0
2  1
√q0
k
< 0,
which implies that G(k) is a concave function. Figure 1 illustrates G(k) for p0 = 0.1. It is observed that G(k) is an
increasing function of k when k is less than 35, and G(k) is
a decreasing function of k when k is greater than 35. In other
words, there are two solutions to the equation G(k) = 0. One
is between 3 and 4, and the other is between 54 and 55.
Figure 2 illustrates the speedup S(k) for p0 = 0.1. It is observed that as k increases, S(k) increases and reaches its maximum value at k = 4, and then decreases. However, when k
exceeds 55, S(k) increases again; nevertheless, the increment
is very little and not noticeable. Furthermore, the speedup
beyond k = 55 is less than 1, i.e., the pooling method is not
effective any more. Therefore, we only need to find the smaller
solution of k.
Our numerical procedure to find k which satisfies G(k) = 0
is essentially the standard bisection method (which is described in [3], p. 22), based on the observation is that G(k)
is an increasing function of k around the smaller solution of
k. Since the k found is a real value, we round it to the nearest
integers, i.e., the optimal group size is k∗ = k.
We say that the pooling method is effective, if there is
at least one k ≥ 2, such that S(k) > 1; and that the pooling
method is ineffective, if S(k) ≤ 1 for all k ≥ 2. Intuitively, if
p0 is too big, the pooling method becomes ineffective. Let
p∗
0 be the largest value of p0 such that the pooling method is
effective. Using numerical verification, we can find that the
FIG. 1. G(k) vs. group size (p0 = 0.1).
FIG. 2. S(k) vs. group size (p0 = 0.1).
278 VOLUME 1, 2020FIG. 3. Speedup vs. group size (p0 = 0.001, 0.002, 0.003, ..., 0.010).
pooling method is effective when p0 = 0.306 (with k = 3 and
S(3) = 1.00092) and ineffective when p0 = 0.307. Therefore,
we can confirm that p∗
0 is in the range (0.306,0.307).
B. NUMERICAL RESULTS
In Figure 3, we show the speedup as a function of the group
size for p0 = 0.001, 0.002, 0.003, ..., 0.010. It is observed that
as k increases, S(k) increases significantly, especially when
p0 is small; however, beyond certain point, S(k) decreases
noticeably. Hence, there is an optimal choice k∗, such that the
speedup is maximized.
In Table 1, we demonstrate the optimal group
size k∗ obtained by our numerical algorithm for
p0 = 10−1, 10−2, 10−3, ..., 10−7. We have the following
important observations.  As p0 becomes smaller, the probability q1 = qk∗
0 that
a group test result is negative becomes higher. For
instances, when p0 = 0.01, the chance for a negative
group test result is q11
0 = 0.9911 = 0.8953382. When
p0 = 0.001, the chance for a negative group test result
is q32
0 = 0.99932 = 0.9684911. Such higher chance will
balance the potential higher cost for individual tests in
case a group test result is positive.  As p0 decreases, the optimal group size and the achieved
speedup increase rapidly. In particular, we have for
p0 = 10−r,
k∗ > 3r = 3log10(1/p0 ) = (1/p0 )
log10 3 = (1/p0 )
0.477.
Furthermore, let S(p0 ) be a speedup function of p0. Then
we have S(10−(r+1))/S(10−r) > 3, and
S(10−r) > 0.56 × 3r = 0.56 × 3log10(1/p0 )
= 0.56(1/p0 )
log10 3 = 0.56(1/p0 )
0.477.
That is, both k∗ and S(p0 ) grow sublinearly with 1/p0, a
quite impressive and nontrivial result.
It is worth to mention that the optimal group size k∗ is determined by the fraction p0 of infected people and independent
of the size N of the population, since the equation G(k) = 0
only involves q0 (actually p0), not N.
VOLUME 1, 2020 279LI: HIERARCHICAL POOLING STRATEGY OPTIMIZATION FOR ACCELERATING ASYMPTOMATIC COVID-19 SCREENING
C. OPTIMAL GROUP SIZE
One important (and surprising) observation from Table 1 is
that the achieved speed is approximately (and a little bit less
than) k∗/2, that is, S(k∗) ≈ k∗/2. Equivalently, for k∗, the expected number of tests for one group is approximately 2. This
gives us an opportunity to derive a closed-form expression of
k∗. Let us consider the equation
S(k) = k
k + 1 − kqk
0
= k
k(1 − qk
0 ) + 1 = k
2
,
that is,
k(1 − qk
0 ) = 1.
Since G(k) = 0, i.e.,
k = 1

qk
0 ln(1/q0 )
,
we get
1 − qk
0 =

qk
0 ln(1/q0 ).
Let x =

qk
0. Then, we have
x2 + 	
ln(1/q0 )x − 1 = 0,
which gives
x = 1
2


−
	
ln(1/q0 ) + 	
ln(1/q0 ) + 4

,
and
qk
0 = x2 =
1
2

	
ln(1/q0 ) + 4 − 	
ln(1/q0 )
2
,
and
k = 2 logq0
1
2

	
ln(1/q0 ) + 4 − 	
ln(1/q0 )

.
Since k∗ needs to be an integer, we set (z means the nearest
integer of z)
k∗ =

2 logq0
1
2

	
ln(1/q0 ) + 4 − 	
ln(1/q0 )

 + 1,
which has been verified to be consistent with Table 1.
III. INTRA-GROUP ACCELERATION
In this section, we develop our method to find the optimal
subgroup size by using intra-group acceleration.
A. THE METHOD
The basic idea of intra-group acceleration is to divide a group
into subgroups. When the test result of a group is positive, the
group of size k is divided into subgroups of size m. For each
subgroup, if the test result of the subgroup is negative, only
one test is enough; if the test result of the subgroup is positive,
(m + 1) tests are required, one for subgroup test, and m for
individual tests. By using this method, the original k tests for
individual samples can possibly be reduced. This method is
more effective for small p0 and large k.
To develop and analyze intra-group acceleration, we define
the following quantities.  p2: the probability that one subgroup test result is positive under the condition that the test result of a group is
positive.  q2: the probability that one subgroup test result is negative under the condition that the test result of a group is
positive.
Note that both p2 and q2 are conditional probabilities. It is
clear that p2 = 1 − q2, and
q2 = qm
0 (1 − qk−m 0 )
p1
= qm
0 − qk
0
1 − qk
0
,
where p1 is the probability that one group test result is positive
(i.e., the condition), qm
0 is the probability that all samples
in a subgroup are negative (i.e., one subgroup test result is
negative), and (1 − qk−m 0 ) is the probability that at least one of
the remaining (k − m) samples in the same group is positive
(to keep the condition).
Under the condition that the test result of a group is positive, the expected number of tests for one subgroup using the
pooling method is
Tsubgroup(m) = 1 × q2 + (m + 1) × p2
= q2 + (m + 1)(1 − q2 )
= m + 1 − mq2.
Under the condition that the test result of a group is positive,
the expected number of tests for one group using intra-group
acceleration is
T 

group =
 k
m

Tsubgroup(m)
=
 k
m

(m + 1 − mq2 )
= k

1 +
1
m − q2

= k

1 +
1
m − qm
0 − qk
0
1 − qk
0

.
Since the number of tests for one group without intra-group
acceleration is k, the speedup of the intra-group acceleration
method is
Sgroup(m) = k
T 

group
= 1
1 +
1
m − qm
0 − qk
0
1 − qk
0

.
To maximize Sgroup(m), we need to minimize
F(m) = 1
m − qm
0 − qk
0
1 − qk
0
.
280 VOLUME 1, 2020It is noticed that
∂F(m)
∂m = − 1
m2 − qm
0 ln q0
1 − qk
0
.
To have ∂F(m)/∂m = 0, we need
1
m2 = qm
0
1 − qk
0
ln
1
q0
,
which implies that m satisfies
m =

(1 − qk
0 )
 1
q0
m
ln
1
q0
.
Again, there is no analytical and closed-form solution to the
above equation of m at this stage. However, m can be obtained
by a numerical algorithm (i.e., the standard bisection method)
based on the observation is that
G(m) = m −

1 − qk
0
qm
0 ln(1/q0 )
is an increasing function of m. We use m∗ to represent the
solution to the equation G(m) = 0 rounded to the nearest
integer.
The expected number of tests for one group using intragroup acceleration is
Tgroup = 1 × q1 + (T 

group + 1) × p1,
where T 

group can be more accurately expressed as
T 

group =
 k
m

Tsubgroup(m) + Tsubgroup(k mod m).
The total number of tests for a population of N (which is
divided into N/k groups) using both inter-group acceleration
and intra-group acceleration is
Tpooling =
N
k

Tgroup.
The speedup of the pooling strategy with both inter-group
acceleration and intra-group acceleration is
S(k, m) = N
Tpooling
= k
Tgroup
.
B. NUMERICAL RESULTS
In Table 2, we demonstrate the optimal subgroup size m∗
(given the optimal group size k∗ of Section II) obtained by our
numerical algorithm for p0 = 10−2, 10−3, ..., 10−7. We have
the following important observations.  It is observed that by using the method of intra-group
acceleration, the expected number T 

group of tests for
one group is noticeably reduced and noticeable speedup
Sgroup(m∗) within a group can be obtained. Of course,
such speedup is gained with probability p1, i.e., when
the test result of a group is positive.
 The speedup S(k∗, m∗) of the pooling strategy with
both inter-group acceleration and intra-group acceleration is noticeably improved. Furthermore, as p0 becomes
smaller, the ratio S(k∗, m∗)/k∗ increases, which means
that S(k∗, m∗) is closer to k∗, and the speedup can almost
be doubled (compared with Table 1).  It is worth to mention that when k∗ is too small (e.g.,
k∗ = 4 for p0 = 10−1), the method of intra-group acceleration is not effective and does not lead to fewer number
of tests.
C. OPTIMAL SUBGROUP SIZE
One important observation from Table 2 is that the speedup of
the intra-group acceleration method is approximately m∗/2,
that is, Sgroup(m∗) ≈ m∗/2. This gives us an opportunity to
derive a closed-form expression of m∗. Let us consider the
equation
Sgroup(m) = 1
1 +
1
m − qm
0 − qk
0
1 − qk
0

= m
2 ,
that is,

1 − qm
0 − qk
0
1 − qk
0

m = 1,
and
1 − qm
0
1 − qk
0

m = 1.
Since G(m) = 0, i.e.,
m =

1 − qk
0
qm
0 ln(1/q0 )
,
we get
1 − qm
0 =

qm
0 (1 − qk
0 ) ln(1/q0 ).
Let x = 	qm
0 . Then, we have
x2 +

(1 − qk
0 ) ln(1/q0 )x − 1 = 0,
which gives
x = 1
2

−

(1 − qk
0 ) ln(1/q0 ) +

(1 − qk
0 ) ln(1/q0 ) + 4

,
and
qm
0 = x2 =
1
2

(1 − qk
0 ) ln(1/q0 ) + 4
−

(1 − qk
0 ) ln(1/q0 )
2
,
and
m = 2 logq0
1
2

(1 − qk
0 ) ln(1/q0 ) + 4
−

(1 − qk
0 ) ln(1/q0 )
.
VOLUME 1, 2020 281LI: HIERARCHICAL POOLING STRATEGY OPTIMIZATION FOR ACCELERATING ASYMPTOMATIC COVID-19 SCREENING
Since m∗ needs to be an integer, we set
m∗ =

2 logq0
1
2

(1 − qk
0 ) ln(1/q0 ) + 4
−

(1 − qk
0 ) ln(1/q0 )

,
which has been verified to be consistent with Table 2.
IV. JOINT OPTIMIZATION
Our optimal group size k∗ in Section II is obtained based on
the assumption that the method of intra-group acceleration
is not used. With the reduced number T 

group of tests for one
group by using intra-group acceleration, it is likely that k∗
can be increased, which creates more room for improving the
speedup. The increased group size certainly affects the choice
of the optimal subgroup size m∗. Fortunately, based on the
analytical expressions of m∗ in Section III, it is possible to
conduct joint optimization for both inter-group acceleration
and intra-group acceleration, i.e., to simultaneously find the
optimal group size and the optimal subgroup size, when both
inter-group acceleration and intra-group acceleration are involved.
A. THE METHOD
Recall that
m(k) = 2
ln q0
ln1
2

(1 − qk
0 ) ln(1/q0 ) + 4
−

(1 − qk
0 ) ln(1/q0 )
,
and
T 

group(k) = k
 1
m(k)
+
1 − qm(k)
0
1 − qk
0

,
and
Tgroup(k) = qk
0 + (T 

group(k) + 1)(1 − qk
0 ),
and
S(k, m(k)) = k
Tgroup(k)
,
where S(k, m(k)), as well as m(k), T 

group(k), and Tgroup(k) are
all viewed as functions of k.
In Figure 4, we display the speedup S(k, m(k)) for p0 =
0.01. It is clear that S(k, m(k)) is a concave function of k,
and there is an optimal choice of k = 25, which maximizes
S(k, m(k)).
To maximize S(k, m(k)), we need ∂S(k, m(k))/∂k = 0,
where
∂S(k, m(k))
∂k = 1
Tgroup(k)
− k
T 2
group(k)
·
∂Tgroup(k)
∂k ,
and
∂Tgroup(k)
∂k = qk
0 ln q0 +
∂T 

group(k)
∂k (1 − qk
0 )
FIG. 4. Speedup S(k, m(k)) vs. group size k (p0 = 0.01).
−(T 

group(k) + 1)qk
0 ln q0
= ∂T 

group(k)
∂k (1 − qk
0 ) − T 

group(k)qk
0 ln q0,
and
∂T 

group(k)
∂k =
 1
m(k)
+
1 − qm(k)
0
1 − qk
0

+k

−
 1
m2(k)
+ qm(k)
0 ln q0
1 − qk
0
∂m(k)
∂k
+(1 − qm(k)
0 )qk
0 ln q0
(1 − qk
0 )2

,
and
∂m(k)
∂k = 1

(1 − qk
0 ) ln(1/q0 ) + 4 −

(1 − qk
0 ) ln(1/q0 )
×
⎛
⎝
1

(1 − qk
0 ) ln(1/q0 )
− 1

(1 − qk
0 ) ln(1/q0 ) + 4
⎞
⎠
× qk
0 ln(1/q0 ).
The equation ∂S(k, m(k))/∂k = 0 can be solved by using the
standard bisection method, based on the observation is that
∂S(k, m(k))/∂k is a decreasing function of k.
282 VOLUME 1, 2020TABLE 1. Optimal Group Size (p0 = 10−1, 10−2, 10−3, ..., 10−7)
TABLE 2. Optimal Subgroup Size (p0 = 10−2, 10−3, ..., 10−7)
TABLE 3. Optimal Group and Subgroup Sizes (p0 = 10−1, 10−2, 10−3, ..., 10−7)
Once the optimal group size k∗ is available, the corresponding optimal subgroup size m(k∗) and the speedup S(k∗, m(k∗))
can be calculated easily.
B. NUMERICAL RESULTS
In Table 3, we demonstrate the optimal group size k∗, the
optimal subgroup size m(k∗), and the speedup S(k∗, m(k∗))
for p0 = 10−1, 10−2, 10−3, ..., 10−7. We have the following
important observations.  The optimal group size k∗ is significantly greater than
the optimal group size of inter-group acceleration (see
Table 1). In particular, we have for p0 = 10−r,
k∗ ≥ (25/16)4r = 1.5625 × 4log10(1/p0 )
= 1.5625(1/p0 )
log10 4 = 1.5625(1/p0 )
0.602.
That is, the optimal group size grows sublinearly with
1/p0.  The optimal subgroup size m(k∗) is noticeably greater
than the optimal subgroup size of intra-group acceleration (see Table 2). In particular, we have for p0 = 10−r,
m∗ ≥ 2r = 2log10(1/p0 ) = (1/p0 )
log10 2 = (1/p0 )
0.301.
That is, the optimal subgroup size grows sublinearly with
1/p0.  The achieved speedup S(k∗, m(k∗)) with joint optimization for both inter-group acceleration and intra-group
acceleration is significantly greater than the speedup
of intra-group acceleration with given and fixed group
sizes (see Table 2). The most important factor that determines the gap is the optimality of k∗. Furthermore,
if the speedup is regarded as a function S(p0 ) of p0, as
r increases, we have S(10−(r+1))/S(10−r) > 4, and for
p0 = 10−r, we have
S(10−r) > (11/16)4r = 0.6875 × 4log10(1/p0 )
= 0.6875(1/p0 )
log10 4 = 0.6875(1/p0 )
0.602.
That is, the speedup grows sublinearly with 1/p0. Also
notice that S(k∗, m(k∗)) is approximately (and a little bit
less than) k∗/2 for small p0.  It is worth to mention that such two-level joint optimization is effective and applicable to any p0.
V. PRACTICAL ISSUES
We would like to mention the following issues related to the
applicability of the research in this paper.  Availability of p0 – In this paper, it has been assumed
that the value of p0, i.e., the fraction of infected people,
is available in advance. In reality, the value of p0 can
be estimated accurately by testing a group of n random
samples, where n is reasonably large but still much less
than the population size N, so that the time spent to
obtain p0 is negligible and does not reduce the speedup
too much.  Independence of Samples – In this paper, it has been
assumed that individual sample test results are independent of each other. In reality, there might be correlation
VOLUME 1, 2020 283LI: HIERARCHICAL POOLING STRATEGY OPTIMIZATION FOR ACCELERATING ASYMPTOMATIC COVID-19 SCREENING
among individual sample test results. Such correlation
exists for people from the same family, the same company, the same school, and so on. One effective way to
reduce the impact of sample correlation is to randomize
the samples, so that people from the same social group
are not tested together. Theoretically, the impact of such
dependency on our methods, analysis, and algorithms
needs deeper investigation.  Limitation on Group Size – In this paper, it has been
assumed that the group size and the subgroup size can
be arbitrarily large. In practice, there can be limitation
on the number of samples that can be combined into one
test. The impact of such restriction on the performance of
our hierarchical pooling strategy deserves more careful
study.  Applications in Real Testing – Although we believe that
our hierarchical pooling strategy can be readily applied
to accelerating asymptomatic COVID-19 screening of
any scale, it is still exciting to actually use our methodology in a real community, city, or country. However,
such effort which involves joint endeavor of social, medical, and governmental agencies, is certainly beyond the
scope of this paper.  Generality of Our Strategy – Although our hierarchical
pooling strategy has been developed for asymptomatic
COVID-19 testing, we believe that our general-purpose
analytical methods and numerical algorithms are also
applicable to accelerating the testing of other deceases
that have already been existing or may appear in the
future.
VI. CONCLUSION
We have developed a two-level hierarchical pooling strategy
for accelerating asymptomatic COVID-19 screening. We have
also been able to determine the optimal group size and the optimal subgroup size, which minimize the total number of tests,
maximize the speedup of the hierarchical pooling strategy, and
minimize both time and cost of testing. It is found that the optimal group size, the optimal subgroup size, and the achieved
speedup grow sublinearly with the reciprocal of the fraction of
infected people. Our method is effective in supporting faster
and cheaper asymptomatic COVID-19 screening.
There are further research directions. One challenge is to
derive a closed-form expression of the optimal group size for
our two-level hierarchical pooling strategy. For another further
investigation, we notice that the hierarchical testing system in
this paper has only two levels, i.e., group and subgroup. It
is interesting to consider a hierarchical acceleration system
with more levels (e.g., for very small p0 and not too small
m(k∗)), in which, there are groups, which are divided into
subgroups, which are further divided into sub-subgroups, and
so on, with group level, subgroup level, and sub-subgroup
level acceleration. For such a multi-level testing system, it
is necessary to determine the optimal group, subgroup, and
sub-subgroup sizes. It is conceivable that such a multi-level
acceleration mechanism is more powerful and more effective
in producing higher speedup. We believe that the analytical
approach and algorithmic procedure developed in this paper
can be extended towards this direction.
ACKNOWLEDGMENT
The author would like to thank the three anonymous reviewers
for their constructive comments. Special thanks are due to Dr.
Andrew Li of Carnegie Mellon University and Mr. Tiansheng
Huang of the South China University of Technology for inspiring discussion on the derivation of q2 and the value of p∗
0.
This research was supported in part by the Hunan University
Coronavirus Disease Special Research Project. A preliminary
version of the paper was posted on Research Square, June 9,
2020.



NEW_PAPER



SPECIAL SECTION ON EMERGING DEEP LEARNING
THEORIES AND METHODS FOR BIOMEDICAL ENGINEERING
Received May 22, 2020, accepted June 2, 2020, date of publication June 12, 2020, date of current version June 24, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3001973
Artificial Intelligence and COVID-19: Deep
Learning Approaches for Diagnosis
and Treatment
MOHAMMAD (BEHDAD) JAMSHIDI 1
, ALI LALBAKHSH 2
, (Member, IEEE), JAKUB TALLA 1
,
ZDENĚK PEROUTKA3
, (Member, IEEE), FARIMAH HADJILOOEI 4
, PEDRAM LALBAKHSH5
,
MORTEZA JAMSHIDI6
, LUIGI LA SPADA7
, MIRHAMED MIRMOZAFARI 8
, (Member, IEEE),
MOJGAN DEHGHANI9
, ASAL SABET10, SAEED ROSHANI11, (Member, IEEE),
SOBHAN ROSHANI11, NIMA BAYAT-MAKOU 12, (Member, IEEE),
BAHARE MOHAMADZADE2
, (Student Member, IEEE), ZAHRA MALEK 13
,
ALIREZA JAMSHIDI14, SARAH KIANI15, HAMED HASHEMI-DEZAKI 3
,
AND WAHAB MOHYUDDIN 16, (Member, IEEE)
1Department of Electromechanical Engineering and Power Electronics (KEV), University of West Bohemia in Pilsen, 301 00 Pilsen, Czech Republic
2School of Engineering, Macquarie University, Sydney, NSW 2109, Australia
3Regional Innovation Centre for Electrical engineering (RICE), University of West Bohemia in Pilsen, 301 00 Pilsen, Czech Republic
4Department of Radiation Oncology, Cancer Institute, Tehran University of Medical Sciences, Tehran 1416753955, Iran
5Department of English Language and Literature, Razi University, Kermanshah 6714414971, Iran
6Young Researchers and Elite Club, Kermanshah Branch, Islamic Azad University, Kermanshah 1477893855, Iran
7School of Engineering and the Built Environment, Edinburgh Napier University, Edinburgh EH11 4DY, U.K.
8Department of Electrical and Computer Engineering, University of Wisconsin–Madison, Madison, WI 53706, USA
9Physics and Astronomy Department, Louisiana State University, Baton Rouge, LA 70803, USA
10Irma Lerma Rangel College of Pharmacy, Texas A&M University, Kingsville, TX 78363, USA
11Department of Electrical Engineering, Kermanshah Branch, Islamic Azad University, Kermanshah 1477893855, Iran
12The Edward S. Rogers, Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON M5S, Canada
13Medical Sciences Research Center, Faculty of Medicine, Tehran Medical Sciences Branch, Islamic Azad University, Tehran 1477893855, Iran
14Dentistry School, Babol University of Medical Sciences, Babol 4717647745, Iran
15Medical Biology Research Center, Health Technology Institute, Kermanshah University of Medical Sciences, Kermanshah 6715847141, Iran
16Research Institute for Microwave and Millimeter-Wave Studies, National University of Sciences and Technology, Islamabad 24090, Pakistan
Corresponding author: Mohammad (Behdad) Jamshidi (jamshidi@kev.zcu.cz)
This work was supported by the Ministry of Education, Youth and Sports of the Czech Republic through the Project OP VVV Electrical
Engineering Technologies with High-Level of Embedded Intelligence under Grant CZ.02.1.01/0.0/0.0/18_069/0009855.
ABSTRACT COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing
life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19’s spread
in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to
5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This
paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning
(DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs),
Extreme Learning Machine (ELM), and Long /Short Term Memory (LSTM). It delineates an integrated
bioinformatics approach in which different aspects of information from a continuum of structured and
unstructured data sources are put together to form the user-friendly platforms for physicians and researchers.
The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of
the COVID-19 disease. The most recent related publications and medical reports were investigated with the
purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural
Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs
for each platform, including various forms of the data, such as clinical data and medical imaging which can
improve the performance of the introduced approaches toward the best responses in practical applications.
INDEX TERMS Artificial intelligence, big data, bioinformatics, biomedical informatics, COVID-19, deep
learning, diagnosis, machine learning, treatment.
The associate editor coordinating the review of this manuscript and
approving it for publication was Shuihua Wang .
I. INTRODUCTION
The novel Coronavirus designated SARS-CoV-2 appeared in
December 2019 to initiate a pandemic of respiratory illness
VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 109581M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
known as COVID-19 which proved itself as a tricky illness that can emerge in various forms and levels of severity
ranging from mild to severe with the risk of organ failure
and death. From mild, self-limiting respiratory tract illness
to severe progressive pneumonia, multiorgan failure, and
death [1]–[4]. With the progress of the pandemic and rising
number of the confirmed cases and patients who experience severe respiratory failure and cardiovascular complications, there are solid reasons to be tremendously concerned
about the consequences of this viral infection [5]. Determining appropriate approaches to reach solutions for the
COVID-19 related problems have received a great deal of
attention. However, another huge problem that researchers
and decision-makers have to deal with is the ever-increasing
volume of the date, known as big data, that challenges them
in the process of fighting against the virus. This justifies how
and to what extent Artificial Intelligence (AI) could be crucial
in developing and upgrading health care systems on a global
scale [6]. AI has been recently attracted increasing research
efforts towards solving the complex issues in a number of
fields, including engineering [7]–[9], medicine [10]–[13],
economy [14], and psychology [15]. Hence, a critical situation like this necessitates mobilization and saving medical,
logistic and human resources and AI can not only facilitate
that but can save time in a period when even one hour of
the time save could end in saving lives in all locations where
Coronavirus is claiming lives. With the recent popularity of
AI application in clinical contexts, it can play an important role in reducing the number of undesired deletions as
well as improving the productivity and efficiency in studies
where large samples are involved [16], and higher degrees
of accuracy in prediction and diagnosis are intended [17].
Utilizing big data can also facilitate viral activity modeling
studies in any country. The analyses of results enable health
care policymakers to prepare their country against the outbreak of the disease and make well-informed decisions [18].
Nevertheless, while treatment strategies, crisis management,
optimization and improvement diagnosis methods, such as
medical imaging and image processing techniques could
take benefit from AI which is potentially capable of helping medical methods, it has not been desirably employed
and well-appropriated to serve health-care systems in their
fights against COVID-19. For instance, one area that can take
special advantage of AI’s useful input is image-based medical diagnosis through which fast and accurate diagnosis of
COVID-19 can take place and save lives [19]. Appropriating
AI techniques to deal with COVID-19 related issues can fill
the void between AI-based methods and medical approaches
and treatments. AI specialists’ use of AI platforms can help
in making connections between various parameters and speed
up the processes to obtain optimum results.
In this paper, our team relies on the findings of the
most recent research focusing on COVID-19 and its various
challenges to generalize and suggest a variety of strategies
relevant but not limited to high-risk groups, epidemiology, radiology and etc. As the paper unfolds, it explores
and discusses the potentials of AI approaches to overcome
COVID-19 related challenges in section 2. Section 3 of the
paper includes a presentation of ANN-based strategies that
can be employed for big data analysis. Section 4 presents the
discussion, and Section 5 o?ers the conclusion.
II. ARTIFICIAL INTELLIGENCE AND COVID-19
The present section focuses on the introduction of some
applicable AI-based strategies that can support existing standard methods of dealing with COVID-19 in health care systems around the world. With the aim of foregrounding the
enhanced effectiveness of these strategies and techniques,
their formation has been informed by and based on the most
recent AI-related published medical updates as well as the
latest updates on COVID-19. Therefore, this section presents
ideas that can enhance and speed up ANN-based methods
obtaining process to improve treatment methods and health
management as well as recognition and diagnosis. However,
the optimal effectiveness of AI tools during COVID-19 pandemic depends on the extent of human input and collaboration
in different roles humans play. The knowledge of capabilities
and limitations of AI, however, stays with data scientists who
play an important role simply because they are the ones who
code AI systems [19].
Different steps in the application of AI-based methods
employed to overcome COVID-19 challenges are presented
in the flowchart shown in Fig.1. The first step is the preparation of the data which are necessary for data mining during
data understanding, data preparation and big data. The data
under discussion here consist of medical information, such
as clinical reports, records, images and other various forms
of information that can be transformed into data that can be
understood by a machine. Objectives of data understanding
include understanding data attributes and identifying main
characteristics such as data volume and the total number
of variables to summarize the data. Before processing and
analysis comes data preparation that is the process through
which raw data are refined and converted. In other words, it is
a process in which data are reformatted, corrected and combined to enriched data. Collecting, analyzing and leveraging
the data such as consumer, patient, physical, and clinical data
ends in big data. It is at this stage that human intervention,
as a part of machine learning methods, takes place and experts
investigate and analyze the data to extract the data with finest
structures, patterns and features.
Humans’ contribution at this stage is important because
their knowledge and potentials are not available to an ML
solution that unlike humans is able to deal with huge data sets
far beyond the extent that humans could handle or observe
in a simultaneous manner. Moreover, Deep Learning (DL)
methods could be employed in cases where enormous or
complex data processing challenge ML or traditional means
of data processing. DL methods, as Fig. 1 demonstrates, are
not dependent on human intervention. As a subset of machine
learning, DL consists of numerous layers of algorithms that
provide a different interpretation of the data it feeds on.
109582 VOLUME 8, 2020M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
FIGURE 1. The process of application of AI-based methods to conquer challenges associated with COVID-19.
However, DL is mainly different from ML because it presents
data in the system in a different manner. Whereas DL networks work by layers of Artificial Neural Networks (ANN),
ML algorithms are usually dependent on structured data.
Unlike supervised learning which is the task of learning
a function mapping an input to an output on the basis of
example input-output pairs, unsupervised learning is marked
by minimum human supervision and could be described
as a sort of machine learning in search of undetected patterns in a data set where no prior labels exist. In conventional medicine, alternatively called as allopathic medicine,
biomedicine, mainstream medicine, orthodox medicine and
Western medicine, medical doctors and other professional
health care providers such as nurses, therapists, and pharmacists use drugs, surgery or radiation to treat illnesses and
eliminate symptoms.
AI could be extensively applied for COVID-19; however,
we aim at finding the best possible solutions COVID-19
related issues that have put the biggest challenges ahead of
health care systems. Accordingly, these solutions have been
categorized into 3 parts, including high-risk groups, outbreak
and control, recognizing and diagnosis.
Fig. 2 is a flowchart that shows various applications of
ANNs in diagnosis and tracing the symptoms in 5 layers.
Although the process has been specifically designed for
COVID-19 related problems, it has the potential for use in
other medical imaging analyses. The input layer as the initial
layer is related to the database and is designed for database
access. A high-speed channel is used to couple this layer
with the main (front-end) computer (s). While the database
server is loosely coupled through the network, the database
machine is tightly coupled to the main CPU. Taking advantage of a good number of microprocessors with database
software database machines can send huge packets of data
to the mainframe. The next layer, selection layer, is designed
by an intelligent ANN-based selector and has the task of
adopting the best possible imaging techniques in the light
of past experiences of the system. If physicians confirm the
decisions made by this layer, the recommended techniques in
the third layer take the required images. Consequently, one or
VOLUME 8, 2020 109583M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
FIGURE 2. Application of AI-based methods in classification, analysis and improvement of the medical imaging approaches.
several imaging techniques may be suggested according to
the previously obtained results. For each patient, Magnetic
Resonance Imaging (MRI), Computed Tomography Scan
(CT Scan), positron emission tomography (PET), Optical and
Digital Microscopic Imaging Techniques and applications in
Pathology and X-Ray imaging are the techniques that may be
used in the process. The conventional optical microscope has
come to be the dominant tool in pathological examinations.
PET scan that, in some cases, detect disease before it can
be detected by other imaging tests, is a valuable imaging
test to determine the extent and quality of body tissues and
organs’ functions [20]–[22]. In the PET scan, a radioactive
drug (tracer) is utilized to investigate this functionality [23].
The fourth layer is dedicated to the optimization and
improvement of the images. To realize a classification network that facilitates discrimination between COVID-19 and
Influenza-A viral pneumonia, a DL technology was used
for network structure, and the classical ResNet was used to
extract features [24]. The fifth layer is reserved for ultimate
diagnosis based on the system’s saved information and is
a layer in which learning algorithms should be done by
an ANN method. DL technologies, such as a convolutional
neural network (CNN), are supposed to be the right option
for achieving these goals. The reason is that this type of
network is significantly capable of nonlinear modeling and
has extensive use in medical image processing and diagnosis
process [25]–[28].
III. THE POSSIBLE PLATFORM TO ACCELERATE
CONVENTIONAL METHODS
Finding solutions for high-risk groups who face COVID-19 is
the main concern of the present paper. Since reaching the
best possible results is the main objective, we will try to
demonstrate ways through which ANN-based methods could
109584 VOLUME 8, 2020M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
be used as complementary to the conventional ones. As [29]
suggested it is necessary to keep patients involved COVID-19
registry that highlights clinical variables and cardiovascular
complications because it facilitates the identification of the
pattern of cardiovascular complications, furthers developing
a risk model for cardiac complications, and assists with identification and/or prediction of the response to different types
of treatment modalities.
FIGURE 3. An ELM model to predict suitable drugs based on the
performed studied in [29].
Fig. 3 presents an Extreme Learning Machine (ELM)
model that relies on the performed studies in [29] to predict suitable drugs based on individuals who are involved
with such cardiovascular complications. ELM ANN can use
previous examples applied to the model to predict desired
outputs. This means that training the supervised model happens through the application of the real data in the network.
Therefore, considering various forms of viral infection for
previous cases, ELM can suggest the best possible drugs for
cardiac complications.
In comparison with conventional feedforward network
learning algorithms like back-propagation (BP) algorithm,
learning speed in ELM is a greatly faster and obtains better generalization performance [30]. Nevertheless, on many
occasions, conventional tuning-based algorithms require a
lot less hidden neurons than ELM [31]. There are several
other studies that have previously scrutinized ELM with
fixed network architectures [30], [32]–[34]. Following the
training process, new data can be predicted through a test
or verification procedure. As [29] suggested, the Coronavirus may cause vascular inflammation, myocarditis, and
cardiac arrhythmias. The suggested model depends on the
data that [29] presents to predict the ways that cardiovascular
system is affected by the Coronavirus. Therefore, the suggested model is capable of reducing the risk of possible
cardiovascular complications. Moreover, it realizes the prediction of response to different treatment modalities because
it can predict the pattern of cardiovascular complications.
Hence, considering their properties and multiple advantages,
ELMs are recommended for such problems.
Another complication that COVID-19 causes in the elderly
is heart failure, which requires heart failure specialists stay
on guard and design a structured approach to these type of
patients and include them in developing algorithms for the
care of these patients in early stages until the time when
definite universal COVID-19 examinations or clinical trials
of antivirals are in place, and deeper understanding of final
stages of the disease is realized [35]. Excessive use of fluid
and drugs, such as NSAIDs that may change the balance of
salt and water in elderly patients, should be avoided. Reference [35] and biomarkers, especially in high-risk elderly
patients with underlying structural cardiac disease should be
used with care and caution. As such, defining and managing
advanced heart failure in the phase of hyper inflammation are
important issues for heart specialists [35].
FIGURE 4. Classifying the best treatment method with high precision
through LSTM ANN a developed method inspired by [35].
Fig. 4 shows a model that uses Long /Short Term Memory (LSTM) network put forward in [35]. This model relies on
appropriately considered inputs to predict the best treatment
as precisely as possible. Being capable of maintaining long
memory, LSTM networks are very advantageous for learning
sequences with longer-term patterns of unknown length [36].
VOLUME 8, 2020 109585M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
In addition to electrocardiography and history of chronic
medical illness which can help the model training process
Mild, moderate and advanced phase of COVID-19 infection
can be considered as inputs. Employing multiplicative gates
that administer continuous error flow through the internal
states of ‘memory cells’ which are special units [36]. LSTM
neural networks [37] solve the problem of disappearing gradient in Recurrent Neural Networks (RNNs) Hochreiter and
Schmidhuber who were the first to introduce this [37] were
followed by others who refined and popularized it [38].
LSTM NN has been popular and increasingly used in robot
control, speed recognition, handwriting recognition, human
action recognition, etc. over the past ten years [39], and it has
worked perfectly in speech recognition [40] and text classification [41], [42]. Reference [43] shows fault prediction to be
the main subject in nonlinear systems [44].
FIGURE 5. Prediction of spreading the infection by Recurrent Neural
Network (GRURNN, Clockwork RNN or CW-RNN)) which is a developed
approach based on [45].
ANN-based methods are alternative ways of predicting COVID-19 outbreak. According to [45], a description of the fields in the database is shown here and can
be reached via a data dictionary on Github [45] (https://
github.com/beoutbreakprepared/nCoV2019/covid19): References to specific settlements along with references to areas
that were administrative units have been two ways to collect geographical information. The real-time epidemiological
data in [45], have been put together in an organized manner to predict the infection spread. Fig. 5 illustrates how a
DL approach, which is powered by RNN can predict the
spreading of infection associated with COVID-19 through
clinical and geographical big data. Depending on geographical and clinical data, variations of RNNs can be utilized to
predict the spread of infection. However, it seems that the best
structure to realize the predictions are LSTM network [37],
Gated Recurrent Unit RNN (GRURNN) [46], and Clockwork
RNN (CW-RNN) [47]. The RNN, as alternatively called Auto
Associative or Feedback Network, falls in the category of
ANNs in which a directed cycle is made through connections
between units [48]. Being a widely appreciated DL family,
RNNs have succeeded to present promising results in a lot
of machine learning and computer vision tasks [49]. One
important task to use this model, however, is the quantification of qualitative inputs such as country and location.
Updating the model is possible because of the real-time data
by RNN with real-time learning capability. Utilization of the
proposed ANN model provides the opportunity of proposing
the epidemiological model of the virus in different locations.
The main objective of the proposed structure is to improve the
accuracy and speed of recognition and classification of the
issues caused by the virus by utilizing DL-based methods.
Although screening, diagnosis, and progress assessment of
COVID-19 have been effectively performed through reliance
on radiological examinations, including CT and digital photography (DR) [50], [51], there has been not much prior experience that could come to help radiologists and technologists
to deal with COVID-19 patients. In areas hit by the epidemy,
negative RT-PCR but positive CT features are significant
signs of COVID-19 and can highlight the importance of
rapid detection of the infection that gives the community as
well as clinicians a better chance to bring the viral spread
under control [52]. While radiological examinations such as
computed tomography CT has been demonstrated as effective
methods for screening and diagnosis, there is evidence that
considerable numbers of radiologists and technologists have
been infected while serving COVID-19 patients [50]. Lung
CT scans of pneumonia caused by COVID19 picture bilateral,
subpleural, groundglass opacities with air bronchograms,
illdefined margins, and a slight predominance in the right
lower lobe [53]. The image classification model facilitates
discrimination of different infections in terms of their appearance and structure. To learn the approximate location information of the patch on the pulmonary image, the model
uses relative distance-from-edge as an extra weight [24].
Although the cumbersome task of obtaining a large number of medical images for machine learning applications is
possible, specialized and professional reading of diagnostic
imaging report that could adroitly address context, syntax,
structure, and specific terminologies needed to interpret the
imaging is solely left with radiologists who could extract
diagnostic information from images and make them available
as structured labels for the use of the machine learning model
training [54].
The first case of this part discussed the process of visualization and detection of new human Coronavirus. However, a recent study has shown that initial propagation of
human respiratory secretions onto human airway epithelial
109586 VOLUME 8, 2020M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
FIGURE 6. Application of Generative Adversarial Network (GAN) for
visualization and detection of new human Coronavirus based on the
results of [55].
cell cultures along with transmission electron microscopy
and whole-genome sequencing of culture supernatant can be
used to visualize and detect new human Coronavirus that
has the possibility of remaining unidentified by traditional
approaches [55]. As [55] demonstrates infection caused by
COVID-19 can damage human airway epithelial cells. It is
also demonstrated that visualizing and detecting new human
Coronavirus can be done through using the effects of the
human respiratory secretions on the human airway along with
the results of transmission electron microscopy, and genome
sequencing of culture supernatant. Fig. 6 depicts the proposed
neural network model and the Generative Adversarial Network (GAN). To analyze electron microscopy images, feature
extraction technique can be adopted. GANs are a special type
of neural network model in which two networks are trained at
the same time while one is focused on generating images, and
the other performs discriminating [56]. GANs [57] can solve
these problems through effective modelling of the latent distribution of the training data. GANs have successfully been
applied to image-to-image translation [58], segmentation [59]
and many other subfields of medical image computing [60].
Because of its usefulness in counteracting domain shift, and
effectiveness in generating new image samples, the adversarial training scheme has recently attracted a lot of attention. This model has achieved state-of-the-art performance
in a lot of tasks, namely text-to-image synthesis [61], superresolution [62], and image-to-image translation [63]. Those
are related to generating images. Another problem to be
solved by ANN-based approaches is estimating the extent of
cardiac involvement. Reference [64] argues that COVID-19
virus is a major cause of myocarditis. Reference [64] has
studied cardiac involvement as a COVID-19 infection capable
of causing severe acute respiratory syndrome to conclude
that the recognition of acute myocarditis’s association with
COVID-19 by the scientific community can be beneficial in
monitoring affected patients in a strict manner and could help
public health officials in coming to a better understanding
of such life-threatening complications. Accordingly, relying
on the findings and proposals of [64], an LSTM network
is put forward for the estimation of COVID-19 related cardiac involvement. Considering that in feedforward neural
networks signals are allowed to merely move in one direction
travelling forward from the input to the output. we prefer
RNNs because they allow signals to travel both ways introducing loops in the network allowing internal connections
among hidden units [65]. Contrary to feedforward neural
network, an RNN processes the sequential inputs through
a recurrent hidden state in which activation at each step is
dependent on the previous one; hence, the ability of the network to exhibit dynamic temporal behavior [49]. Fig. 7 lists
the features from Tesla cardiac magnetic resonance imaging
that can be utilized for model training.
FIGURE 7. Estimation of cardiac involvement caused by the virus
infection extracted from The features from Tesla cardiac magnetic
resonance imaging and the information given in [64].
Also, an AI-based model exists to estimate the behavior
of Remdesivir as well as some clinical parameters. As noted
in [66], suggest compared to patients with high viral replication and systemic virus dissemination, patients with a viral
load decrease in the upper respiratory tract may need various
therapeutic approaches depending on viral kinetics monitoring, may be required. However, due to the small number
of patients in this case data analysis be done cautiously.
Reference [64] has studied clinical and biological data of
five COVID-19 patients. To estimate the behavior of Remdesivir, antiviral medication for post-infection treatment for
COVID-19, in treatments of the patients as well as hospital
stay, ICU stays and symptomatic period, clinical data of
these patients including chronic medical illness or history
VOLUME 8, 2020 109587M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
of chronic medical illness, symptoms, age and gender and
tests results on hospital admission are utilized. Nevertheless,
the numbers of patients were not sufficient for ELM network. ELM is exactly a least-square based learning algorithm
for ‘‘generalized’’ single hidden layer feedforward networks
(SLFNs), is useful for estimating regression problem or classifying tasks [67].
While input weights (linking the input layer to the hidden
layer) and hidden biases in ELM are selected in an arbitrary manner, the output weights (linking the hidden layer
to the output layer) are determined in an analytic manner
and through the use of Moore–Penrose (MP) generalized
inverse [31]. Therefore, ELM technique can be used to train
the suggested model. The proposed mentioned ELM model
is depicted in Fig. 8.
FIGURE 8. Estimation of Remdesivir drug behavior on the patient’s
treatments, hospital stay, ICU stay and symptomatic period using ELM
and the ideas of [66].
We propose a model equipped by GAN for viral gastrointestinal infection probability estimation in the last part of
the diagnosis system. In [68], evidence for gastrointestinal
infection of SARS-CoV-2 and the possibility of faecal-oral
transmission route is provided. The spread of the virus from
infected to uninfected cells makes viral-specific target cells
or organs the main role player in determining the viral
transmission routes. The first step of viral infection is the
receptor-mediated viral entry into the receiving cell [68].
Besides, ACE2, which is rarely expressed in the oesophagal epithelium, abundantly distributed in cilia of glandular
epithelia [68].
However, even after negative conversion of the viral RNA
in respiratory tract over 20% of SARS-CoV-2 patients show
positive viral RNA in feces which is an indication of viral
gastrointestinal infection and the possibility of faecal-oral
transmission that can still take place after viral clearance in
the respiratory tract [68].
Therefore, routine rRT-PCR testing for SARS-CoV-2 from
feces is highly recommended in the case of SARS-CoV-2
patients. Besides, in case rRT-PCR testing demonstrated
positive feces test, transmission-Based precautions for hospitalized SARS-CoV-2 patients should be in place [68].
Reference [68] studies the gastrointestinal infection caused
by COVID-19. COVID-19-related gastrointestinal infection
in this study is evidenced by a collection of images of histological and immunofluorescent staining of rectum, duodenum, stomach and oesophagus. These fluorescent staining
images are the output of laser scanning confocal microscopy.
A GAN network to predict viral gastrointestinal infection
probability can be done through the extraction of the feature
from these images to help patients in the process of their
treatment. Fig. 9 presents this model a decision to continue
or discontinue transmission-based precautions for hospitalized SARS-CoV-2 patients is dependent on rRT-PCR testing for SARS-CoV-2. The GANs generative process, which
projects a standard distribution to complex high-dimensional
real-world data distribution stands higher when compared
to most discriminative tasks (e.g., classification and clustering) [69]. In addition to image generation tasks, GANs have
been introduced to tasks, such as video generation, visual
tracking [70], domain adaption [71], hashing coding [72], and
feature learning [73].
GANs are of two different users in medical imaging [56].
With their focus on the generative aspect, they facilitate
exploration and discovery of the underlying structure of training data and help with learning to generate new images. With
their focus on the discriminative aspect, where the discriminator D can be regarded as a learned prior for normal images
they can be used as a regularizer or detector when presented
with abnormal images [56].
Early screening of COVID-19 patients seems to be effectively managed through DL models demonstrated in this
study that can be an effectively helpful supplementary diagnostic method for clinical doctors in close contact with
patients [74].
IV. DISCUSSION
Focusing on the possibility of the ANN application for
analyzing COVID-19-related infection problems, such as
high-risk patients, control of the outbreak, recognizing and
radiology, we used RNN, LSTM, GAN and ELM to suggest several AI-based methods. Advanced machine learning
algorithms can integrate and analyze large-scale data related
to COVID-19 patients to facilitate a deeper understanding
of viral spread pattern, improve the speed and accuracy of
diagnosis, develop fresh, effective therapeutic approaches,
and even identify individuals who, depending on their genetic
and physiological features, are most susceptible to the disease [75]. Despite much praise that such data has received
because of its role in improving efficiency, productivity and
processes in different sectors, it has been criticized for its
small number of users who collect, store, manage the data and
have access to them [76]. However, as Heyman maintains AI
109588 VOLUME 8, 2020M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
FIGURE 9. The process of viral gastrointestinal infection probability estimation using a combination of GAN and rRT-PCR
testing for SARS-CoV-2 from feces to determine the transmission-based precautions for hospitalized SARS-CoV-2 inspired
by [68].
makes it possible to tell when wrong things are happening,
or actions are to be taken regarding COVID-19 because it
monitors and collects data coming from social media, newsfeeds, and airliner ticketing systems [77].
A large bulk of various information coming from the
most recent advancement and publications in the relevant
case can be covered by the suggested methods. Nevertheless,
while a variety of inputs exist, clinical data remains as the
input shared by almost all the techniques. When it comes to
groups that are defined as high risk, overviewing COVID-19
patients’ clinical characteristics throughout pregnancy or disease period is particularly important. The model proposed
here is mainly focused on patients with heart failure during
the hyper-inflammation phase of this illness and individuals
for whom systematic recordings of clinical variables and
cardiovascular complications exist. These ideas, however,
yield themselves to be extended to other high-risk patients
because there are similarities between the structure of ML
or DL techniques in complex data estimation and prediction.
ELM algorithm is suggested for predicting suitable drugs
because it is highly advantageous in problem-solving, but
the gradient-based learning algorithms like back-propagation
are good to feedforward neural networks with more than one
hidden layers. In the case of SLFNs, the present form of the
ELM algorithm is valid.
We proposed an LSTM equipped model for the second
case, which is the classification of the best treatment method.
LSTM networks seem to be good options for classification,
process, and prediction according to time series data because
lags of unknown duration may take place between major
events in a time series. Exploding and vanishing gradient
problems that may appear in training traditional RNNs can
be effectively dealt with by LSTMs which is proved to be a
working tool in cases where sequences exist because in such
cases the meaning of a word is dependent on the previous
word. Predicting the epidemiology and outbreak by AI was
another subject discussed in this paper. The model that we
suggested here is based on RNN with a comprehensive set
of inputs that can be completed by the database presented
in [45]. RNN can be considered a class of ANNs is in which a
directed graph along a temporal sequence is formed by connections between nodes making the exhibition of temporal
dynamic behavior possible. RNNs’ prediction of the future
is influenced by their remembering of past events before
learning the underlying relationship of the data when trying
to reach the hidden layers RNNs run in a loop. Considering
that Imaging workflows can inspire advances in machine
learning methods capable of assisting radiologists who seek
an analysis of complex imaging and text data, we described
models that can analyze medical imaging facilitating the
completion of a process that recognizes COVID-19-related
infections [54]. As for the epidemic area, we explained that
COVID-19 could be the case when negative RT-PCR and
positive CT are in place. Considering the importance of rapid
detection of the viral infection that can significantly help with
more effective control of the viral spread, clinical and societal
implications of this argument cannot be ignored [52]. Radiological examinations, such as computed tomography CT,
were discussed as effective methods to screen and diagnose
infection. It was also mentioned that a considerable number
VOLUME 8, 2020 109589M. Jamshidi et al.: AI and COVID-19: Deep Learning Approaches for Diagnosis and Treatment
of radiologists and technologists have been infected in the
process of examining COVID-19 patients [50]. COVID19
pneumonia is mostly seen on lung CT scans as bilateral,
subpleural, groundglass opacities with air bronchograms,
illdefined margins, and a slight predominance in the right
lower lobe [53].
In the first case of recognizing, visualization and detection
of new human Coronavirus by a GAN, the inputs of the
proposed network consist of the effects of the human respiratory secretions on the human airway, results of transmission electron microscopy, and genome sequencing of culture
supernatant.
It is important to emphasize that COVID-19 is notorious
for the rapid deterioration of the function of the respiratory
system that often happens in the second week of the disease;
therefore, the current wellness of the patients cannot be a
guarantee that they are not hit by the disease and safety netting
advice has to be taken seriously [78]. This highlights the
importance of utilizing an effective ANN-based method in
visualizing and detecting new human Coronavirus. When a
training set is given to this technique, it learns to generate new
data while it uses the same statistics as the training set. It is
also demonstrated that GANs are useful for semi-supervised
learning [79], fully supervised learning [80] and reinforcement learning [81]. While GANs learn to map from a latent
space to a data distribution of interest, the discriminative
network discriminates candidates that the generator creates
from the true data distribution. The second case of recognizing includes an LSTM approach that estimates cardiac
involvement caused by the virus infection. LSTM units come
with multiple architectures. One common architecture consists of a cell and three ‘‘regulators’’ or information flow gates
inside the LSTM unit: an input gate, an output gate and a
forget gate. Keeping track of the dependencies between the
elements in the input sequence is done by the cell. While
controlling the extent of a new value flow into the cell is
the responsibility of input gate., the extent to which a value
remains in the cell is controlled by the forget gate, and the
extent to which the value in the cell is used to compute the
output activation of the LSTM unit is controlled by the output
gate. It is recommended, however, that in the third case of
recognizing, ELM network does the estimation of Remdesivir’s behavior in patient’s treatments, hospital stay, ICU stay
and symptomatic period. Generally, the black-box character
of neural networks and ELM network are major concerns that
put engineers on guard when it comes to application in unsafe
automation tasks.
However, there are a variety of techniques available, such
as reducing the dependence on random input, to approach
this particular issue [82], [83]. In the last case of recognizing a GAN predicts the probability of viral gastrointestinal
infection. Candidate generation is done by the generative
network, and evaluation of the candidate is completed by the
discriminative network [57]. The contest operates in terms
of data distributions. While the generative network learns to
map from a latent space to a data distribution of interest,
the discriminative network discriminates candidates that the
generator creates from the true data distribution and hence the
benefits of using this characteristic into an approximate viral
gastrointestinal infection.
Although the proposed techniques have not been utilized
yet to evaluate their effectiveness, there are many medical
reports and valid sources of information proven the efficiency
and accuracy of these methods in many different kinds of
similar diseases. The most important result here is to generalize such strong methods based on the characteristics of
COVID-19.
V. CONCLUSION
The introduced conceptual structures and platforms in the
research field of AI-based techniques, which are suitable for
dealing with COVID-19 issues, have been studied in this
paper. Different techniques have been developed, incorporating COVID-19’s diagnostic systems, such as RNN, LSTM,
GAN, and ELM. The geographical issues, high-risk people,
and recognizing and radiology were the main problems with
COVID-19 and have been studied and discussed in this work.
Also, we showed a mechanism for selecting the appropriate
models of estimation and prediction of desired parameters
using a number of clinical and non-clinical datasets. Considering these platforms assists AI experts to analyze huge
datasets and help physicians train machines, set algorithms
or optimize the analyzed data for dealing with the virus with
more speed and accuracy. We discussed that they are desirable
because of their potential for creating a workspace while AI
experts and physicians could work side by side. However,
it should be noted while AI speeds up the methods to conquer COVID-19, real experiments should happen because a
full understanding of advantages and limitations of AI-based
methods for COVID-19 is yet to be achieved, and novel
approaches have to be in place for problems of this level
of complexity. Succeeding in the combat against COVID-19
toward its eventual demise is highly dependent on building
an arsenal of platforms, methods, approaches, and tools that
converge to achieve the sought goals and realize saving more
lives.



NEW_PAPER



Received January 16, 2021, accepted February 12, 2021, date of publication March 2, 2021, date of current version March 12, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3063152
Blockchains for COVID-19 Contact Tracing and
Vaccine Support: A Systematic Review
LAURA RICCI 1
, DAMIANO DI FRANCESCO MAESA2
, ALFREDO FAVENZA3
,
AND ENRICO FERRO3
1Department of Computer Science, University of Pisa, 56126 Pisa, Italy
2Department of Engineering, University of Cambridge, Cambridge CB3 0FS, U.K.
3LINKS Foundation, 10131 Turin, Italy
Corresponding author: Laura Ricci (laura.ricci@unipi.it)
ABSTRACT Several blockchain projects to help against COVID-19 are emerging at a fast pace, showing
the potential of this disruptive technology to mitigate the multi-systemic threats the pandemic is posing on
all phases of the emergency management and generate value for the economy and society as a whole. This
survey investigates how blockchain technology can be useful in the scope of supporting health actions that
can reduce the spread of COVID-19 infections and allow a return to normality. Since the prominent use of
blockchains to mitigate COVID-19 consequences are in the area of contact tracing and vaccine/immunity
passport support, the survey mainly focuses on these two classes of applications. The aim of the survey is
to show that only a proper combination of blockchain technology with advanced cryptographic techniques
can guarantee a secure and privacy preserving support to fight COVID-19. In particular, this article first
presents these techniques, i.e. zero-knowledge, Diffie Hellman, blind signatures, and proxy re-encryption,
then describes how they are used in combination with blockchains to define robust and privacy-preserving
solutions. Finally, a brief description of blockchain applications beyond contact tracing and vaccine certification is presented.
INDEX TERMS Blockchain, distributed ledgers, cryptography, smart contracts, COVID-19, contact tracing,
vaccine.
I. INTRODUCTION
On the 30th of January 2020, the Coronavirus Disease
(COVID-19), an outbreak caused by the virus ‘Severe Acute
Respiratory Syndrome Coronavirus 2 (SARS-CoV-2)’, was
declared a Public Health Emergency of International concern
by the World Health Organization (WHO) [1]. Even if it
was referred to as a health crisis first, it has also produced
collateral and multi-systemic consequences on healthcare,
economic, social, and information systems.
Several areas of society have been affected by the
COVID-19 crisis. The economic system is significantly struggling to offset the financial losses caused by the pandemic.
This situation will inevitably lead to the closure of many
companies and the consequent loss of jobs [2], [3]. The
education system is also suffering a severe blow, with abrupt
interruption of learning paths of young people, a problem
The associate editor coordinating the review of this manuscript and
approving it for publication was Theofanis P. Raptis .
which, according to the United Nations, is involving a large
portion of the school-age population in the world.
Even if all the previous areas have been deeply involved
in the COVID-19 crisis, there is no doubt that the area that
has mainly suffered the fallout of the crisis is that of healthcare infrastructures. The consequences of COVID-19 have
particularly caused problems in this area, at different levels.
At the supply chain level, with a shortage of medical equipment [4] and evident difficulties of governments and national
healthcare services to provide medical staff and population
with the minimum medical facilities necessary to face the
pandemic and reduce its diffusion. Moreover, the national
systems are struggling in performing an accurate prediction
of the pandemic course, mainly due to the widespread lack
of automation in data sharing between different healthcare
structures [5].
Despite the wide applicability of blockchain technology [6], a recently published work [7], highlights that the
most prominent uses of blockchains to mitigate COVID-19
consequences are in the area of contact tracing and
37936 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
vaccine/immunity passports support. Also an official document of the European Parliament [8], which recognizes blockchains as one of the ten technologies to fight
COVID-19, acknowledges as main current application scenarios infections tracking and health data monitoring. For this
reason, we decided to focus this survey mainly on an in depth
analysis of these blockchain based applications.
Automatic contact tracing apps have been proposed to
detect an individual’s exposure to contagion together with
social distancing directives to protect the health of individuals and minimize infections. Most of these apps require
the presence of a centralized server, raising serious privacy
concerns, as they are susceptible to deanonimyzation and
mass surveillance attacks.
The recent availability of vaccines for COVID-19 makes it
urgently necessary to consider proper infrastructures for vaccine delivery and deployment of vaccination e-certificates.
Indeed, even if, during the first phases of the pandemics,
WHO [9] did not recommend the deployment of ‘‘immunity
passports’’, because there was no evidence of a permanent
immunity given by the infection of COVID-19, in December 2020, with a view on several coming COVID-19 vaccines,
WHO [10] is suggesting to use e-vaccination certificates.
Both contact tracing apps and vaccination e-certificates
have posed doubts on the protection of some of the fundamental rights of citizens and the possible ‘‘Big brother’’
effect generated by the contact tracing traces and vaccinations
recording by the authorities [11]. This makes it urgently
necessary to find proper technologies able to improve the
level of security and privacy for these applications.
The aim of this survey is to investigate how blockchains,
and, more in general, Distributed Ledger Technology (DLT)
can be adopted in the scope of social and health measures
aimed at reducing the spread of the COVID-19 infection to
allow a return to ‘‘normality’’. To this aim, this study mainly
focuses on a deep analysis of several blockchain-based
approaches for contact tracing and for immune/vaccine certifications, analysing their strengths and weaknesses and how
they can perform as effective tools to monitor and combat the
spread and impact of the disease.
Even if some surveys on the use of blockchain for mitigating COVID-19 consequences have been recently presented [12]–[16], all of them present a general, high level
description of the architectures of the blockchain-based systems. Instead, our aim is to present an in depth analysis of
how blockchain technology can be enhanced with advanced
cryptographic tools to guarantee secure and privacy preserving supports for fighting COVID-19, with the goal of defining
applications respecting the fundamental rights of citizens. In
particular, we focus on the automation of contact tracing and
e-certificates management.
This article is organized as follows. Sect. II introduces
the background on blockchain technology and cryptographic
techniques. The solutions for blockchain-based contact tracing are presented in Sect. III, while those for immune/vaccine
certifications in Sect. IV. Other blockchain-based proposals
to face COVID-19 consequences are briefly presented in
Sect. V. Sect. VI contains a discussion of the open problems
and Sect. VII presents related works. Finally, Sect. VIII draws
the conclusions.
II. BACKGROUND
In this section we introduce the essential background to
understand the blockchain-based solutions presented in the
following sections. Sect. II-A introduces the basic concepts
of blockchain technology, while Sect. II-B presents the cryptographic protocols used in the considered blockchain-based
proposals.
A. BLOCKCHAINS AND SMART CONTRACTS
Blockchains and, more in general, distributed ledgers, are a
new disruptive technology introduced in the last decade. They
allow the management of a tamper free ledger shared between
several entities in an untrusted environment. The ledger can
store a collection of records, like cryptocurrency transactions
in Bitcoin [17], the events occurring in a supply chain or the
state of a set of smart contract, like in Ethereum [18]. The
ledger can be stored in a chain of blocks, or in more complex
data structure, like a directed acyclic graph (DAG) (first
proposed in [19]), where the tamper freeness of the ledger
is guaranteed by a cryptographic protocol. In the following,
we will refer to distributed ledgers stored in chains of block,
i.e. blockchains, because this is the structure exploited by all
the solutions we will present.
To decide which blocks have to be added to the blockchain,
a distributed consensus algorithm is executed which guarantees that, under certain conditions (often related to the
percentage of honest participants), a consistent and correct
version of the blockchain is updated and shared by all the
participants. The tamper freenes guarantees that the blocks
of the blockchain cannot be changed, providing persistency
(information remains publicly visible), timestamping (information exists at a given discrete time), and immutability
(information can not be changed). These properties altogether
provide auditability, i.e. it is possible to prove that a given
information does exist at a given time and is not changed later.
An important breakthrough in blockchain technology has
been achieved with Ethereum [20], a blockchain platform
able to execute smart contracts, i.e. stateful applications
executed by all the nodes participating to the peer-to-peer
network, without involving third parties. Smart contract are
written in a Turing-complete programming language, which
may be domain specific, like Solidity, or general purpose,
like C++, and executed on the Ethereum Virtual Machine
(EVM). The execution of a smart contract updates the state
of the blockchain only if the majority of the nodes agrees on
it through the consensus algorithm.
Several types of blockchain have been proposed in
the last years, which may be classified as permissionless/permissioned and public/private. The first dimension
distinguishes between blockchain whose governance, which
is mainly related to the set of nodes allowed to participate
VOLUME 9, 2021 37937L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
to the consensus, is opened to everyone from those which
restrict it to a set of authenticated users. The second dimension, public versus private blockchains, regards the choice
to enable any node to read the information stored in the
blockchain or to restrict it. Public blockchains are good in
terms of transparency but may not suit, for instance, the needs
of a company, that obviously cannot allow unknown entities
to view the transactions of its customers. Instead, a public administrative office may adopt a permissioned public
blockchain to keep the control of the registration of transactions on the blockchain, while making all the transactions
public and accessible to all citizens, to provide transparency
and auditability.
B. CRYPTOGRAPHIC TECHNIQUES
This section introduces the basic cryptographic tools used by
the proposals described in the next sections.
FIGURE 1. The Diffie Hellman protocol at a glance.
The Diffie Hellman protocol (DH) [21] is generally used
when two entities, connected by an insecure channel, want
to share a secret key, which may be needed, for example,
to encrypt a message with a symmetric encryption algorithm.
The two entities share two numbers, a prime number p and
a generator g of the group Zp. Figure 1 shows a simplified
version of the DH protocol: each entity first generates a secret
s and then exchanges with the other entity a value computed
from g, p and s. After the exchange, the two entities are able
to compute a secret key only known to them. The protocol is
secure if and only if the Decisional Diffie–Hellman (DDH)
assumption holds, i.e. the assumption which guarantees computational hardness of discrete logarithms in cyclic groups.
A zero-knowledge proof is a cryptographic mechanism [22]
by which one entity, the prover, can show to another party,
the verifier, that they know some information (e.g. a simple
value or the correct execution of a program on a set of inputs),
by only proving the knowledge of it, without revealing any
additional information on the information itself. The first
proposals of zero-knowledge protocols envisaged multiple
rounds of interaction back and forth between the prover and
verifier. In the last years, the diffusion of blockchain has
offered an incentive for the definition of more scalable and
efficient protocols, like zk-SNARKS, i.e. ‘‘Zero-Knowledge
Succinct Non-Interactive Argument of Knowledge’’ [23].
The acronym refers to the fact that the protocol requires a
single round of interaction between the prover and verifier
and that the length of the proofs and the complexity of their
execution are reduced so to make it possible to integrate these
techniques in the blockchain. Several implementations of
zk-SNARKS currently exist [24], [25] and can be integrated
with blockchains (e.g. [26]).
Blind signatures, introduced by Chaum [27], are a kind of
digital signature where the content is disguised before it is
signed by a third party unable to inspect the content. After
that, the content may be revealed, and the signature appear on
it as a normal digital signature. Blind signatures are generally
employed in privacy critical protocols, where the signer and
content generator are different parties, and the privacy of the
content is important. Electronic-election systems and digital
cash schemes have been among the main applications that
have seen their adoption.
Finally, Proxy re-encryption [28] is a type of Public Key
Encryption technique that allows a proxy to re-encrypt data
encrypted with one public key K1 to another public key K2,
without having access to the underlying plaintext or to
the private key corresponding to K1. Consider the example
in Figure 2: Alice has encrypted a document t with her
public key pk_A, and has sent the encrypted document c_a
to a Proxy, which may be a cloud provider or an IPFS [29]
node. Afterwards, Alice decides to delegate the access to
the document to Bob, who owns a pair of asymmetric keys
sk_B, pk_B. Instead of decrypting the document with her
private key and re-encrypting it with Bob’s public key, Alice
creates a re-encryption key using her secret key and the
public key of Bob and sends it to the Proxy. The Proxy will
re-encrypt c_a by using the re-encryption key, so obtaining a
new encrypted document c_b. Bob can then decrypt c_b using
his secret key.
III. BLOCKCHAIN FOR CONTACT TRACING
Before presenting how blockchain technology can support
and enhance contact tracing, we briefly summarize the main
approaches for tracing contacts recently proposed to cope
with the COVID-19 outbreak.
Contact tracing is the process of identifying individuals
that may have been in contact with an infected persons to
notify them the possibility of infection. The idea of using contact tracing for tackling epidemics dates back to the fourteen
century, when the idea of quarantine was introduced to reduce
the black plague infection [30]. In more recent times, manual
contact tracing has been used by interviewing infected individuals to detect the people they have recently been in contact
with. Manual contact tracing presents the evident drawbacks
of being slow and requiring relevant manpower. This can be
avoided if the same goal is achieved by taking advantage of
the rich set of mobile communication technologies currently
available.
Below we briefly list the main technologies currently
exploited by contact tracing apps, while we refer to [31] for
a more in-depth analysis.
37938 VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
FIGURE 2. Proxy re-encryption.
• Proximity-based Contact-tracing (PCT). The proposals falling in this area are based on detecting the relative
positions of smartphones. Most of them employ the
BLE (Bluetooth Low Energy) technology and exploit the
Blue-Trace protocol [32]. Many contact tracing apps are
currently based on this solution, an in-depth analysis of
these apps is presented in [33].
Even if BLE is intrinsically a distributed protocol,
which enables peer-to-peer interactions between the
mobile nodes, many solutions, like TraceTogether
(Singapore) [34], CovidSafe (Australia) [35], and the
solutions based on the PEPP-PT model [36], like StopCovid (France) [37], use a centralized server, so introducing privacy threats.
The most serious privacy problems characterize the solutions where the central server generates a Temporary
ID (TID), comprising the UserID, the creation and the
expiry time, for each device registered to the service, and
then encrypts the TID symmetrically with a secret key
which is known only to the central health authority. The
TIDs are then exchanged between the mobile phones,
to register their encounters. The health authority uploads
to the server the TID of an infected user together with the
TID of the other users they have encountered. Even if the
possibility of replay attacks is minimized by reducing
the validity of each TID to 15 minutes, this solution
raises several privacy concerns. Indeed, the server is able
to decrypt the identities of all individuals at risk, to send
them a warning.
On the other side, the ‘‘Decentralized PrivacyPreserving Proximity Tracing’’ project, DP3T, [38]
proposes a decentralized approach which enable mobile
phones to autonomously generate a set of pseudonyms,
which are exchanged between phones in close proximity,
without the intervention of a central server. However,
even these applications exploit a centralized server,
which, in this case, only acts as a ‘‘rendez-vous’’
point where infected users upload their pseudonyms,
while other users download them from the server and
autonomously find potential matching with infected
users. As we will discuss in the following, the function of the server may be carried out by a blockchain,
so enhancing the transparency of the whole process.
• Location-based Contact Tracing (LCT). In this class
of solutions, contacts are detected by exploiting the
absolute locations of the smartphones, returned by the
GPS or by WiFi access-points. Only a few countries, like
Iceland and India, are currently employing LCT apps.
A drawback of these approach is that current location
mechanisms, like GPS, are not secure, because nodes
could easily provide fake information. Furthermore, this
solution may present serious privacy problems.
• Mobile Operator Contact Tracing (MOCT). Mobile
operation location tracking exploits the mobile operator’s infrastructures, like base stations of cellular networks, to locate cell phones. This is the solution adopted
in Israel, which has tracked all citizens during the
COVID-19 pandemic. Its main drawbacks are low accuracy and the privacy risks. For these reasons, it is not
generally used to perform contact tracing, but rather to
evaluate the impact of the lockdown measures and to
detect potentially contagion hotspots.
A more comprehensive discussions of the advantages and
drawbacks of the previous solutions is presented in [31].
In the following sections, we discuss how blockchains can
improve the effectiveness of each one of these technologies.
A. BLOCKCHAIN SUPPORT FOR PCT SOLUTIONS
The proposals described in this section enhance proximity
tracing through the blockchain technology. We only consider decentralized solutions, since the centralized ones are
strongly based on the trust of users in a central authority, which is just the opposite approach of the one behind
blockchains.
The main feature of the following proposals is that they
exploit BLE to exchange pseudonyms of the mobile phones
coming into close contact and exploit the blockchain as a
bulletin board for notifying new infections. The solutions are
characterized by different level of privacy and differ in the
techniques used for generating the users’ pseudonyms.
Authors of [39] present a system unifying, in a single
blockchain-based framework, PCT and LCT. The individual
tracing system focus on person-to-person contact via BLT.
Since WHO declared that the virus could survive on material surfaces [40], the authors propose also a location-based
tracing system supported by a set of smart contracts.
VOLUME 9, 2021 37939L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
FIGURE 3. Contact and location tracing.
The proposal is schematically shown in Figure 3. The left part
of the Figure shows a scenario where the user A visits several
locations, i.e. home, bus and office, afterwards is detected
infected. As shown in the right part of Figure 3, the support
enables each person who came in close contact with A to
detect the possibility of contagion (note that H and I are not
at risk because their distance from A has not been considered
at risk) and the location visited by A are tagged as infected,
while the users at risk are depicted in pink. Both actions are
supported by a blockchain, ad described in the following.
In this section, we describe the system component of [39]
which manages PCT, while the LCT part of the system will
be described in the next section.
The mobile phones coming in contact exchange randomized mac addresses by BLE. Contact information includes,
besides the close phone’s mac address, the start and end time
of the interaction and the strength of the received signal, and
may be recorded on the mobile phone or on the blockchain.
When a user U becomes infected, they broadcast a transaction
containing their health status update alongside all the BLE
randomized mac addresses they have generated in the past
14 days (older addresses are no more useful, because the
incubation period of COVID-19 is at most 14 days). Other
users can check the local copy of the blockchain and verify if
they have been in contact with U.
To guarantee privacy, authors suggest to use Bluetooth
Random Private mac addresses, that are randomly generated
and frequently modified by the Bluetooth protocol. A higher
level of privacy is guaranteed by increasing the number of
identifiers, which, on the other hand, increases also the network traffic and the blockchain load. The challenge is to
define the number of identifiers exchanged by the mobile
phones to obtain a proper balance between the two factors.
A similar approach is proposed in [41].
The main advantage of this solution is that it avoids
the use of a centralized server which may tamper
with the pseudonyms uploaded by the infected citizens,
by using instead a blockchain. However this solution fails
to solve many privacy attacks which affect BLE-based
solutions [42], [43]. Indeed, despite the use of dynamic randomized mac addresses helps to increase the anonymity of
users, it is still vulnerable to several privacy threats. Consider,
for instance, the Paparazzi attack [33] whose goal is to
deanonymize an infected user U. The attacker installs a set
of passive BLE devices, i.e. devices only able to receive BLE
signals, in strategic positions, for instance along the way U
uses to go from home to work. When the user U, target of the
attack, is detected positive, they upload all their randomized
mac addresses on the blockchain, and the attacker may
compare the addresses it has collected with those uploaded
on the blockchain and so deanonymize U. As shown in [44],
more sophisticated attacks may be organized to implement a
real mass surveillance strategy.
Another strong assumption made in [39] is that users
always honestly upload their infection status on the
blockchain. This is not a realistic assumption, since malicious
users could upload fake status updates on the blockchain
with the goal of provoking panic in the population. Finally,
the possibility of dynamic updating the mac addresses is
currently not fully supported by current operating systems for
mobile phones.
A more robust proximity-based contact tracing proposal
is PRONTO-C2 [44], an interesting proposal combining
the Diffie-Hellman (DH) secret sharing protocol with a
bulletin-board implemented through a blockchain. A similar approach is also proposed in [45]. The protocol can be
described through a simple metaphor: PRONTO-C2 enables
users to autonomously and confidentially call each other to
alert the presence of a detected infection (note that the Italian
word ‘‘Pronto’’ stays for ‘‘Hello’’ and C2 pronounced in
English stays for ‘‘is you’’ in Neapolitan language). This
is obtained by properly applying the DH protocol. To this
end, the pseudonym of each user is a group element in a
setting where the Decision DH assumption holds. The basic
idea of the protocol is to replace the generation of users’
pseudonyms with that of unique encounter identifiers generated by applying the DH protocol. An encounter identifier
is a secret key K, which is computed by applying DH, and
is shared only by the two mobile phones which have been in
close contact. The protocol defines a mechanism enabling the
users detected as infected by the health authority ‘‘to call’’
all the contacts with whom they have shared the secret in a
secure and privacy-preserving way. After having received an
authorization from the health authority, they upload the secret
37940 VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
FIGURE 4. The ProntoC2 protocol.
keys, which uniquely identify each of their encounters, on a
blockchain acting as a bulletin-board. Users can periodically
check the blockchain to verify if some of the keys in their
possession have been published on it.
Figure 4 presents an outline of the protocol: in the left part,
an individual comes into contact with three other people and
shares different secret keys, respectively K1, K2, and K3,
with each of them. The right part of the Figure shows that,
when that individual is detected infected, all their encounter
keys are uploaded on the blockchain. The other ones query the
blockchain to check if their own secret has been published.
Note that an attacker can only intercept the single messages
of the DH protocol, but cannot steal the secret keys, which are
known only to the users that came in contact with each other,
so the information published on the blockchain is not linked
ad, thus, can not help deanonymization attack attempts.
Of course, to prevent Denial of Service (DoS) attacks (or
panic spreading attempts), only users authorized from the
health authority can upload their identifier on the blockchain.
To prevent the government from linking patients to information on the server, PRONTO-C2 suggests to use blind
signatures. The health authority releases an authorization
code to the infected users, which are sent to the laboratory
from the government. The infected user then exchange the
authorization code with a blind signature which can be verified on the blockchain through a smart contract.
Note that the implementation of the bulletin-board with a
public blockchain guarantees the transparency of the whole
process. Indeed, the encounter identifiers are meaningful only
for the users involved in the contacts with the infected one
and the blind signature guarantees the anonymity (inside the
tested population) of the identities of the infected users.
The main problem of the proposal is that the DH protocol
requires elements of at least 256 bits for the group element
and this may exceed the size of the Bluetooth identifier
beacon. For this reason, the authors have recently proposed
a lighter version of the protocol, PRONTO-B2 that does
not require to translate the beacon identifier in to a group
element.
A solution for contact-tracing, similar to the first one presented in this section, as far as concerns the advertisement on
the blockchain of the infected users, is that of [46] which is
affected by similar privacy problems. The extra contribution
of [46] regards the use of the blockchain to enhance the
control of the pandemics. The author observes that current
proximity-based contact tracing solutions do not enable a
global view of the outbreak evolution, which may be useful, for the government and for the citizens. Indeed, all the
relevant information about encounters is stored on the users’
mobile phones, making it unfeasible to obtain aggregated
information. As a first solution, [46] suggests to exploit a
public blockchain where each user can upload synthetic information about each of their qualified encounters, i.e. encounters with another phone within a certain distance and lasting
a certain period of time. While a personal record of the
encounter includes the pseudonymous of the phones and the
time and duration of the contact, and is used to perform
contact tracing, a redacted record reports information to compute aggregated statistics. A redacted record may contain, for
instance, only the information that a mobile phone has had at
least one qualified encounter. The list of the redacted encounters is stored on a public site, while its hash is published on
a blockchain so that all the citizens can access and check the
integrity of the information.
The list of redacted encounters may be simply replaced by
the number of qualified encounters of a mobile phone. Note
that also a minimal amount of aggregated information, for
instance only the number of encounters, may be very useful
for the government to guide the governance of the outbreak.
For instance, it is possible to follow the trend of the contacts increase, due to the re-opening of some activities, like,
for instance, discos and other entertainment venues. As far
as concerns the scalability of the proposal, [46] suggests
to ease congestion of the blockchain by posting on it only
the hash of the encounters list. Furthermore, scalability is
also guaranteed by the cryptographic sortition technique of
Algorand [47].
A working web-app, iReport-Covid, has been developed [48] to share COVID-19 data on the Algorand
blockchain [47]. The app suggests the users to compile a
survey about their experience, if they have been infected. Data
provided by the users are registered on the blockchain, where
VOLUME 9, 2021 37941L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
FIGURE 5. The BeepTrace protocol.
they can never be removed or changed, so they are shared in
a transparent way.
B. BLOCKCHAIN SUPPORT FOR LCT SOLUTIONS
LCT solutions use absolute geographic locations of mobile
phones to perform contact tracing. One of the main problems
of these approaches is maintaining user’s privacy, because
location data can be easily used to violate the private lives
of citizens. Another problem is location forging that can be
easily achieved by exploiting, for instance, the GPS open
APIs available for smart phone operating systems.
The proposal [39], which has already been considered in
the previous section as for the contact tracing system, defines
also a location-based tracing based on a hierarchy of smart
contracts, paired with hierarchical administrative domains,
e.g. state, region, city. The smart contracts are invoked by
the users, when they check in an area, to control if that area
has been infected. Furthermore the users voluntarily notify
their health status to the smart contracts relative to the areas
visited in the last 14 days. The smart contract automatically
reverts the status of the location to non-infected as soon as
the contagion period is expired. An incentive mechanism is
defined to encourage individuals to use the system. This may
lead to several attacks, as will discuss in Sect. VI.
The BeepTrace proposal [49] is mainly focused on defining
mechanisms to guarantee user’s privacy in the whole contact
tracing cycle. Several positioning technologies (GPS, Bluetooth, Cellular network and WiFi) are used together with
two blockchains, a tracing and a notification blockchain. The
tracing system as a whole is based on the collaboration of
several parties, users, diagnosticians, Certification Authorities, geodata solvers and positioning service providers which
interact through both blockchains.
We refer to Figure 5 to show how contact tracing is implemented in BeepTrace:
• at bootstrap, a certification authority distributes asymmetric key pairs to the authorized diagnosticians and to
the geodata solver authority. The geodata public key is
also distributed to the users.
• the app installed on the users’ phones periodically generates a TraceCode, obtained by encrypting their identifier
with a private key and concatenating the identifier with
their location and timestamp information. The resulting TraceCode is uploaded on the Tracing Blockchain.
A local private key, which is refreshed daily, is used
to generate the user’ pseudonym, while the location
and timestamp is encrypted using the public key of the
geodata solver authority.
• when the trusted health authority diagnoses an infected
user, it collects from them their recent TraceCodes and
verifies, through the user’s private key, the real ownership of the pseudonyms. The user identity is revealed
to the diagnostician, but this step is protected from regulations and laws, like the GDPR. On the other hand,
this guarantees that information about infected users is
shared responsibly, and prevents the diffusion of fake
pseudonyms which may produce panic in the population. To further enhance users’ privacy, the trusted health
authority replaces the pseudonym in TraceCode, with
their pseudonym, signed by their private key.
• at this point, the geodata solver decrypts the location
information from the TraceCodes certified by the health
autority and stored in the tracing blockchain, and performs location matching. The geodata solver uploads
pseudonyms of the users at risk on the notification
blockchain, together with a risk level. Users can access
the notification blockchain to check the presence of their
pseudonyms and, if present, of the risk level.
A problem to be faced in Location Based Tracing is
that of location forging. The blockchain can be exploited
to face this phenomenon, by providing Proof-of-location
(PoL) mechanisms, i.e. certifications of the users’ presence at a location at a certain time. Reference [50] originally proposed Proof-of-Location based on blockchains, for
37942 VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
TABLE 1. Blockchain-based contact tracing solutions.
location-based-services, like location-based rewards, recommendations or social networks gaming. Short rangecommunications are exploited to enable provers, i.e. nodes
that need a certification of their location, to collect proofs of
location from their neighbours, called witnesses. The proofs
of location are stored in a blockchain whose consensus algorithms is a modified version of Proof of Stake, which favours
the election of nodes according to the number of PoL they
have registered in the latest T blocks of the blockchain.
More recently, PoL has been proposed for contact tracing.
In [51], Bychain, a permissionless blokchain for location
based tracing is presented. Witnesses may be WiFi Access
Points, nodes equipped with BLE, or LTE base stations
owned by an Internet Service Provider, all equipped with
GPSs and identified by a couple of public-private keys. The
node which needs a certification (prover) collects a set of
proves from close witnesses, combines them, and registers
them on a blockchain, together with a trust level given by
the number of proves received. A smart contract may certify
the trustfulness of a Proof of Location, without breaking the
user’s privacy, by exploiting an interactive zero-knowledge
protocol. Figure 6 shows an overview of the system. As we
will discuss in Sect. VI, it is realistic to suppose that the
witnesses share their resources (e.g. bandwidth) for PoL services only if a proper incentive mechanism is provided, for
instance by implementing a token-based rewarding system on
the blockchain.
FIGURE 6. Blockchain for proof of location.
C. BLOCKCHAIN SUPPORT FOR MOCT SOLUTIONS
[52] proposes PriLok, an infrastructure that should be managed by a state in collaboration with other entities, like
telecommunication companies, public administrations and
health authorities. The basic idea is to use the cellular network
to promote inclusion, since a part of the population, generally
aged people, may not own a smartphone or is not able to use
Bluetooth. This is even more true in less developed countries.
Furthermore, cellular networks are considered more reliable
with respect to GPS or Bluetooth.
PriLok is defined as an overlay laying on existing infrastructures which adds several functionalities to them. Contact
tracing is performed by registering a Proximity Detail Record
detailing, for each region, the continuous period of time
spent by a phone in that region. The PrilLok Data Vault is
the main data repository which is distributed among several
authorities. PriLok requires that a quorum of independent
entities reach consensus for all critical operations. Both classical solutions, such as Byzantine fault tolerant protocols
(e.g., PBFT [53], MinBFT [54], CheapBFT [55], and modern
blockchains [47], [56], [57] can be exploited.
D. CONTACT TRACING PROPOSALS: A COMPARISON
A summary of the main proposals dicussed in the previous
sections is presented in Table 1. We can notice that most
proposals use the blockchain as a bulletin board. Most of the
proposals exploit Bluetooh, while only a few of them rely on
smart contracts and, in such cases, the Ethereum blockchain
is generally used, with Solidity as the language chosen for
smart contracts development.
IV. BLOCKCHAIN SUPPORT FOR IMMUNE AND VACCINE
CERTIFICATION
In this section we will discuss how blockchain can support the
management of immunity passports and vaccination certificates which are official documents certifying different aspect
of the users’ health. An immunity passport is an official
document certifying that an individual has been infected
and then recovered from COVID-19, and they have likely
developed antibodies for SARS-CoV-2. Anyway, it is much
safer for the immune system to learn how to protect you from
diseases through vaccination than by catching the disease and
VOLUME 9, 2021 37943L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
attempting to treat it. Furthermore, vaccination gives a strong
proof of immunity, as shown by several vaccines recently
produced, whose first trials suggest they are highly effective
for preventing the infection.
As far as concerns immunity certificates, the topic of
their effectiveness is currently being debated [9]. Even if in
April 2020 WHO affirmed that there is not enough evidence
about the immunity generated by the COVID-19 infection,
some countries, like Estonia, developed a digital ‘‘immunity
passport’’ app [58] allowing users with antibodies to show
their reduced risk of spreading the virus. In early April 2020,
the health secretary of the United Kingdom introduced, for
the first time, the idea of Immunity Passport as a mean to
enable people to come back to work [59]. A strictly related
theme is that of public transport, as one of the main contexts
where the contagion may spread. Reference [60] proposes
to emit Antibody certificates to allow immune citizens to
travel on public transports, with the goal of returning to work.
Reference [60] investigates also another interesting use of
antibody certificates, that is to use them to reduce the risks
related to food/goods delivery services for aged/vulnerable
people. In this case, requiring an antibody certificate to the
good carrier may reduce the risk of infection for these people.
An initiative of the Greek Government [61] proposes Digital Health Passports [62] certifying risk-free individuals,
i.e. individuals not actively carrying the virus. The idea originates from the initiative which required a certification for
travelers entering Greece, attesting they have been tested to be
COVID-19 free at most 72 hours before their departure. This
initiative may be framed in the context of measures trying
to contain the spreading of the pandemic, while reducing its
negative impact on the economy, that, in Greece, is mainly
based on tourism.
In all the cases, an efficient structure enabling fast access
and a simple management of certifications is urgently
required to safely admit individuals in social activities and
travels.
In the next sections we first introduce the idea of Distributed Public Key Infrastructures and of Verifiable Credentials as two building blocks, based on blockchain technology,
for the definition of a certification system. We then present a
set of recent proposals targeted to the COVID-19 scenario.
A. DECENTRALIZED VERIFIABLE CREDENTIALS
The problem of defining a standard for digital certifications
and credential predates the COVID-19 outbreak. A verifiable
credential or verifiable claim is a piece of information that
a third party can validate digitally, in a secure and privacy
preserving way. Verifiable credentials support self-sovereign
identity, that means that the identity owners accumulate
credentials into an identity account and use the credentials
to prove some property to verifiers, revealing the minimal
amount of information necessary for the verification.
The ‘‘W3C Verifiable Claims Working Group’’ of the
WWW Consortium, presented, in November 2019, a standard called ‘‘Verifiable Credentials Data Model’’ [63].
They define a standard document format for certification,
and, more important, propose a new distributed architecture
for Public Key Infrastructures, responsible for the authentication and the distribution of public keys, which may greatly
benefit from blockchain technology. The idea is to use the
blockchain as a register to store the correspondence between
the Decentralized Identifiers (DIDs) and their public key. The
control of a DID is managed through the DID’s private key.
So doing, the blockchain takes the role of the registers managed by the centralized Certification Authorities. Note that
DID may represent individuals, but also communities, states,
companies, connected objects, etc. The use of blockchain
may help to solve many of the problems of centralized PKI.
For instance identity retention, i.e. preventing a user from registering a public key under an identity which is already been
register, is not always ensured by current centralized PKIs,
while it may be guaranteed by the blockchain consensus
protocol [64]. Several blockchain-based platforms supporting
the verifiable credential data model are currently available,
like Sovrin [65], which is based on Hyperledger Indy and
uPort [66], which exploits Ethereum.
Several credentials may be assigned by different issuers to
the entities whose identity is registered on the blockchain.
For instance, the issuer of a COVID-19 certificate may be a
public health office, which distributes antibody credentials to
immune citizens. The citizen presents their credential to the
interested parties, i.e. public travel authorities, airport authorities and so on, which verify them. An example is shown
in Figure 7. Note that the certificates assigned to a user are not
necessarily stored on blockchain. To preserve user’s privacy,
the credentials may be stored in a personal wallet or in a
personal cloud storage or also, encrypted, in a distributed file
system like the InterPlanetary File System (IPFS) [29], [67].
The blockchain is used by the verifier to find out the public
key of the issuer which enables the verification of the claim,
through its signature. Furthermore, the issuer may store the
hash of the document on the blockchain, to enable the verifier
to check the integrity of the data.
B. BLOCKCHAIN-BASED PROPOSALS FOR COVID-19
CERTIFICATIONS
The idea of using verifiable credentials on a distributed
infrastructure for defining a immunity/vaccine certification
system is exploited by [68]. The verifiable credential is, in this
case, the claim that the individual has been vaccinated. When
a vaccination or a blood test for immunity is performed,
the issuer, which is, in this case, a representative of the
National Health Service, first authenticates the holder, then
provides a Verifiable Credential which is digitally signed
by both the issuer and the holder. The Verifiable Credential
is stored on a Consortium blockchain based on a Proof of
Authority consensus mechanism [69]. The holder can now
present a provably valid certificate to the verifier, which may
be the airport or school authority, and so on. This proposal
exploits the openEthereum platform, which is a Consortium
blockchain. The system exploits zero-knowledge proofs to
37944 VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
FIGURE 7. Distributed identifiers and verifible claims.
FIGURE 8. The architecture of the system presented in [70].
minimize the information which is sent to the verifiers. The
authors also present an app, which is used to generate DID
for the certificate issuer and holder.
Authors of [70] present a system which combines decentralized identities, smart contracts and IPFS as off-chain storage for documents, to manage COVID-19 certifications in
a decentralized way. The actors of the system, i.e. the Ministry of Foreign Affairs and of Public Health, the COVID-19
testing centers, and the citizens, use the system to manage
the digital health passports, which record information on
citizens’ travel history, immunization, vaccination records,
and so on. The Ministries of Foreign Affairs and of Health are
the entities authorized to give verifiable credentials to testing
centers and health authorities or to revoke them.
Each entity is associated with a smart contract on the
Ethereum blockchain. Furthermore, a smart contract is paired
with every citizen and includes only the hash of their certificate, while the certificate encrypted with their public key is
stored in IPFS. Since the citizen will have to provide proof of
vaccination by showing the certificate to different authorities,
they delegate the Proxy, which in this case is the IPFS node,
through a proxy re-encription scheme scheme. As discussed
in Sect.II, proxy re-encryption is a type of public-key encryption which enables to transform a text encrypted with a given
public key to a text encrypted with another public key, without
requiring the knowledge of the hidden plain text. This mechanism, integrated with a blockchain supporting a decentralized
key management infrastructure, enables users to encrypt and
store their private documents on IPFS and to grant access to
authorized users, without the need of new encryption of the
data for each new authorization.
Figure 8 shows the operation flow of the system which
exploits both symmetric and public key cryptography. Alice
recives a certification, encrypts the document with her symmetric key and stores the result in IPFS (1). Furthermore,
she sends the symmetric key encrypted with her public key
to the proxy (the IPFS node) (2). Suppose Bob is a border
control authority which checks Alice’s certification to admit
her in the country. Bob sends a request to Alice (3), which
retrieves Bob’s public key from his DID, which is stored
on a blockchain (for instance Sovrin exploits a blockchain
to store DIDs). Then, Alice computes the re-encryption key
VOLUME 9, 2021 37945L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
(from her private key and Bob’s public key) and sends it to the
proxy (4), which uses this key to re-encrypt the symmetric key
previously ciphered by Alice, without accessing the secret
key (5). Finally, the re-encrypted key is used by Bob to
decrypt Alice’s symmetric key which enables him to accesses
IPFS and retrieve and decode the document (6) and check its
integrity through the blockchain.
Authors of [71] propose an online ‘‘COVID-19 Passport’’
reporting the vaccination status of a citizen. A special feature of this work is that each user is uniquely identified by
considering information that the ‘‘user knows’’ (like gender
and Date of Birth) and biometric information that the ‘‘user
possesses’’ (like users’s iris scans). When a user presents
themselves to the health organization, a unique blockchain
identifier is generated by considering both information and a
record with the vaccination history is stored or updated on the
blockchain. Using the biometric information is a good idea,
but requires to address the problem that different scans of
the same individual may be slightly different. For this reason,
techniques like SHA-256 or SHA-3 cannot be used, because,
due the properties of the chryptographic hash functions, even
a small difference in the input data of the function returns a
completely different hash value. Reference [71] suggests to
address this problem by using a Locality Sensing Hashing,
LSH, technique [72], able to generate similar hash for similar
input data, i.e. putting all the similar biometric scans in the
same bucket which may be paired with a single user.
Reference [73] proposes to use a blockchain managed
by government to store COVID-19 antibody certifications.
The blockchain provides quick and trusted access by several
actors, and facilitates the exchange of cross-border information. Authors solicit the use of IoT devices (laboratory and
hospital devices) enabled to access directly the blockchain,
without human intervention, so to further increase the level of
trust in the platform. A token is issued to the account of people
who have verified positive to antibodies characterized by an
expiry date according to the expected age of antibodies. The
system used biometric authentication, to enhance anonymity
and privacy.
Finally, the DHP framework [62], proposes a private
blockchain, where the Digital Health Passports (DHP) of
citizens are registered and can be exploited for international
tourism. The digital passport contains the result of a antibody
tests, the timestamp specifying when the test is performed,
the testing method. Unfortunately, the authors do not describe
the cryptographic primitives used to link the DHP to the
tested users. The blockchain is accessed by the Health Service
Authorities of different countries, having full rights on the
blockchain and by other authorized members which can only
read data registered on it. The consensus algorithm is Proof of
Authority.
V. BLOCKCHAIN FOR COVID-19 BEYOND CONTACT
TRACING AND VACCINE CERTIFICATION
In this section we briefly introduce some further blockchainbased applications for mitigating COVID-19 consequences.
Some interesting proposals [74], [75] combine machine
learning and blockchain to define a federated or swarm learning approach. Reference [74] proposes a blockchain based
federated learning framework to train and share a collaborative model. The objective of the proposed architecture is to
train a global model by using locally trained models. Actual
patients’ data are stored by the hospital and the blockchain
helps to retrieve the trained models. Reference [75] exploits
a private permissioned blockchain to coordinate the nodes
of a Swarm Learning system. New nodes obtain the model,
and perform local model training until defined conditions
for synchronization are met. Then nodes exchange model
parameters and a leader is dynamically elected, to perform
the merge of the model parameters.
An interesting application to support social distancing is
presented in [76]. The idea is to help health authorities to
promote social distancing by controlling the number of individuals in specific areas. The blockchain is run by different government authorities. Citizens create a wallet where
they receive ‘‘movement passes’’ or time-based tokens which
can be spent and expire after a period of time. This way,
the authorities can restrict the total number of tokens released
in a certain period of the day for a certain area to limit the
number of people in that area.
Finally, it is worth noticing that several blockchain-based
applications for healthcare had already been proposed before
COVID-19, and are currently very useful to face different
aspects of the pandemics. [77] presents the main applications of blockchain in the healthcare area. One of the most
important is the sharing of health records between different
institutions, which is particularly complex, because of the
presence of sensitive data. An example is MedRec [72],
a permissioned blockchain for storing electronic healthcare
records. Furthermore, blockchain can also assist the monitoring of patients through sensors and other IoT devices, by
making the process more reliable. Finally, blockchain can be
used to monitor the medical supply chain, in particular the
distribution of vaccines.
VI. DISCUSSION AND CHALLENGES
In this section we first discuss some general issues of
blockchain technology, then we present some considerations
more strictly related to the use of this technology in the
COVID-19 pandemic.
Even if blockchain is a promising technology, some issues
are not yet completely resolved and deserve further research.
The main one is related to the throughput of blockchain
platforms, which may be too low for some applications and
depends on the number of nodes participating to the protocol
and number of transactions generated by them. A strictly
related problem is that of transactions acceptance latency,
dependent on the time needed to validate a block. To mitigate these problems, new consensus algorithms have been
developed and are currently object of research. In particular,
permissioned blockchains are characterized by a higher level
of efficiency, since the number of participating nodes may be
37946 VOLUME 9, 2021L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
controlled and more efficient consensus algorithms may be
adopted.
Another challenge is related to the trade-off between data
auditability and privacy. All data published on the blockchain
are public, so particular attention to sensitive data should
be paid to fulfill privacy laws and regulations like the General Data Protection Regulation (GDPR). As shown in the
previous sections, promising cryptographic techniques, like
zero-knowledge proofs, can be exploited to retain the advantages of a blockchain, while ensuring the privacy of sensitive
data.
As far as concerns the use of blockchains-based contact
tracing solutions, some solutions presented in Sect. III present
serious privacy threats. An example is that of the already
discussed Paparazzi attack, which can be simply delivered
exploiting silent tracing devices. If the attacker uses active
devices (behaving as regular smartphones) more complex
massive surveillance attacks can be performed. Therefore,
the use of a blockchain is not, in itself, a panacea for contact
tracing solutions. However, the use of a blockchain as a
bulletin board where the pseudonyms of infected users are
published, makes the entire process transparent and reliable
and avoids attacks based on the collusion between the attacker
and a centralized server. Using advanced cryptographic techniques, like Diffie Hellman or zero-knowledge proofs, combined with blockchain may guarantee stronger resistance to
attacks and, at the same time, transparency.
Several location-based solutions exploit the Proofof-Location mechanism which certifies the presence of a
user at a location, at a certain time, where the witnesses are
WIFI access points or other devices. However, a rewarding
mechanism should be used to make this solution really
feasible, since it is unrealistic that these devices would
voluntary accept to use part of their resources, such as
bandwidth, to implement PoL mechanisms. Furthermore,
incentive strategies would help mitigating DoS attacks on
such devices.
As for immunity certificates, even if they may favour the
return to normal life for many citizens, [78], [79] observe that
they may also raise several practical and legal challenges,
because they give the privilege of working and participating to other social-related activities only to a the subset
of certificated citizens. Close attention has to be paid also
to the management of vaccine certifications, as they create
disparities in the population. It is likely the certifications will
be administered by government offices, and this may give
rise to corrupt practices and bias towards a subset of citizens.
Furthermore, dedicated legal regulations and protection are
not yet available, so citizens cannot rely on legal certainty
as a guarantee of their rights. The success of immunity and
vaccine certifications will be largely dependent on the trust
in the public authority, which, in many countries, can not
be taken for granted. The use of blockchain technology,
which provides trust in a trustless environment by design, can
contribute to a wider popular acceptance of the use of these
certifications.
VII. RELATED WORKS
Even if the COVID-19 outbreak dates back just a year ago,
the interest for technological solutions supporting the management of the pandemic has been very high. Some review
articles [7], [12]–[16] have already presented several applications of blockchains for COVID-19.
Authors of [7] present an interesting statistical analysis
of the main use cases of blockchain technology to mitigate
COVID-19 challenges. The study is based on a search of scientific publications in the main bibliographic databases, looking for search terms related to the target technology. Nineteen
eligible proposals are detected. Authors show that the most
prominent use cases are contact tracing and immune/vaccine
passports. Several interesting statistics are reported in this
article, e.g. most applications use smart contracts on the
Ethereum platform, and smart contracts are mainly developed
in Solidity, and the second most used platform is Hyperledger.
A part from the interesting statistics, this article neither
describes the proposals in-depth nor shows any technical
details. All the contact tracing and immunity passports proposals referred in [7] are investigated in depth in our survey.
The survey [12] reports a wide analysis of the main potential use cases pertinent to COVID-19. The work presents an
high level description of the use cases, neither delving deep
into the technological details nor presenting the technological
challenges that these use cases present.
Reference [13] first introduces the general context of the
COVID-19 outbreak, the main impacts of the pandemics on
the global economy, and the clinical tests for COVID-19
detection. The last part of this article is devoted to the emerging technologies which may bring benefit to the management
of the pandemics, i.e. IoT, drone technology, robots and
autonomous vehicles, wearables, and blockchain. As such,
only a small section of this article is dedicated to blockchain.
Also the survey [14] is an high level roundup of the main
applications of blockchain technology for the COVID-19
pandemic, like disease control, traceability, supply chain of
medical parts, and healthcare management. The technological side of these solutions is not investigated in this article.
References [15], [16] present comprehensive surveys of
contact tracing applications for COVID-19 with particular focus on their privacy and security implications. However, [15] presents a single reference to a blockchain-based
contact tracing application, i.e. PRONTO-C2, while [16]
evaluates the current solutions on the basis of five parameters, i.e. centralization, proximity/GPS, privacy, adversarial
model, and scalability, but this article does not consider the
blockchain-based solutions.
VIII. CONCLUSION
This article has presented an in-depth analysis of the recent
blockchain-based solutions for COVID-19 contact tracing
and for the management of immune/vaccine certifications.
Contact tracing approaches have been classified according
to the communication infrastructure they exploit: proximity based solution use mainly BLE, location-based solution
VOLUME 9, 2021 37947L. Ricci et al.: Blockchains for COVID-19 Contact Tracing and Vaccine Support
may rely on GPS or Wifi, and some proposals also leverage
the cellular network. We have shown how some proposals
present serious security and privacy concerns. These issues
can be overcome by using more advanced cryptographic
techniques, like Diffie Hellman or zero-knowledge protocols.
This article has also described blockchain-based solutions for
immune/vaccine certifications, showing that a proper integration of self-sovereign identity systems with blockchain
technology might enable to define privacy-aware and secure
solutions.




NEW_PAPER


1810 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 5, MAY 2021
Convolutional Sparse Support Estimator-Based
COVID-19 Recognition From X-Ray Images
Mehmet Yamaç , Mete Ahishali , Aysen Degerli , Serkan Kiranyaz , Senior Member, IEEE,
Muhammad E. H. Chowdhury , Senior Member, IEEE, and Moncef Gabbouj , Fellow, IEEE
Abstract— Coronavirus disease (COVID-19) has been the main
agenda of the whole world ever since it came into sight. X-ray
imaging is a common and easily accessible tool that has great
potential for COVID-19 diagnosis and prognosis. Deep learning
techniques can generally provide state-of-the-art performance
in many classification tasks when trained properly over large
data sets. However, data scarcity can be a crucial obstacle when
using them for COVID-19 detection. Alternative approaches such
as representation-based classification [collaborative or sparse
representation (SR)] might provide satisfactory performance with
limited size data sets, but they generally fall short in performance or speed compared to the neural network (NN)-based
methods. To address this deficiency, convolution support estimation network (CSEN) has recently been proposed as a bridge
between representation-based and NN approaches by providing
a noniterative real-time mapping from query sample to ideally
SR coefficient support, which is critical information for class
decision in representation-based techniques. The main premises
of this study can be summarized as follows: 1) A benchmark
X-ray data set, namely QaTa-Cov19, containing over 6200 X-ray
images is created. The data set covering 462 X-ray images from
COVID-19 patients along with three other classes; bacterial
pneumonia, viral pneumonia, and normal. 2) The proposed
CSEN-based classification scheme equipped with feature extraction from state-of-the-art deep NN solution for X-ray images,
CheXNet, achieves over 98% sensitivity and over 95% specificity
for COVID-19 recognition directly from raw X-ray images
when the average performance of 5-fold cross validation over
QaTa-Cov19 data set is calculated. 3) Having such an elegant
COVID-19 assistive diagnosis performance, this study further
provides evidence that COVID-19 induces a unique pattern in
X-rays that can be discriminated with high accuracy.
Index Terms— Coronavirus disease (COVID-19) recognition,
representation-based classification, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) virus, transfer learning.
I. INTRODUCTION
CORONAVIRUS disease 2019 (COVID-19) has been
declared as a pandemic by the World Health Organization (WHO) a few months after its first appearance. It has
infected more than 70 million people, caused a few million
causalities, and has so far paralyzed mobility all around the
Manuscript received May 7, 2020; revised October 9, 2020 and
December 21, 2020; accepted March 23, 2021. Date of publication April 19,
2021; date of current version May 3, 2021. (Corresponding author:
Mehmet Yamaç.)
Mehmet Yamaç, Mete Ahishali, Aysen Degerli, and Moncef Gabbouj
are with the Faculty of Information Technology and Communication Sciences, Tampere University, 33720 Tampere, Finland (e-mail:
mehmet.yamac@tuni.fi).
Serkan Kiranyaz and Muhammad E. H. Chowdhury are with the Department
of Electrical Engineering, Qatar University, Doha 2713, Qatar.
Color versions of one or more figures in this article are available at
https://doi.org/10.1109/TNNLS.2021.3070467.
Digital Object Identifier 10.1109/TNNLS.2021.3070467
world. The spreading rate of COVID-19 is so high that the
number of cases is expected to be doubled every three days
if the social distancing is not strictly observed to slow this
accretion [1]. Roughly around half of the COVID-19 positive
patients also exhibit a comorbidity [2], making it difficult
to differentiate COVID-19 from other lung diseases. Automated and accurate COVID-19 diagnosis is critical for both
saving lives and preventing its rapid spread in the community. Currently, reverse transcription-polymerase chain reaction
(RT-PCR) and computed tomography (CT) are the common
diagnostic techniques used today. RT-PCR results are ready at
the earliest 24 h for critical cases and generally take several
days to conclude a decision [3]. CT may be an alternative
at initial presentation; however, it is expensive and not easily
accessible [4]. The most common tool that medical experts use
for both diagnostic and monitoring the course of the disease
is X-ray imaging. Compared to RT-PCR or CT test, having
an X-ray image is an extremely low cost and a fast process,
usually taking only a few seconds. Recently, WHO reported
that even RT-PCR may give false results in COVID-19 cases
due to several reasons such as poor quality specimen from the
patient, inappropriate processing of the specimen, taking the
specimen at an early or late stage of the disease [5]. For this
reason, X-ray imaging has a great potential to be an alternative
technological tool to be used along with the other tests for an
accurate diagnosis.
In this study, we aim to differentiate X-ray images of
COVID-19 patients among other classes; bacterial pneumonia,
viral pneumonia, and normal. For this work, a benchmark
COVID-19 X-ray data set, Qata-Cov19 (Qatar University
and Tampere University COVID-19 Data set) that contains
462 X-ray images from COVID-19 patients was collected. The
images in the data set are different in quality, resolution, and
SNR levels as shown in Fig. 1. QaTa-Cov19 also contains
many X-ray images from the COVID-19 patients who are in
the early stages; therefore, their X-ray images show mild or nosign of COVID-19 infestation by the naked eye.1 Some sample
images are shown in Fig. 2(b). Another fact that makes the
diagnosis far more challenging is that interclass similarity can
be very high for many X-ray images as some samples are
shown in Fig. 2(a). Against such high interclass similarities
and intraclass variations, in this study, we aim for a high
robustness level.
In numerous classification tasks, deep learning techniques
have been shown to achieve state-of-the-art performance in
1The statements belong to the medical doctors whose names are listed in
the Acknowledgment section.
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/YAMAÇ et al.: CONVOLUTIONAL SPARSE SUPPORT ESTIMATOR-BASED COVID-19 RECOGNITION 1811
Fig. 1. Sample COVID-19 X-ray images from QaTa-Cov19.
terms of both recognition accuracy and their parallelizable
computing structures which play an important role, especially
in real-time applications. Despite their advantages, in order to
achieve the desired performance level in a deep model, proper
training over a massive training data set is usually needed.
Nevertheless, this is unfortunately unfeasible for this problem
since the available data is still rather limited.
An alternative supervised approach, which requires a limited
number of training samples to achieve satisfactory classification accuracy is representation-based classification [6]–[8].
In representation-based classification systems, a dictionary,
the columns of which consist of the training samples that are
stacked in such a way that a subset of them corresponding
to a class, is predefined. A test sample is expected to be a
linear combination of all points from the same class as the test
sample. Therefore, given a predefined dictionary matrix, D and
a test sample y, we expect the solution xˆ from y = Dx, carry
enough information about the class of y. Overall, in this study,
we draw a convolutional support estimation network (CSEN)
[9]-based solution pipeline, which fuses the representationbased classification scheme into a neural network (NN) body.
The rest of this article is organized as follows. In Section II,
notations and mathematical preliminaries are given with
emphasis on sparse representation (SR) and sparse support
estimation (SE). Then in Section III, a literature review on
deep learning models over X-ray images and representationbased classification is presented. The proposed CSEN-based
COVID-19 recognition system is introduced in Section IV
along with two recent alternative approaches that are used as
the competing methods. The data collection is also explained
in this section. Experimental setup and the main results are
provided in Section V. Finally, Section VII concludes this
article and suggests topics for future research.
II. PRELIMINARIES AND MATHEMATICAL NOTATIONS
A. Notations
In this study, the p-norm of a vector x ∈ Rn is defined
as xn
p = n
i=1|xi|
p1/p for p ≥ 1. On the other hand,
Fig. 2. Sample QaTa-Cov19 X-ray images. (a) X-ray images from different
classes. (b) X-ray images from the COVID-19 patients who are in the different
stages.
the 0-norm of the vector x ∈ Rn is defined as xn
0 =
limp→0
n
i=1|xi|
p = #{j : x j =0} and the ∞-norm is defined
as xn
∞ = maxi=1,...,n(|xi|). A signal s is called strictly
k-sparse if x0 ≤ k. Sparse support set or simply support
set,  ⊂ {1, 2, 3,..., n} of sparse signal x can be defined as
the set of nonzero coefficients’ location, i.e.,  := {i : xi = 0}.
B. Sparse Signal Representation
SR of a signal s ∈ Rd in a predefined set of waveforms,
 ∈ Rd×n, can be defined as representing s as a linear
combination of only a small subset of atoms in the dictionary
, i.e., s = x. Defining these sets, which dates back to
Fourier’s pioneering work [10], has been excessively studied in
the literature. In the early approaches, these sets of waveforms
have been selected as a collection of linearly independent and
generally orthogonal waveforms (which are called a complete
dictionary or basis, i.e., d = n) such as Fourier transform,
DCT, and wavelet transform, until the pioneering work of
Mallat [11] on overcomplete dictionaries (n 
 d). In the
last decade, interest in SR research increased tremendously.
Their wide range of applications includes denoising [12],
classification [13], anomaly detection [14], [15], deep learning
[16], and compressive sensing (CS) [17], [18].
With a possible dimensional reduction that can be satisfied
via a compression matrix A ∈ Rm×d (m  d), sample can be
obtained from s
y = As = Ax = Dx (1)
where D ∈ Rm×n can be called the equivalent dictionary.
Because (1) describes an underdetermined system of linear equations, finding the representation coefficient vector x
requires at least one more constraint to have a unique solution.
Using the prior information about sparsity, the following1812 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 5, MAY 2021
representation:
minx x0 s.t. Dx = y (2)
which is also an SR of x has a unique solution provided that x
is strictly sparse and D satisfies some required properties [19].
For instance, if x0 = k, the minimum number of linearly
independent columns of D, spark(D), should be greater than
2k, i.e., spark(D) ≥ 2k in order to not to have Dx = Dx for
distinct k-sparse signals, x and x [19]. However, the optimization problem in (2) is a NP-hard. Fortunately, the following relaxation:
minx x1 s.t. Dx = y (3)
produces exactly the same solution as that of (2) provided that
D obeys some criteria: the equivalence of 0–1 minimization
problems can be guaranteed when D satisfies a notation
of null space property (NSP) [20], [21] not only for exact
sparse signals but approximately sparse signals. Furthermore,
the query sample y can be corrupted with an additive noise
pattern. In this case, the equality constraint in (3) can be
further relaxed such as in the basis pursuit denoising (BPDN)
[22]: minxx s.t. y − Dx ≤ , where  is a small constant
that depends on the noise level. In this case, a stronger property
which is known as restricted isometry property (RIP) [23],
[24] is frequently used which both cover conditions satisfying
exact recovery of BP and stable recovery of BPDN, e.g.,
exact recovery of x from (3) is possible when D has RIP
and m > k(log(n/k)).
We may refer to the sparse SE problem as finding the
indices a set, , of nonzero elements of x [25], [26]. Indeed,
in many applications, SE can be more important than finding
the magnitude and sign of x as well as , which refers to the
sparse signal recovery (SSR) via a recovery technique, such
as (3). For example, in a sparse representation-based classification (SRC) system, a query sample y can be represented
with sparse coefficient vector, x, in the dictionary, D in such
a way that when we recover this representation coefficient
from y = Dx, the solution vector xˆ is expected to have a
significant number of nonzero coefficients coming from the
particular locations corresponding to the class of y.
Readers are referred to [9] for a more detailed literature
review on SE and its applications. In the sequel, we briefly
summarize the building blocks of the proposed approach.
III. BACKGROUND AND PRIOR ART
A. CheXNet
In the proposed approach, we first use the pretrained deep
network, CheXNet, to extract discriminative features from
raw X-ray images. CheXNet was developed for pneumonia
detection from the chest X-ray images [27]. In [27], it was
claimed that CheXNet can perform even better than expert
radiologists in the pneumonia detection problem. This deep
NN design is based on the previously proposed DenseNet [28]
that consists of 121 layers. It is first pretrained over ImageNet
data set [29] and performed transfer learning over 112120
frontal-view chest X-ray images in the ChestX-ray14 data
set [30].
B. Representation-Based Classification
Consider we are given a test sample y, which represents
either the extracted features, s, or their dimensionally reduced
version, i.e., y = As. In developing the dictionary, training
samples are stacked in the dictionary D with particular locations in such a way that the optimal support for a given query
y should be the set of all points coming from the same class
as y. Therefore, a solution vector, xˆ of y = Dx is supposed to
have enough information, i.e., the sparse support should be the
set of location indices of the training sample from the same
class as y. This strategy is generally known as representationbased classification. However, a typical solution xˆ of y = Dx
is not necessarily a sparse one especially when its size
grows with more training samples, which results in a highly
underdetermined system of linear equations. Fortunately, if one
estimates the representation coefficient vector with a sparse
recovery design such as 1-minimization as in (3), we can
expect that the important nonzero entries of the solution, xˆ,
are grouped in the particular locations that correspond to the
locations of the training samples from the same class as y. This
can be a typical example of scenarios where SE can be more
valuable than the magnitudes and sign recovery as explained
in Section II-B.
For instance, Wright et al. [8] proposed a systematic way of
determining the identity of face images using 1-minimization.
The authors develop a three-step classification technique that
includes: (i) normalization of all the atoms in D and y to have
unit 2-norm; (ii) estimating the representation coefficient vector via sparse recovery, i.e., xˆ = arg minxx1 s.t.y − Dx2;
and (iii) finding the residuals corresponding to each class via
ei = y − Dixˆi2, where xˆi is the group of the estimated
coefficients, xˆ, that correspond to class i.
This technique, which is known as SRC, and its variants
have been applied to a wide range of applications in the
literature [31], [32], e.g., human action recognition [33], and
hyperspectral image classification [34], to name a few. Despite
the good recognition accuracy performance of SRC systems,
their main drawbacks is the fact that their sparse recovery
algorithms (e.g., 1-minimization) are iterative methods and
computationally costly, rendering them infeasible in real-time
applications. Later, the authors of [6] introduced collaborative
representation-based classification (CRC), which is similar
to SRC except for the use of traditional 2-minimization in
the second step; xˆ = arg minx

y − Dx2
2 + λx2
2

. Thus,
CRC does not require an iterative solution to obtain representation coefficient thanks to that 2-minimization has a
closed form solution, xˆ = 
DTD + λIn×n
−1
DTy. Although,
the sparsity in xˆ cannot be guaranteed, it has often been
reported to achieve a comparable classification performance,
especially in small-size training data sets.
IV. PROPOSED APPROACH
For a computer-aided COVID-19 recognition system design,
our primary objective is to achieve the highest sensitivity
possible in the diagnosis of COVID-19 induced pneumonia
with an acceptable false-alarm rate (e.g., specificity > 95%).
In particular, the misdiagnosis of a COVID-19 X-ray imageYAMAÇ et al.: CONVOLUTIONAL SPARSE SUPPORT ESTIMATOR-BASED COVID-19 RECOGNITION 1813
Fig. 3. Proposed approach for Covid recognition from X-ray images. The proposed convolution support estimator network (CSEN) which can be trained from
a moderate size training set. The pipeline employs the pretrained deep NN for feature extraction. A is the dimensional reduction (PCA) matrix, the coarse
estimation of representation coefficient (sparse in ideal case), xˆ is obtained via the denoiser matrix, B = 
DT D + λI
−1
DT , where D = A and  is the
predefined dictionary matrix of training samples (before dimensional reduction).
as a normal case should be minimized whilst a small number
of false negatives (FNs) is tolerable.
Our interest in representation-based classification is that
they perform well in classification tasks even in the cases
where training data is scarce. As mentioned, the two wellknown representation-based classification methodologies are
SRC [7] and CRC [6]. Among them, SRC provides slightly
improved accuracy by solving an SR problem, i.e., producing
a sparse solution xˆ from y = Dx. Then, the location of
the nonzero elements of xˆ, which is also known as support
set, provides the class information of the query y. Despite
improved recognition accuracy, SRC solutions are iterative
solutions and can be computationally demanding compared to
CRC. In a recent work [9], a compact NN design that can be
considered as a bridge between NN-based and representationbased methodologies was proposed. The so-called CSEN uses
a predefined dictionary and learns a direct mapping using
moderate/low size training set, which maps query samples,
y, directly to the support set of representation coefficients, x
(as it should be purely sparse in the ideal case).
In this study, to address the data scarcity limitations
in COVID-19 diagnosis from X-ray images we propose
a CSEN-based approach. Since a relatively larger set of
COVID-19 X-ray images ever compiled is used in this study,
the proposed approach can be evaluated rigorously against
a high level of diversity to obtain a reliable analysis. The
general pipeline of the proposed CSEN-based recognition
scheme is illustrated in Fig. 3. In order to obtain highly
discriminative features, we use the recently proposed CheXNet
[27], which is the fine-tuned version of 121 layer Dense
Convolutional Network (DenseNet-121) [28] by using over
100 000 frontal view X-ray images form 14 classes. Having
the pretrained CheXNet for feature extraction, we develop
two different strategies to obtain the classes of query X-ray
images: 1) using CRC with proper preprocessing; 2) a slightly
modified version of our recently proposed convolution support
estimator (CSEN) models. In the sequel, both techniques will
be explained in detail as well as alternative solutions.
A. Benchmark Data Set: QaTa-Cov19
Accordingly, there are several recent works [35]–[38] that
have been proposed for COVID-19 detection/classification
from X-ray images. However, they use a rather small data set
(the largest containing only a few hundreds of X-ray images),
with only a few COVID-19 samples. This makes it difficult to
generalize their results in practice. To address this deficiency
and provide reliable results, in this study the researchers of
Qatar University and Tampere University have compiled a
bechmark Covid-19 data set, called QaTa-Cov19. Compared
to the earlier benchmark data set created in this domain, such
as COVID Chestxray Data set [39] or COVID-19 DATA SET
[40], QaTa-Cov19 has the following unique benchmarking
properties. First, it is a larger data set, not only in terms
of the number of images (more than 6200 images) but its
versatility, i.e., QaTa-Cov19 contains additional major pneumonia categories, such as viral and bacterial, along with the
control (normal) class. Moreover, this is a diverse data set
encapsulating X-ray images from several countries (e.g., Italy,
Spain, China, etc.) produced by different X-ray machines.
COVID-19 chest X-ray images were gathered from
different publicly available but scattered image sources.
However, the major sources of COVID-19 images are
Italian Society of Medical and Interventional Radiology (SIRM) COVID-19 Database [40], Radiopaedia [41],
Chest Imaging (Spain) at thread reader [42] and online articles
and news portals [43]. The authors have carried out the task
of collecting and indexing the X-ray images for COVID19 positive cases reported in the published and preprint articles
from China, South Korea, USA, Taiwan, Spain, and Italy,
as well as online news-portals (up to 20th April 2020).
Therefore, these X-ray images represent different age groups,
gender, ethnicity, and country. Negative Covid19 cases were
normal, viral, and bacterial pneumonia chest X-ray images and
collected from the Kaggle chest X-ray database. Kaggle chest
X-ray database contains 5863 chest X-ray images of normal,
viral, and bacterial pneumonia with varying resolutions [44].
Out of these 5863 chest X-ray images, 1583 images are normal
images and the remaining are bacterial and viral pneumonia
images. Sample X-ray images from QaTa-Cov19 data set are
shown in Fig. 4.
B. Feature Extraction
With their outstanding performance in image classification along with other inference tasks, deep NNs became
a dominant paradigm. However, these techniques usually
necessitate a large number of training samples (e.g., several1814 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 5, MAY 2021
Fig. 4. Samples from the benchmark QU-Chest data set.
hundred-thousand to millions depending on the network
size) to achieve an adequate generalization capability. Albeit,
we can still leverage their power by finding properly pretrained
models for similar problems. To this end, we use a state-ofthe-art pneumonia detection network, CheXNet, whose details
are summarized in Section III-A. With the pretrained model,
we extract 1024-long vectors, right after the last average
pooling layer. After data normalization (zero mean and unit
variance), we obtain a feature vector s ∈ Rd=1024.
A dimensionality reduction PCA is applied to s in order to
get the query sample, y = As ∈ Rm, where A ∈ Rm×d is PCA
matrix (m < d).
C. Proposed CSEN-Based Classification
Considering the limited number of training data in our
COVID-19 data set, a representation-based classification can
be applied hereafter to obtain the class of y using the dictionary  (in the form of D = A), whose columns are stacked
training samples with class-specific locations.
As discussed earlier, SRC is an SE problem which is
expected to be an easier task than an SSR problem. On the
other hand, even if the exact signal recovery is not possible in noisy cases or in cases where xˆ is not exactly but
approximately sparse (which is the case almost all the time in
dictionary-based classification problems), it is still possible to
recover the support set exactly [25], [38], [45], [46] or partially
[46]–[48]. However, many works in the literature dealing with
SE problems tend to first apply a sparse recovery technique
on y to first get xˆ, then use simple thresholding over xˆ to
obtain a sparse SE, ˆ . However, SSR techniques such as
1-minimization are rather slow and their performance varies
from one SRR tool to another [9]. In our previous work [9],
we proposed an alternative solution for this iterative sparse
recovery approach which aims to learn a direct mapping from
a test sample y to the corresponding support set ˆ . Along with
Fig. 5. Illustration of proposed dictionary design versus conventional design
in representation-based classifiers.
the speed and stability compared to conventional SSR-based
techniques and recent deep learning-based SSR solutions,
CSEN has the crucial advantage of having a compact design
that can achieve a good performance level even over scarce
training data.
Mathematically speaking, an ideal CSEN is supposed to
yield a binary mask v ∈ {0, 1}
n
vi =1 if i ∈  (4)
which indicates the true support, i.e.,  =
{i ∈ {1, 2,..., n} : vi = 1}. In order to approximate this
ideal case, a CSEN network, P(y, D) produces a probability
vector p which returns a measure about the probability of
each index being in  such that pi ∈ [0, 1]. Having the
estimated probability map, estimating the support can easily
be done via ˆ = {i ∈ {1, 2,..., n} : pi > τ }, by thresholding
p with τ where τ is a fixed threshold.
A CSEN is composed of fully convolutional layers, and as
input it takes a proxy, x˜, of sparse coefficient vector, which
is a coarse estimation of x, i.e., 
DT D + λI
−1
DT y or simply
x˜ = DT y. Then, it yields the aforementioned probability like
vector p via fully convolutional layers. Using such a proxy of
x, instead of making inference directly on y has also studied
in a few more recent studies. For instance, in [49] and [50],
the authors proposed reconstruction-free image classification
from compressively sensed images. Alternatively, one may
design a network to learn proxy x˜ by fully connected dense
layers [49]. However, it increases the computational complexity and may result in an even over-fitting problem with scarce
training data [9].
The input vector x˜ is reshaped to have a 2-D plane representation in order to use it with 2-D convolutional layers.
This transformation is performed via reordering the indices
of the atoms in such a way that the nonzero elements of the
representation vector x for a specific class come together in
the 2-D plane. A representative illustration of the proposed
dictionary design compared to the traditional one is shown
in Fig. 5.
Hereafter, the proxy x˜ is convolved with the weight kernels,
connecting the input with the next layer with Nl filters to yield
the inputs of the next layer, with the biases b1 as follows:
f1 = 
S1

ReLu
bi
1 + wi
1 ∗ x˜
N1
i=1 (5)YAMAÇ et al.: CONVOLUTIONAL SPARSE SUPPORT ESTIMATOR-BASED COVID-19 RECOGNITION 1815
Fig. 6. Baseline Approach I: CRC is fed by deep learning-based extracted features that are preprocessed.
Fig. 7. Baseline Approach II: A 5-layer MLP layer is used over the features of CheXNet.
where b1 is the weight bias, S1(.) is either identity or subsampling operator predefined according to network structure
and ReLu(x) = max(0, x). For other layers, i.e., l > 2, the kth
feature map of layer l is defined as
f
k
l = Sl

ReLu
bk
l +
Nl−1
i
wik
l ∗ f
i
l−1
		 (6)
where Sl(.) is either identity operator or one the operations
from down- and up-sampling and Nl is the number of feature
maps in lth layer. Therefore, the trainable parameters of CSEN
will be: CSEN = 
{wi
1, bi
1}
N1
i=1,{wi
2, bi
2}
N2
i=1,...,{wi
L , bi
L}
NL
i=1

for an L layer CSEN design.
In developing the dictionary that is to be used in the
SRC, the training samples are stacked-in by grouping them
according to their classes. Thus, instead of using traditional 1-minimization formulation as in (3), the following
group 1-minimization formulation may result in increased
classification accuracy:
minx


Dx − y2
2 + λ
c
i=1
xGi2

(7)
where xGi is the group of coefficients from the ith class. In this
manner, one possible cost function for a SE network would
be
E(x) = 
p
(P(x˜)p − v p)
2 + λ
c
i=1
P(x˜)Gi2 (8)
where P(x˜)p is network output at location p and v p is the
ground truth binary mask of the sparse code x. Due to its high
computational complexity, we approximate the cost function
in (8) with a simpler average pooling layer after convolutional
layer, which can produce directly the estimated class in
our CSEN design. An illustration of proposed CSEN-based
COVID-19 recognition is shown in Fig. 3.
D. Competing Methods
This section summarizes the competing methods that are
selected among numerous alternatives due to their superior
performance levels obtained in similar problems. For fair
comparative evaluations, all classification methods have the
same input feature vectors fed to the proposed CSENs.
1) Collaborative Representation-Based Classification: As a
possible competing technique to the proposed CSEN-based
technique which is a hybrid method, CRC [6] is a direct and
representation-based classification method that can be applied
to this problem as shown in Fig. 6. It is a noniterative SE
technique, that satisfies faster and comparable classification
performance with SRC while it is more stable compared
to existing iterative sparse recovery tools as it is shown
in [9]. In the first step of CRC, the tradeoff parameter of
the regularized least-square solution is set as λ = 2 ∗ 10−12.
In order to obtain the best possible λ, a grid search was made
in the range [10−15, 10−1] with a log scale.
2) Multilayer Perceptron (MLP) Classification: The proposed COVID-19 recognition pipeline can be modified by
replacing CSEN or CRC part with another classifier. As one
of the most-common classifiers, a 4-hidden layer multilayer
perceptron (MLP) is used for this problem as shown in Fig. 7.
For training, we used back-propagation (BP) with Adam
optimization technique [51]. The network and training hyperparameters are as follows: learning rate, α = 10−4, and
moment updates β1 = 0.9, β2 = 0.999, and 50 as the number
of epochs. Fig. 8 illustrates the network configuration in detail.
This network configuration has achieved the best performance
among others (deeper and shallower) where deep configurations have suffered from over-fitting while the shallow ones
exhibit an inferior learning performance.
3) Support Vector Machines (SVMs): For a multiclass
problem, the first objective is to select the SVM topology for
ensemble learning: one-versus-one or one-versus-all. In order
to find the optimal topology and the hyperparameters (e.g., kernel type and its parameters) we first performed a grid-search
with the following variations and setting: kernel function1816 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 5, MAY 2021
Fig. 8. MLP configuration.
TABLE I
CLASSIFICATION PERFORMANCES OF THE PROPOSED CSEN AND
COMPETING METHODS. THE BEST COVID-19 RECOGNITION
RATES ARE HIGHLIGHTED
{linear, radial basis function (RBF)}, box constraint
(C parameter) in the range [1, 103] with a log scale, and
kernel scale (γ for the RBF kernel) in the range [10−4, 10−2]
with a log scale.
4) k-Nearest-Neighbor (k-NN): Finally, we use a traditional
approach, k-nearest neighbor (k-NN) is used with PCA dimensionality reduction. In a similar fashion, the distance metric
and the k-value are optimized by a prior grid-search. The
following distance metrics are evaluated: City-block, Chebyshev, correlation, cosine, Euclidean, Hamming, Jaccard, Mahalanobis, Minkowski, standardized Euclidean, and Spearman
metrics. The k-value is varied within the range of [1, 4416]
with a log scale.
V. EXPERIMENTAL RESULTS
A. Experimental Setup
We have performed our experiments over the
QaTa-Cov19 data set, which consists of normal and
three pneumonia classes: bacterial, viral, and COVID-19.
TABLE II
NUMBER OF IMAGES PER CLASS AND PER-FOLD BEFORE AND
AFTER DATA AUGMENTATION
The proposed approach is evaluated using a stratified fivefold
cross-validation (CV) scheme with a ratio of 80% for training
and 20% for the test (unseen folds) splits, respectively.
Table II shows the number of X-ray images per class in the
QaTa-Cov19 data set. Since the data set is unbalanced, we have
applied data augmentation to the training set in order to balance the size of each class in the train set. Therefore, the X-ray
images in viral and COVID-19 pneumonia and normal classes
are augmented up to the same number as the bacterial pneumonia class in the train set. We use Image Data Generator by
Keras to perform data augmentation by randomly rotating the
X-ray images in a range of 10◦, randomly shifting images both
horizontally and vertically within the interval of [−0.1, +0.1].
In each CV fold, we use a total of 8832 and 1257 images in
the train and test (unseen in the fold) sets, respectively.
The experimental evaluations of SVM, k-NN, and CRC are
performed using MATLAB version 2019a, running on PC with
Intel® i7-8650U CPU and 32 GB system memory. On the
other hand, MLP and CSEN methods are implemented using
Tensorflow library [52] with Python on NVidia® TITAN-X
GPU card. For the CSEN training, ADAM optimizer [51] is
used with the proposed default learning parameters: learning
rate, α = 10−3, and moment updates β1 = 0.9, β2 = 0.999
with only 15 back-propagation epochs. Neither grid-search
nor any other parameter or configuration optimization was
performed for CSEN.
B. Experimental Results
The same network configurations are used for CSEN as
in [9]. Accordingly, we use two compact CSEN designs:
CSEN1 and CSEN2, respectively. The first CSEN network
consists of only two hidden convolutional layers, the first
layer has 48 neurons and the second has 24. ReLu activation
function is used in the hidden layers and the filter size was
3×3. On the other hand, CSEN2 uses max-pooling and has one
additional hidden layer with 24 neurons to perform transposedconvolution. CSEN1 and CSEN2 are compared against the 6
competing methods under the same experimental setup.
For the dictionary construction in  each CSEN design, 625
images for each class (from the augmented training samples
per fold) are stacked in such way that the representation coefficient in the 2-D plane, X has 50 ×50 size as shown in Fig. 5.
The rest of the images in the training set are used to train
each CSEN, i.e., 1583 samples from each class. We use PCA
dimensional reduction matrix, A with the compression ratio,
CR = (m/d) = 0.5. Therefore, we have 512×2500 equivalentYAMAÇ et al.: CONVOLUTIONAL SPARSE SUPPORT ESTIMATOR-BASED COVID-19 RECOGNITION 1817
TABLE III
NUMBER OF NETWORK PARAMETERS OF EACH METHOD
dictionary, D, and 2500×512 denoiser B = 
DT D + λI
−1
DT
to obtain a coarse estimation of the representation (sparse in
the ideal case) coefficients, x˜ ∈ Rn=2500. Hereafter, the CSEN
networks are trained to obtain the class information of y from
input x˜ as illustrated in Fig. 3.
Due to the lack of other learning-based SE studies in the
literature, we chose a deeper network compared to CSEN
designs to investigate the role of network depth in this
problem. ReconNet [53] was proposed as a noniterative deep
learning solution to CS problem, i.e., sˆ ← P(y) and it is one of
the state of the art in compressively sensed image recognition
task. It consists of six fully convolutional layers and one dense
layer in front of the convolutional ones, which act as the
learned denoiser for the mapping from y ∈ Rm to s˜ ∈ Rd .
Then, the convolutional layers are responsible for producing
the reconstructed signal, sˆ from s˜. Therefore, by replacing this
dense layer with the denoiser matrix B, this network can be
used as a competing method.
Both CSEN and the modified ReconNet use x˜ as an input,
which is produced using an equivalent dictionary D and its
pseudo-inverse matrix B.
In designing the dictionary of the CRC system, all training
samples are stacked in the dictionary, , i.e., 2208 samples
from each class. The same PCA matrix used in CSEN-based
recognition, A is applied to features, s ∈ Rd=1024. Therefore,
a dictionary D of size 512 × 8832 and the corresponding
denoiser matrix B of size 8832 × 512 are used in the CRC
framework.
Overall, the confusion matrix elements are formed as follows: true positive (TP): the number of correctly detected
positive class members, true negative (TN): the number of correctly detected negative class samples, false positive (FP): the
number of misclassified negative class members as positive,
and FN: the number of misclassified positive class samples
as negative (i.e., missed positive cases). Then, the standard
performance evaluation metrics are defined as follows:
Sensitivity = TP
TP + FN (9)
where sensitivity (or Recall) is the rate of correctly detected
positive samples in the positive class
Specificity = TN
TN + FP (10)
where specificity is the ratio of accurately detected negative
class samples to all negative class
Precision = TP
TP + FP (11)
where precision is the rate of correctly classified positive class
samples among all the members classified as a positive sample
Accuracy = TP + TN
TN + TP + FP + FN (12)
TABLE IV
COMPUTATION TIMES (SEC) OF EACH METHOD OVER 1257 TEST IMAGES
TABLE V
OVERALL (CUMULATIVE) CONFUSION MATRIX OF THE
PROPOSED RECOGNITION SCHEME
where accuracy is the ratio of correctly classified elements
among all the data
F(β) = 
1 + β2 (Precision + Sensitivity)

β2 ∗ Precision
+ Sensitivity (13)
where F-score is defined by the weighting parameter β. The
F1-score is calculated with β = 1, which is the harmonic
average of precision and sensitivity.
The classification performance of the proposed CSEN-based
approach and the competing methods is presented in Table I.
As can be easily observed from Table I, the proposed
approaches surpass all competing methods in COVID19 recognition performance by achieving 98.5% sensitivity,
and over 95% specificity. As shown in Table III, compared
to MLP and ReconNet, the proposed CSEN designs are
very compact and computationally efficient. This is evident
in Table IV where the computational complexity (measured as
total computation, time over the 1257 test images) is reported.
Finally, Table V presents the overall (cumulative) confusion
matrix of the proposed CSEN-based COVID-19 recognition
approach over the new QaTa-Cov19 data set. The most critical
misclassifications are the false-positives, i.e., the misclassified
COVID-19 X-ray images. The confusion matrix shows that the
proposed approach has misclassified seven COVID-19 images
(out of 462). The 3 out of 7 misclassifications are still in “viral
pneumonia” category, which can be an expected confusion
due to the viral nature of COVID-19. However, the other four
cases are misclassified as “Normal” which is indeed a severe
clinical misdiagnosis. A close look at these false-negatives
in Fig. 9 reveals the fact that they are indeed very similar to
normal images where typical COVID-19 patterns are hardly
visible even by an expert’s naked eye. It is possible that these
images come from patients who were in the very early stages
of COVID-19.
VI. DISCUSSION
A. CRC Versus CSEN
When compared against CRC in particular, CSEN-based
classification has two advantages; computational efficiency
and, a superior COVID-19 recognition performance. The
computational efficiency comes from the fact that a larger
size dictionary matrix (of the size of 512 × 8832) is used1818 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 5, MAY 2021
Fig. 9. FNs of the proposed COVID-19 recognition scheme.
TABLE VI
PERFORMANCE OF CRC ALGORITHM WHEN THE DICTIONARY (SIZE
OF 625 PER CLASS) THAT IS USED IN CSEN IS USED
in CRC and hence, this requires more computations in
terms of matrix-vector multiplications. Furthermore, saving
the trainable parameters (∼16k) and a light dictionary matrix
coefficients (∼1280k) in the test device is more memory
efficient compared to saving coefficients (∼4521k) of larger
size dictionary used in CRC.
For further analysis, we also tested the CRC framework
by using the light dictionary (of size 512 × 2500) used in
CSEN-based recognition. We called it CRC (light), and as
it can be seen in Table VI, the performance of CRC further
reduced, and there was no significant improvement concerning
the computational cost. When it comes to creating deeper
convolutional layers instead of using CSEN designs, such
as the modified ReconNet, the results presented in Table I
shows us that compact CSEN structures are indeed preferable
to achieve superior classification performances compared to
deeper networks.
B. Compact Versus Deep CSENs
Representation-based classifications are known for providing satisfactory performance when it comes to limited size data
sets. On the other hand, deep artificial NNs usually require
a large training set to achieve a satisfactory generalization
capability.
In a representation-based (dictionary) classification scheme
when the dictionary size getting bigger (increase the number of
training samples), the computational complexity of the method
drastically increases. The proposed CSEN is an alternative
approach to handle both moderate and scarce data sets via
compact as possible NN structures for the dictionary-based
classification.
Since there is no other learning-based SE method except
CSEN in the literature, we chose ReconNet as a possible
competing algorithm for this problem as explained in detail
in Section V. ReconNet has six fully convolution layers.
As an ablation study, we also add more hidden layers to
proposed CSEN models to compare: CSEN3 and CSEN4 models were obtained by adding one and two hidden layers to
CSEN2, respectively, after the transposed convolutional layer.
TABLE VII
PERFORMANCE OF ALTERNATIVE DEEPER DESIGNS COMPARED
TO COMPACT CSENS
TABLE VIII
NUMBER OF NETWORK PARAMETERS OF COMPETING SE NETWORKS
Additional layers have 24 neurons, ReLu activation functions
and filter size 3 × 3. As we can observe from Tables VII
and VIII, the proposed compact designs, CSEN1 and CSEN2,
both surpass deeper counterparts both in performance and the
required number of parameters.
VII. CONCLUSION
The commonly used methods in COVID-19 diagnosis,
namely RT-PCR and CT have certain limitations and drawbacks such as long processing times and unacceptably high
misdiagnosis rates. These drawbacks are also shared by most
of the recent works in the literature based on deep learning
due to data scarcity from the COVID-19 cases. Although deep
learning-based recognition techniques are dominant in computer vision where they achieved state-of-the-art performance,
their performance degrades fast due to data scarcity, which is
the reality in this problem at hand. This study aims to address
such limitations by proposing a robust and highly accurate
COVID-19 recognition approach directly from X-ray images.
The proposed approach is based on the CSEN that can be seen
as a bridge between deep learning models and representationbased methods. CSEN uses both a dictionary and a set of
training samples to learn a direct mapping from the query
samples to the sparse support set of representation coefficients.
With this unique ability and having the advantage of a compact
network, the proposed CSEN-based COVID-19 recognition
systems surpass the competing methods and achieve over 98%
sensitivity and over 95% specificity. Furthermore, they yield
the most computationally efficient scheme in terms of speed
and memory.
ACKNOWLEDGMENT
The authors would like to thank the following medical
doctor team for their generous feedbacks and continuousYAMAÇ et al.: CONVOLUTIONAL SPARSE SUPPORT ESTIMATOR-BASED COVID-19 RECOGNITION 1819
proof reading: Khalid Hameed is a MD in Reem Medical
Center, Doha, Qatar. Tahir Hamid is consultant cardiologist in
Hamad Medical Corporation Hospital and with Weill Cornell
Medicine-Qatar, Doha. Rashid Mazhar is a MD in Hamad
Medical Corporation Hospital, Doha, Qatar.








